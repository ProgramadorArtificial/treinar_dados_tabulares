{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ff24d5-84fb-4a0f-8ff1-7a2797582079",
   "metadata": {},
   "source": [
    "# Criador de dataset tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71db96a-1b1a-4bd5-a538-1f7059f3c182",
   "metadata": {},
   "source": [
    "## Criar dataset complexo (regressor e classificador)\n",
    "Cria um dataset com 8 entrada (features), sendo utilizado 6 deles para criar a saída (target) como regressor utilizando um cálculo complexo. Com o resultado da regressão é criado outro dataset com os mesmos valores de entrada, mas em formato categórico (target).\n",
    "\n",
    "A saída é previsível (não contem ruído)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c537fa6-152d-47ba-8908-efb1e8dfb7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Regression #####\n",
      "      feature_1 feature_2   feature_3   feature_4  feature_5  feature_6  \\\n",
      "0     16.647436         E  183.980936   24.617366   5.717618  -0.631023   \n",
      "1     10.604436         A   85.459194  307.449148   6.655153   0.767629   \n",
      "2     77.388714         E   40.558116  155.780617   6.921389   0.015533   \n",
      "3     90.406079         A   15.880388   33.010214   6.250944  -1.473239   \n",
      "4     87.356717         E  170.070489  178.530697   6.204453   1.044204   \n",
      "...         ...       ...         ...         ...        ...        ...   \n",
      "1995  52.551128         B   12.801325  246.448995   5.907150   0.017774   \n",
      "1996  59.145417         D  156.294131  216.923304   5.872186   0.194822   \n",
      "1997  22.532483         B  115.050490  217.424978   6.890049   0.120550   \n",
      "1998  18.649490         F   38.755850  314.397756   6.590435  -0.790071   \n",
      "1999  84.994711         E   82.194049  242.364786   6.448571   1.690049   \n",
      "\n",
      "      feature_7  feature_8    target  \n",
      "0          1.20   0.866846  0.084420  \n",
      "1          1.10   0.977042  3.017718  \n",
      "2          1.20   0.803368  0.227664  \n",
      "3          1.10   0.964277  3.053986  \n",
      "4          1.20   0.052600  3.184864  \n",
      "...         ...        ...       ...  \n",
      "1995       0.90   0.771878 -1.185614  \n",
      "1996       0.95   0.143240  0.734101  \n",
      "1997       0.90   0.550371 -0.678976  \n",
      "1998       0.85   1.441102  9.878362  \n",
      "1999       1.20   0.566841  2.101166  \n",
      "\n",
      "[2000 rows x 9 columns]\n",
      "\n",
      "\n",
      "##### Classification #####\n",
      "      feature_1 feature_2   feature_3   feature_4  feature_5  feature_6  \\\n",
      "0     16.647436         E  183.980936   24.617366   5.717618  -0.631023   \n",
      "1     10.604436         A   85.459194  307.449148   6.655153   0.767629   \n",
      "2     77.388714         E   40.558116  155.780617   6.921389   0.015533   \n",
      "3     90.406079         A   15.880388   33.010214   6.250944  -1.473239   \n",
      "4     87.356717         E  170.070489  178.530697   6.204453   1.044204   \n",
      "...         ...       ...         ...         ...        ...        ...   \n",
      "1995  52.551128         B   12.801325  246.448995   5.907150   0.017774   \n",
      "1996  59.145417         D  156.294131  216.923304   5.872186   0.194822   \n",
      "1997  22.532483         B  115.050490  217.424978   6.890049   0.120550   \n",
      "1998  18.649490         F   38.755850  314.397756   6.590435  -0.790071   \n",
      "1999  84.994711         E   82.194049  242.364786   6.448571   1.690049   \n",
      "\n",
      "      feature_7  feature_8  target  \n",
      "0          1.20   0.866846  type_3  \n",
      "1          1.10   0.977042  type_4  \n",
      "2          1.20   0.803368  type_3  \n",
      "3          1.10   0.964277  type_4  \n",
      "4          1.20   0.052600  type_4  \n",
      "...         ...        ...     ...  \n",
      "1995       0.90   0.771878  type_2  \n",
      "1996       0.95   0.143240  type_3  \n",
      "1997       0.90   0.550371  type_2  \n",
      "1998       0.85   1.441102  type_5  \n",
      "1999       1.20   0.566841  type_4  \n",
      "\n",
      "[2000 rows x 9 columns]\n",
      "\n",
      "Thresholds: [-2.95240243 -0.58038554  1.53311903  4.04514732 16.75651944]\n",
      "\n",
      "target\n",
      "type_3    400\n",
      "type_4    400\n",
      "type_1    400\n",
      "type_2    400\n",
      "type_5    399\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Number of rows\n",
    "n_rows = 2000\n",
    "\n",
    "feature_1 = np.random.uniform(1, 100, n_rows) + np.random.normal(0, 5, n_rows)\n",
    "\n",
    "feature_2 = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F'], size=n_rows)\n",
    "category_factors = {'A': 1.1, 'B': 0.9, 'C': 1.05, 'D': 0.95, 'E': 1.2, 'F': 0.85}\n",
    "\n",
    "feature_3 = (\n",
    "    np.random.uniform(10, 200, n_rows) +\n",
    "    np.sin(np.random.uniform(0, 2 * np.pi, n_rows)) +\n",
    "    np.log1p(np.random.uniform(1, 50, n_rows))\n",
    ")\n",
    "\n",
    "feature_4 = (\n",
    "    (np.random.uniform(5, 50, n_rows) ** 1.5) +\n",
    "    np.sqrt(np.random.uniform(1, 20, n_rows))\n",
    ")\n",
    "\n",
    "feature_5 = (\n",
    "    np.log1p(np.random.uniform(10, 1000, n_rows)) +\n",
    "    np.exp(-np.random.uniform(0, 10, n_rows))\n",
    ")\n",
    "\n",
    "feature_6 = (\n",
    "    np.sin(np.random.uniform(0, 2 * np.pi, n_rows)) +\n",
    "    np.cos(np.random.uniform(0, 2 * np.pi, n_rows))\n",
    ")\n",
    "\n",
    "feature_7 = np.vectorize(category_factors.get)(feature_2)\n",
    "\n",
    "feature_8 = (\n",
    "    np.exp(-np.random.uniform(0, 50, n_rows)) +\n",
    "    np.sin(np.random.uniform(0, np.pi / 2, n_rows))\n",
    ")\n",
    "\n",
    "\n",
    "# Normalization of features to similar scales\n",
    "features = [feature_1, feature_3, feature_4, feature_5, feature_6, feature_8]\n",
    "features_normalized = [(f - np.mean(f)) / (np.std(f) + 1e-8) for f in features]\n",
    "\n",
    "feature_1_norm, feature_3_norm, feature_4_norm, feature_5_norm, feature_6_norm, feature_8_norm = features_normalized\n",
    "\n",
    "# ### Regression\n",
    "target_reg = (\n",
    "    # Combinação linear inicial balanceada\n",
    "    (1.55 * feature_1_norm + \n",
    "     0.95 * feature_3_norm + \n",
    "     1.80 * feature_4_norm + \n",
    "     0.4 * feature_5_norm + \n",
    "     0.15 * feature_6_norm + \n",
    "     2.10 * feature_8_norm)\n",
    "    \n",
    "    + (np.sin(feature_1_norm * feature_3_norm) * \n",
    "       np.log1p(np.abs(feature_4_norm - feature_6_norm)))\n",
    "    \n",
    "    + (np.exp(-np.abs(feature_5_norm - feature_8_norm)) *\n",
    "       (feature_3_norm ** 2))\n",
    "    \n",
    "    + (np.cos(feature_4_norm * feature_6_norm) *\n",
    "       np.sqrt(np.abs(feature_1_norm - feature_8_norm)))\n",
    "    \n",
    "    + ((feature_3_norm ** 3) - (feature_5_norm ** 2)) *\n",
    "      (np.sin(feature_6_norm) + np.cos(feature_8_norm))\n",
    "    \n",
    "    * np.vectorize(category_factors.get)(feature_2)\n",
    ")\n",
    "\n",
    "# ### Classification\n",
    "# Categories based on thresholds\n",
    "thresholds = np.percentile(target_reg, [20, 40, 60, 80, 100])\n",
    "clss = ['type_1', 'type_2', 'type_3', 'type_4', 'type_5'] \n",
    "\n",
    "def assign_category(score):\n",
    "    for cl, threshold in zip(clss, thresholds):\n",
    "        if score < threshold:\n",
    "            return cl\n",
    "target_cat = np.array([assign_category(score) for score in target_reg])\n",
    "\n",
    "\n",
    "df_reg = pd.DataFrame({\n",
    "    'feature_1': feature_1,\n",
    "    'feature_2': feature_2,\n",
    "    'feature_3': feature_3,\n",
    "    'feature_4': feature_4,\n",
    "    'feature_5': feature_5,\n",
    "    'feature_6': feature_6,\n",
    "    'feature_7': feature_7,\n",
    "    'feature_8': feature_8,\n",
    "    'target': target_reg  # regression\n",
    "})\n",
    "\n",
    "df_cat = pd.DataFrame({\n",
    "    'feature_1': feature_1,\n",
    "    'feature_2': feature_2,\n",
    "    'feature_3': feature_3,\n",
    "    'feature_4': feature_4,\n",
    "    'feature_5': feature_5,\n",
    "    'feature_6': feature_6,\n",
    "    'feature_7': feature_7,\n",
    "    'feature_8': feature_8,\n",
    "    'target': target_cat,  # classification\n",
    "})\n",
    "\n",
    "print('##### Regression #####')\n",
    "print(df_reg)\n",
    "print('\\n\\n##### Classification #####')\n",
    "print(df_cat)\n",
    "print(f'\\nThresholds: {thresholds}\\n')\n",
    "print(df_cat['target'].value_counts())\n",
    "\n",
    "# Save as CSV\n",
    "df_reg.to_csv('dataset/dados_ficticios_reg.csv', index=False)\n",
    "df_cat.to_csv('dataset/dados_ficticios_cat.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffdc867-abdb-4d47-b53d-4155a97cc933",
   "metadata": {},
   "source": [
    "## Criar dataset E=mc²\n",
    "Cria um dataset contendo a massa como entrada (features) e a energia como saída (target).\n",
    "\n",
    "A saída é previsível (não contem ruído)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "470c7551-7970-4d34-9664-5b30ee03d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       massa        target\n",
      "0  59.290703  5.336163e+06\n",
      "1  74.847717  6.736295e+06\n",
      "2  74.895715  6.740614e+06\n",
      "3  11.491273  1.034215e+06\n",
      "4  41.090341  3.698131e+06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Number of rows\n",
    "n_rows = 1000\n",
    "\n",
    "# Constant c^2 (light speed) (c)\n",
    "c_squared = 9e16\n",
    "\n",
    "# Randomly generated mass (m)\n",
    "mass = np.random.uniform(0.1, 100, n_rows)\n",
    "\n",
    "# Energy in joules: Calculated by the formula E = mc^2 (E)\n",
    "energy_joules = mass * c_squared\n",
    "\n",
    "# Convert energy to terajoules (1 TJ = 10^12 J)\n",
    "energy_terajoules = energy_joules / 1e12\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'massa': mass,\n",
    "    'target': energy_terajoules\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv('dataset/dataset_e_mc2_in_terajoules.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3fe82-b03c-4943-8847-362ea4519ed2",
   "metadata": {},
   "source": [
    "## Criar dataset climático temporal (regressão)\n",
    "Cria valores randomico e após utiliza alguns dias para calcular um valor target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a8bffe-d184-4065-9e6f-edf4bf8d2082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  temperature  atmospheric_pressure   humidity  wind_speed  \\\n",
      "0 2025-01-03    21.945101            985.302886  79.747740    3.849785   \n",
      "1 2025-01-04    24.256379            992.558017  70.013222    3.537094   \n",
      "2 2025-01-05    25.437674           1002.415965  85.906186   16.613512   \n",
      "3 2025-01-06    26.343396            980.012419  73.849816   12.854979   \n",
      "4 2025-01-07    15.172844            998.832892  82.972967   15.764626   \n",
      "\n",
      "      target  \n",
      "0  11.598255  \n",
      "1  11.729554  \n",
      "2  10.067073  \n",
      "3  11.774130  \n",
      "4   7.019475  \n",
      "\n",
      "Correlation:\n",
      "date                    0.008596\n",
      "temperature             0.656812\n",
      "atmospheric_pressure   -0.092622\n",
      "humidity               -0.342406\n",
      "wind_speed             -0.050533\n",
      "target                  1.000000\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Number of rows\n",
    "n_rows = 1000\n",
    "\n",
    "# Generate sequential date\n",
    "initial_data = datetime(2025, 1, 1)\n",
    "dates = [initial_data + timedelta(days=i) for i in range(n_rows)]\n",
    "\n",
    "# Generate features that will bee important for the target\n",
    "temperature = np.random.uniform(10, 30, n_rows)\n",
    "atmospheric_pressure = np.random.uniform(980, 1030, n_rows)\n",
    "humidity = np.random.uniform(30, 90, n_rows)\n",
    "wind_speed = np.random.uniform(0, 20, n_rows)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'temperature': temperature,\n",
    "    'atmospheric_pressure': atmospheric_pressure,\n",
    "    'humidity': humidity,\n",
    "    'wind_speed': wind_speed\n",
    "})\n",
    "\n",
    "# Calculate target\n",
    "def calculate_target(df, idx):\n",
    "    if idx < 2:\n",
    "        return np.nan  # Ignore the first two days because they don't have historical data\n",
    "    \n",
    "    features = {}\n",
    "    for day in range(3):\n",
    "        row = df.iloc[idx - day]\n",
    "        features[f'd{day}'] = {\n",
    "            'temperature': row['temperature'],\n",
    "            'atmospheric_pressure': row['atmospheric_pressure'],\n",
    "            'humidity': row['humidity'],\n",
    "            'wind_speed': row['wind_speed']\n",
    "        }\n",
    "    \n",
    "    # Calculate the target using data from the past three days\n",
    "    target = (\n",
    "        # Temperature\n",
    "        0.4 * features['d0']['temperature'] + \n",
    "        0.3 * features['d1']['temperature'] + \n",
    "        0.2 * features['d2']['temperature'] +\n",
    "        # Atmospheric pressure\n",
    "        -0.03 * (features['d0']['atmospheric_pressure'] - 1013) +\n",
    "        -0.02 * (features['d1']['atmospheric_pressure'] - 1013) +\n",
    "        -0.01 * (features['d2']['atmospheric_pressure'] - 1013) +\n",
    "        # Humidity\n",
    "        -0.08 * features['d0']['humidity'] +\n",
    "        -0.05 * features['d1']['humidity'] +\n",
    "        -0.02 * features['d2']['humidity'] +\n",
    "        # Wind speed\n",
    "        -0.04 * features['d0']['wind_speed'] +\n",
    "        -0.03 * features['d1']['wind_speed'] +\n",
    "        -0.01 * features['d2']['wind_speed']# +\n",
    "        # Small random values\n",
    "        # np.random.normal(0, 0.2)\n",
    "    )\n",
    "\n",
    "    #return np.clip(target, 5, 35)  # Clip temperature between 5°C e 35°C\n",
    "    return target\n",
    "\n",
    "# Calculate the target for each line\n",
    "df['target'] = [calculate_target(df, i) for i in range(len(df))]\n",
    "\n",
    "# Remove the first two lines without target\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n",
    "print(\"\\nCorrelation:\")\n",
    "print(df[['date', 'temperature', 'atmospheric_pressure', 'humidity', 'wind_speed', 'target']].corr()['target'])\n",
    "df.to_csv('dataset/time_series_temperature.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
