{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ff24d5-84fb-4a0f-8ff1-7a2797582079",
   "metadata": {},
   "source": [
    "# Criador de dataset tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71db96a-1b1a-4bd5-a538-1f7059f3c182",
   "metadata": {},
   "source": [
    "## Criar dataset complexo (regressor e classificador)\n",
    "Cria um dataset com 8 entrada (features), sendo utilizado 6 deles para criar a saída (target) como regressor utilizando um cálculo complexo. Com o resultado da regressão é criado outro dataset com os mesmos valores de entrada, mas em formato categórico (target).\n",
    "\n",
    "A saída é previsível (não contem ruído)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c537fa6-152d-47ba-8908-efb1e8dfb7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Regression #####\n",
      "      feature_1 feature_2   feature_3   feature_4  feature_5  feature_6  \\\n",
      "0     16.647436         E  183.980936   24.617366   5.717618  -0.631023   \n",
      "1     10.604436         A   85.459194  307.449148   6.655153   0.767629   \n",
      "2     77.388714         E   40.558116  155.780617   6.921389   0.015533   \n",
      "3     90.406079         A   15.880388   33.010214   6.250944  -1.473239   \n",
      "4     87.356717         E  170.070489  178.530697   6.204453   1.044204   \n",
      "...         ...       ...         ...         ...        ...        ...   \n",
      "1995  52.551128         B   12.801325  246.448995   5.907150   0.017774   \n",
      "1996  59.145417         D  156.294131  216.923304   5.872186   0.194822   \n",
      "1997  22.532483         B  115.050490  217.424978   6.890049   0.120550   \n",
      "1998  18.649490         F   38.755850  314.397756   6.590435  -0.790071   \n",
      "1999  84.994711         E   82.194049  242.364786   6.448571   1.690049   \n",
      "\n",
      "      feature_7  feature_8    target  \n",
      "0          1.20   0.866846  0.084420  \n",
      "1          1.10   0.977042  3.017718  \n",
      "2          1.20   0.803368  0.227664  \n",
      "3          1.10   0.964277  3.053986  \n",
      "4          1.20   0.052600  3.184864  \n",
      "...         ...        ...       ...  \n",
      "1995       0.90   0.771878 -1.185614  \n",
      "1996       0.95   0.143240  0.734101  \n",
      "1997       0.90   0.550371 -0.678976  \n",
      "1998       0.85   1.441102  9.878362  \n",
      "1999       1.20   0.566841  2.101166  \n",
      "\n",
      "[2000 rows x 9 columns]\n",
      "\n",
      "\n",
      "##### Classification #####\n",
      "      feature_1 feature_2   feature_3   feature_4  feature_5  feature_6  \\\n",
      "0     16.647436         E  183.980936   24.617366   5.717618  -0.631023   \n",
      "1     10.604436         A   85.459194  307.449148   6.655153   0.767629   \n",
      "2     77.388714         E   40.558116  155.780617   6.921389   0.015533   \n",
      "3     90.406079         A   15.880388   33.010214   6.250944  -1.473239   \n",
      "4     87.356717         E  170.070489  178.530697   6.204453   1.044204   \n",
      "...         ...       ...         ...         ...        ...        ...   \n",
      "1995  52.551128         B   12.801325  246.448995   5.907150   0.017774   \n",
      "1996  59.145417         D  156.294131  216.923304   5.872186   0.194822   \n",
      "1997  22.532483         B  115.050490  217.424978   6.890049   0.120550   \n",
      "1998  18.649490         F   38.755850  314.397756   6.590435  -0.790071   \n",
      "1999  84.994711         E   82.194049  242.364786   6.448571   1.690049   \n",
      "\n",
      "      feature_7  feature_8  target  \n",
      "0          1.20   0.866846  type_3  \n",
      "1          1.10   0.977042  type_4  \n",
      "2          1.20   0.803368  type_3  \n",
      "3          1.10   0.964277  type_4  \n",
      "4          1.20   0.052600  type_4  \n",
      "...         ...        ...     ...  \n",
      "1995       0.90   0.771878  type_2  \n",
      "1996       0.95   0.143240  type_3  \n",
      "1997       0.90   0.550371  type_2  \n",
      "1998       0.85   1.441102  type_5  \n",
      "1999       1.20   0.566841  type_4  \n",
      "\n",
      "[2000 rows x 9 columns]\n",
      "\n",
      "Thresholds: [-2.95240243 -0.58038554  1.53311903  4.04514732 16.75651944]\n",
      "\n",
      "target\n",
      "type_3    400\n",
      "type_4    400\n",
      "type_1    400\n",
      "type_2    400\n",
      "type_5    399\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Number of rows\n",
    "n_rows = 2000\n",
    "\n",
    "feature_1 = np.random.uniform(1, 100, n_rows) + np.random.normal(0, 5, n_rows)\n",
    "\n",
    "feature_2 = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F'], size=n_rows)\n",
    "category_factors = {'A': 1.1, 'B': 0.9, 'C': 1.05, 'D': 0.95, 'E': 1.2, 'F': 0.85}\n",
    "\n",
    "feature_3 = (\n",
    "    np.random.uniform(10, 200, n_rows) +\n",
    "    np.sin(np.random.uniform(0, 2 * np.pi, n_rows)) +\n",
    "    np.log1p(np.random.uniform(1, 50, n_rows))\n",
    ")\n",
    "\n",
    "feature_4 = (\n",
    "    (np.random.uniform(5, 50, n_rows) ** 1.5) +\n",
    "    np.sqrt(np.random.uniform(1, 20, n_rows))\n",
    ")\n",
    "\n",
    "feature_5 = (\n",
    "    np.log1p(np.random.uniform(10, 1000, n_rows)) +\n",
    "    np.exp(-np.random.uniform(0, 10, n_rows))\n",
    ")\n",
    "\n",
    "feature_6 = (\n",
    "    np.sin(np.random.uniform(0, 2 * np.pi, n_rows)) +\n",
    "    np.cos(np.random.uniform(0, 2 * np.pi, n_rows))\n",
    ")\n",
    "\n",
    "feature_7 = np.vectorize(category_factors.get)(feature_2)\n",
    "\n",
    "feature_8 = (\n",
    "    np.exp(-np.random.uniform(0, 50, n_rows)) +\n",
    "    np.sin(np.random.uniform(0, np.pi / 2, n_rows))\n",
    ")\n",
    "\n",
    "\n",
    "# Normalization of features to similar scales\n",
    "features = [feature_1, feature_3, feature_4, feature_5, feature_6, feature_8]\n",
    "features_normalized = [(f - np.mean(f)) / (np.std(f) + 1e-8) for f in features]\n",
    "\n",
    "feature_1_norm, feature_3_norm, feature_4_norm, feature_5_norm, feature_6_norm, feature_8_norm = features_normalized\n",
    "\n",
    "# ### Regression\n",
    "target_reg = (\n",
    "    # Combinação linear inicial balanceada\n",
    "    (1.55 * feature_1_norm + \n",
    "     0.95 * feature_3_norm + \n",
    "     1.80 * feature_4_norm + \n",
    "     0.4 * feature_5_norm + \n",
    "     0.15 * feature_6_norm + \n",
    "     2.10 * feature_8_norm)\n",
    "    \n",
    "    + (np.sin(feature_1_norm * feature_3_norm) * \n",
    "       np.log1p(np.abs(feature_4_norm - feature_6_norm)))\n",
    "    \n",
    "    + (np.exp(-np.abs(feature_5_norm - feature_8_norm)) *\n",
    "       (feature_3_norm ** 2))\n",
    "    \n",
    "    + (np.cos(feature_4_norm * feature_6_norm) *\n",
    "       np.sqrt(np.abs(feature_1_norm - feature_8_norm)))\n",
    "    \n",
    "    + ((feature_3_norm ** 3) - (feature_5_norm ** 2)) *\n",
    "      (np.sin(feature_6_norm) + np.cos(feature_8_norm))\n",
    "    \n",
    "    * np.vectorize(category_factors.get)(feature_2)\n",
    ")\n",
    "\n",
    "# ### Classification\n",
    "# Categories based on thresholds\n",
    "thresholds = np.percentile(target_reg, [20, 40, 60, 80, 100])\n",
    "clss = ['type_1', 'type_2', 'type_3', 'type_4', 'type_5'] \n",
    "\n",
    "def assign_category(score):\n",
    "    for cl, threshold in zip(clss, thresholds):\n",
    "        if score < threshold:\n",
    "            return cl\n",
    "target_cat = np.array([assign_category(score) for score in target_reg])\n",
    "\n",
    "\n",
    "df_reg = pd.DataFrame({\n",
    "    'feature_1': feature_1,\n",
    "    'feature_2': feature_2,\n",
    "    'feature_3': feature_3,\n",
    "    'feature_4': feature_4,\n",
    "    'feature_5': feature_5,\n",
    "    'feature_6': feature_6,\n",
    "    'feature_7': feature_7,\n",
    "    'feature_8': feature_8,\n",
    "    'target': target_reg  # regression\n",
    "})\n",
    "\n",
    "df_cat = pd.DataFrame({\n",
    "    'feature_1': feature_1,\n",
    "    'feature_2': feature_2,\n",
    "    'feature_3': feature_3,\n",
    "    'feature_4': feature_4,\n",
    "    'feature_5': feature_5,\n",
    "    'feature_6': feature_6,\n",
    "    'feature_7': feature_7,\n",
    "    'feature_8': feature_8,\n",
    "    'target': target_cat,  # classification\n",
    "})\n",
    "\n",
    "print('##### Regression #####')\n",
    "print(df_reg)\n",
    "print('\\n\\n##### Classification #####')\n",
    "print(df_cat)\n",
    "print(f'\\nThresholds: {thresholds}\\n')\n",
    "print(df_cat['target'].value_counts())\n",
    "\n",
    "# Save as CSV\n",
    "df_reg.to_csv('dataset/dados_ficticios_reg.csv', index=False)\n",
    "df_cat.to_csv('dataset/dados_ficticios_cat.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffdc867-abdb-4d47-b53d-4155a97cc933",
   "metadata": {},
   "source": [
    "## Criar dataset E=mc²\n",
    "Cria um dataset contendo a massa como entrada (features) e a energia como saída (target).\n",
    "\n",
    "A saída é previsível (não contem ruído)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "470c7551-7970-4d34-9664-5b30ee03d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       massa        target\n",
      "0  59.290703  5.336163e+06\n",
      "1  74.847717  6.736295e+06\n",
      "2  74.895715  6.740614e+06\n",
      "3  11.491273  1.034215e+06\n",
      "4  41.090341  3.698131e+06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Number of rows\n",
    "n_rows = 1000\n",
    "\n",
    "# Constant c^2 (light speed) (c)\n",
    "c_squared = 9e16\n",
    "\n",
    "# Randomly generated mass (m)\n",
    "mass = np.random.uniform(0.1, 100, n_rows)\n",
    "\n",
    "# Energy in joules: Calculated by the formula E = mc^2 (E)\n",
    "energy_joules = mass * c_squared\n",
    "\n",
    "# Convert energy to terajoules (1 TJ = 10^12 J)\n",
    "energy_terajoules = energy_joules / 1e12\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'massa': mass,\n",
    "    'target': energy_terajoules\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv('dataset/dataset_e_mc2_in_terajoules.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
