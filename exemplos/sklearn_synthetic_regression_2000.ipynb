{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3489c1bc-d70b-4089-a6fc-9428e959dfc3",
   "metadata": {},
   "source": [
    "# Sklearn\n",
    "Notebook pensando para facilitar e agiliar o treinamento de Machine Learning, sendo necessário, em grande parte das vezes, somente alterar o caminho do dataset e o tipo (classificador ou regressão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7227abb5-2f27-4fc4-be31-afe3a4a093ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0be3e-6a93-41aa-9ec8-0ceb6ffece8c",
   "metadata": {},
   "source": [
    "## Preparar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a81160e-461d-440f-a3ac-7869034ff805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_cols, max_unique_values=10, window_size=1):\n",
    "    \"\"\"\n",
    "    Preprocess dataset, converting string columns to number and identifying numeric, categorical, and date columns.\n",
    "    Adds a window of historical rows to the data.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame with data to analyze.\n",
    "        target_cols (list): All target columns to not add in numeric, categorical, or date feature lists.\n",
    "        max_unique_values (int): Maximum number of unique values to consider a numeric column as categorical.\n",
    "        window_size (int): Number of previous rows to include for each row.\n",
    "\n",
    "    Returns:\n",
    "        df_copy (DataFrame): Processed DataFrame with transformations applied.\n",
    "        num_col_names (list): List of numeric feature column names.\n",
    "        cat_col_names (list): List of categorical feature column names.\n",
    "        date_col_names (list): List of date feature column names.\n",
    "        mappings (dict): Mapping of original categorical values (or target columns) to transformed numeric values.\n",
    "    \"\"\"\n",
    "    # Create a copy so as not to alter the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Remove lines with null values\n",
    "    df_copy = df_copy.dropna()\n",
    "    \n",
    "    # Identify categorical and numeric columns\n",
    "    cat_col_names = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_col_names = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    date_col_names = []\n",
    "\n",
    "    # Identify columns that are dates\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['object', 'string']:  # Only check object/string columns\n",
    "            try:\n",
    "                # Attempt to convert the column to datetime\n",
    "                pd.to_datetime(df[col], errors='raise')\n",
    "                if col not in target_cols:  # Avoid considering target columns as date columns\n",
    "                    date_col_names.append(col)\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "    # Identify numeric columns that are categorical\n",
    "    potential_categorical = []\n",
    "    for col in num_col_names:\n",
    "        if col not in target_cols and df_copy[col].nunique() <= max_unique_values:\n",
    "            potential_categorical.append(col)\n",
    "\n",
    "    cat_col_names += potential_categorical\n",
    "\n",
    "    # Remove target columns from the lists\n",
    "    num_col_names = [col for col in num_col_names if col not in potential_categorical + target_cols]\n",
    "    cat_col_names = [col for col in cat_col_names if col not in target_cols]\n",
    "    \n",
    "    mappings = {}\n",
    "    label_encoders = {}\n",
    "\n",
    "    # Convert string columns to category and create a mapping (old value -> new value)\n",
    "    for col in cat_col_names + target_cols:\n",
    "        if df_copy[col].dtype not in ['int64', 'float64']:\n",
    "            le = LabelEncoder()\n",
    "            df_copy[col] = le.fit_transform(df_copy[col])\n",
    "            mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            label_encoders[col] = le\n",
    "            # Convert values to int (otherwise will raise error if save as json)\n",
    "            for key, value in mappings[col].items():\n",
    "                mappings[col][key] = int(value)\n",
    "        #else:\n",
    "        #    mappings[col] = {int(val): int(val) for val in df_copy[col].unique()}\n",
    "\n",
    "    # Add historical data based on window_size\n",
    "    if window_size > 1:\n",
    "        historical_features = []\n",
    "        for i in range(window_size - 1, 0, -1):  # Criar features lag, do mais antigo ao mais recente\n",
    "            shifted = df_copy.drop(columns=target_cols, errors='ignore').shift(i).add_suffix(f'_lag_{i}')\n",
    "            historical_features.append(shifted)\n",
    "        \n",
    "        # Concatenate the lags to the left and keep the current values\n",
    "        df_copy = pd.concat(historical_features + [df_copy], axis=1)\n",
    "    \n",
    "        # Remove NaNs columns created by shifts\n",
    "        df_copy = df_copy.dropna()\n",
    "    \n",
    "        # Add lags\n",
    "        num_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in num_col_names]\n",
    "        cat_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in cat_col_names]\n",
    "        date_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in date_col_names]\n",
    "        mappings_lags = {}\n",
    "        for col, value in mappings.items():\n",
    "            for i in range(window_size - 1, 0, -1):\n",
    "                mappings_lags[f'{col}_lag_{i}'] = value\n",
    "    \n",
    "        # Update main columns + lags columns\n",
    "        num_col_names = num_col_lags + num_col_names\n",
    "        cat_col_names = cat_col_lags + cat_col_names\n",
    "        date_col_names = date_col_lags + date_col_names\n",
    "        mappings = {**mappings_lags, **mappings}\n",
    "    \n",
    "    return df_copy, num_col_names, cat_col_names, date_col_names, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dda78a0-630b-4947-8e10-a24019cf98d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.647436</td>\n",
       "      <td>E</td>\n",
       "      <td>183.980936</td>\n",
       "      <td>24.617366</td>\n",
       "      <td>5.717618</td>\n",
       "      <td>-0.631023</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.866846</td>\n",
       "      <td>0.084420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.604436</td>\n",
       "      <td>A</td>\n",
       "      <td>85.459194</td>\n",
       "      <td>307.449148</td>\n",
       "      <td>6.655153</td>\n",
       "      <td>0.767629</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.977042</td>\n",
       "      <td>3.017718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.388714</td>\n",
       "      <td>E</td>\n",
       "      <td>40.558116</td>\n",
       "      <td>155.780617</td>\n",
       "      <td>6.921389</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.803368</td>\n",
       "      <td>0.227664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.406079</td>\n",
       "      <td>A</td>\n",
       "      <td>15.880388</td>\n",
       "      <td>33.010214</td>\n",
       "      <td>6.250944</td>\n",
       "      <td>-1.473239</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.964277</td>\n",
       "      <td>3.053986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.356717</td>\n",
       "      <td>E</td>\n",
       "      <td>170.070489</td>\n",
       "      <td>178.530697</td>\n",
       "      <td>6.204453</td>\n",
       "      <td>1.044204</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>3.184864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>52.551128</td>\n",
       "      <td>B</td>\n",
       "      <td>12.801325</td>\n",
       "      <td>246.448995</td>\n",
       "      <td>5.907150</td>\n",
       "      <td>0.017774</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.771878</td>\n",
       "      <td>-1.185614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>59.145417</td>\n",
       "      <td>D</td>\n",
       "      <td>156.294131</td>\n",
       "      <td>216.923304</td>\n",
       "      <td>5.872186</td>\n",
       "      <td>0.194822</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.143240</td>\n",
       "      <td>0.734101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>22.532483</td>\n",
       "      <td>B</td>\n",
       "      <td>115.050490</td>\n",
       "      <td>217.424978</td>\n",
       "      <td>6.890049</td>\n",
       "      <td>0.120550</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.550371</td>\n",
       "      <td>-0.678976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>18.649490</td>\n",
       "      <td>F</td>\n",
       "      <td>38.755850</td>\n",
       "      <td>314.397756</td>\n",
       "      <td>6.590435</td>\n",
       "      <td>-0.790071</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.441102</td>\n",
       "      <td>9.878362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>84.994711</td>\n",
       "      <td>E</td>\n",
       "      <td>82.194049</td>\n",
       "      <td>242.364786</td>\n",
       "      <td>6.448571</td>\n",
       "      <td>1.690049</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.566841</td>\n",
       "      <td>2.101166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_1 feature_2   feature_3   feature_4  feature_5  feature_6  \\\n",
       "0     16.647436         E  183.980936   24.617366   5.717618  -0.631023   \n",
       "1     10.604436         A   85.459194  307.449148   6.655153   0.767629   \n",
       "2     77.388714         E   40.558116  155.780617   6.921389   0.015533   \n",
       "3     90.406079         A   15.880388   33.010214   6.250944  -1.473239   \n",
       "4     87.356717         E  170.070489  178.530697   6.204453   1.044204   \n",
       "...         ...       ...         ...         ...        ...        ...   \n",
       "1995  52.551128         B   12.801325  246.448995   5.907150   0.017774   \n",
       "1996  59.145417         D  156.294131  216.923304   5.872186   0.194822   \n",
       "1997  22.532483         B  115.050490  217.424978   6.890049   0.120550   \n",
       "1998  18.649490         F   38.755850  314.397756   6.590435  -0.790071   \n",
       "1999  84.994711         E   82.194049  242.364786   6.448571   1.690049   \n",
       "\n",
       "      feature_7  feature_8    target  \n",
       "0          1.20   0.866846  0.084420  \n",
       "1          1.10   0.977042  3.017718  \n",
       "2          1.20   0.803368  0.227664  \n",
       "3          1.10   0.964277  3.053986  \n",
       "4          1.20   0.052600  3.184864  \n",
       "...         ...        ...       ...  \n",
       "1995       0.90   0.771878 -1.185614  \n",
       "1996       0.95   0.143240  0.734101  \n",
       "1997       0.90   0.550371 -0.678976  \n",
       "1998       0.85   1.441102  9.878362  \n",
       "1999       1.20   0.566841  2.101166  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/synthetic_dataset_reg_2000.csv')\n",
    "model_type = 'regressor'  # classifier or regressor\n",
    "window_size = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502d6196-e3f8-4683-8d12-73fcf834d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['target']\n",
    "# Aplicar o pré-processamento\n",
    "df, num_col_names, cat_col_names, date_col_names, category_mappings = preprocess_data(df, target_cols, max_unique_values=10, window_size=window_size)\n",
    "col_names_order = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60931f8-4c85-41bc-ad1d-0ac0443fb35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.647436</td>\n",
       "      <td>4</td>\n",
       "      <td>183.980936</td>\n",
       "      <td>24.617366</td>\n",
       "      <td>5.717618</td>\n",
       "      <td>-0.631023</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.866846</td>\n",
       "      <td>0.084420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.604436</td>\n",
       "      <td>0</td>\n",
       "      <td>85.459194</td>\n",
       "      <td>307.449148</td>\n",
       "      <td>6.655153</td>\n",
       "      <td>0.767629</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.977042</td>\n",
       "      <td>3.017718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.388714</td>\n",
       "      <td>4</td>\n",
       "      <td>40.558116</td>\n",
       "      <td>155.780617</td>\n",
       "      <td>6.921389</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.803368</td>\n",
       "      <td>0.227664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.406079</td>\n",
       "      <td>0</td>\n",
       "      <td>15.880388</td>\n",
       "      <td>33.010214</td>\n",
       "      <td>6.250944</td>\n",
       "      <td>-1.473239</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.964277</td>\n",
       "      <td>3.053986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.356717</td>\n",
       "      <td>4</td>\n",
       "      <td>170.070489</td>\n",
       "      <td>178.530697</td>\n",
       "      <td>6.204453</td>\n",
       "      <td>1.044204</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>3.184864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>52.551128</td>\n",
       "      <td>1</td>\n",
       "      <td>12.801325</td>\n",
       "      <td>246.448995</td>\n",
       "      <td>5.907150</td>\n",
       "      <td>0.017774</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.771878</td>\n",
       "      <td>-1.185614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>59.145417</td>\n",
       "      <td>3</td>\n",
       "      <td>156.294131</td>\n",
       "      <td>216.923304</td>\n",
       "      <td>5.872186</td>\n",
       "      <td>0.194822</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.143240</td>\n",
       "      <td>0.734101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>22.532483</td>\n",
       "      <td>1</td>\n",
       "      <td>115.050490</td>\n",
       "      <td>217.424978</td>\n",
       "      <td>6.890049</td>\n",
       "      <td>0.120550</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.550371</td>\n",
       "      <td>-0.678976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>18.649490</td>\n",
       "      <td>5</td>\n",
       "      <td>38.755850</td>\n",
       "      <td>314.397756</td>\n",
       "      <td>6.590435</td>\n",
       "      <td>-0.790071</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.441102</td>\n",
       "      <td>9.878362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>84.994711</td>\n",
       "      <td>4</td>\n",
       "      <td>82.194049</td>\n",
       "      <td>242.364786</td>\n",
       "      <td>6.448571</td>\n",
       "      <td>1.690049</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.566841</td>\n",
       "      <td>2.101166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_1  feature_2   feature_3   feature_4  feature_5  feature_6  \\\n",
       "0     16.647436          4  183.980936   24.617366   5.717618  -0.631023   \n",
       "1     10.604436          0   85.459194  307.449148   6.655153   0.767629   \n",
       "2     77.388714          4   40.558116  155.780617   6.921389   0.015533   \n",
       "3     90.406079          0   15.880388   33.010214   6.250944  -1.473239   \n",
       "4     87.356717          4  170.070489  178.530697   6.204453   1.044204   \n",
       "...         ...        ...         ...         ...        ...        ...   \n",
       "1995  52.551128          1   12.801325  246.448995   5.907150   0.017774   \n",
       "1996  59.145417          3  156.294131  216.923304   5.872186   0.194822   \n",
       "1997  22.532483          1  115.050490  217.424978   6.890049   0.120550   \n",
       "1998  18.649490          5   38.755850  314.397756   6.590435  -0.790071   \n",
       "1999  84.994711          4   82.194049  242.364786   6.448571   1.690049   \n",
       "\n",
       "      feature_7  feature_8    target  \n",
       "0          1.20   0.866846  0.084420  \n",
       "1          1.10   0.977042  3.017718  \n",
       "2          1.20   0.803368  0.227664  \n",
       "3          1.10   0.964277  3.053986  \n",
       "4          1.20   0.052600  3.184864  \n",
       "...         ...        ...       ...  \n",
       "1995       0.90   0.771878 -1.185614  \n",
       "1996       0.95   0.143240  0.734101  \n",
       "1997       0.90   0.550371 -0.678976  \n",
       "1998       0.85   1.441102  9.878362  \n",
       "1999       1.20   0.566841  2.101166  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6911e8e8-d77e-497e-a8bc-134fdcd791fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_names_order: ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'target']\n",
      "num_col_names: ['feature_1', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_8']\n",
      "cat_col_names: ['feature_2', 'feature_7']\n",
      "date_col_names: []\n",
      "target_cols: ['target']\n",
      "category_mappings: {'feature_2': {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}}\n"
     ]
    }
   ],
   "source": [
    "print(f'''col_names_order: {col_names_order}\n",
    "num_col_names: {num_col_names}\n",
    "cat_col_names: {cat_col_names}\n",
    "date_col_names: {date_col_names}\n",
    "target_cols: {target_cols}\n",
    "category_mappings: {category_mappings}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed57e737-f6d9-4fe3-b38c-038d44e280bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature_1  2000 non-null   float64\n",
      " 1   feature_2  2000 non-null   int64  \n",
      " 2   feature_3  2000 non-null   float64\n",
      " 3   feature_4  2000 non-null   float64\n",
      " 4   feature_5  2000 non-null   float64\n",
      " 5   feature_6  2000 non-null   float64\n",
      " 6   feature_7  2000 non-null   float64\n",
      " 7   feature_8  2000 non-null   float64\n",
      " 8   target     2000 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 140.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eacf642-fe7f-465c-8f74-fea497c7453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'classifier':\n",
    "    print(df[target_cols].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fffec-dfee-49f8-815d-3fc5c94a51c1",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8adfa6d0-8dee-468c-8c3b-b00ab8a204a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e972c845-197d-4055-bfb0-641a680b9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[target_cols]\n",
    "x_train = train.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4b2e59-7601-42ad-bf06-f2a4982a7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[target_cols]\n",
    "x_test = test.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee0910a-7f2d-4009-9b66-67bdd31fc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7ec3c7-e375-40d3-8a2c-663157d552e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skelarn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeca4cce-663a-43b1-8539-37ccc4f433ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>67.544623</td>\n",
       "      <td>3</td>\n",
       "      <td>32.522853</td>\n",
       "      <td>235.941887</td>\n",
       "      <td>5.746202</td>\n",
       "      <td>-1.338127</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.932226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>85.042208</td>\n",
       "      <td>0</td>\n",
       "      <td>164.208258</td>\n",
       "      <td>107.601123</td>\n",
       "      <td>5.212654</td>\n",
       "      <td>0.051899</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.954364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>65.780308</td>\n",
       "      <td>2</td>\n",
       "      <td>167.361942</td>\n",
       "      <td>173.341236</td>\n",
       "      <td>2.945498</td>\n",
       "      <td>-1.789363</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.931517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>69.421835</td>\n",
       "      <td>1</td>\n",
       "      <td>72.046314</td>\n",
       "      <td>191.618844</td>\n",
       "      <td>5.790783</td>\n",
       "      <td>-0.640412</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.090948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>79.298105</td>\n",
       "      <td>0</td>\n",
       "      <td>50.033287</td>\n",
       "      <td>212.877431</td>\n",
       "      <td>6.765211</td>\n",
       "      <td>-1.979848</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.986794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>50.241351</td>\n",
       "      <td>1</td>\n",
       "      <td>50.197003</td>\n",
       "      <td>321.201175</td>\n",
       "      <td>6.847595</td>\n",
       "      <td>-0.268847</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.986761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>51.443458</td>\n",
       "      <td>2</td>\n",
       "      <td>61.457905</td>\n",
       "      <td>154.912172</td>\n",
       "      <td>5.287440</td>\n",
       "      <td>1.447192</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.974001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>58.794885</td>\n",
       "      <td>4</td>\n",
       "      <td>93.880053</td>\n",
       "      <td>280.535823</td>\n",
       "      <td>6.611720</td>\n",
       "      <td>-0.451735</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.961178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>94.316044</td>\n",
       "      <td>5</td>\n",
       "      <td>142.481204</td>\n",
       "      <td>53.094994</td>\n",
       "      <td>5.779037</td>\n",
       "      <td>1.436159</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.997631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>81.983137</td>\n",
       "      <td>4</td>\n",
       "      <td>145.528090</td>\n",
       "      <td>174.604989</td>\n",
       "      <td>6.303744</td>\n",
       "      <td>0.276738</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.653955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_1  feature_2   feature_3   feature_4  feature_5  feature_6  \\\n",
       "836   67.544623          3   32.522853  235.941887   5.746202  -1.338127   \n",
       "575   85.042208          0  164.208258  107.601123   5.212654   0.051899   \n",
       "557   65.780308          2  167.361942  173.341236   2.945498  -1.789363   \n",
       "1235  69.421835          1   72.046314  191.618844   5.790783  -0.640412   \n",
       "1360  79.298105          0   50.033287  212.877431   6.765211  -1.979848   \n",
       "...         ...        ...         ...         ...        ...        ...   \n",
       "1130  50.241351          1   50.197003  321.201175   6.847595  -0.268847   \n",
       "1294  51.443458          2   61.457905  154.912172   5.287440   1.447192   \n",
       "860   58.794885          4   93.880053  280.535823   6.611720  -0.451735   \n",
       "1459  94.316044          5  142.481204   53.094994   5.779037   1.436159   \n",
       "1126  81.983137          4  145.528090  174.604989   6.303744   0.276738   \n",
       "\n",
       "      feature_7  feature_8  \n",
       "836        0.95   0.932226  \n",
       "575        1.10   0.954364  \n",
       "557        1.05   0.931517  \n",
       "1235       0.90   0.090948  \n",
       "1360       1.10   0.986794  \n",
       "...         ...        ...  \n",
       "1130       0.90   0.986761  \n",
       "1294       1.05   0.974001  \n",
       "860        1.20   0.961178  \n",
       "1459       0.85   0.997631  \n",
       "1126       1.20   0.653955  \n",
       "\n",
       "[1400 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bddd440-aac8-4616-94fa-22e859de77ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5754406473155761,\n",
       "  3.0,\n",
       "  -1.3256520501304294,\n",
       "  0.7909372788613815,\n",
       "  -0.32536907590359293,\n",
       "  -1.3221477639198636,\n",
       "  0.95,\n",
       "  0.8568696049148864],\n",
       " [1.1709315269160976,\n",
       "  0.0,\n",
       "  1.0366938817993758,\n",
       "  -0.4937393366829178,\n",
       "  -0.9212728255666511,\n",
       "  0.05550620840067808,\n",
       "  1.1,\n",
       "  0.9249967837943772],\n",
       " [0.5153961745308646,\n",
       "  2.0,\n",
       "  1.093268823810139,\n",
       "  0.16431180606889903,\n",
       "  -3.453390774550749,\n",
       "  -1.7693678917937505,\n",
       "  1.05,\n",
       "  0.8546906214874607],\n",
       " [0.6393273335033021,\n",
       "  1.0,\n",
       "  -0.6166282418847506,\n",
       "  0.3472686050934994,\n",
       "  -0.27557729378051066,\n",
       "  -0.6306426870788125,\n",
       "  0.9,\n",
       "  -1.7319680861844189],\n",
       " [0.9754439189389543,\n",
       "  0.0,\n",
       "  -1.0115268571120537,\n",
       "  0.5600646653715994,\n",
       "  0.8127314956351022,\n",
       "  -1.9581575448535626,\n",
       "  1.1,\n",
       "  1.024792029890227],\n",
       " [0.6319277753412749,\n",
       "  1.0,\n",
       "  0.6150475012919152,\n",
       "  0.22091934762142906,\n",
       "  -0.4932730592448747,\n",
       "  1.8803312320403007,\n",
       "  0.9,\n",
       "  -1.9387137362563516],\n",
       " [1.6358080466834828,\n",
       "  2.0,\n",
       "  -0.41942774010435546,\n",
       "  -1.3992299022297776,\n",
       "  0.4034738529782387,\n",
       "  -1.180186323321175,\n",
       "  1.05,\n",
       "  0.8159133612486006],\n",
       " [-0.05649865258667489,\n",
       "  2.0,\n",
       "  0.5018206806179052,\n",
       "  0.9617712887799323,\n",
       "  -0.1567588730770484,\n",
       "  -0.9515907381810822,\n",
       "  1.05,\n",
       "  0.8775934717395947],\n",
       " [1.557651335310645,\n",
       "  2.0,\n",
       "  0.4863363191837259,\n",
       "  -0.6504317112462757,\n",
       "  -0.05404281677081248,\n",
       "  -1.8461998766873722,\n",
       "  1.05,\n",
       "  0.29418570154299506],\n",
       " [-0.5428793642675636,\n",
       "  0.0,\n",
       "  0.7837025579327567,\n",
       "  1.5011854337863568,\n",
       "  0.8432076067903342,\n",
       "  -1.5912509873773821,\n",
       "  1.1,\n",
       "  -1.1258312198799125],\n",
       " [0.07797949329611148,\n",
       "  2.0,\n",
       "  -0.231211793559808,\n",
       "  0.5167305716415485,\n",
       "  -0.28816118210335084,\n",
       "  1.9838380493174586,\n",
       "  1.05,\n",
       "  -1.2317558741289003],\n",
       " [1.6184160730520867,\n",
       "  0.0,\n",
       "  -0.05935153337404986,\n",
       "  -0.6979494207254064,\n",
       "  -1.9651660009822134,\n",
       "  1.1311146306492952,\n",
       "  1.1,\n",
       "  -0.38610148140577416],\n",
       " [-0.5277782931140812,\n",
       "  2.0,\n",
       "  -1.5297047215932922,\n",
       "  -0.41758686128502476,\n",
       "  0.7020289104074949,\n",
       "  0.6850791961224555,\n",
       "  1.05,\n",
       "  0.3306012873387643],\n",
       " [-1.2361125641864692,\n",
       "  1.0,\n",
       "  0.7247397962940653,\n",
       "  1.3906860504065177,\n",
       "  -0.9287354037266683,\n",
       "  0.5581223104927465,\n",
       "  0.9,\n",
       "  0.834305331564951],\n",
       " [-0.905279157540128,\n",
       "  2.0,\n",
       "  -0.4083859809969285,\n",
       "  -0.5051883123566517,\n",
       "  0.5907215903330262,\n",
       "  0.008861938239616549,\n",
       "  1.05,\n",
       "  -1.805517687527714],\n",
       " [0.24265916094539142,\n",
       "  1.0,\n",
       "  -0.03493175428938075,\n",
       "  0.027351644947270923,\n",
       "  -1.0248980225237017,\n",
       "  -1.6871906479053036,\n",
       "  0.9,\n",
       "  -0.09469108144059916],\n",
       " [-1.2891306145329158,\n",
       "  0.0,\n",
       "  -0.4074082860494102,\n",
       "  1.9144141376060844,\n",
       "  0.7138044937490623,\n",
       "  1.1592496556120597,\n",
       "  1.1,\n",
       "  -0.6138355170528941],\n",
       " [0.9704733906533101,\n",
       "  1.0,\n",
       "  -0.9518538067475207,\n",
       "  -1.4112451942947841,\n",
       "  0.40097245193455544,\n",
       "  1.9145096000937294,\n",
       "  0.9,\n",
       "  0.7410145083000743],\n",
       " [0.6588979600805724,\n",
       "  1.0,\n",
       "  1.2128433542978516,\n",
       "  1.3066287073943337,\n",
       "  0.4029654113379963,\n",
       "  -0.33573922870164075,\n",
       "  0.9,\n",
       "  -0.2676551180436764],\n",
       " [-1.6050206487805319,\n",
       "  5.0,\n",
       "  0.015100923773162033,\n",
       "  0.510082367789702,\n",
       "  0.7044372818566493,\n",
       "  -0.3558748851539656,\n",
       "  0.85,\n",
       "  0.5480295864032716],\n",
       " [-0.0812300019203214,\n",
       "  5.0,\n",
       "  -0.5758837165196816,\n",
       "  -0.9884329514733527,\n",
       "  0.7627048891693569,\n",
       "  -0.4420104415873569,\n",
       "  0.85,\n",
       "  0.2520804704462661],\n",
       " [-0.7762216914776007,\n",
       "  3.0,\n",
       "  -1.3463989551079976,\n",
       "  0.9051738422424289,\n",
       "  -0.10365850623799501,\n",
       "  -0.6549908048108737,\n",
       "  0.95,\n",
       "  -0.4493617478043486],\n",
       " [-1.3972708298625343,\n",
       "  3.0,\n",
       "  0.7173762711226839,\n",
       "  -0.36221976621483887,\n",
       "  -3.0414152256548554,\n",
       "  -0.12936927194479705,\n",
       "  0.95,\n",
       "  -0.937007761590601],\n",
       " [0.862787721511821,\n",
       "  5.0,\n",
       "  1.70346239333807,\n",
       "  -0.09917719489409471,\n",
       "  -3.1781516841488724,\n",
       "  -0.8985611655402435,\n",
       "  0.85,\n",
       "  -0.3566367843319521],\n",
       " [0.7374839042906399,\n",
       "  2.0,\n",
       "  -1.5926706332248306,\n",
       "  -0.9966444252454847,\n",
       "  1.0170708915293698,\n",
       "  0.3067948427299266,\n",
       "  1.05,\n",
       "  0.9677912508774635],\n",
       " [0.5099733846271659,\n",
       "  5.0,\n",
       "  -0.8708576667997957,\n",
       "  1.2411139065114036,\n",
       "  1.1746203410804372,\n",
       "  -1.0996102835311523,\n",
       "  0.85,\n",
       "  0.292801520275333],\n",
       " [-0.2564085094886555,\n",
       "  4.0,\n",
       "  0.281101038777172,\n",
       "  -1.2412239106874725,\n",
       "  -0.2811418956361473,\n",
       "  -1.4429412508160846,\n",
       "  1.2,\n",
       "  0.7441961037055732],\n",
       " [0.6779870100426931,\n",
       "  3.0,\n",
       "  0.7640600944200261,\n",
       "  -1.0450765610199773,\n",
       "  -1.3469734521404695,\n",
       "  -0.25283946810061675,\n",
       "  0.95,\n",
       "  -0.8437199157106983],\n",
       " [0.5480209639855979,\n",
       "  1.0,\n",
       "  1.2362772776661837,\n",
       "  0.8205228421200239,\n",
       "  0.536491018038065,\n",
       "  0.8425850312525298,\n",
       "  0.9,\n",
       "  -1.8556867496482152],\n",
       " [-0.17781374329069147,\n",
       "  4.0,\n",
       "  0.9712767687173289,\n",
       "  0.10107853541200577,\n",
       "  0.12473346224994883,\n",
       "  -1.1967026495841264,\n",
       "  1.2,\n",
       "  -1.5760767323461378],\n",
       " [-0.6674601371194356,\n",
       "  4.0,\n",
       "  -0.27654371864682703,\n",
       "  -0.505586701774515,\n",
       "  -1.2024172891454876,\n",
       "  1.0934774242892888,\n",
       "  1.2,\n",
       "  0.7706320134230444],\n",
       " [1.3368998376680865,\n",
       "  1.0,\n",
       "  1.1491161339563665,\n",
       "  -0.9448579884146326,\n",
       "  -1.0224244661656237,\n",
       "  0.9250395626097778,\n",
       "  0.9,\n",
       "  -0.8136347787874797],\n",
       " [-0.7791048484744577,\n",
       "  0.0,\n",
       "  -1.308934597686884,\n",
       "  -0.5961325021426432,\n",
       "  0.5680586475137204,\n",
       "  1.6036638781758534,\n",
       "  1.1,\n",
       "  0.12501465473252074],\n",
       " [-0.12614751968759774,\n",
       "  5.0,\n",
       "  0.7443642289558284,\n",
       "  -0.9193636996209404,\n",
       "  0.49292321032014974,\n",
       "  0.6851890007774573,\n",
       "  0.85,\n",
       "  -0.3713059402601172],\n",
       " [0.08103223790055707,\n",
       "  3.0,\n",
       "  -0.5412856043994786,\n",
       "  -0.667866371322098,\n",
       "  0.6681285712623416,\n",
       "  -0.31116593807665005,\n",
       "  0.95,\n",
       "  -0.97777324545547],\n",
       " [0.8413889835203376,\n",
       "  1.0,\n",
       "  -1.364443391259961,\n",
       "  0.9199940656800211,\n",
       "  -0.5081639614725272,\n",
       "  0.10291635023748769,\n",
       "  0.9,\n",
       "  1.0580900466767746],\n",
       " [1.0201200850152874,\n",
       "  5.0,\n",
       "  -0.23114321684860423,\n",
       "  -1.3340793838794744,\n",
       "  0.7108715036330637,\n",
       "  -0.5191036511607469,\n",
       "  0.85,\n",
       "  0.8956620294207266],\n",
       " [-0.9481523093519739,\n",
       "  2.0,\n",
       "  -0.8322769758379076,\n",
       "  0.4902615398800514,\n",
       "  0.7933614548196904,\n",
       "  1.886896778772134,\n",
       "  1.05,\n",
       "  -1.332311609602078],\n",
       " [1.1641357259506098,\n",
       "  3.0,\n",
       "  1.0846507567572123,\n",
       "  1.0109274097225691,\n",
       "  1.894766480636731,\n",
       "  -0.048136732390045456,\n",
       "  0.95,\n",
       "  -1.5003923709301272],\n",
       " [0.030940509692062884,\n",
       "  2.0,\n",
       "  -1.4593269381155873,\n",
       "  -1.3886192990341664,\n",
       "  0.056700339526345074,\n",
       "  -0.4241835674136819,\n",
       "  1.05,\n",
       "  -0.08374813065725022],\n",
       " [-1.078736623997965,\n",
       "  0.0,\n",
       "  1.557677083731916,\n",
       "  -0.5741959054796568,\n",
       "  0.7343020062335445,\n",
       "  -0.21751220349738767,\n",
       "  1.1,\n",
       "  0.9975175852363452],\n",
       " [0.5995291052090274,\n",
       "  5.0,\n",
       "  -1.084451981467174,\n",
       "  -1.4059153376815863,\n",
       "  1.4381098060003483,\n",
       "  -1.4392178620721776,\n",
       "  0.85,\n",
       "  -0.4504564918202498],\n",
       " [1.136750493791172,\n",
       "  2.0,\n",
       "  1.5217167416156232,\n",
       "  -0.9313785789001549,\n",
       "  -1.1625040656087007,\n",
       "  0.37147826675033124,\n",
       "  1.05,\n",
       "  0.7912610287000357],\n",
       " [1.6036702579476165,\n",
       "  2.0,\n",
       "  1.0210148462237818,\n",
       "  0.12494735885147788,\n",
       "  0.264936989319369,\n",
       "  0.13710642888003013,\n",
       "  1.05,\n",
       "  0.9081518000788282],\n",
       " [-1.6099280029031902,\n",
       "  4.0,\n",
       "  -1.276782396374185,\n",
       "  -1.091262103070259,\n",
       "  -0.5354812822606696,\n",
       "  -0.03949219699347398,\n",
       "  1.2,\n",
       "  -1.8975718544773525],\n",
       " [-1.322983230350947,\n",
       "  0.0,\n",
       "  0.23507301614686668,\n",
       "  1.9768295481934721,\n",
       "  0.41023192915226625,\n",
       "  0.28693206816252187,\n",
       "  1.1,\n",
       "  0.7230204627220652],\n",
       " [1.3256058489133649,\n",
       "  0.0,\n",
       "  0.9784034163139399,\n",
       "  -1.061678771229762,\n",
       "  -0.5783652559003838,\n",
       "  0.8469664058900177,\n",
       "  1.1,\n",
       "  -0.9243161778709165],\n",
       " [0.6233850237472309,\n",
       "  4.0,\n",
       "  -1.650623535981408,\n",
       "  -0.17379325973456278,\n",
       "  -0.17547436500354538,\n",
       "  -0.2793799420946548,\n",
       "  1.2,\n",
       "  1.0605132328372406],\n",
       " [0.21957515572175157,\n",
       "  3.0,\n",
       "  0.7986760833256322,\n",
       "  -1.0217162907671784,\n",
       "  0.6382009426177613,\n",
       "  -0.511761910155551,\n",
       "  0.95,\n",
       "  -0.44286538339276926],\n",
       " [0.9928606298294699,\n",
       "  1.0,\n",
       "  -1.5478288251807044,\n",
       "  -0.6849179994584303,\n",
       "  0.7170428317808708,\n",
       "  -1.2488357124591798,\n",
       "  0.9,\n",
       "  -0.17637240222794157],\n",
       " [1.2559724592581714,\n",
       "  1.0,\n",
       "  0.5413222113417602,\n",
       "  -0.6942117283218125,\n",
       "  -1.0570950977856675,\n",
       "  -0.25318376082676175,\n",
       "  0.9,\n",
       "  0.7537923302495309],\n",
       " [1.6015792483283013,\n",
       "  0.0,\n",
       "  1.220583824802036,\n",
       "  -1.3957324765247203,\n",
       "  0.1409107010042217,\n",
       "  -0.2550699639747697,\n",
       "  1.1,\n",
       "  1.0626520648209046],\n",
       " [-1.1916890942898015,\n",
       "  5.0,\n",
       "  -0.6022523640461318,\n",
       "  1.0165868993017582,\n",
       "  -1.1338160667701782,\n",
       "  0.9267876285678188,\n",
       "  0.85,\n",
       "  -1.0753740265198715],\n",
       " [1.2596413431586087,\n",
       "  3.0,\n",
       "  0.12084916512090962,\n",
       "  -0.32204767303033427,\n",
       "  -0.2750942198503942,\n",
       "  1.7387659239370081,\n",
       "  0.95,\n",
       "  -1.5018636436646093],\n",
       " [0.6899574886125094,\n",
       "  0.0,\n",
       "  -1.5287868160312603,\n",
       "  1.0180531999234799,\n",
       "  1.94855918888405,\n",
       "  0.12861901152773098,\n",
       "  1.1,\n",
       "  0.3237464389822755],\n",
       " [-0.49191660331531234,\n",
       "  3.0,\n",
       "  1.0282549794116935,\n",
       "  0.34388720144603624,\n",
       "  -1.2502824048657157,\n",
       "  1.2165591790304195,\n",
       "  0.95,\n",
       "  1.0647644192447279],\n",
       " [1.512737439082456,\n",
       "  3.0,\n",
       "  0.7388409719803923,\n",
       "  1.2574868504803984,\n",
       "  0.6204942870575934,\n",
       "  1.9496557967494752,\n",
       "  0.95,\n",
       "  0.24075476367929802],\n",
       " [1.2585791436929492,\n",
       "  3.0,\n",
       "  0.6548512006814092,\n",
       "  1.392975097604395,\n",
       "  -0.9315858754052341,\n",
       "  -1.0028250392140128,\n",
       "  0.95,\n",
       "  0.7290139407749482],\n",
       " [-0.01580872824080495,\n",
       "  0.0,\n",
       "  -1.4120777028210196,\n",
       "  -0.7693702409768249,\n",
       "  -0.2984095110745191,\n",
       "  0.018159563222567433,\n",
       "  1.1,\n",
       "  1.0250138852101403],\n",
       " [0.9096231956684174,\n",
       "  1.0,\n",
       "  1.307201908778504,\n",
       "  -0.29516253770379347,\n",
       "  -2.654267190737536,\n",
       "  0.18211390968742966,\n",
       "  0.9,\n",
       "  1.0593230179897593],\n",
       " [-1.8783369582406946,\n",
       "  3.0,\n",
       "  -0.23595783743515097,\n",
       "  -1.3066623920756917,\n",
       "  0.6694756921280732,\n",
       "  -0.5746296479291384,\n",
       "  0.95,\n",
       "  -1.6523486065688717],\n",
       " [-0.6906605234918273,\n",
       "  4.0,\n",
       "  -0.2974785088267379,\n",
       "  1.1737793601373643,\n",
       "  0.01847983336607255,\n",
       "  0.350932643846731,\n",
       "  1.2,\n",
       "  1.064369173005495],\n",
       " [0.6707785733926229,\n",
       "  4.0,\n",
       "  -1.0647883727257308,\n",
       "  1.3084079215872995,\n",
       "  0.2505053665299928,\n",
       "  0.19598366812870996,\n",
       "  1.2,\n",
       "  1.1192064214223938],\n",
       " [1.08318541464065,\n",
       "  1.0,\n",
       "  1.601456954600125,\n",
       "  0.17772237371236246,\n",
       "  0.8566760576990546,\n",
       "  0.36282968845370184,\n",
       "  0.9,\n",
       "  0.10593279504244434],\n",
       " [-0.719539027921112,\n",
       "  5.0,\n",
       "  -0.07825229506685784,\n",
       "  -0.9962537248763429,\n",
       "  -3.1614527052677217,\n",
       "  -0.6087653312113265,\n",
       "  0.85,\n",
       "  -1.8137900488418455],\n",
       " [-1.34356481138392,\n",
       "  5.0,\n",
       "  1.3631778965353156,\n",
       "  0.30310057697060844,\n",
       "  0.9718527139418457,\n",
       "  0.046100820207136115,\n",
       "  0.85,\n",
       "  0.7752867816590246],\n",
       " [1.5994460184027992,\n",
       "  4.0,\n",
       "  -1.0232481474146515,\n",
       "  -0.9475068577967727,\n",
       "  0.2481673416085662,\n",
       "  -0.3038137238852281,\n",
       "  1.2,\n",
       "  -1.2340139828118049],\n",
       " [-0.38536991089165556,\n",
       "  5.0,\n",
       "  0.15123157439710483,\n",
       "  -0.11040469566014319,\n",
       "  -1.2742556905522993,\n",
       "  -1.2316263558622171,\n",
       "  0.85,\n",
       "  -1.2384144252748297],\n",
       " [0.8827962161022849,\n",
       "  3.0,\n",
       "  1.6142088940636894,\n",
       "  -0.7655015963541467,\n",
       "  -1.9730437570369437,\n",
       "  0.6082201579715474,\n",
       "  0.95,\n",
       "  -0.5334042021960537],\n",
       " [0.12323038503685194,\n",
       "  5.0,\n",
       "  1.5732349216847714,\n",
       "  -1.308991762163652,\n",
       "  0.2242724440719338,\n",
       "  0.17449544795760918,\n",
       "  0.85,\n",
       "  -1.1260493158928229],\n",
       " [-1.6089808911089085,\n",
       "  4.0,\n",
       "  -0.3282309516535343,\n",
       "  1.9291402105155386,\n",
       "  0.8685465031382418,\n",
       "  -1.2270638520849861,\n",
       "  1.2,\n",
       "  -0.04154671856929238],\n",
       " [1.7918552275090134,\n",
       "  4.0,\n",
       "  0.35685984593606196,\n",
       "  -0.020746583646330075,\n",
       "  0.3930561592080325,\n",
       "  -1.330070087813302,\n",
       "  1.2,\n",
       "  0.29809103502779016],\n",
       " [0.5000853402984807,\n",
       "  3.0,\n",
       "  -0.7365152344068776,\n",
       "  -0.8621584925085372,\n",
       "  0.8875703548961671,\n",
       "  0.3318516697539064,\n",
       "  0.95,\n",
       "  0.768494311100111],\n",
       " [-1.595468340236827,\n",
       "  1.0,\n",
       "  1.290981469445716,\n",
       "  -1.112046159625184,\n",
       "  -1.8823196012374488,\n",
       "  -0.4698877019149487,\n",
       "  0.9,\n",
       "  1.0129573518686548],\n",
       " [0.07007051584409398,\n",
       "  2.0,\n",
       "  -0.7483955855707448,\n",
       "  1.387572517989662,\n",
       "  0.31018436641798386,\n",
       "  -0.011231822337583354,\n",
       "  1.05,\n",
       "  -0.39588256263539073],\n",
       " [-0.19217860749887133,\n",
       "  5.0,\n",
       "  -1.3609343183891778,\n",
       "  0.7846637502320132,\n",
       "  0.8077140971302011,\n",
       "  1.6067982226197817,\n",
       "  0.85,\n",
       "  -0.6608846215984479],\n",
       " [-0.26482653998674677,\n",
       "  2.0,\n",
       "  0.18809623054835942,\n",
       "  -0.8374168754888518,\n",
       "  -2.182069382616422,\n",
       "  -0.184692880542362,\n",
       "  1.05,\n",
       "  0.8585783655603396],\n",
       " [-1.8155267950879226,\n",
       "  0.0,\n",
       "  -0.4952316487148108,\n",
       "  -0.27721800815989034,\n",
       "  0.7671323044543593,\n",
       "  -0.2749992920845638,\n",
       "  1.1,\n",
       "  -0.02429736316106325],\n",
       " [-1.265633833407391,\n",
       "  0.0,\n",
       "  1.2560123552636335,\n",
       "  -0.9890255558496003,\n",
       "  0.09018877731222213,\n",
       "  -1.0434351659134231,\n",
       "  1.1,\n",
       "  -0.6561475197591126],\n",
       " [-0.9660424648983987,\n",
       "  3.0,\n",
       "  0.8396178311659601,\n",
       "  -1.4085301925001903,\n",
       "  0.376606759949567,\n",
       "  -0.08516243323154263,\n",
       "  0.95,\n",
       "  0.5739464029505617],\n",
       " [0.40712216443522875,\n",
       "  1.0,\n",
       "  -1.101917666316082,\n",
       "  -1.1441053842591467,\n",
       "  0.4372784425867518,\n",
       "  0.043075884898343034,\n",
       "  0.9,\n",
       "  -1.374134030555837],\n",
       " [0.3503954259892507,\n",
       "  5.0,\n",
       "  0.09082753022990434,\n",
       "  -0.8985011456544025,\n",
       "  0.8154128155434256,\n",
       "  -0.7055600763298467,\n",
       "  0.85,\n",
       "  0.6370498551353678],\n",
       " [1.6043597235535945,\n",
       "  4.0,\n",
       "  -0.20697276382164168,\n",
       "  1.729930371367016,\n",
       "  -0.08190085188528734,\n",
       "  -0.08447043328661856,\n",
       "  1.2,\n",
       "  0.7303928653578163],\n",
       " [-0.16732725765271889,\n",
       "  2.0,\n",
       "  1.436752342605695,\n",
       "  1.8680648508092035,\n",
       "  -0.34214336998557426,\n",
       "  -1.0630472098315726,\n",
       "  1.05,\n",
       "  -0.11576982088677826],\n",
       " [-1.14365336764533,\n",
       "  5.0,\n",
       "  0.21331371807895977,\n",
       "  -1.2421404270869736,\n",
       "  0.5409272832640243,\n",
       "  -0.32319553735822826,\n",
       "  0.85,\n",
       "  -0.2292829860350092],\n",
       " [0.40107313964310803,\n",
       "  1.0,\n",
       "  1.4244805863506953,\n",
       "  -0.6072318472243674,\n",
       "  -2.058553495126933,\n",
       "  0.5840868041983036,\n",
       "  0.9,\n",
       "  1.0480852997466898],\n",
       " [0.8379685177248605,\n",
       "  3.0,\n",
       "  1.327537224508281,\n",
       "  -0.009250075136213428,\n",
       "  -0.308827085996682,\n",
       "  1.5706682387778963,\n",
       "  0.95,\n",
       "  -0.25905662748577674],\n",
       " [-0.8369902540942948,\n",
       "  5.0,\n",
       "  -0.6807386862763398,\n",
       "  1.050085494103126,\n",
       "  -1.646931465303437,\n",
       "  -0.8806187273512247,\n",
       "  0.85,\n",
       "  2.954615445985758],\n",
       " [-0.1470929951473667,\n",
       "  5.0,\n",
       "  -0.534050722986303,\n",
       "  0.878655686659338,\n",
       "  -0.128774064861035,\n",
       "  -1.8510056473904781,\n",
       "  0.85,\n",
       "  -1.6109934683795566],\n",
       " [-0.6405456304266701,\n",
       "  3.0,\n",
       "  -0.28983523805199213,\n",
       "  1.2569767213312804,\n",
       "  0.22647738342575588,\n",
       "  1.345969241843494,\n",
       "  0.95,\n",
       "  -0.8364117390316202],\n",
       " [0.6221944417946903,\n",
       "  1.0,\n",
       "  1.4097099245325264,\n",
       "  0.2379314752059543,\n",
       "  -1.018434554921756,\n",
       "  0.7833221787331086,\n",
       "  0.9,\n",
       "  1.0651227931846619],\n",
       " [1.3188688800754111,\n",
       "  0.0,\n",
       "  -0.07450618501160719,\n",
       "  1.8267125422019912,\n",
       "  0.21835443603988164,\n",
       "  -0.3014352314392723,\n",
       "  1.1,\n",
       "  -0.07137305839269648],\n",
       " [-1.2075764849944888,\n",
       "  2.0,\n",
       "  1.715555789478144,\n",
       "  0.48814731746391476,\n",
       "  0.8186158559121293,\n",
       "  -0.21523553772377446,\n",
       "  1.05,\n",
       "  1.0634129105378822],\n",
       " [0.7402051045334868,\n",
       "  3.0,\n",
       "  -0.8224836247597466,\n",
       "  -0.6854688172696045,\n",
       "  1.4234190543245633,\n",
       "  -1.5143707978683516,\n",
       "  0.95,\n",
       "  0.20746386886384172],\n",
       " [1.3932379428712012,\n",
       "  2.0,\n",
       "  -0.06086771452060744,\n",
       "  -1.3418630302101426,\n",
       "  0.46183493129109765,\n",
       "  1.3063912861492888,\n",
       "  1.05,\n",
       "  0.8764627544421715],\n",
       " [-0.8182586238939453,\n",
       "  0.0,\n",
       "  1.3770214694497858,\n",
       "  -0.24948919405728773,\n",
       "  0.6666609429615248,\n",
       "  0.22536373096582235,\n",
       "  1.1,\n",
       "  0.4350615588402184],\n",
       " [0.053080673954216416,\n",
       "  3.0,\n",
       "  -1.2252133425779348,\n",
       "  1.828617764188649,\n",
       "  0.552668780910638,\n",
       "  -0.15069200115898052,\n",
       "  0.95,\n",
       "  1.0619849559394452],\n",
       " [1.213970412283294,\n",
       "  5.0,\n",
       "  -1.3941266848237328,\n",
       "  -0.5775880072600946,\n",
       "  0.9312229359093557,\n",
       "  -0.15451516518581046,\n",
       "  0.85,\n",
       "  0.1567994029995277],\n",
       " [-0.7933461437183589,\n",
       "  2.0,\n",
       "  1.0491619304839717,\n",
       "  -1.3459774292359132,\n",
       "  0.8898769119844686,\n",
       "  -1.1808055402746527,\n",
       "  1.05,\n",
       "  -1.669070650369502],\n",
       " [-0.6350588808176448,\n",
       "  2.0,\n",
       "  -0.43171422777814383,\n",
       "  0.6498403263859022,\n",
       "  1.142922681763806,\n",
       "  0.320191766169348,\n",
       "  1.05,\n",
       "  -1.3768980039675005],\n",
       " [1.1490283965336479,\n",
       "  3.0,\n",
       "  -1.396261659836498,\n",
       "  -1.2253438196842743,\n",
       "  0.32177287134937876,\n",
       "  -0.27493399940485447,\n",
       "  0.95,\n",
       "  0.9241804999972857],\n",
       " [-0.7299721644547573,\n",
       "  4.0,\n",
       "  -1.0918600767183364,\n",
       "  -1.0085199575344266,\n",
       "  0.6707078113293802,\n",
       "  -0.1490615165150221,\n",
       "  1.2,\n",
       "  -0.987469785010921],\n",
       " [-1.65233992989201,\n",
       "  1.0,\n",
       "  1.4600145000347453,\n",
       "  -1.2814558170448096,\n",
       "  1.1374182754860356,\n",
       "  -0.5418343524029744,\n",
       "  0.9,\n",
       "  0.6455012037173965],\n",
       " [0.8802208031465509,\n",
       "  4.0,\n",
       "  0.2781396098634638,\n",
       "  1.212307784935173,\n",
       "  0.5322940355020173,\n",
       "  -1.621641879675472,\n",
       "  1.2,\n",
       "  0.7374634580829769],\n",
       " [-0.8021278723023172,\n",
       "  2.0,\n",
       "  0.3122711468746545,\n",
       "  -0.18262001470079442,\n",
       "  -2.0341160641986837,\n",
       "  -1.5783346621930439,\n",
       "  1.05,\n",
       "  0.282068582315152],\n",
       " [0.4007808956422826,\n",
       "  4.0,\n",
       "  -1.6223186685757973,\n",
       "  -1.1895203641978176,\n",
       "  0.7699050937431149,\n",
       "  0.007811899676047299,\n",
       "  1.2,\n",
       "  0.9844898287872231],\n",
       " [0.37091039385660973,\n",
       "  5.0,\n",
       "  0.46242149245892444,\n",
       "  1.4704287764160557,\n",
       "  -0.9484532301470348,\n",
       "  0.9945699139320091,\n",
       "  0.85,\n",
       "  -1.698204329312652],\n",
       " [1.0097138686688645,\n",
       "  4.0,\n",
       "  -0.1800722373307849,\n",
       "  -1.277179526218331,\n",
       "  1.3090710173708269,\n",
       "  0.656679294175802,\n",
       "  1.2,\n",
       "  0.9921785559873987],\n",
       " [0.5494907155347425,\n",
       "  2.0,\n",
       "  -1.1938384813878553,\n",
       "  1.3289247041714958,\n",
       "  0.5564813696937023,\n",
       "  -0.2361243522525212,\n",
       "  1.05,\n",
       "  0.9394406059849596],\n",
       " [-0.6265825542347045,\n",
       "  1.0,\n",
       "  -0.32036239524447463,\n",
       "  -1.2343230926176039,\n",
       "  1.210042034275876,\n",
       "  -0.4201529583594411,\n",
       "  0.9,\n",
       "  -1.8677463956208151],\n",
       " [-0.5874943065114426,\n",
       "  1.0,\n",
       "  -0.553001119337482,\n",
       "  1.0167776212935036,\n",
       "  0.6418625321593344,\n",
       "  0.75123540332525,\n",
       "  0.9,\n",
       "  -1.5781889284418709],\n",
       " [-0.5027361875376276,\n",
       "  2.0,\n",
       "  -0.0895465746018298,\n",
       "  -1.1127024079182903,\n",
       "  -1.967629006305034,\n",
       "  0.2217994377965935,\n",
       "  1.05,\n",
       "  1.363699807429202],\n",
       " [-1.158813844243124,\n",
       "  0.0,\n",
       "  -0.22707972811898997,\n",
       "  -1.218885390024975,\n",
       "  1.0217214153685574,\n",
       "  1.4888576870253627,\n",
       "  1.1,\n",
       "  -0.10388739822543698],\n",
       " [-0.5622738131619544,\n",
       "  2.0,\n",
       "  -0.17521690315447083,\n",
       "  1.9069808651621647,\n",
       "  0.5599980271703047,\n",
       "  -0.6247281354434443,\n",
       "  1.05,\n",
       "  -1.1092123218810703],\n",
       " [-1.6080516471340986,\n",
       "  4.0,\n",
       "  1.5588600236678756,\n",
       "  0.8196132188795706,\n",
       "  1.2890407962346695,\n",
       "  1.1053454233898123,\n",
       "  1.2,\n",
       "  -1.012215354834092],\n",
       " [1.34927112285528,\n",
       "  0.0,\n",
       "  0.07887993238082175,\n",
       "  -0.6219558619179301,\n",
       "  0.41432421327528135,\n",
       "  -0.5654365760962721,\n",
       "  1.1,\n",
       "  0.9750650610171627],\n",
       " [-0.9640461650515136,\n",
       "  2.0,\n",
       "  1.7023014946291197,\n",
       "  0.562202702782475,\n",
       "  0.26191292959442297,\n",
       "  -1.4095941443470223,\n",
       "  1.05,\n",
       "  1.052324875601628],\n",
       " [-1.5389242645576207,\n",
       "  2.0,\n",
       "  -0.842576872215723,\n",
       "  1.1736143452194872,\n",
       "  -2.1540128438179114,\n",
       "  -1.3922462072021031,\n",
       "  1.05,\n",
       "  -1.4089946741928459],\n",
       " [-0.4466087925088471,\n",
       "  0.0,\n",
       "  -1.6316702642225334,\n",
       "  -1.3947577555787019,\n",
       "  -2.796218023653316,\n",
       "  -0.8509525562616097,\n",
       "  1.1,\n",
       "  -1.8671411131827707],\n",
       " [1.8189755539223829,\n",
       "  1.0,\n",
       "  0.14696865608522003,\n",
       "  -0.6846702490090143,\n",
       "  0.9559719191951694,\n",
       "  -1.2219248930907234,\n",
       "  0.9,\n",
       "  -0.5632958014454563],\n",
       " [-0.78505599672854,\n",
       "  3.0,\n",
       "  0.18973915424030668,\n",
       "  -1.369654385382055,\n",
       "  0.35143540545303437,\n",
       "  -0.4521390594259065,\n",
       "  0.95,\n",
       "  0.28659777828209243],\n",
       " [-0.3231703452085775,\n",
       "  3.0,\n",
       "  1.4867255714360563,\n",
       "  -1.2117289434686669,\n",
       "  -0.49955651736620554,\n",
       "  1.9713808841613403,\n",
       "  0.95,\n",
       "  0.3390184294853659],\n",
       " [-0.2677610862574563,\n",
       "  1.0,\n",
       "  -1.5384483721192121,\n",
       "  -0.4806531056252359,\n",
       "  0.7330479000810418,\n",
       "  -0.17587662823276856,\n",
       "  0.9,\n",
       "  -0.7095178796014473],\n",
       " [0.2635617768479213,\n",
       "  4.0,\n",
       "  -1.4695124897303478,\n",
       "  -0.9655305485036056,\n",
       "  0.4492500862816579,\n",
       "  -0.1423371344521277,\n",
       "  1.2,\n",
       "  -0.612535591023539],\n",
       " [0.8343395129142428,\n",
       "  0.0,\n",
       "  -1.1146347063921378,\n",
       "  0.5542710977503684,\n",
       "  0.4905315603105134,\n",
       "  0.4061071741790051,\n",
       "  1.1,\n",
       "  0.11510520515525122],\n",
       " [-1.8153131294746667,\n",
       "  1.0,\n",
       "  -0.013954422004231718,\n",
       "  0.5182917419526447,\n",
       "  0.029280781975010103,\n",
       "  0.016545382212327604,\n",
       "  0.9,\n",
       "  -1.2671140966150445],\n",
       " [0.4678653363597491,\n",
       "  5.0,\n",
       "  -1.336256012652649,\n",
       "  -1.3169203321978356,\n",
       "  -0.8709322675104463,\n",
       "  -1.5641414916633491,\n",
       "  0.85,\n",
       "  0.42493380148666543],\n",
       " [-0.5815329720714733,\n",
       "  0.0,\n",
       "  1.3625699486978862,\n",
       "  -1.217978302224314,\n",
       "  0.8594175258251483,\n",
       "  1.0173590613745462,\n",
       "  1.1,\n",
       "  -0.3610347088527391],\n",
       " [-0.31689210054861733,\n",
       "  0.0,\n",
       "  1.7085882979075702,\n",
       "  1.5774258429631893,\n",
       "  0.04543097370935554,\n",
       "  0.7739729191636197,\n",
       "  1.1,\n",
       "  1.0126690631395652],\n",
       " [-0.5071190487747806,\n",
       "  5.0,\n",
       "  -0.7164353923068782,\n",
       "  -0.12177041280311675,\n",
       "  0.8047763214135228,\n",
       "  1.0495900548358572,\n",
       "  0.85,\n",
       "  -0.07428974467149098],\n",
       " [1.136447512283001,\n",
       "  5.0,\n",
       "  0.7677573865189875,\n",
       "  1.2789066046683373,\n",
       "  1.2714017847247125,\n",
       "  -0.9503309370220157,\n",
       "  0.85,\n",
       "  -0.029558908196048176],\n",
       " [-1.1804578334932128,\n",
       "  1.0,\n",
       "  1.465262078960584,\n",
       "  0.12277684600818792,\n",
       "  -0.0058199213871573344,\n",
       "  1.681707113379052,\n",
       "  0.9,\n",
       "  -1.5090502415981455],\n",
       " [-0.7679412704443987,\n",
       "  0.0,\n",
       "  0.6414235872825322,\n",
       "  -1.0146194222648248,\n",
       "  0.5783426714666261,\n",
       "  0.7899145674770868,\n",
       "  1.1,\n",
       "  -1.3394337603973234],\n",
       " [1.2995173488123677,\n",
       "  3.0,\n",
       "  -1.6033703581882934,\n",
       "  1.355078628809248,\n",
       "  -0.6433685723825386,\n",
       "  0.09715642518326642,\n",
       "  0.95,\n",
       "  -1.9764595302909815],\n",
       " [-1.2141773703693308,\n",
       "  0.0,\n",
       "  -0.65987326401498,\n",
       "  -0.9307032456943863,\n",
       "  -2.764754972098067,\n",
       "  1.4433115846088604,\n",
       "  1.1,\n",
       "  0.3281350339786096],\n",
       " [-1.3788951179521636,\n",
       "  5.0,\n",
       "  0.22439077132018323,\n",
       "  0.3916006857467863,\n",
       "  0.351702208084398,\n",
       "  -0.5718546606378129,\n",
       "  0.85,\n",
       "  -0.4271248824774989],\n",
       " [1.646140157526916,\n",
       "  5.0,\n",
       "  0.4151602553779305,\n",
       "  -0.6130618924795322,\n",
       "  0.69492942090035,\n",
       "  1.7575262947896875,\n",
       "  0.85,\n",
       "  1.065423398763753],\n",
       " [-0.8070428456848535,\n",
       "  4.0,\n",
       "  0.5228549364913727,\n",
       "  1.0091559040411808,\n",
       "  0.43952264387173146,\n",
       "  1.6796231647172173,\n",
       "  1.2,\n",
       "  1.0281011979995334],\n",
       " [1.4814159338142239,\n",
       "  4.0,\n",
       "  0.14982522417036018,\n",
       "  0.8892768307636146,\n",
       "  0.26229663141405735,\n",
       "  0.585694018192291,\n",
       "  1.2,\n",
       "  -1.391546125881358],\n",
       " [-1.4333073898979467,\n",
       "  2.0,\n",
       "  -1.0202524084051108,\n",
       "  0.5883721554809422,\n",
       "  1.3799950978904385,\n",
       "  -0.7425575545167913,\n",
       "  1.05,\n",
       "  -0.13483592930870061],\n",
       " [-0.4134842620096236,\n",
       "  4.0,\n",
       "  0.7303236375707316,\n",
       "  0.6729646074103831,\n",
       "  -0.36448984514786703,\n",
       "  0.6173939118603158,\n",
       "  1.2,\n",
       "  -0.6429449920383091],\n",
       " [-0.8900640730892404,\n",
       "  4.0,\n",
       "  0.2932461634772697,\n",
       "  -0.5970990268050507,\n",
       "  -0.3401204829529026,\n",
       "  -1.2469467774467704,\n",
       "  1.2,\n",
       "  0.30827022659587383],\n",
       " [0.8241371806069195,\n",
       "  1.0,\n",
       "  -1.2973839075001339,\n",
       "  0.19386499871666735,\n",
       "  -1.0780747891254987,\n",
       "  0.004553972218732199,\n",
       "  0.9,\n",
       "  -0.2934495151295108],\n",
       " [-1.3498715217921646,\n",
       "  4.0,\n",
       "  0.18928289026101713,\n",
       "  0.6172305409616493,\n",
       "  0.9401398373239205,\n",
       "  -0.12912441594176052,\n",
       "  1.2,\n",
       "  -1.3146903192721882],\n",
       " [0.6421631983428597,\n",
       "  0.0,\n",
       "  -0.3987157092962069,\n",
       "  -1.3999644187576334,\n",
       "  0.13444138685026705,\n",
       "  -0.7895214113568064,\n",
       "  1.1,\n",
       "  -1.3650022546669573],\n",
       " [-0.22269949438314518,\n",
       "  0.0,\n",
       "  -1.2798493805773268,\n",
       "  0.16917837712918982,\n",
       "  0.2470446187195542,\n",
       "  1.4316756794474859,\n",
       "  1.1,\n",
       "  -1.3362280957086725],\n",
       " [0.09506724716219789,\n",
       "  1.0,\n",
       "  1.447318813413826,\n",
       "  -1.0172503635846506,\n",
       "  -0.13922227198492415,\n",
       "  0.007546396379142433,\n",
       "  0.9,\n",
       "  -1.7253065906977176],\n",
       " [-1.3268960404600427,\n",
       "  4.0,\n",
       "  -1.6313114726387001,\n",
       "  0.5342625206064026,\n",
       "  -0.11490644962664409,\n",
       "  1.0535318920504182,\n",
       "  1.2,\n",
       "  -0.9400531587321079],\n",
       " [1.9245705745643529,\n",
       "  1.0,\n",
       "  -1.3514144402618098,\n",
       "  -0.4247532224603775,\n",
       "  0.5465659247030833,\n",
       "  -0.12210106021877098,\n",
       "  0.9,\n",
       "  -0.1568136888191112],\n",
       " [1.6478043832219227,\n",
       "  3.0,\n",
       "  0.11020599815879402,\n",
       "  -0.9908880179690387,\n",
       "  1.0655524419199354,\n",
       "  -0.5860418856456163,\n",
       "  0.95,\n",
       "  -0.12755360238848332],\n",
       " [-1.3998931357207476,\n",
       "  1.0,\n",
       "  0.07936014537533383,\n",
       "  -1.3637355938060791,\n",
       "  0.5718600696159251,\n",
       "  1.6279227820107953,\n",
       "  0.9,\n",
       "  0.8266315747707323],\n",
       " [-0.4333970330938544,\n",
       "  0.0,\n",
       "  1.28609004700362,\n",
       "  0.005141343074244311,\n",
       "  0.9011604362113953,\n",
       "  0.03939990201808525,\n",
       "  1.1,\n",
       "  0.9694637833698863],\n",
       " [-0.5132119146470029,\n",
       "  3.0,\n",
       "  1.5365565895797417,\n",
       "  1.2972200825975566,\n",
       "  -1.7632114158096868,\n",
       "  -1.648264551215408,\n",
       "  0.95,\n",
       "  -1.7589227620261605],\n",
       " [-1.397225562320642,\n",
       "  4.0,\n",
       "  -1.6081023304629676,\n",
       "  -0.787858709041036,\n",
       "  0.2881216085789208,\n",
       "  -0.1797409685387178,\n",
       "  1.2,\n",
       "  -0.9934737296418974],\n",
       " [-0.003134159177562897,\n",
       "  0.0,\n",
       "  0.8678928504338047,\n",
       "  -0.27634964709086557,\n",
       "  0.9341202216078552,\n",
       "  0.0513133854326963,\n",
       "  1.1,\n",
       "  0.6993330064538885],\n",
       " [-0.5967043836499323,\n",
       "  2.0,\n",
       "  -1.0385004286948114,\n",
       "  -0.45865714824230064,\n",
       "  0.571602708470128,\n",
       "  0.9887810081864393,\n",
       "  1.05,\n",
       "  0.1062377411577478],\n",
       " [0.2388784021052066,\n",
       "  3.0,\n",
       "  0.2825289393295064,\n",
       "  -0.8181247833184184,\n",
       "  -0.6348535178892643,\n",
       "  -1.9425824197514503,\n",
       "  0.95,\n",
       "  -1.0323621879931655],\n",
       " [1.731009610724449,\n",
       "  0.0,\n",
       "  -0.260926642201861,\n",
       "  -0.7933185148955219,\n",
       "  0.9241562405413987,\n",
       "  0.019209188362335403,\n",
       "  1.1,\n",
       "  0.3467919620808747],\n",
       " [1.5068842289241735,\n",
       "  0.0,\n",
       "  0.3911686083803462,\n",
       "  -0.5521795705732835,\n",
       "  -1.6294383794613438,\n",
       "  1.069810340966081,\n",
       "  1.1,\n",
       "  -0.28729438579489625],\n",
       " [0.11688910432920638,\n",
       "  2.0,\n",
       "  -0.9992891423147797,\n",
       "  -0.5437177947654791,\n",
       "  0.47428895079189703,\n",
       "  -1.9685888125852244,\n",
       "  1.05,\n",
       "  -0.5081973930237664],\n",
       " [-0.6623241780591245,\n",
       "  0.0,\n",
       "  1.361825478782983,\n",
       "  -1.2308652152827626,\n",
       "  -1.4287310376928144,\n",
       "  0.9522166414829251,\n",
       "  1.1,\n",
       "  2.338890859875918],\n",
       " [0.6647651273068028,\n",
       "  3.0,\n",
       "  -0.8785717586789142,\n",
       "  -0.4097963435540291,\n",
       "  0.27114513528905476,\n",
       "  -0.49720906566156875,\n",
       "  0.95,\n",
       "  -1.89542909740616],\n",
       " [0.3771248610995154,\n",
       "  1.0,\n",
       "  -0.6573923326151746,\n",
       "  0.5898758884632294,\n",
       "  -0.41562248033638416,\n",
       "  -1.546947606973004,\n",
       "  0.9,\n",
       "  0.49683644758308737],\n",
       " [-1.3802864129043502,\n",
       "  5.0,\n",
       "  0.6974400818196985,\n",
       "  -0.6506386335903904,\n",
       "  0.9439324882663362,\n",
       "  -0.9311635217686204,\n",
       "  0.85,\n",
       "  0.9165414554254321],\n",
       " [-1.367010220379922,\n",
       "  0.0,\n",
       "  1.6002360526839718,\n",
       "  0.29273370129231313,\n",
       "  -0.05765690424908335,\n",
       "  0.5221240192059495,\n",
       "  1.1,\n",
       "  -1.776979114037198],\n",
       " [0.011388388338104113,\n",
       "  1.0,\n",
       "  0.802882095744934,\n",
       "  1.1521843756396124,\n",
       "  1.0218619839492153,\n",
       "  -0.36474387289694415,\n",
       "  0.9,\n",
       "  0.2998104884469673],\n",
       " [-0.8287019253392675,\n",
       "  1.0,\n",
       "  -1.1068538285193388,\n",
       "  -0.0923625045513225,\n",
       "  1.0084863412372893,\n",
       "  1.212962309753593,\n",
       "  0.9,\n",
       "  1.0606169069961764],\n",
       " [-0.5585029927795301,\n",
       "  1.0,\n",
       "  -0.2356542080062905,\n",
       "  0.8686468801334272,\n",
       "  0.8171282194885858,\n",
       "  0.051805380161846375,\n",
       "  0.9,\n",
       "  -0.9837386983034634],\n",
       " [-1.512331404919873,\n",
       "  1.0,\n",
       "  1.658796675128848,\n",
       "  -0.5428390802803735,\n",
       "  -1.683187053540252,\n",
       "  0.8354874793500741,\n",
       "  0.9,\n",
       "  -0.571251431828612],\n",
       " [-1.9231833863696979,\n",
       "  1.0,\n",
       "  0.7713962372673919,\n",
       "  1.9512778229989378,\n",
       "  0.5036496331772427,\n",
       "  -0.4948881471206497,\n",
       "  0.9,\n",
       "  -2.00942030480285],\n",
       " [0.569860167958927,\n",
       "  2.0,\n",
       "  0.5770098690072707,\n",
       "  -0.6908357204232076,\n",
       "  0.660794190008003,\n",
       "  0.47230525289817765,\n",
       "  1.05,\n",
       "  -0.09447342594377639],\n",
       " [-0.46839674626561345,\n",
       "  0.0,\n",
       "  -1.233620991617308,\n",
       "  -0.9554120242021692,\n",
       "  0.07893154155707897,\n",
       "  -0.2809014627617666,\n",
       "  1.1,\n",
       "  0.9512834441296915],\n",
       " [0.29595517495921025,\n",
       "  5.0,\n",
       "  0.8586997443322064,\n",
       "  -0.6090061089083034,\n",
       "  0.09756905604572505,\n",
       "  1.043183986030478,\n",
       "  0.85,\n",
       "  1.0530468985217742],\n",
       " [-1.5640459833782003,\n",
       "  3.0,\n",
       "  0.39510681914487417,\n",
       "  1.0536403840253152,\n",
       "  -1.07585627383825,\n",
       "  -0.8733279603717684,\n",
       "  0.95,\n",
       "  0.06738373654617931],\n",
       " [1.2339614392297311,\n",
       "  5.0,\n",
       "  0.7060792971477763,\n",
       "  -0.8568405268331133,\n",
       "  -3.8431896965524284,\n",
       "  -1.22070546143972,\n",
       "  0.85,\n",
       "  0.3932215757142325],\n",
       " [-0.40709252800016454,\n",
       "  5.0,\n",
       "  1.6514172285904745,\n",
       "  -1.3292470000853929,\n",
       "  0.3662405252969281,\n",
       "  -0.23229841699569143,\n",
       "  0.85,\n",
       "  -1.780471098877164],\n",
       " [-0.5211729102844532,\n",
       "  0.0,\n",
       "  0.158715734982304,\n",
       "  0.6682866258222884,\n",
       "  0.43400608530008117,\n",
       "  1.0297898823004055,\n",
       "  1.1,\n",
       "  0.3026105564933301],\n",
       " [0.13475212965784916,\n",
       "  5.0,\n",
       "  -1.566517329847677,\n",
       "  -1.1998134360398258,\n",
       "  -0.9690511651531237,\n",
       "  0.5104910511674788,\n",
       "  0.85,\n",
       "  -1.088247835390476],\n",
       " [-0.6503076164822565,\n",
       "  4.0,\n",
       "  0.8375409900594322,\n",
       "  0.24017553710685738,\n",
       "  0.954292744545996,\n",
       "  -0.05834681226682151,\n",
       "  1.2,\n",
       "  0.6457328320641696],\n",
       " [0.2734133351703535,\n",
       "  0.0,\n",
       "  1.1919631147195018,\n",
       "  -0.4477415338226806,\n",
       "  -2.259819149394985,\n",
       "  1.469423067287583,\n",
       "  1.1,\n",
       "  -0.2484440206693043],\n",
       " [-1.0473889154818712,\n",
       "  5.0,\n",
       "  -0.4068190585872606,\n",
       "  -1.0989889453970938,\n",
       "  0.6589377490343401,\n",
       "  0.4107977200604204,\n",
       "  0.85,\n",
       "  1.0293940438193943],\n",
       " [-1.5516944855105774,\n",
       "  3.0,\n",
       "  0.8290624895472346,\n",
       "  0.5241967568085555,\n",
       "  -0.28789256737364777,\n",
       "  1.6748922656772605,\n",
       "  0.95,\n",
       "  -1.3507068947898635],\n",
       " [0.9606211746504583,\n",
       "  4.0,\n",
       "  -0.22039676676605205,\n",
       "  0.6902512598710935,\n",
       "  0.690407610085643,\n",
       "  1.2791539107753236,\n",
       "  1.2,\n",
       "  -0.6968359709986593],\n",
       " [1.0632711674601518,\n",
       "  5.0,\n",
       "  1.4995099393285591,\n",
       "  1.3840445930281031,\n",
       "  0.9279997554620552,\n",
       "  0.36225959801732127,\n",
       "  0.85,\n",
       "  0.8499680179519683],\n",
       " [-1.4490841674314094,\n",
       "  3.0,\n",
       "  1.4887453915739206,\n",
       "  -0.9031535236945508,\n",
       "  0.8058869151697597,\n",
       "  1.7614531157098239,\n",
       "  0.95,\n",
       "  1.0629847821538339],\n",
       " [0.7819480501338433,\n",
       "  2.0,\n",
       "  -0.17202142282747512,\n",
       "  0.4554209141857849,\n",
       "  0.746786117680345,\n",
       "  1.384748811439269,\n",
       "  1.05,\n",
       "  0.8167897188455941],\n",
       " [1.4733618184718398,\n",
       "  5.0,\n",
       "  -0.5257610208797284,\n",
       "  1.1026244750344132,\n",
       "  0.9632160313187073,\n",
       "  0.25084267160765217,\n",
       "  0.85,\n",
       "  0.9485597473102034],\n",
       " [0.685722303247228,\n",
       "  2.0,\n",
       "  0.7249717088268449,\n",
       "  1.8281378286882373,\n",
       "  -0.9363391161636867,\n",
       "  0.2602746723520402,\n",
       "  1.05,\n",
       "  0.6264461982933028],\n",
       " [-0.22883953325939285,\n",
       "  1.0,\n",
       "  -0.7353978676186408,\n",
       "  -0.9427955755290595,\n",
       "  0.4016652714239302,\n",
       "  0.2821607148428319,\n",
       "  0.9,\n",
       "  -1.0634792741421382],\n",
       " [0.6737440885767642,\n",
       "  4.0,\n",
       "  0.016814373615916103,\n",
       "  -0.9688562638585374,\n",
       "  0.11907887668421048,\n",
       "  1.2652471935517655,\n",
       "  1.2,\n",
       "  0.6175625061977467],\n",
       " [1.0695753402021582,\n",
       "  0.0,\n",
       "  -0.4312513194406306,\n",
       "  0.3511446532633926,\n",
       "  -1.823393921650378,\n",
       "  -1.6778914249984416,\n",
       "  1.1,\n",
       "  -0.43766345649274907],\n",
       " [-1.6528567026837677,\n",
       "  2.0,\n",
       "  1.4576222096312266,\n",
       "  -0.31391246001060763,\n",
       "  0.7421598410557524,\n",
       "  0.8683552733723406,\n",
       "  1.05,\n",
       "  0.797343203412471],\n",
       " [1.1896925583105595,\n",
       "  4.0,\n",
       "  -0.11129743947661234,\n",
       "  -0.08356029183813819,\n",
       "  0.5962403382546999,\n",
       "  -1.6100001905998815,\n",
       "  1.2,\n",
       "  -0.13077670012811293],\n",
       " [-0.08160772940538051,\n",
       "  4.0,\n",
       "  0.19065333363403383,\n",
       "  0.40230256866856057,\n",
       "  0.8567235454397327,\n",
       "  -1.822316313787261,\n",
       "  1.2,\n",
       "  -1.834538477885396],\n",
       " [-0.13566678725476686,\n",
       "  1.0,\n",
       "  0.7343233814245339,\n",
       "  -1.1108080633399182,\n",
       "  0.831744355126993,\n",
       "  -0.0917080313230299,\n",
       "  0.9,\n",
       "  0.7016642427155716],\n",
       " [1.7150195925863547,\n",
       "  3.0,\n",
       "  0.8738809610554615,\n",
       "  -0.07896335637979432,\n",
       "  -1.8327193759542348,\n",
       "  -0.12185133785894424,\n",
       "  0.95,\n",
       "  0.8233995839172501],\n",
       " [-2.0274688659136966,\n",
       "  5.0,\n",
       "  -1.0140941730611397,\n",
       "  0.06230178872899438,\n",
       "  0.8364820341748469,\n",
       "  1.898835855522476,\n",
       "  0.85,\n",
       "  0.7852682757229736],\n",
       " [1.616223664526409,\n",
       "  3.0,\n",
       "  0.21205058806989321,\n",
       "  0.4411473050458295,\n",
       "  0.5803704688322264,\n",
       "  -1.3930031088553874,\n",
       "  0.95,\n",
       "  1.0579284071528239],\n",
       " [0.7128666653259083,\n",
       "  0.0,\n",
       "  -0.21578486451881174,\n",
       "  -0.1981631678555043,\n",
       "  0.5243384070545812,\n",
       "  -0.00992553225236546,\n",
       "  1.1,\n",
       "  0.9988420471714639],\n",
       " [-0.37137560950463105,\n",
       "  4.0,\n",
       "  -0.18995134469994288,\n",
       "  -0.4262272222247051,\n",
       "  -0.5116876071006348,\n",
       "  -0.04082799011203988,\n",
       "  1.2,\n",
       "  0.2311250505864287],\n",
       " [-1.56298280828456,\n",
       "  1.0,\n",
       "  -0.8606471020167072,\n",
       "  1.851755208079144,\n",
       "  0.3101654441100554,\n",
       "  -1.01484383805961,\n",
       "  0.9,\n",
       "  0.6401779312773672],\n",
       " [0.3137461327705335,\n",
       "  1.0,\n",
       "  1.2612648418992063,\n",
       "  0.986330065010117,\n",
       "  -0.6095963947808747,\n",
       "  -0.0313748237547894,\n",
       "  0.9,\n",
       "  -0.4447253084494228],\n",
       " [1.5201547381277394,\n",
       "  4.0,\n",
       "  1.5432112094190626,\n",
       "  0.17477605458703582,\n",
       "  0.1996417475129786,\n",
       "  0.6392118649366463,\n",
       "  1.2,\n",
       "  0.8392973449740126],\n",
       " [1.4469198831062113,\n",
       "  4.0,\n",
       "  1.0565845183365976,\n",
       "  0.2692973175360884,\n",
       "  0.6542031268776561,\n",
       "  1.8607737507982165,\n",
       "  1.2,\n",
       "  -1.8957767188631023],\n",
       " [0.06517084763530076,\n",
       "  1.0,\n",
       "  -1.6794427501722602,\n",
       "  0.8961122542422117,\n",
       "  -0.14561086012842123,\n",
       "  0.02168534916148734,\n",
       "  0.9,\n",
       "  0.36343724284762424],\n",
       " [-0.15039868214920815,\n",
       "  5.0,\n",
       "  -1.472558126650181,\n",
       "  -0.10405556304692029,\n",
       "  -0.7011138376269355,\n",
       "  1.3632258211381016,\n",
       "  0.85,\n",
       "  -1.9561331365028092],\n",
       " [1.4116866658359455,\n",
       "  2.0,\n",
       "  1.6674434822850501,\n",
       "  -1.0965838529482856,\n",
       "  0.2945453749532491,\n",
       "  -0.7346656344632031,\n",
       "  1.05,\n",
       "  1.0643225306818658],\n",
       " [1.0670901010190412,\n",
       "  3.0,\n",
       "  0.513548646789349,\n",
       "  -0.8303383818918479,\n",
       "  -0.16949138516452578,\n",
       "  -1.76448059595045,\n",
       "  0.95,\n",
       "  -0.6780584029715652],\n",
       " [1.6193576351957923,\n",
       "  2.0,\n",
       "  0.6266022316098966,\n",
       "  -0.36442774675671025,\n",
       "  -0.12646815480372206,\n",
       "  -0.05978536539557183,\n",
       "  1.05,\n",
       "  0.982941388162538],\n",
       " [0.8725664267326223,\n",
       "  2.0,\n",
       "  1.7212491403558472,\n",
       "  1.7271613626681415,\n",
       "  0.001984692071200684,\n",
       "  -0.9259755405750204,\n",
       "  1.05,\n",
       "  0.583932061718154],\n",
       " [0.2773834835936358,\n",
       "  2.0,\n",
       "  -0.20062309633156764,\n",
       "  1.141210164344769,\n",
       "  -2.5633352211514815,\n",
       "  -0.9067531131727796,\n",
       "  1.05,\n",
       "  -1.9283310831957248],\n",
       " [-0.17857108713782305,\n",
       "  3.0,\n",
       "  1.0840604712290445,\n",
       "  0.2619837033589534,\n",
       "  0.7822860893586008,\n",
       "  0.946942447719064,\n",
       "  0.95,\n",
       "  -0.28622425018414566],\n",
       " [-0.7973198513779022,\n",
       "  3.0,\n",
       "  -0.8926406505474093,\n",
       "  1.8981500948961085,\n",
       "  0.45467845038634785,\n",
       "  -0.5871661500514844,\n",
       "  0.95,\n",
       "  1.0547463997573363],\n",
       " [-1.312362472069534,\n",
       "  1.0,\n",
       "  -1.179121990975732,\n",
       "  1.319341807522427,\n",
       "  -0.17783755428047918,\n",
       "  1.128463306209122,\n",
       "  0.9,\n",
       "  -1.8316798042749538],\n",
       " [0.8269585509900504,\n",
       "  0.0,\n",
       "  -0.26507404405041385,\n",
       "  -0.24889665369188974,\n",
       "  0.4660063705059176,\n",
       "  -1.4591354867754411,\n",
       "  1.1,\n",
       "  1.0023625125582407],\n",
       " [0.8594575665626885,\n",
       "  4.0,\n",
       "  -0.08054203167735406,\n",
       "  -0.38553561423766125,\n",
       "  -0.11296836049594157,\n",
       "  -0.7502565800723816,\n",
       "  1.2,\n",
       "  0.6450814624637021],\n",
       " [-1.5973981727877042,\n",
       "  1.0,\n",
       "  0.7895805074037724,\n",
       "  1.6085769841562858,\n",
       "  -2.6519646565484813,\n",
       "  -0.14996080923611554,\n",
       "  0.9,\n",
       "  0.542295323822768],\n",
       " [0.48691283365944293,\n",
       "  4.0,\n",
       "  -0.4846489813954801,\n",
       "  1.4696250303423046,\n",
       "  1.135713383604994,\n",
       "  1.4268358125728877,\n",
       "  1.2,\n",
       "  0.9363876481749006],\n",
       " [-0.05264964819077338,\n",
       "  3.0,\n",
       "  0.34354911262026416,\n",
       "  -0.0674817366965213,\n",
       "  -0.6446888630304055,\n",
       "  -0.19949364653843565,\n",
       "  0.95,\n",
       "  -0.10771290804933795],\n",
       " [0.7229750451873954,\n",
       "  2.0,\n",
       "  1.1880559396239676,\n",
       "  0.15637392969832895,\n",
       "  0.9063968308909546,\n",
       "  0.5975530290695598,\n",
       "  1.05,\n",
       "  -1.9740385202793167],\n",
       " [0.16846874669989476,\n",
       "  5.0,\n",
       "  1.103515504321709,\n",
       "  -0.1515942476182706,\n",
       "  0.049487676007360024,\n",
       "  -0.4407639796514775,\n",
       "  0.85,\n",
       "  0.2523829237965197],\n",
       " [-0.1441264576541089,\n",
       "  0.0,\n",
       "  0.6972826339834408,\n",
       "  -1.1436371673668912,\n",
       "  0.8485364226352228,\n",
       "  0.7511276640659166,\n",
       "  1.1,\n",
       "  0.1005389424314517],\n",
       " [1.0714404842386231,\n",
       "  4.0,\n",
       "  -0.2694536618816809,\n",
       "  -0.08369192955966694,\n",
       "  -0.6953542299452683,\n",
       "  -0.1832721430844507,\n",
       "  1.2,\n",
       "  -0.8317359836527488],\n",
       " [-0.6432350984144664,\n",
       "  1.0,\n",
       "  -1.387571064768865,\n",
       "  -1.1930745690384652,\n",
       "  0.6440137540154266,\n",
       "  0.3958594162455718,\n",
       "  0.9,\n",
       "  0.9155022381724832],\n",
       " [1.2867149962501467,\n",
       "  4.0,\n",
       "  -0.551949790172619,\n",
       "  1.6330957102939927,\n",
       "  0.08489404534705082,\n",
       "  0.19786240804731903,\n",
       "  1.2,\n",
       "  0.9742465735600596],\n",
       " [0.9046298119155158,\n",
       "  3.0,\n",
       "  -1.5235113614108695,\n",
       "  0.08620984193696098,\n",
       "  0.6612854641227586,\n",
       "  1.2745010777797203,\n",
       "  0.95,\n",
       "  0.49868704918835094],\n",
       " [-0.40603086733487254,\n",
       "  1.0,\n",
       "  -1.0931598124359179,\n",
       "  0.18639043105758965,\n",
       "  -0.4234119448601227,\n",
       "  1.0233028847269265,\n",
       "  0.9,\n",
       "  0.4229875673686106],\n",
       " [-1.0500371895573148,\n",
       "  2.0,\n",
       "  -1.4118252591170846,\n",
       "  -0.7200333544747975,\n",
       "  0.5075366399147314,\n",
       "  -0.21915932092631568,\n",
       "  1.05,\n",
       "  0.2917013040524942],\n",
       " [0.32254128743341837,\n",
       "  4.0,\n",
       "  1.2122613358297598,\n",
       "  -0.9823507224585204,\n",
       "  0.21090274685993154,\n",
       "  -0.05965058589736939,\n",
       "  1.2,\n",
       "  -0.8706636678054872],\n",
       " [-0.3165274196628514,\n",
       "  0.0,\n",
       "  1.2585836020806114,\n",
       "  -0.25910862781944816,\n",
       "  -1.6167963696554923,\n",
       "  1.3340767061053989,\n",
       "  1.1,\n",
       "  0.8781818729634856],\n",
       " [-1.420665069703904,\n",
       "  0.0,\n",
       "  0.8601085666399783,\n",
       "  1.9125506559296175,\n",
       "  0.43314417428742547,\n",
       "  -0.36892199414452315,\n",
       "  1.1,\n",
       "  -1.9168438698595043],\n",
       " [-0.4915049401162831,\n",
       "  4.0,\n",
       "  1.3704722079513938,\n",
       "  1.313611554451208,\n",
       "  0.6924557634336465,\n",
       "  0.5800638733478541,\n",
       "  1.2,\n",
       "  0.7799837455737902],\n",
       " [-0.028325352173307516,\n",
       "  3.0,\n",
       "  -0.4512665486645845,\n",
       "  1.3820014742219175,\n",
       "  -0.29592822069816693,\n",
       "  1.428877896549874,\n",
       "  0.95,\n",
       "  0.4043735923950466],\n",
       " [1.2549645915157261,\n",
       "  5.0,\n",
       "  0.2392226634689928,\n",
       "  0.348207373926388,\n",
       "  -0.6318867959876824,\n",
       "  0.6914513700408668,\n",
       "  0.85,\n",
       "  -1.3682595997327167],\n",
       " [0.2224419628355293,\n",
       "  0.0,\n",
       "  0.02764251940639688,\n",
       "  -0.827392918159189,\n",
       "  0.4974560543168001,\n",
       "  -0.5174781062395148,\n",
       "  1.1,\n",
       "  -0.07809198621318918],\n",
       " [1.010845659650615,\n",
       "  4.0,\n",
       "  -0.7881676265539026,\n",
       "  -0.21108646483309013,\n",
       "  0.4731627896181889,\n",
       "  -0.16428673069465874,\n",
       "  1.2,\n",
       "  0.030514885338288607],\n",
       " [0.021045576097556903,\n",
       "  2.0,\n",
       "  -0.07661099436986592,\n",
       "  -0.1687048837641771,\n",
       "  -2.40604542465937,\n",
       "  1.0052884169717404,\n",
       "  1.05,\n",
       "  0.60234849417014],\n",
       " [1.7842342145758356,\n",
       "  4.0,\n",
       "  1.0048155452054963,\n",
       "  -0.6015315855049345,\n",
       "  0.9386209920003917,\n",
       "  1.4712646366503532,\n",
       "  1.2,\n",
       "  0.994985377568406],\n",
       " [1.6286457631027893,\n",
       "  3.0,\n",
       "  -0.878046324617708,\n",
       "  1.007767016074292,\n",
       "  0.13793416609031486,\n",
       "  -0.2853712852821113,\n",
       "  0.95,\n",
       "  -1.541005504803161],\n",
       " [1.500331082516954,\n",
       "  3.0,\n",
       "  0.17645440136756513,\n",
       "  1.3430093168364106,\n",
       "  0.940200842094099,\n",
       "  -1.658342583843629,\n",
       "  0.95,\n",
       "  0.30694039234367837],\n",
       " [-1.1445050686237073,\n",
       "  0.0,\n",
       "  1.220722068319817,\n",
       "  -0.8414857235968798,\n",
       "  -1.2473322698496017,\n",
       "  0.6555421567238309,\n",
       "  1.1,\n",
       "  1.063703969005531],\n",
       " [1.2572746604481502,\n",
       "  4.0,\n",
       "  1.3835230390284965,\n",
       "  1.2652407059677335,\n",
       "  -2.7874997934455044,\n",
       "  -0.7347896840974468,\n",
       "  1.2,\n",
       "  -0.4033112173397519],\n",
       " [-1.646782067214933,\n",
       "  2.0,\n",
       "  -0.27467876166365457,\n",
       "  -1.2952763920783419,\n",
       "  0.4962569056372118,\n",
       "  0.4043659324720193,\n",
       "  1.05,\n",
       "  1.0307694505629834],\n",
       " [-1.257007578734734,\n",
       "  4.0,\n",
       "  1.2572850995890625,\n",
       "  -0.36452891639498747,\n",
       "  -1.8059909090364974,\n",
       "  0.4335786340466744,\n",
       "  1.2,\n",
       "  -1.4200583401464766],\n",
       " [-1.1716511975133954,\n",
       "  2.0,\n",
       "  0.14353277871307696,\n",
       "  -0.4196087005341536,\n",
       "  0.50047810788251,\n",
       "  0.41446142185308826,\n",
       "  1.05,\n",
       "  -0.23917547693996843],\n",
       " [-1.4655514510200838,\n",
       "  0.0,\n",
       "  -0.29248927430410954,\n",
       "  -0.3785463105354898,\n",
       "  -1.0063916762578493,\n",
       "  0.20764845741093554,\n",
       "  1.1,\n",
       "  -1.3893999971897195],\n",
       " [-1.5549758272549472,\n",
       "  2.0,\n",
       "  0.41534881595409656,\n",
       "  1.3144266077755828,\n",
       "  0.013274676457097697,\n",
       "  -0.19512521975479535,\n",
       "  1.05,\n",
       "  -0.4617652323622564],\n",
       " [-0.5580462311530462,\n",
       "  2.0,\n",
       "  0.46101474422541694,\n",
       "  0.7515002230666837,\n",
       "  -0.9474171664980242,\n",
       "  0.09493991715547821,\n",
       "  1.05,\n",
       "  0.8271299463178415],\n",
       " [-1.7261677691437078,\n",
       "  3.0,\n",
       "  -0.6665999639345621,\n",
       "  -0.3773188016742186,\n",
       "  0.20882206137394366,\n",
       "  1.6256268448903144,\n",
       "  0.95,\n",
       "  0.15332587373332915],\n",
       " [1.6455856945228484,\n",
       "  0.0,\n",
       "  -1.6856614034635984,\n",
       "  -0.5459711225471922,\n",
       "  -0.04293052937196267,\n",
       "  -0.8743970193063177,\n",
       "  1.1,\n",
       "  -0.7551874043637811],\n",
       " [0.01024454179877056,\n",
       "  2.0,\n",
       "  0.7804864732453193,\n",
       "  0.6178574205852077,\n",
       "  -0.6948802326256077,\n",
       "  -1.7871388126303087,\n",
       "  1.05,\n",
       "  0.7450634670152935],\n",
       " [-0.25228432119023425,\n",
       "  1.0,\n",
       "  0.8814774569915567,\n",
       "  -0.5971824829010631,\n",
       "  -0.953558973801876,\n",
       "  -0.4731550021893359,\n",
       "  0.9,\n",
       "  0.013716132855638793],\n",
       " [1.0470820390816942,\n",
       "  2.0,\n",
       "  -0.7539873196996599,\n",
       "  0.4727494752319768,\n",
       "  -1.568268569760839,\n",
       "  0.3737854667222296,\n",
       "  1.05,\n",
       "  0.8093057672018781],\n",
       " [1.1158610257509187,\n",
       "  3.0,\n",
       "  -0.4968142065511101,\n",
       "  1.571416107262762,\n",
       "  0.5865200150682028,\n",
       "  -0.10218502297497123,\n",
       "  0.95,\n",
       "  0.816571518378453],\n",
       " [-0.8045789524898098,\n",
       "  0.0,\n",
       "  0.9043553016537834,\n",
       "  1.8033127370173567,\n",
       "  -3.45964472143575,\n",
       "  0.43728679799522135,\n",
       "  1.1,\n",
       "  0.6897700367506051],\n",
       " [-1.5105888694031375,\n",
       "  2.0,\n",
       "  1.4848021109723188,\n",
       "  0.8249810871034309,\n",
       "  0.9089062168367811,\n",
       "  0.9746537136308153,\n",
       "  1.05,\n",
       "  0.47898483900884303],\n",
       " [-0.16225970766602624,\n",
       "  5.0,\n",
       "  0.043904187659939836,\n",
       "  -1.3544511133567378,\n",
       "  -0.5276253514192032,\n",
       "  -0.028655009359012478,\n",
       "  0.85,\n",
       "  -1.6816704842748478],\n",
       " [0.6716258462468689,\n",
       "  4.0,\n",
       "  -1.4492258081205511,\n",
       "  -0.696212479147495,\n",
       "  0.9678512339806495,\n",
       "  0.41135487199828735,\n",
       "  1.2,\n",
       "  -0.35201763474393977],\n",
       " [0.7407726964385011,\n",
       "  0.0,\n",
       "  0.7095893466158049,\n",
       "  0.02516022443616773,\n",
       "  0.4940476206990503,\n",
       "  -1.919756512943565,\n",
       "  1.1,\n",
       "  -0.2740582520818751],\n",
       " [-0.022142304626192363,\n",
       "  3.0,\n",
       "  0.2776062284613569,\n",
       "  -0.6330048678290835,\n",
       "  0.35923079750009207,\n",
       "  -0.00032974165366088745,\n",
       "  0.95,\n",
       "  0.48856311663068763],\n",
       " [1.754548165741167,\n",
       "  0.0,\n",
       "  -1.2875976947631487,\n",
       "  -0.0346895832558361,\n",
       "  0.9014370795491664,\n",
       "  -1.732917954292428,\n",
       "  1.1,\n",
       "  1.0646642468026046],\n",
       " [0.7252058872879639,\n",
       "  1.0,\n",
       "  0.7040944557817971,\n",
       "  -1.2733733700550598,\n",
       "  -1.28358748577593,\n",
       "  0.29633810463686927,\n",
       "  0.9,\n",
       "  -0.4376359769018641],\n",
       " [0.3888949763253302,\n",
       "  3.0,\n",
       "  0.12625934202180003,\n",
       "  0.27666715271585285,\n",
       "  0.11405475788126276,\n",
       "  -1.4501758879035924,\n",
       "  0.95,\n",
       "  -1.2027438115873732],\n",
       " [0.47596376169995724,\n",
       "  5.0,\n",
       "  -0.5721888925092743,\n",
       "  -0.5586299098407931,\n",
       "  -0.9482685740215782,\n",
       "  1.265145784844382,\n",
       "  0.85,\n",
       "  0.319423795906176],\n",
       " [-1.0380532511214071,\n",
       "  2.0,\n",
       "  0.7432350803640766,\n",
       "  1.5273307033292804,\n",
       "  0.3125360959125313,\n",
       "  1.1030774075835406,\n",
       "  1.05,\n",
       "  0.05454420383973642],\n",
       " [1.1665984578960864,\n",
       "  2.0,\n",
       "  -0.4167959188905132,\n",
       "  -0.6203323319251952,\n",
       "  -1.5298832390664443,\n",
       "  0.0180304907784947,\n",
       "  1.05,\n",
       "  1.0597392797427623],\n",
       " [0.530464682296908,\n",
       "  0.0,\n",
       "  1.0237062827485715,\n",
       "  1.0054364803740607,\n",
       "  -0.27012351452849337,\n",
       "  1.3409964109704835,\n",
       "  1.1,\n",
       "  0.6586076114375518],\n",
       " [0.19443604613916207,\n",
       "  1.0,\n",
       "  -0.805436445723745,\n",
       "  -1.189990091560255,\n",
       "  0.9306039837060887,\n",
       "  -0.09179312071253722,\n",
       "  0.9,\n",
       "  0.7896275428574625],\n",
       " [0.6666425319110403,\n",
       "  3.0,\n",
       "  1.400052049714298,\n",
       "  0.2717442588448678,\n",
       "  -1.8532827955283024,\n",
       "  0.6721028436359648,\n",
       "  0.95,\n",
       "  0.27636492484372677],\n",
       " [1.6640073253304601,\n",
       "  2.0,\n",
       "  1.6299675647937024,\n",
       "  0.8260720383767558,\n",
       "  0.22393303952196364,\n",
       "  -0.5751188499266298,\n",
       "  1.05,\n",
       "  -0.22347489250177224],\n",
       " [-0.5648567653712838,\n",
       "  4.0,\n",
       "  1.6720684440387898,\n",
       "  -0.6953998401885179,\n",
       "  0.3546750005547552,\n",
       "  1.222866700821583,\n",
       "  1.2,\n",
       "  0.9412214561336546],\n",
       " [1.2805392907702773,\n",
       "  5.0,\n",
       "  -0.13063357493960895,\n",
       "  -1.2220728115780093,\n",
       "  0.1924290228442682,\n",
       "  -0.3253432164320946,\n",
       "  0.85,\n",
       "  0.5170357156866192],\n",
       " [1.181991763224012,\n",
       "  1.0,\n",
       "  -0.23899098794483384,\n",
       "  1.1234352318566623,\n",
       "  0.5346416262315282,\n",
       "  -0.5486655241747739,\n",
       "  0.9,\n",
       "  0.37272835016040046],\n",
       " [1.4179212840719342,\n",
       "  1.0,\n",
       "  1.1743270129735917,\n",
       "  -0.5697555151725905,\n",
       "  0.7037861107673734,\n",
       "  -0.6292854190981471,\n",
       "  0.9,\n",
       "  1.05492810674778],\n",
       " [0.588878007261854,\n",
       "  3.0,\n",
       "  -0.4307180196157247,\n",
       "  0.278740129369443,\n",
       "  1.136915182104095,\n",
       "  -0.2872147151718676,\n",
       "  0.95,\n",
       "  -0.41087776799457615],\n",
       " [-1.3810346018587805,\n",
       "  2.0,\n",
       "  -0.3322074096202004,\n",
       "  -0.3211413562660578,\n",
       "  0.06895681151870295,\n",
       "  -0.0092175244659917,\n",
       "  1.05,\n",
       "  0.4416813726362318],\n",
       " [0.6189096339958201,\n",
       "  4.0,\n",
       "  0.4284613782559124,\n",
       "  0.9980904318240855,\n",
       "  -0.241414916979988,\n",
       "  0.811858410855867,\n",
       "  1.2,\n",
       "  -1.4908519438585164],\n",
       " [1.6584141214228585,\n",
       "  2.0,\n",
       "  0.4414120859521989,\n",
       "  -0.6258118403090493,\n",
       "  1.0380705149027871,\n",
       "  1.010805062554592,\n",
       "  1.05,\n",
       "  0.6744990338117368],\n",
       " [1.177338554094659,\n",
       "  1.0,\n",
       "  -0.3102517881016138,\n",
       "  1.036430390852575,\n",
       "  0.4374325018358578,\n",
       "  -0.4894673758512055,\n",
       "  0.9,\n",
       "  0.38985031060479114],\n",
       " [-0.0782596941760649,\n",
       "  2.0,\n",
       "  -1.5267650879482013,\n",
       "  -1.418457062254147,\n",
       "  -0.32101002673827633,\n",
       "  0.6463079622776032,\n",
       "  1.05,\n",
       "  0.7747577292451999],\n",
       " [0.8533287475224631,\n",
       "  4.0,\n",
       "  1.3717704118471459,\n",
       "  -0.6266607528227823,\n",
       "  0.3629469601615219,\n",
       "  1.5032126443452183,\n",
       "  1.2,\n",
       "  0.21920310371040488],\n",
       " [-1.7021594350058604,\n",
       "  4.0,\n",
       "  1.1396431459210976,\n",
       "  -1.0775718788254305,\n",
       "  -0.4768516567890538,\n",
       "  1.1417591446723523,\n",
       "  1.2,\n",
       "  -1.2142928868712108],\n",
       " [1.6208736748164374,\n",
       "  0.0,\n",
       "  1.625039033410804,\n",
       "  1.040015033573462,\n",
       "  -0.465604644652811,\n",
       "  0.2402991876634544,\n",
       "  1.1,\n",
       "  -0.05868833253479994],\n",
       " [1.4189725573388612,\n",
       "  3.0,\n",
       "  1.009443504000734,\n",
       "  -1.081414714686015,\n",
       "  0.635538727698037,\n",
       "  1.0471367489824488,\n",
       "  0.95,\n",
       "  -1.5993878371241623],\n",
       " [0.08280962822814315,\n",
       "  5.0,\n",
       "  0.0008735600812381916,\n",
       "  0.3480560008671778,\n",
       "  0.5310422738445344,\n",
       "  -1.0880063957366808,\n",
       "  0.85,\n",
       "  -1.6987387375056573],\n",
       " [-0.14224519779949374,\n",
       "  0.0,\n",
       "  -0.4635070425343647,\n",
       "  -0.8678951675026844,\n",
       "  0.9706224549325411,\n",
       "  -1.0286351373487248,\n",
       "  1.1,\n",
       "  1.3498023099707244],\n",
       " [-0.7063233494041307,\n",
       "  1.0,\n",
       "  -1.0964048607623718,\n",
       "  -1.0753819944420453,\n",
       "  0.3661832804554425,\n",
       "  -0.14789879699997313,\n",
       "  0.9,\n",
       "  0.42377846472813896],\n",
       " [0.4690390628391084,\n",
       "  3.0,\n",
       "  -0.017016844644743005,\n",
       "  0.052406245582213316,\n",
       "  0.34076751811831535,\n",
       "  -0.9398104771516395,\n",
       "  0.95,\n",
       "  -1.3840148764152287],\n",
       " [1.6206031651599944,\n",
       "  4.0,\n",
       "  -0.9701368361487174,\n",
       "  -1.3536311054460168,\n",
       "  -1.9378651691259845,\n",
       "  -0.1660195436645398,\n",
       "  1.2,\n",
       "  -0.9925549499069085],\n",
       " [0.6256471556894683,\n",
       "  4.0,\n",
       "  0.7563387968980269,\n",
       "  -1.2957463345230302,\n",
       "  0.8724174677214973,\n",
       "  0.23173358899899,\n",
       "  1.2,\n",
       "  -0.3003613375881339],\n",
       " [1.8940844639613723,\n",
       "  0.0,\n",
       "  -1.3389945927301867,\n",
       "  1.4685105717096956,\n",
       "  0.3480756723292062,\n",
       "  -1.7365240538447286,\n",
       "  1.1,\n",
       "  0.09061529010315181],\n",
       " [-1.7693523019432902,\n",
       "  4.0,\n",
       "  1.6840162853805218,\n",
       "  0.45147079797617684,\n",
       "  0.3091818121800672,\n",
       "  -0.8276209660114906,\n",
       "  1.2,\n",
       "  -1.1503021802827822],\n",
       " [0.3777677639602737,\n",
       "  3.0,\n",
       "  0.7032430433110736,\n",
       "  0.6651770951568586,\n",
       "  0.5498438634956703,\n",
       "  -0.7823935339767016,\n",
       "  0.95,\n",
       "  0.7156318958488916],\n",
       " [0.12968952999755246,\n",
       "  1.0,\n",
       "  0.41456527611543825,\n",
       "  -1.0064988794663852,\n",
       "  0.519044282409627,\n",
       "  1.2641650990336024,\n",
       "  0.9,\n",
       "  1.061956370702821],\n",
       " [0.5814833775425966,\n",
       "  3.0,\n",
       "  -0.21352882585998767,\n",
       "  1.1253282972727252,\n",
       "  -0.9772360155355385,\n",
       "  0.10105858613379312,\n",
       "  0.95,\n",
       "  0.645033266120767],\n",
       " [-1.5555847488436676,\n",
       "  3.0,\n",
       "  0.9406836569010357,\n",
       "  -0.045709224269016066,\n",
       "  0.9803524059609903,\n",
       "  1.2845219927624907,\n",
       "  0.95,\n",
       "  0.44258450017536954],\n",
       " [1.470365533075818,\n",
       "  2.0,\n",
       "  -1.6760972476678524,\n",
       "  -1.103995222447347,\n",
       "  -0.21644066900209535,\n",
       "  0.039607136320661235,\n",
       "  1.05,\n",
       "  0.21311749708140945],\n",
       " [-0.6131669026640827,\n",
       "  0.0,\n",
       "  -1.229573607756723,\n",
       "  1.7074954608866697,\n",
       "  0.5860644349382185,\n",
       "  0.17366268880590557,\n",
       "  1.1,\n",
       "  -1.6046226707228075],\n",
       " [0.7756732524428238,\n",
       "  1.0,\n",
       "  -0.1421143511464034,\n",
       "  0.3963397843594989,\n",
       "  0.38539158448013616,\n",
       "  -0.8993602172459728,\n",
       "  0.9,\n",
       "  0.9418560764753233],\n",
       " [1.4817420800298007,\n",
       "  5.0,\n",
       "  0.4126427819264995,\n",
       "  -0.841364540741543,\n",
       "  0.16641786450386079,\n",
       "  0.2734186890992447,\n",
       "  0.85,\n",
       "  0.7090658086199995],\n",
       " [-1.5821877219526381,\n",
       "  1.0,\n",
       "  -1.6536707234494112,\n",
       "  -1.356847927191692,\n",
       "  0.7026312158450368,\n",
       "  -0.21990923448114072,\n",
       "  0.9,\n",
       "  -1.4695482018588475],\n",
       " [1.5003053300711597,\n",
       "  2.0,\n",
       "  0.09854595393415054,\n",
       "  -0.9891235543822652,\n",
       "  -0.3777166828386376,\n",
       "  0.14944363592118226,\n",
       "  1.05,\n",
       "  -1.9622082591507093],\n",
       " [1.3588283915014914,\n",
       "  5.0,\n",
       "  -0.19736777061513602,\n",
       "  -1.1570704343118658,\n",
       "  -0.6010931705030975,\n",
       "  -1.890554628900701,\n",
       "  0.85,\n",
       "  -1.5179860031232848],\n",
       " [1.358674002241166,\n",
       "  4.0,\n",
       "  -0.36661648870287156,\n",
       "  1.6106658444897355,\n",
       "  -1.1704290467705434,\n",
       "  0.17819077230295843,\n",
       "  1.2,\n",
       "  0.7855386124144579],\n",
       " [-1.0643540737130828,\n",
       "  3.0,\n",
       "  0.019620991698930043,\n",
       "  -1.0863146977384026,\n",
       "  0.8641555763693733,\n",
       "  1.58551458741347,\n",
       "  0.95,\n",
       "  0.8787971396975568],\n",
       " [-0.15815773021330878,\n",
       "  2.0,\n",
       "  1.4484153948257867,\n",
       "  -1.303385134860994,\n",
       "  -0.2039684245030119,\n",
       "  0.6711086430431767,\n",
       "  1.05,\n",
       "  1.2983354409415233],\n",
       " [1.3157512504065731,\n",
       "  5.0,\n",
       "  0.6031358086494015,\n",
       "  -0.30853935450210085,\n",
       "  0.9985152432168543,\n",
       "  -0.26103117387302954,\n",
       "  0.85,\n",
       "  0.9234872041387872],\n",
       " [-0.31919073021685207,\n",
       "  0.0,\n",
       "  0.9767217898459856,\n",
       "  0.17994544258630382,\n",
       "  -1.3794652094660742,\n",
       "  0.7816079117343967,\n",
       "  1.1,\n",
       "  0.825680989589634],\n",
       " [0.9088461168131088,\n",
       "  5.0,\n",
       "  -1.0786164153620998,\n",
       "  0.23597360540542947,\n",
       "  0.8570149083554283,\n",
       "  -1.8655188321559792,\n",
       "  0.85,\n",
       "  0.45837034545442706],\n",
       " [-0.21922718769397526,\n",
       "  1.0,\n",
       "  0.6003697670173971,\n",
       "  -0.2839184014652548,\n",
       "  0.9684634711386846,\n",
       "  0.9938885823981864,\n",
       "  0.9,\n",
       "  -1.8141790792177177],\n",
       " [1.7371428012121963,\n",
       "  4.0,\n",
       "  -1.5025297883778213,\n",
       "  -0.15817605581210573,\n",
       "  0.8714788469342839,\n",
       "  1.561708098733661,\n",
       "  1.2,\n",
       "  4.02103488484536],\n",
       " [-1.3300804476201336,\n",
       "  3.0,\n",
       "  1.3827835844734637,\n",
       "  1.1674816984941836,\n",
       "  0.10051088495792161,\n",
       "  0.0020002697948256726,\n",
       "  0.95,\n",
       "  -1.6693534368891358],\n",
       " [0.1381466454619123,\n",
       "  1.0,\n",
       "  -0.6960269646603053,\n",
       "  1.0848593347349769,\n",
       "  0.46519796555361426,\n",
       "  -1.1064334290651199,\n",
       "  0.9,\n",
       "  -1.9164590680561964],\n",
       " [-1.0350416909931681,\n",
       "  3.0,\n",
       "  -0.6882004856974568,\n",
       "  -0.16985443139579948,\n",
       "  0.029472800002509566,\n",
       "  -0.022953691628014257,\n",
       "  0.95,\n",
       "  -1.3452933954127464],\n",
       " [-1.5089434226969842,\n",
       "  0.0,\n",
       "  -0.6106249644894001,\n",
       "  -0.7735390270142474,\n",
       "  -0.1318426269653536,\n",
       "  0.2773674383854184,\n",
       "  1.1,\n",
       "  1.0626363808765],\n",
       " [-0.06414754297496358,\n",
       "  1.0,\n",
       "  -1.0912340165413845,\n",
       "  -0.48578123141419893,\n",
       "  -0.21259748844562587,\n",
       "  -1.7625843884446655,\n",
       "  0.9,\n",
       "  1.0532027995696496],\n",
       " [-1.087874551368503,\n",
       "  5.0,\n",
       "  0.8756810722608245,\n",
       "  -0.47035634704000573,\n",
       "  0.30502850713380414,\n",
       "  0.23578193809502232,\n",
       "  0.85,\n",
       "  -1.372755781562169],\n",
       " [0.025581649845444438,\n",
       "  1.0,\n",
       "  0.3985145985353692,\n",
       "  -0.15155842202546874,\n",
       "  -1.3204628703889223,\n",
       "  1.0992429564073054,\n",
       "  0.9,\n",
       "  1.0892215418055118],\n",
       " [1.1647179879546197,\n",
       "  2.0,\n",
       "  0.23787415538383672,\n",
       "  -0.01608161475449409,\n",
       "  0.9642443794141955,\n",
       "  1.7802006788359825,\n",
       "  1.05,\n",
       "  1.1388433927235313],\n",
       " [-0.2588303606862005,\n",
       "  3.0,\n",
       "  0.03328495792402525,\n",
       "  0.163644238715828,\n",
       "  0.9436262554831566,\n",
       "  1.474797573434591,\n",
       "  0.95,\n",
       "  0.6446847316270242],\n",
       " [1.3176029914776954,\n",
       "  5.0,\n",
       "  0.2965273754389059,\n",
       "  -0.3504397600097497,\n",
       "  0.9588767076563569,\n",
       "  -1.3144622765931042,\n",
       "  0.85,\n",
       "  -0.6754850923341063],\n",
       " [0.8212228749454928,\n",
       "  4.0,\n",
       "  1.0754893775645336,\n",
       "  -0.9370112404634434,\n",
       "  0.6565990314896845,\n",
       "  -1.68191088441578,\n",
       "  1.2,\n",
       "  0.9273834134118565],\n",
       " [0.027611667526495135,\n",
       "  0.0,\n",
       "  0.3752286957938365,\n",
       "  -0.8814251949399962,\n",
       "  -0.2271761725426281,\n",
       "  -0.5065184185845549,\n",
       "  1.1,\n",
       "  0.9934637877158695],\n",
       " [1.526419238450985,\n",
       "  2.0,\n",
       "  -0.6550621805952535,\n",
       "  1.143286432884104,\n",
       "  0.9778866569310554,\n",
       "  -1.1194674929555137,\n",
       "  1.05,\n",
       "  -1.9986529944521185],\n",
       " [0.5613211181981244,\n",
       "  4.0,\n",
       "  -1.5148903971382057,\n",
       "  -1.1806468772720304,\n",
       "  -0.6529893951193972,\n",
       "  0.01507165255878542,\n",
       "  1.2,\n",
       "  -0.43646267922334225],\n",
       " [0.3199397420093793,\n",
       "  2.0,\n",
       "  -1.1601890100663017,\n",
       "  0.7263739003004052,\n",
       "  -2.3775257624149315,\n",
       "  1.4145432694560685,\n",
       "  1.05,\n",
       "  0.6977029928480655],\n",
       " [1.5036545877292689,\n",
       "  1.0,\n",
       "  -1.1509692665898765,\n",
       "  -0.7560477716887964,\n",
       "  -0.2803384704292674,\n",
       "  -1.9047921689293246,\n",
       "  0.9,\n",
       "  0.5299375818563865],\n",
       " [0.9976473396055205,\n",
       "  1.0,\n",
       "  0.042707671633955245,\n",
       "  -0.36607375487355276,\n",
       "  -0.06151273654729343,\n",
       "  1.8648871680928543,\n",
       "  0.9,\n",
       "  0.663077239769053],\n",
       " [-0.06505921678590584,\n",
       "  5.0,\n",
       "  -0.27676431839681953,\n",
       "  1.8190859678565288,\n",
       "  -1.8354810285286343,\n",
       "  1.6857894137099274,\n",
       "  0.85,\n",
       "  -1.614600686290104],\n",
       " [1.3811234234475365,\n",
       "  2.0,\n",
       "  1.5652608404589092,\n",
       "  -0.6827551503158267,\n",
       "  -0.309416224850363,\n",
       "  1.2387017708667727,\n",
       "  1.05,\n",
       "  0.6909132623869025],\n",
       " [1.8407251118169663,\n",
       "  5.0,\n",
       "  -1.2500124556131638,\n",
       "  0.7241660214711692,\n",
       "  0.04596795824024817,\n",
       "  -0.6025822393963259,\n",
       "  0.85,\n",
       "  1.0139024984052623],\n",
       " [-0.8710360645008569,\n",
       "  1.0,\n",
       "  1.0898535697145912,\n",
       "  0.5319210107934077,\n",
       "  0.4094269352104755,\n",
       "  0.3619743337667277,\n",
       "  0.9,\n",
       "  -1.8864816856901736],\n",
       " [0.16428447799774204,\n",
       "  3.0,\n",
       "  0.25724945030633933,\n",
       "  0.2908755012142732,\n",
       "  0.2335261667212522,\n",
       "  0.6691055172928745,\n",
       "  0.95,\n",
       "  0.7710301904973053],\n",
       " [1.4204314829697926,\n",
       "  4.0,\n",
       "  1.627623444814191,\n",
       "  0.40749126416865816,\n",
       "  -0.8119370808799866,\n",
       "  1.020781593128102,\n",
       "  1.2,\n",
       "  1.0366234066412356],\n",
       " [-1.1298100460427465,\n",
       "  1.0,\n",
       "  -1.1514798657123768,\n",
       "  1.5591179087358238,\n",
       "  -1.7696177200709398,\n",
       "  0.5392219339940519,\n",
       "  0.9,\n",
       "  0.9323954929162375],\n",
       " [-0.7496565011208915,\n",
       "  0.0,\n",
       "  0.4571739465355353,\n",
       "  -1.3216099567916746,\n",
       "  0.6191236129002292,\n",
       "  -0.0463757837606319,\n",
       "  1.1,\n",
       "  1.0653207815957761],\n",
       " [0.2659887952164432,\n",
       "  0.0,\n",
       "  -0.5195796190523244,\n",
       "  0.8897573503876044,\n",
       "  0.9230796462071804,\n",
       "  -0.4362542060284434,\n",
       "  1.1,\n",
       "  3.1851439237385764],\n",
       " [-1.4257860947162522,\n",
       "  3.0,\n",
       "  -1.4364862448042615,\n",
       "  -0.35025693910730155,\n",
       "  -0.7548291651834513,\n",
       "  1.9762533540780745,\n",
       "  0.95,\n",
       "  -1.6418107775611182],\n",
       " [-1.5450947731019407,\n",
       "  3.0,\n",
       "  1.0318339003118828,\n",
       "  -0.5284495330645965,\n",
       "  0.7609276894985006,\n",
       "  0.44502426506511844,\n",
       "  0.95,\n",
       "  0.8490597107477336],\n",
       " [-0.209271840838818,\n",
       "  1.0,\n",
       "  -0.9803878161925063,\n",
       "  0.5139207093031818,\n",
       "  0.1450938820652166,\n",
       "  1.7356098306413696,\n",
       "  0.9,\n",
       "  0.9991343050640974],\n",
       " [0.16264093256360307,\n",
       "  0.0,\n",
       "  0.18341028817178287,\n",
       "  1.3441666430770642,\n",
       "  -1.059465655108329,\n",
       "  0.5454461212889871,\n",
       "  1.1,\n",
       "  -0.9865556498965097],\n",
       " [1.5023760072851682,\n",
       "  4.0,\n",
       "  0.12163758856690728,\n",
       "  1.2800823175805698,\n",
       "  -0.5965412198522211,\n",
       "  1.5573780531391335,\n",
       "  1.2,\n",
       "  -0.34905789408979676],\n",
       " [-0.4827692888300954,\n",
       "  3.0,\n",
       "  1.1160951732182005,\n",
       "  0.09280232638911069,\n",
       "  -0.9944810894547346,\n",
       "  0.7156905449459112,\n",
       "  0.95,\n",
       "  1.585852181287676],\n",
       " [-1.361493220247517,\n",
       "  0.0,\n",
       "  1.176181169429868,\n",
       "  -0.6299846650543772,\n",
       "  -0.523369912641054,\n",
       "  -0.28294447506395504,\n",
       "  1.1,\n",
       "  -0.11061319550158236],\n",
       " [-1.7207252331387506,\n",
       "  0.0,\n",
       "  0.3425935895166147,\n",
       "  1.9895565823087566,\n",
       "  0.2827882581635554,\n",
       "  -0.5164317397826376,\n",
       "  1.1,\n",
       "  1.145304009677102],\n",
       " [-0.48124186380513734,\n",
       "  3.0,\n",
       "  -0.17354464192756297,\n",
       "  1.1450536417958792,\n",
       "  -3.282648381569402,\n",
       "  -1.1714171443768504,\n",
       "  0.95,\n",
       "  -0.24936769600506456],\n",
       " [-0.8752548802550383,\n",
       "  0.0,\n",
       "  -0.9107838113569817,\n",
       "  -1.1834276362876748,\n",
       "  0.2952339125860755,\n",
       "  0.387917587375321,\n",
       "  1.1,\n",
       "  -0.07344585880990978],\n",
       " [1.4761739849898545,\n",
       "  2.0,\n",
       "  1.2117823938554022,\n",
       "  1.7098067953273652,\n",
       "  0.40192668674198734,\n",
       "  0.27327732311926245,\n",
       "  1.05,\n",
       "  0.9067172667408265],\n",
       " [-1.067527679211258,\n",
       "  5.0,\n",
       "  1.5905945167398974,\n",
       "  -1.053413789280283,\n",
       "  0.9224435275976574,\n",
       "  -1.239754852386034,\n",
       "  0.85,\n",
       "  0.8395284831100386],\n",
       " [-0.7699138272362465,\n",
       "  0.0,\n",
       "  0.779371268759673,\n",
       "  1.1650292264049886,\n",
       "  0.9068143919653138,\n",
       "  -1.1035941442441592,\n",
       "  1.1,\n",
       "  0.17857813226505578],\n",
       " [-0.9339235821618215,\n",
       "  1.0,\n",
       "  -0.048908908568783896,\n",
       "  -0.8051415109225551,\n",
       "  -3.5567145550582144,\n",
       "  -0.1904962813232983,\n",
       "  0.9,\n",
       "  0.8940579386799075],\n",
       " [0.6784819740308305,\n",
       "  2.0,\n",
       "  -0.42534205987900137,\n",
       "  -1.1620891464432381,\n",
       "  0.6969137658567109,\n",
       "  1.2092212385922343,\n",
       "  1.05,\n",
       "  -1.2521223465181832],\n",
       " [-1.3699103777955348,\n",
       "  5.0,\n",
       "  -1.475906946076645,\n",
       "  -1.3152727763735041,\n",
       "  -0.7649051585555495,\n",
       "  1.0211275761973315,\n",
       "  0.85,\n",
       "  -0.06541502619586306],\n",
       " [-0.7050161430159609,\n",
       "  0.0,\n",
       "  -1.0853824488983932,\n",
       "  -0.22266460865284665,\n",
       "  0.663252116238029,\n",
       "  -1.3063322292637272,\n",
       "  1.1,\n",
       "  1.0094032365793406],\n",
       " [0.8678432413689291,\n",
       "  4.0,\n",
       "  1.1256743055398932,\n",
       "  0.5813527184259465,\n",
       "  0.6366110267727382,\n",
       "  0.4492279129822024,\n",
       "  1.2,\n",
       "  -0.7676674792829482],\n",
       " [-0.7742647667249709,\n",
       "  0.0,\n",
       "  -1.190417082756597,\n",
       "  0.2231300535962322,\n",
       "  -1.9323490661731615,\n",
       "  -1.161298643727385,\n",
       "  1.1,\n",
       "  0.3422497513013412],\n",
       " [0.3976895622854749,\n",
       "  0.0,\n",
       "  1.6043199375260586,\n",
       "  0.8303376652164616,\n",
       "  0.8264610710162553,\n",
       "  -0.35620166607007914,\n",
       "  1.1,\n",
       "  -0.06533648215433234],\n",
       " [-0.3947203773361497,\n",
       "  1.0,\n",
       "  -0.9088337821853965,\n",
       "  -0.5912713825248603,\n",
       "  0.5830379287623345,\n",
       "  -0.6690522069057081,\n",
       "  0.9,\n",
       "  -0.6523946508910564],\n",
       " [-0.6050603538274902,\n",
       "  1.0,\n",
       "  0.944110642956992,\n",
       "  -1.078594316765857,\n",
       "  0.3546274553915275,\n",
       "  1.9075926555665397,\n",
       "  0.9,\n",
       "  -1.4210633979391938],\n",
       " [0.11550101464750617,\n",
       "  2.0,\n",
       "  -1.3945521464386121,\n",
       "  0.6444451671198511,\n",
       "  -0.568482456059145,\n",
       "  0.8365204632673816,\n",
       "  1.05,\n",
       "  0.4130012958407769],\n",
       " [-1.632465034195534,\n",
       "  0.0,\n",
       "  0.9497997790919245,\n",
       "  0.220504723650612,\n",
       "  0.8029757938836716,\n",
       "  -0.7897217538641842,\n",
       "  1.1,\n",
       "  -0.9695428711764369],\n",
       " [0.8117806650024039,\n",
       "  1.0,\n",
       "  0.48790166094703896,\n",
       "  1.6009777947683863,\n",
       "  0.6557771660397278,\n",
       "  0.28857098418494137,\n",
       "  0.9,\n",
       "  -1.3162982341194656],\n",
       " [-0.26982801862321576,\n",
       "  2.0,\n",
       "  1.0382440129593795,\n",
       "  -1.3593582704229425,\n",
       "  0.8047360446139242,\n",
       "  0.8276811238456362,\n",
       "  1.05,\n",
       "  -0.2934059308708714],\n",
       " [1.2711313101055837,\n",
       "  3.0,\n",
       "  0.8242884011421667,\n",
       "  1.4037146035193668,\n",
       "  0.3838154704906803,\n",
       "  0.525904102705573,\n",
       "  0.95,\n",
       "  0.9691618177821661],\n",
       " [1.418165877313273,\n",
       "  0.0,\n",
       "  1.1695969614624042,\n",
       "  -0.6452826828774425,\n",
       "  0.6777933065527454,\n",
       "  0.09245402968827465,\n",
       "  1.1,\n",
       "  -1.6709294584651926],\n",
       " [-1.2719028908254393,\n",
       "  1.0,\n",
       "  1.633091292200294,\n",
       "  1.3338504870842225,\n",
       "  -2.1214449543036893,\n",
       "  0.08618286193589461,\n",
       "  0.9,\n",
       "  0.5918871223011811],\n",
       " [-1.061105290433253,\n",
       "  2.0,\n",
       "  -1.6448122471116484,\n",
       "  1.3451205718996715,\n",
       "  -2.488728067005698,\n",
       "  1.050866363532471,\n",
       "  1.05,\n",
       "  -0.43126968863498905],\n",
       " [-0.5354416036524667,\n",
       "  0.0,\n",
       "  -0.7150401546947119,\n",
       "  1.4490693559523073,\n",
       "  -2.1073147935033236,\n",
       "  0.4734648353939212,\n",
       "  1.1,\n",
       "  0.7052658254903952],\n",
       " [1.73891013015225,\n",
       "  5.0,\n",
       "  -1.386306968834605,\n",
       "  0.45709729911148,\n",
       "  -1.2221272140144457,\n",
       "  -1.7094263128386322,\n",
       "  0.85,\n",
       "  1.0112489430620906],\n",
       " [0.5329389300751776,\n",
       "  1.0,\n",
       "  1.0185573538611634,\n",
       "  1.0913488812697139,\n",
       "  0.621559882647568,\n",
       "  0.6050584075089009,\n",
       "  0.9,\n",
       "  1.0654211727647063],\n",
       " [0.10122471875050965,\n",
       "  5.0,\n",
       "  0.6072726386354087,\n",
       "  0.20027696503536466,\n",
       "  -1.3619584957439814,\n",
       "  0.5797808128646154,\n",
       "  0.85,\n",
       "  0.0509151472023175],\n",
       " [0.5626444676138509,\n",
       "  3.0,\n",
       "  -1.4430584077031925,\n",
       "  -1.0822368008060368,\n",
       "  0.42362160913539404,\n",
       "  1.6806774496068169,\n",
       "  0.95,\n",
       "  0.8582261475778838],\n",
       " [-1.642521854178948,\n",
       "  2.0,\n",
       "  0.1299363338661631,\n",
       "  -0.871651055162905,\n",
       "  0.3066882046847269,\n",
       "  -1.9734207181963064,\n",
       "  1.05,\n",
       "  -1.1935064881882507],\n",
       " [0.34782095187414014,\n",
       "  5.0,\n",
       "  0.34826310065253835,\n",
       "  0.017903205787024007,\n",
       "  0.06653406636855384,\n",
       "  0.6074629732898684,\n",
       "  0.85,\n",
       "  -0.48595883610491564],\n",
       " [1.549869870222647,\n",
       "  3.0,\n",
       "  -1.299536894697626,\n",
       "  -0.9419787891038066,\n",
       "  0.18820647848853134,\n",
       "  0.5317829954916228,\n",
       "  0.95,\n",
       "  -0.21604403053618232],\n",
       " [0.2537861563463005,\n",
       "  1.0,\n",
       "  -0.5280684538813223,\n",
       "  0.6320593215384175,\n",
       "  0.8820086974163082,\n",
       "  1.051445663570025,\n",
       "  0.9,\n",
       "  1.2785360760694293],\n",
       " [-1.337154126259837,\n",
       "  4.0,\n",
       "  -0.4177087015258098,\n",
       "  -0.4589511957535854,\n",
       "  0.3041830987777672,\n",
       "  -0.44868030803424563,\n",
       "  1.2,\n",
       "  -0.11955521673302824],\n",
       " [-0.5114822799065876,\n",
       "  1.0,\n",
       "  -0.25216754135336117,\n",
       "  0.7031003289377868,\n",
       "  -1.6110509415938228,\n",
       "  -0.9874708525601373,\n",
       "  0.9,\n",
       "  -1.8987962571593582],\n",
       " [-0.3043034325202316,\n",
       "  4.0,\n",
       "  1.4277123579902256,\n",
       "  -1.1698222997446446,\n",
       "  0.3478377530241832,\n",
       "  0.5401525475755682,\n",
       "  1.2,\n",
       "  0.8469622333344506],\n",
       " [0.5376973060495551,\n",
       "  5.0,\n",
       "  -0.5320497196164791,\n",
       "  -1.2362761773017958,\n",
       "  -0.22034335678381595,\n",
       "  1.3288953209159435,\n",
       "  0.85,\n",
       "  -0.2058006292267299],\n",
       " [0.9285410617957602,\n",
       "  0.0,\n",
       "  1.7333432310081442,\n",
       "  1.8996034564846207,\n",
       "  0.5944572176764978,\n",
       "  -1.296553108932101,\n",
       "  1.1,\n",
       "  0.5009215135512791],\n",
       " [-1.2930943347412351,\n",
       "  3.0,\n",
       "  -0.20933270479102764,\n",
       "  -0.22789119593455948,\n",
       "  -0.15664372971099638,\n",
       "  0.45628486113858135,\n",
       "  0.95,\n",
       "  -1.8557841673129383],\n",
       " [-0.9255318275508444,\n",
       "  5.0,\n",
       "  0.32893285133785377,\n",
       "  -1.4094705415802882,\n",
       "  0.9136190708105478,\n",
       "  1.0250389913500841,\n",
       "  0.85,\n",
       "  -0.37152450201310466],\n",
       " [1.6208948759053081,\n",
       "  0.0,\n",
       "  1.002055954203682,\n",
       "  -0.34216742351102747,\n",
       "  -3.7156749318663627,\n",
       "  0.19721258543266604,\n",
       "  1.1,\n",
       "  -1.6366822389917],\n",
       " [0.6833915647119805,\n",
       "  1.0,\n",
       "  1.2275221238821101,\n",
       "  -1.31161484501394,\n",
       "  0.7882446005538589,\n",
       "  0.23602955628411149,\n",
       "  0.9,\n",
       "  0.014634328762576535],\n",
       " [0.8093920263054808,\n",
       "  5.0,\n",
       "  0.8997072700720036,\n",
       "  -0.19113997337803185,\n",
       "  0.4248726676502121,\n",
       "  0.47146967878819573,\n",
       "  0.85,\n",
       "  0.7639768913035994],\n",
       " [-1.040137415360054,\n",
       "  5.0,\n",
       "  0.7892839253488805,\n",
       "  1.818683257448684,\n",
       "  0.830895147709509,\n",
       "  -1.8678457399830501,\n",
       "  0.85,\n",
       "  0.9445133722221489],\n",
       " [0.4032565601929526,\n",
       "  0.0,\n",
       "  1.5947227837794342,\n",
       "  -0.39024591529948366,\n",
       "  -0.5230004630776216,\n",
       "  -0.10151080492796465,\n",
       "  1.1,\n",
       "  0.8211704753676715],\n",
       " [-1.41627730094275,\n",
       "  5.0,\n",
       "  -1.0488112099114617,\n",
       "  1.3387371203749838,\n",
       "  0.9203907262579178,\n",
       "  0.9889536964665523,\n",
       "  0.85,\n",
       "  1.0474169209614188],\n",
       " [0.17681630961739608,\n",
       "  5.0,\n",
       "  0.8234788662694547,\n",
       "  -1.1696508805207273,\n",
       "  -0.44716488580839614,\n",
       "  1.968098264955409,\n",
       "  0.85,\n",
       "  -0.9748885964620967],\n",
       " [1.710243638469125,\n",
       "  1.0,\n",
       "  1.617111416353045,\n",
       "  -0.7016537481149702,\n",
       "  0.6004562038142454,\n",
       "  -0.6131644469333962,\n",
       "  0.9,\n",
       "  -0.6454424840252291],\n",
       " [0.5399055702672116,\n",
       "  3.0,\n",
       "  -1.3951107428689051,\n",
       "  -1.2232455342488693,\n",
       "  0.9282142309584029,\n",
       "  -0.08734777677841864,\n",
       "  0.95,\n",
       "  1.0645306544767197],\n",
       " [-1.4337204411045532,\n",
       "  0.0,\n",
       "  -1.1908102673282033,\n",
       "  -0.7761655197904794,\n",
       "  -0.3486196897028316,\n",
       "  -0.42423990707334147,\n",
       "  1.1,\n",
       "  0.9132072944517511],\n",
       " [-0.7367089025524446,\n",
       "  1.0,\n",
       "  0.33056443261989193,\n",
       "  0.8956365811958802,\n",
       "  -1.3508807547161106,\n",
       "  -1.900377958019683,\n",
       "  0.9,\n",
       "  0.7646985918217886],\n",
       " [-0.6803163726824588,\n",
       "  1.0,\n",
       "  0.12671747700442548,\n",
       "  -1.0648584634096432,\n",
       "  -0.8680623203716996,\n",
       "  -1.0137632836187374,\n",
       "  0.9,\n",
       "  1.018794198214358],\n",
       " [-1.1405521559267888,\n",
       "  5.0,\n",
       "  0.8298464217442333,\n",
       "  -1.3036254307694026,\n",
       "  0.12366029960013564,\n",
       "  0.7989219040100767,\n",
       "  0.85,\n",
       "  0.7145531940963312],\n",
       " [0.603653566054683,\n",
       "  4.0,\n",
       "  -0.8397434180464404,\n",
       "  0.190730001916421,\n",
       "  1.8703311827293827,\n",
       "  1.1410637085455608,\n",
       "  1.2,\n",
       "  1.0038223827186534],\n",
       " [0.2191248733243711,\n",
       "  1.0,\n",
       "  -0.45887676583358383,\n",
       "  0.8407336892754111,\n",
       "  0.3233296059995932,\n",
       "  1.0330255736357947,\n",
       "  0.9,\n",
       "  0.7968126304850761],\n",
       " [0.7604747252792978,\n",
       "  5.0,\n",
       "  1.635553956945062,\n",
       "  0.7750891779490651,\n",
       "  0.5515992154682693,\n",
       "  -0.4519428351198138,\n",
       "  0.85,\n",
       "  -1.7845954556111587],\n",
       " [-1.825119012942441,\n",
       "  0.0,\n",
       "  0.07183659246722413,\n",
       "  -0.674522110581836,\n",
       "  -0.6286438683023461,\n",
       "  -0.7250386680043494,\n",
       "  1.1,\n",
       "  -0.41405167287169303],\n",
       " [0.39607382640326255,\n",
       "  0.0,\n",
       "  1.1925578439419169,\n",
       "  -1.1984174282525748,\n",
       "  0.6276501193441385,\n",
       "  1.1128923385817686,\n",
       "  1.1,\n",
       "  0.0525863623168435],\n",
       " [-1.2966625742600668,\n",
       "  3.0,\n",
       "  -1.6600903294987757,\n",
       "  1.6089669702050522,\n",
       "  -1.2275964181414096,\n",
       "  0.8404680396713212,\n",
       "  0.95,\n",
       "  -0.04276463480749861],\n",
       " [1.1233396347752367,\n",
       "  2.0,\n",
       "  -1.6360643525283955,\n",
       "  -1.2135905669152005,\n",
       "  0.7505103750848511,\n",
       "  1.6557659813280123,\n",
       "  1.05,\n",
       "  0.21947421795089642],\n",
       " [0.39208513194652195,\n",
       "  0.0,\n",
       "  -1.155237290301662,\n",
       "  -0.6061213820172429,\n",
       "  0.9724173724593007,\n",
       "  1.1658003551550484,\n",
       "  1.1,\n",
       "  -0.6807037915504922],\n",
       " [1.0454202896368816,\n",
       "  3.0,\n",
       "  -0.4856155272281812,\n",
       "  -1.1925482444015714,\n",
       "  0.6788597763277691,\n",
       "  -1.2561262857228421,\n",
       "  0.95,\n",
       "  0.34205081001162785],\n",
       " [1.0092830681690328,\n",
       "  1.0,\n",
       "  -0.8527194871531715,\n",
       "  1.073842973061693,\n",
       "  -0.06302610430777512,\n",
       "  -0.09618177920595085,\n",
       "  0.9,\n",
       "  -1.7273126229715856],\n",
       " [1.6199569198676698,\n",
       "  5.0,\n",
       "  0.3512396187650684,\n",
       "  0.8679637500054583,\n",
       "  -1.9832554678049854,\n",
       "  -0.12279912330698455,\n",
       "  0.85,\n",
       "  1.05244176072783],\n",
       " [-1.3020159748949054,\n",
       "  4.0,\n",
       "  -0.0509468470306548,\n",
       "  1.859883462846824,\n",
       "  0.9932130918150841,\n",
       "  -1.1368734157656468,\n",
       "  1.2,\n",
       "  -0.11523921293723458],\n",
       " [1.3339301583670602,\n",
       "  1.0,\n",
       "  -0.10242087910468126,\n",
       "  1.585339173641576,\n",
       "  -2.276891457134923,\n",
       "  -1.2903780181547657,\n",
       "  0.9,\n",
       "  1.0554626741497153],\n",
       " [-0.39054438290426446,\n",
       "  3.0,\n",
       "  -0.3582227945878122,\n",
       "  -0.19856183674366776,\n",
       "  0.8797908398494259,\n",
       "  0.9241086105427714,\n",
       "  0.95,\n",
       "  0.5647906351283379],\n",
       " [1.3534787757132385,\n",
       "  0.0,\n",
       "  -1.6242064596993666,\n",
       "  -1.2403859552482028,\n",
       "  0.23836179660355203,\n",
       "  -1.4560576474877422,\n",
       "  1.1,\n",
       "  0.9555019469140029],\n",
       " [-0.7926636319052512,\n",
       "  2.0,\n",
       "  -1.3707097657494616,\n",
       "  1.1608771422137134,\n",
       "  0.4468252028373095,\n",
       "  -0.13737669072938352,\n",
       "  1.05,\n",
       "  0.08143386137919072],\n",
       " [0.47142992934562333,\n",
       "  2.0,\n",
       "  -0.9282764862442622,\n",
       "  1.7254565245549827,\n",
       "  0.18485146409672348,\n",
       "  -0.9261345668651259,\n",
       "  1.05,\n",
       "  -1.5653089584816187],\n",
       " [1.4401174060384032,\n",
       "  2.0,\n",
       "  -0.03369583354569843,\n",
       "  -0.9713159721689001,\n",
       "  0.5202463455043581,\n",
       "  0.15851479708091218,\n",
       "  1.05,\n",
       "  0.5450921047412343],\n",
       " [-1.3283777805865638,\n",
       "  3.0,\n",
       "  -0.48130062815370667,\n",
       "  -0.5733568208237265,\n",
       "  -0.06615864272612935,\n",
       "  0.3066292767862722,\n",
       "  0.95,\n",
       "  -1.834493462854195],\n",
       " [-1.6784167800312264,\n",
       "  1.0,\n",
       "  0.03594430867214834,\n",
       "  1.6117372982417224,\n",
       "  -3.275812278154436,\n",
       "  -0.30555078499771215,\n",
       "  0.9,\n",
       "  0.3414173054674453],\n",
       " [1.2541479391006876,\n",
       "  3.0,\n",
       "  -1.0492164080692028,\n",
       "  -0.5856480770006389,\n",
       "  -0.13977977537468853,\n",
       "  -0.01701903153635389,\n",
       "  0.95,\n",
       "  0.9468442510475821],\n",
       " [-1.290587748586409,\n",
       "  2.0,\n",
       "  -0.8006817988960395,\n",
       "  -1.1608478930962283,\n",
       "  0.5955038436845034,\n",
       "  -0.5121029067048183,\n",
       "  1.05,\n",
       "  0.38891919273168324],\n",
       " [-1.7913223526940394,\n",
       "  5.0,\n",
       "  -1.5597116105025077,\n",
       "  -0.5918264814340353,\n",
       "  0.8505500474493607,\n",
       "  -0.490299182063698,\n",
       "  0.85,\n",
       "  -1.762449798467642],\n",
       " [-0.20675415295887944,\n",
       "  4.0,\n",
       "  -0.9770655566207105,\n",
       "  1.592060858888651,\n",
       "  0.7678150302236695,\n",
       "  -0.3627953907140082,\n",
       "  1.2,\n",
       "  -0.9428135932669724],\n",
       " [0.6842134405811138,\n",
       "  3.0,\n",
       "  1.2327091256941434,\n",
       "  1.026050099920927,\n",
       "  1.1296355955949684,\n",
       "  0.9650810416041591,\n",
       "  0.95,\n",
       "  -1.7859010750860136],\n",
       " [-1.6414512462567787,\n",
       "  0.0,\n",
       "  0.48907212874342665,\n",
       "  -0.07127654955716951,\n",
       "  0.5838472429929977,\n",
       "  1.6776525617096891,\n",
       "  1.1,\n",
       "  -1.4959791501540884],\n",
       " [0.48196302163607085,\n",
       "  2.0,\n",
       "  -0.43081835054951073,\n",
       "  1.9616497950163503,\n",
       "  -2.1092045339634766,\n",
       "  0.5431427237436185,\n",
       "  1.05,\n",
       "  -1.7881544433760623],\n",
       " [1.132472232539316,\n",
       "  4.0,\n",
       "  0.1434852388371761,\n",
       "  -1.1779089818545598,\n",
       "  -0.8245774751268297,\n",
       "  0.30319051149362997,\n",
       "  1.2,\n",
       "  1.0614986384092389],\n",
       " [-0.47607317995343745,\n",
       "  3.0,\n",
       "  1.1458616158635675,\n",
       "  -0.6266525320897528,\n",
       "  1.0447693703441134,\n",
       "  0.8607237700436294,\n",
       "  0.95,\n",
       "  0.047271746128038625],\n",
       " [-0.9394904101830662,\n",
       "  1.0,\n",
       "  -1.2910917231502295,\n",
       "  -1.2214117549552725,\n",
       "  -0.42876484141463406,\n",
       "  1.1781617336123782,\n",
       "  0.9,\n",
       "  -0.7824881603101631],\n",
       " [1.6455937571659194,\n",
       "  4.0,\n",
       "  1.306814291294291,\n",
       "  -0.6905527880159384,\n",
       "  -1.010368539734271,\n",
       "  -1.4789704011287008,\n",
       "  1.2,\n",
       "  -1.6199178500376425],\n",
       " [1.3699208540964125,\n",
       "  0.0,\n",
       "  1.6580752266778043,\n",
       "  -0.4996967633733472,\n",
       "  -0.23496536521568157,\n",
       "  0.7360643020750463,\n",
       "  1.1,\n",
       "  -0.08210125512039655],\n",
       " [0.8273873901595824,\n",
       "  1.0,\n",
       "  -0.27753299141383303,\n",
       "  0.6510871857913283,\n",
       "  0.28706509303037075,\n",
       "  -1.218121781242672,\n",
       "  0.9,\n",
       "  0.5912919223122443],\n",
       " [0.7229573256788082,\n",
       "  2.0,\n",
       "  -1.0518546387149004,\n",
       "  1.7283359602682768,\n",
       "  -1.0840961443972634,\n",
       "  1.1191004260924406,\n",
       "  1.05,\n",
       "  0.9945174994987365],\n",
       " [1.564932254826653,\n",
       "  1.0,\n",
       "  0.5200995578583089,\n",
       "  -0.11854306131947964,\n",
       "  -2.1465469335203204,\n",
       "  0.7393638636554081,\n",
       "  0.9,\n",
       "  0.6921492190571589],\n",
       " [0.8165614048424059,\n",
       "  2.0,\n",
       "  -1.4010788868826893,\n",
       "  0.3907807904294834,\n",
       "  0.840917165034969,\n",
       "  -1.0303671130107588,\n",
       "  1.05,\n",
       "  1.06235456874933],\n",
       " [1.1003773731707491,\n",
       "  2.0,\n",
       "  -1.504827146565047,\n",
       "  -1.009396109726339,\n",
       "  0.20405906674290958,\n",
       "  -0.6151334401717469,\n",
       "  1.05,\n",
       "  0.4818398963591462],\n",
       " [0.3746952931212073,\n",
       "  1.0,\n",
       "  -1.0419407683988182,\n",
       "  0.982617285790012,\n",
       "  -0.3204542607819357,\n",
       "  -1.153614838910855,\n",
       "  0.9,\n",
       "  0.9667069738921423],\n",
       " [0.8929626883856006,\n",
       "  4.0,\n",
       "  1.024474105862552,\n",
       "  1.0873218477520123,\n",
       "  -0.17454467011468253,\n",
       "  -0.15419441489564986,\n",
       "  1.2,\n",
       "  -1.5942792729089352],\n",
       " [-2.0154037005223655,\n",
       "  4.0,\n",
       "  1.0887859658792827,\n",
       "  -1.4041338631838487,\n",
       "  -0.1768718399851419,\n",
       "  1.884265984959341,\n",
       "  1.2,\n",
       "  0.9676583933926391],\n",
       " [1.1990291076330544,\n",
       "  2.0,\n",
       "  -0.14638494561329762,\n",
       "  1.0500693389656135,\n",
       "  0.043868220688095275,\n",
       "  1.0789423149874235,\n",
       "  1.05,\n",
       "  -0.5760203476547618],\n",
       " [-1.3222515617098818,\n",
       "  5.0,\n",
       "  -0.8077963231853702,\n",
       "  -1.2514349113030034,\n",
       "  0.74279193360586,\n",
       "  0.136044709861583,\n",
       "  0.85,\n",
       "  1.1246201864480327],\n",
       " [0.5994708613732733,\n",
       "  3.0,\n",
       "  1.084582472689183,\n",
       "  -0.5513662275600282,\n",
       "  0.9280183475299201,\n",
       "  1.2357604678186351,\n",
       "  0.95,\n",
       "  -1.3645225117896846],\n",
       " [1.3974053341495303,\n",
       "  0.0,\n",
       "  0.9601993424742539,\n",
       "  0.3159240415192823,\n",
       "  -0.35571930216943687,\n",
       "  -0.7631428919075695,\n",
       "  1.1,\n",
       "  1.057731871443905],\n",
       " [0.07687392017953561,\n",
       "  2.0,\n",
       "  -0.4230402327244125,\n",
       "  1.7238590139037078,\n",
       "  -3.11375065608555,\n",
       "  1.635409367337232,\n",
       "  1.05,\n",
       "  1.0638750207474648],\n",
       " [-1.0763231733818774,\n",
       "  1.0,\n",
       "  -0.40206481166359687,\n",
       "  0.6651280166311451,\n",
       "  0.16612816726254856,\n",
       "  0.6651613363918666,\n",
       "  0.9,\n",
       "  -1.1067884671392967],\n",
       " [1.1645440029403893,\n",
       "  3.0,\n",
       "  -0.42094789191377074,\n",
       "  -0.7728375561463846,\n",
       "  0.8594934503455299,\n",
       "  1.5505198292239173,\n",
       "  0.95,\n",
       "  -1.6678567363784707],\n",
       " [1.235666945710413,\n",
       "  3.0,\n",
       "  -0.13047341425067305,\n",
       "  -1.418628737542331,\n",
       "  0.6877012327703848,\n",
       "  -0.615109719466866,\n",
       "  0.95,\n",
       "  0.9968335685071493],\n",
       " [-0.055995885047029285,\n",
       "  5.0,\n",
       "  -0.390678222813853,\n",
       "  0.8692756531934969,\n",
       "  0.36274765389375685,\n",
       "  0.05963660934642876,\n",
       "  0.85,\n",
       "  -0.535855995536714],\n",
       " [0.5388896567690464,\n",
       "  4.0,\n",
       "  1.4036049320104478,\n",
       "  1.17116924004795,\n",
       "  -1.7730517972190856,\n",
       "  -0.15131288441523458,\n",
       "  1.2,\n",
       "  2.5950030065540488e-05],\n",
       " [-0.0316121230460941,\n",
       "  5.0,\n",
       "  1.4360142371991762,\n",
       "  -1.3006619407950144,\n",
       "  0.596514156462918,\n",
       "  -1.1981935858190411,\n",
       "  0.85,\n",
       "  -0.60692567658271],\n",
       " [1.4466948673034405,\n",
       "  3.0,\n",
       "  0.7067541760361947,\n",
       "  1.1763587758907983,\n",
       "  0.6238821966148835,\n",
       "  -1.2544938234304248,\n",
       "  0.95,\n",
       "  0.4989971202444649],\n",
       " [-0.8734866460994549,\n",
       "  1.0,\n",
       "  0.4132211377166757,\n",
       "  -0.3105355573067557,\n",
       "  -0.25863312019722035,\n",
       "  0.07176864664224923,\n",
       "  0.9,\n",
       "  -0.3867760780353235],\n",
       " [-0.6965954288108246,\n",
       "  0.0,\n",
       "  0.26330412129435454,\n",
       "  0.7996674447927771,\n",
       "  1.3903813995524013,\n",
       "  -0.009597356842919982,\n",
       "  1.1,\n",
       "  0.784504210002641],\n",
       " [-0.06887642505234633,\n",
       "  1.0,\n",
       "  0.4551010524531984,\n",
       "  0.8961135702061379,\n",
       "  0.2515944786323394,\n",
       "  -0.14241448442847232,\n",
       "  0.9,\n",
       "  0.014018913214132853],\n",
       " [-0.2848966928088769,\n",
       "  1.0,\n",
       "  1.1844375063633874,\n",
       "  -1.384031435491256,\n",
       "  0.27469323549277147,\n",
       "  -1.9286259083111759,\n",
       "  0.9,\n",
       "  -0.2756793297573724],\n",
       " [-0.5879275607002488,\n",
       "  0.0,\n",
       "  -1.0818499185908867,\n",
       "  0.5033950534307305,\n",
       "  -1.8069140171236429,\n",
       "  1.5167660211363845,\n",
       "  1.1,\n",
       "  0.929067323144555],\n",
       " [0.41212416004394264,\n",
       "  3.0,\n",
       "  -1.6464243733856228,\n",
       "  -1.242355713490953,\n",
       "  -0.201879034295529,\n",
       "  0.4581219144410801,\n",
       "  0.95,\n",
       "  -0.8004213383266716],\n",
       " [-1.2260129828061777,\n",
       "  2.0,\n",
       "  -0.4322588169102325,\n",
       "  -0.289425579693503,\n",
       "  -1.7952106069550395,\n",
       "  0.6274040410062884,\n",
       "  1.05,\n",
       "  -0.04527139716131579],\n",
       " [-0.4540733012040399,\n",
       "  5.0,\n",
       "  1.129837651751343,\n",
       "  -0.38951329551625524,\n",
       "  -0.23139612525971445,\n",
       "  0.2185073256645636,\n",
       "  0.85,\n",
       "  1.03880454848433],\n",
       " [1.6339427269747189,\n",
       "  1.0,\n",
       "  0.09849422985075766,\n",
       "  0.9633686613088956,\n",
       "  0.9724026413086695,\n",
       "  -0.8199759390585195,\n",
       "  0.9,\n",
       "  1.0445480155861557],\n",
       " [0.21632958834110172,\n",
       "  2.0,\n",
       "  1.6535025354449504,\n",
       "  -0.012585014569306698,\n",
       "  0.9297286728528761,\n",
       "  1.6887822811596163,\n",
       "  1.05,\n",
       "  0.8939305261991043],\n",
       " [-0.6602625325970125,\n",
       "  1.0,\n",
       "  1.5256575178018805,\n",
       "  -0.45628735126419756,\n",
       "  0.8354614800952623,\n",
       "  -0.22930202305971065,\n",
       "  0.9,\n",
       "  0.3898322340855209],\n",
       " [1.176903923326048,\n",
       "  5.0,\n",
       "  -1.3362097361902647,\n",
       "  -0.14928601213590229,\n",
       "  0.8607851986580608,\n",
       "  0.4096787814029111,\n",
       "  0.85,\n",
       "  -0.9790522359008961],\n",
       " [-0.8698470083090915,\n",
       "  0.0,\n",
       "  0.6024368156621228,\n",
       "  -0.005684496447637133,\n",
       "  0.031800000070353635,\n",
       "  0.6664829939230201,\n",
       "  1.1,\n",
       "  -0.06713684170391465],\n",
       " [-1.0935604139929567,\n",
       "  0.0,\n",
       "  -1.3956223563301668,\n",
       "  0.016917305998286263,\n",
       "  0.3848083286489524,\n",
       "  -0.9409329312816728,\n",
       "  1.1,\n",
       "  0.5669432208335845],\n",
       " [-0.0738932712565032,\n",
       "  4.0,\n",
       "  0.2752903890069255,\n",
       "  0.3480847192238468,\n",
       "  1.4783137090430227,\n",
       "  1.1290066692862923,\n",
       "  1.2,\n",
       "  0.9796868682054289],\n",
       " [-0.8434194475088183,\n",
       "  3.0,\n",
       "  0.257473734626279,\n",
       "  -0.9380804432202346,\n",
       "  -1.142705906312012,\n",
       "  -1.4771277854480163,\n",
       "  0.95,\n",
       "  0.2507572095332257],\n",
       " [1.0872370008601544,\n",
       "  3.0,\n",
       "  0.048493964490294604,\n",
       "  1.894127639144227,\n",
       "  0.8333500714914543,\n",
       "  0.9025270413066806,\n",
       "  0.95,\n",
       "  -1.6753996716815622],\n",
       " [-1.5562703727597254,\n",
       "  5.0,\n",
       "  -0.577467953720556,\n",
       "  1.9902274015201324,\n",
       "  0.2625408365634186,\n",
       "  -0.6708745904637701,\n",
       "  0.85,\n",
       "  1.0279412108135801],\n",
       " [0.47854158018588666,\n",
       "  3.0,\n",
       "  0.5782630490906493,\n",
       "  -1.1369447593962858,\n",
       "  0.9696142675442008,\n",
       "  -0.34072124969668033,\n",
       "  0.95,\n",
       "  0.10686783192710014],\n",
       " [0.246174081267137,\n",
       "  4.0,\n",
       "  1.4877029140436597,\n",
       "  -0.6494186829640491,\n",
       "  -0.6220097099074687,\n",
       "  0.37812906514020567,\n",
       "  1.2,\n",
       "  0.441344509388608],\n",
       " [-0.1373706688951541,\n",
       "  4.0,\n",
       "  0.025823010136513717,\n",
       "  0.4028816110616034,\n",
       "  0.9321062891577313,\n",
       "  0.027815744810722874,\n",
       "  1.2,\n",
       "  -0.48933221287594586],\n",
       " [0.9099107263895257,\n",
       "  2.0,\n",
       "  0.45528066477637014,\n",
       "  -0.8092255591239083,\n",
       "  -0.18172770211513264,\n",
       "  0.17361310673564642,\n",
       "  1.05,\n",
       "  -1.3033382327561138],\n",
       " [1.5885436197080045,\n",
       "  0.0,\n",
       "  0.0886601384842564,\n",
       "  0.7558762463151073,\n",
       "  0.8519403422660149,\n",
       "  -0.4834256645487896,\n",
       "  1.1,\n",
       "  1.0670630935397873],\n",
       " [1.441156673057239,\n",
       "  2.0,\n",
       "  -1.2168015051368506,\n",
       "  1.5958253375923797,\n",
       "  0.7936733480469121,\n",
       "  0.12819113116258155,\n",
       "  1.05,\n",
       "  0.8268358393612802],\n",
       " [-0.8683750124459374,\n",
       "  0.0,\n",
       "  -1.6591817633761745,\n",
       "  0.7615231913230825,\n",
       "  -0.9699901062383247,\n",
       "  -0.46755283482331744,\n",
       "  1.1,\n",
       "  0.9923894266866113],\n",
       " [0.9558080513499161,\n",
       "  2.0,\n",
       "  -0.7226667938948158,\n",
       "  -0.18061971118679981,\n",
       "  0.4797890409962231,\n",
       "  1.0304308297703748,\n",
       "  1.05,\n",
       "  -1.485948831832394],\n",
       " [-0.6576604716341827,\n",
       "  2.0,\n",
       "  -1.4467564794900696,\n",
       "  1.744389840446724,\n",
       "  -0.27904472365729766,\n",
       "  1.7427169303038026,\n",
       "  1.05,\n",
       "  -1.0940635979253535],\n",
       " [0.18108455283379912,\n",
       "  4.0,\n",
       "  -1.2038154148804923,\n",
       "  -0.7431706914637872,\n",
       "  -3.5543704646511993,\n",
       "  -1.3045050247491616,\n",
       "  1.2,\n",
       "  -1.1011744592467514],\n",
       " [1.3789860911763494,\n",
       "  2.0,\n",
       "  -1.4339649343720873,\n",
       "  -0.6301059615449107,\n",
       "  0.7530597792649913,\n",
       "  -1.211183578651988,\n",
       "  1.05,\n",
       "  -0.5609017533605877],\n",
       " [1.4093286519925197,\n",
       "  4.0,\n",
       "  1.1916245755893178,\n",
       "  0.36212565639340105,\n",
       "  -0.38675007982067394,\n",
       "  -0.8798921553661976,\n",
       "  1.2,\n",
       "  0.5713308748674422],\n",
       " [-0.23466153964558925,\n",
       "  1.0,\n",
       "  1.2673322900172412,\n",
       "  -0.6925698299093174,\n",
       "  -0.6868604282497268,\n",
       "  -1.7217231659806733,\n",
       "  0.9,\n",
       "  0.7675253416045281],\n",
       " [1.2387127693121645,\n",
       "  5.0,\n",
       "  -1.5963544368179565,\n",
       "  -0.36821410288908174,\n",
       "  0.4778805622093542,\n",
       "  0.584323687674915,\n",
       "  0.85,\n",
       "  0.015281697041101954],\n",
       " [-0.32734957100695666,\n",
       "  3.0,\n",
       "  -1.2445316993215447,\n",
       "  -1.3923454614510726,\n",
       "  0.32820174964694426,\n",
       "  -0.16735320948641985,\n",
       "  0.95,\n",
       "  1.063403388213975],\n",
       " [-0.21440282614078152,\n",
       "  3.0,\n",
       "  1.1262749473273983,\n",
       "  -0.7401148244461405,\n",
       "  -0.1306516070334736,\n",
       "  0.9415058821304059,\n",
       "  0.95,\n",
       "  0.05840851908610719],\n",
       " [0.25709097316457463,\n",
       "  4.0,\n",
       "  0.6431342438917541,\n",
       "  -1.243411792383837,\n",
       "  0.9175034177614242,\n",
       "  1.0372703624767887,\n",
       "  1.2,\n",
       "  0.8152982374483563],\n",
       " [-1.0972239886579578,\n",
       "  5.0,\n",
       "  -0.2690291079064353,\n",
       "  -1.239920840029954,\n",
       "  -0.7550857604113458,\n",
       "  0.0009100159074169841,\n",
       "  0.85,\n",
       "  0.6039242908037943],\n",
       " [-1.1429823120775744,\n",
       "  2.0,\n",
       "  0.027171542844431063,\n",
       "  -1.3061376347808717,\n",
       "  -0.299240672574447,\n",
       "  0.4722122214701826,\n",
       "  1.05,\n",
       "  -0.4468337803371559],\n",
       " [0.10502815790967662,\n",
       "  3.0,\n",
       "  -0.8100134787882575,\n",
       "  -1.0711122073774126,\n",
       "  -0.13394697642985617,\n",
       "  -1.6889231945826209,\n",
       "  0.95,\n",
       "  0.9270854734621752],\n",
       " [-0.8167815604677764,\n",
       "  2.0,\n",
       "  0.9084577366092845,\n",
       "  -0.5008585487657383,\n",
       "  0.28765044968437126,\n",
       "  -0.11575467574563636,\n",
       "  1.05,\n",
       "  0.7659461910199475],\n",
       " [-0.5156347613187305,\n",
       "  0.0,\n",
       "  1.1299730670205097,\n",
       "  0.43704650509203363,\n",
       "  -1.3554728267519336,\n",
       "  -0.627390911275906,\n",
       "  1.1,\n",
       "  -1.1964538419949944],\n",
       " [1.3004705391945017,\n",
       "  5.0,\n",
       "  0.3326835626462349,\n",
       "  1.7099495905098876,\n",
       "  -0.30458816340474754,\n",
       "  0.77708759928515,\n",
       "  0.85,\n",
       "  -0.9940205935857797],\n",
       " [0.8401876178370804,\n",
       "  1.0,\n",
       "  -1.1586406273705148,\n",
       "  -0.26680094109101965,\n",
       "  0.5618007324186928,\n",
       "  -0.10521471253184701,\n",
       "  0.9,\n",
       "  -1.0372035159803552],\n",
       " [-1.0512661642227397,\n",
       "  5.0,\n",
       "  1.7281168310549195,\n",
       "  -1.340675356066964,\n",
       "  0.11464311854213383,\n",
       "  -1.229266142501857,\n",
       "  0.85,\n",
       "  1.0463970189614755],\n",
       " [0.0213180358531919,\n",
       "  4.0,\n",
       "  0.9078245496621661,\n",
       "  0.10542921270131239,\n",
       "  -1.6936736664341867,\n",
       "  -1.040587713891601,\n",
       "  1.2,\n",
       "  1.0623370837668624],\n",
       " [1.7224492917792396,\n",
       "  2.0,\n",
       "  1.6223262166142989,\n",
       "  1.5661837065858166,\n",
       "  -1.2653854108784741,\n",
       "  -1.7189106388911854,\n",
       "  1.05,\n",
       "  0.7606510440146167],\n",
       " [0.5309924048603353,\n",
       "  2.0,\n",
       "  0.09823042789278981,\n",
       "  -0.505426152846908,\n",
       "  -0.486781715745009,\n",
       "  -0.5145732983615766,\n",
       "  1.05,\n",
       "  0.30716526905829883],\n",
       " [0.9504448954507612,\n",
       "  0.0,\n",
       "  -1.675451336091365,\n",
       "  1.4544498334178584,\n",
       "  -0.022839185406735157,\n",
       "  0.029015086774586616,\n",
       "  1.1,\n",
       "  0.9097997540155571],\n",
       " [-0.4801002348941548,\n",
       "  1.0,\n",
       "  -0.25401073414534003,\n",
       "  -0.26309264247319075,\n",
       "  -1.8763614107057267,\n",
       "  0.579377323315909,\n",
       "  0.9,\n",
       "  0.9248855691047351],\n",
       " [-0.4750299658641796,\n",
       "  5.0,\n",
       "  1.5366145026247873,\n",
       "  1.8205660491406421,\n",
       "  0.5873851151093744,\n",
       "  -1.3769300710668066,\n",
       "  0.85,\n",
       "  0.8128291501481818],\n",
       " [-0.8481699751441821,\n",
       "  3.0,\n",
       "  -0.9477531034720479,\n",
       "  -1.2255353254237582,\n",
       "  -1.7384983261968776,\n",
       "  0.9746953536891027,\n",
       "  0.95,\n",
       "  0.4271022060234896],\n",
       " [-0.22540663640286046,\n",
       "  1.0,\n",
       "  -0.2536937105576633,\n",
       "  -0.8438174626476745,\n",
       "  0.5866597467400145,\n",
       "  -0.650358923147374,\n",
       "  0.9,\n",
       "  0.5103792756212321],\n",
       " [-1.4624960078306453,\n",
       "  3.0,\n",
       "  0.36611689899822475,\n",
       "  -1.4076496065873936,\n",
       "  -1.586757519121881,\n",
       "  0.5749242605546202,\n",
       "  0.95,\n",
       "  0.3227413480368088],\n",
       " [-1.0928631098502428,\n",
       "  0.0,\n",
       "  1.4479852928088393,\n",
       "  1.2290595190998055,\n",
       "  0.3203056253660983,\n",
       "  0.29048267463138555,\n",
       "  1.1,\n",
       "  -0.9889403492990148],\n",
       " [-0.5390174876337546,\n",
       "  0.0,\n",
       "  0.5346747677326688,\n",
       "  0.028298858119347996,\n",
       "  0.9409559067731563,\n",
       "  -1.5957166048089788,\n",
       "  1.1,\n",
       "  -0.5897771822826904],\n",
       " [0.7679002265716874,\n",
       "  5.0,\n",
       "  -1.6128489427991877,\n",
       "  -0.31358478907052506,\n",
       "  -0.7373249991322829,\n",
       "  -0.27395470547097733,\n",
       "  0.85,\n",
       "  -1.2715816182975093],\n",
       " [-1.5146783919813225,\n",
       "  5.0,\n",
       "  0.06378416379958282,\n",
       "  0.7789343974075086,\n",
       "  0.7220652071899099,\n",
       "  1.651951613674744,\n",
       "  0.85,\n",
       "  0.9238080599412074],\n",
       " [0.03552546304885816,\n",
       "  0.0,\n",
       "  1.0679136668903453,\n",
       "  -0.546788780705229,\n",
       "  0.9622769619683923,\n",
       "  -0.20908614724046687,\n",
       "  1.1,\n",
       "  0.9142809181781804],\n",
       " [-1.3373094197860431,\n",
       "  3.0,\n",
       "  -0.7048442151204369,\n",
       "  -1.1694208742031784,\n",
       "  -0.09683853331908764,\n",
       "  -0.9074133131470099,\n",
       "  0.95,\n",
       "  0.1264789746421863],\n",
       " [0.1142613372096225,\n",
       "  3.0,\n",
       "  -0.8917548586298892,\n",
       "  -1.2438798444720722,\n",
       "  0.6631597387711837,\n",
       "  -1.9112439739224045,\n",
       "  0.95,\n",
       "  0.800701275510418],\n",
       " [-1.082521916810167,\n",
       "  0.0,\n",
       "  0.4943842352126555,\n",
       "  -0.2334256927842242,\n",
       "  0.9021119706113655,\n",
       "  -0.2561908055627956,\n",
       "  1.1,\n",
       "  0.8481528526521618],\n",
       " [-0.651124673123167,\n",
       "  2.0,\n",
       "  1.5370714552631106,\n",
       "  -1.0074024436639346,\n",
       "  0.8202720669642648,\n",
       "  0.5725327930913037,\n",
       "  1.05,\n",
       "  -0.08981212571798479],\n",
       " [-1.0862337787541698,\n",
       "  4.0,\n",
       "  -0.8975739536340996,\n",
       "  -1.3905177052266917,\n",
       "  -3.0254092160610084,\n",
       "  0.4487489351892474,\n",
       "  1.2,\n",
       "  0.9531643899464503],\n",
       " [-0.31302960371365757,\n",
       "  1.0,\n",
       "  0.05734288960689693,\n",
       "  0.4694544145030127,\n",
       "  0.02195359478460888,\n",
       "  0.729576560942512,\n",
       "  0.9,\n",
       "  0.800575143134307],\n",
       " [0.28717744688570906,\n",
       "  3.0,\n",
       "  0.16151031269985563,\n",
       "  1.5192933532313115,\n",
       "  0.2348731438525482,\n",
       "  -0.30192303908526147,\n",
       "  0.95,\n",
       "  1.056339294115023],\n",
       " [1.2948795482042859,\n",
       "  0.0,\n",
       "  0.8266730707276951,\n",
       "  1.0884819498468905,\n",
       "  -0.5628080786313661,\n",
       "  0.4522851719339491,\n",
       "  1.1,\n",
       "  -1.3341476377091155],\n",
       " [1.3698120404427563,\n",
       "  2.0,\n",
       "  -0.5423864387507957,\n",
       "  1.0049069114534086,\n",
       "  0.14247777098538209,\n",
       "  -0.17004827477629417,\n",
       "  1.05,\n",
       "  0.32468048450079157],\n",
       " [-0.7066471776305855,\n",
       "  2.0,\n",
       "  -0.16023084388838843,\n",
       "  0.620268681428006,\n",
       "  0.967347413394828,\n",
       "  0.6412400326761881,\n",
       "  1.05,\n",
       "  -1.035061385310134],\n",
       " [0.09735961006134711,\n",
       "  2.0,\n",
       "  1.6294383245018322,\n",
       "  1.5222874311368704,\n",
       "  -0.9283277793590938,\n",
       "  0.3516692486574884,\n",
       "  1.05,\n",
       "  0.8576934837453205],\n",
       " [-1.7118122267504756,\n",
       "  3.0,\n",
       "  1.6171692936587012,\n",
       "  1.4268772516115384,\n",
       "  -0.4330216207482988,\n",
       "  -1.618328894176293,\n",
       "  0.95,\n",
       "  0.7945631718749679],\n",
       " [1.234011746280395,\n",
       "  5.0,\n",
       "  -0.9647069387303384,\n",
       "  -0.8254887438149728,\n",
       "  -0.07564474683315991,\n",
       "  1.6906303071606823,\n",
       "  0.85,\n",
       "  2.303956637136057],\n",
       " [-1.5472926811007628,\n",
       "  0.0,\n",
       "  0.9947720044599372,\n",
       "  -0.3458436293664555,\n",
       "  0.09450364353553312,\n",
       "  -0.5337570158772433,\n",
       "  1.1,\n",
       "  -0.7124133839959371],\n",
       " [-0.2525247842025145,\n",
       "  2.0,\n",
       "  -1.1839354408604101,\n",
       "  -0.28033395984488235,\n",
       "  0.8143849539272361,\n",
       "  -1.8541870940927836,\n",
       "  1.05,\n",
       "  -0.014023238111404037],\n",
       " [-1.467636016518994,\n",
       "  5.0,\n",
       "  -0.3095856286357642,\n",
       "  -1.33305168159827,\n",
       "  -1.4159416930812356,\n",
       "  -0.028227678992949614,\n",
       "  0.85,\n",
       "  -1.1721276738851334],\n",
       " [-0.7448328894097358,\n",
       "  1.0,\n",
       "  -1.672505807392887,\n",
       "  1.5318929023418308,\n",
       "  0.5170455428651826,\n",
       "  -0.023070449767286904,\n",
       "  0.9,\n",
       "  0.09730027783308413],\n",
       " [-0.7235832533470322,\n",
       "  3.0,\n",
       "  -0.31583777484351333,\n",
       "  0.33412776907243225,\n",
       "  0.2390743796814647,\n",
       "  1.347318552756631,\n",
       "  0.95,\n",
       "  -0.16410800502341788],\n",
       " [0.6454612678913043,\n",
       "  3.0,\n",
       "  -1.661091247324998,\n",
       "  -0.6893613447722309,\n",
       "  0.4140969325366577,\n",
       "  0.7427615625619859,\n",
       "  0.95,\n",
       "  0.9993855947438809],\n",
       " [0.8250903356357515,\n",
       "  0.0,\n",
       "  0.4841454717088768,\n",
       "  1.3576250144171382,\n",
       "  -0.6590643262038456,\n",
       "  -1.0105873945291213,\n",
       "  1.1,\n",
       "  -0.20832941212854078],\n",
       " [-0.8701490194936844,\n",
       "  0.0,\n",
       "  -0.2399103018869559,\n",
       "  1.4771086554414088,\n",
       "  -0.9387299261989384,\n",
       "  -0.1746255110988974,\n",
       "  1.1,\n",
       "  1.0588418811282971],\n",
       " [-1.510196235589911,\n",
       "  5.0,\n",
       "  -0.5154270805234875,\n",
       "  -0.3736298153718115,\n",
       "  -0.8220877254554132,\n",
       "  0.005735058104031528,\n",
       "  0.85,\n",
       "  -2.005856139716574],\n",
       " [1.1294695996040445,\n",
       "  3.0,\n",
       "  0.9666778110485575,\n",
       "  1.752982145160069,\n",
       "  0.42804381521660756,\n",
       "  0.9776102848777549,\n",
       "  0.95,\n",
       "  0.3026800175036358],\n",
       " [0.8364188611991619,\n",
       "  0.0,\n",
       "  0.01308090862811263,\n",
       "  -0.3821829719668478,\n",
       "  -2.06188563998572,\n",
       "  1.882525941651873,\n",
       "  1.1,\n",
       "  0.4260611208856484],\n",
       " [0.41505196375670944,\n",
       "  4.0,\n",
       "  1.082619324497868,\n",
       "  -0.5657983170369323,\n",
       "  -0.9070263496440537,\n",
       "  0.504183752788353,\n",
       "  1.2,\n",
       "  2.909408004723025],\n",
       " [-1.3006010452640038,\n",
       "  0.0,\n",
       "  1.57772387706018,\n",
       "  -0.395260470080701,\n",
       "  -0.14003190546978933,\n",
       "  0.302930581460686,\n",
       "  1.1,\n",
       "  1.066474678727251],\n",
       " [0.2120905209775995,\n",
       "  0.0,\n",
       "  -1.497643025035796,\n",
       "  -1.4283193158210212,\n",
       "  -0.04908414651135864,\n",
       "  -0.8205497923794244,\n",
       "  1.1,\n",
       "  0.0015249400114321987],\n",
       " [0.6528794187666888,\n",
       "  2.0,\n",
       "  -0.9122944155573762,\n",
       "  -1.1469553891102608,\n",
       "  -1.6878983188774843,\n",
       "  -0.6933739792557936,\n",
       "  1.05,\n",
       "  0.12327107754667875],\n",
       " [-0.40484528932497205,\n",
       "  5.0,\n",
       "  0.16875944465406564,\n",
       "  -0.838429110648001,\n",
       "  -0.18743914532027103,\n",
       "  0.2325604082648669,\n",
       "  0.85,\n",
       "  -1.4129423274627297],\n",
       " [-0.6442657307347546,\n",
       "  0.0,\n",
       "  -0.6833518767564536,\n",
       "  1.673827061103539,\n",
       "  -1.8828167527151662,\n",
       "  -1.7899009915146822,\n",
       "  1.1,\n",
       "  0.9793534723752191],\n",
       " [-0.8573617063580071,\n",
       "  5.0,\n",
       "  -0.20500744324035217,\n",
       "  -0.35630785332708026,\n",
       "  0.9445257265422045,\n",
       "  0.1111766328948188,\n",
       "  0.85,\n",
       "  0.655594782646092],\n",
       " [-0.5843231829746496,\n",
       "  0.0,\n",
       "  -1.4243338143601467,\n",
       "  -0.04185066509519275,\n",
       "  0.678870088318064,\n",
       "  0.08427357700439621,\n",
       "  1.1,\n",
       "  -1.3115906966899418],\n",
       " [-1.3918404941148614,\n",
       "  1.0,\n",
       "  -0.2872749891237756,\n",
       "  0.7663427833235845,\n",
       "  -0.4480879166228186,\n",
       "  -0.7333226921381945,\n",
       "  0.9,\n",
       "  0.22371503819475408],\n",
       " [-0.33398861782292494,\n",
       "  1.0,\n",
       "  0.9648045379924178,\n",
       "  -0.9853005351119657,\n",
       "  -0.3007215044247772,\n",
       "  -0.41694279091599473,\n",
       "  0.9,\n",
       "  -0.44903261853348336],\n",
       " [-0.7896244569232066,\n",
       "  4.0,\n",
       "  -1.5462150413937656,\n",
       "  -0.4039152503455434,\n",
       "  0.5725325750831823,\n",
       "  0.6723521031256666,\n",
       "  1.2,\n",
       "  0.4212958846800136],\n",
       " [-1.1871258530426596,\n",
       "  4.0,\n",
       "  0.9913937815976366,\n",
       "  -0.05928142903150261,\n",
       "  -0.8000741936357814,\n",
       "  1.06585336663877,\n",
       "  1.2,\n",
       "  -0.796468657694895],\n",
       " [-1.3168199617541172,\n",
       "  4.0,\n",
       "  -1.0805089821081224,\n",
       "  1.7628080993919315,\n",
       "  -1.5327831282705036,\n",
       "  -0.285602250825096,\n",
       "  1.2,\n",
       "  -0.34077556919056423],\n",
       " [-1.8502025505440238,\n",
       "  4.0,\n",
       "  1.2168292765892845,\n",
       "  -0.36403069297486795,\n",
       "  0.3667146659016565,\n",
       "  1.4430105089411875,\n",
       "  1.2,\n",
       "  0.577072102609191],\n",
       " [-0.02811932661832397,\n",
       "  2.0,\n",
       "  -1.2197676950350798,\n",
       "  -1.2963617675919004,\n",
       "  -1.454016765941814,\n",
       "  1.7386385758826464,\n",
       "  1.05,\n",
       "  -1.4186206620261668],\n",
       " [0.5238564248108246,\n",
       "  4.0,\n",
       "  -0.2913061163523518,\n",
       "  -0.25255261505836923,\n",
       "  0.4932053881482101,\n",
       "  -1.1534087495303005,\n",
       "  1.2,\n",
       "  0.24121148966407016],\n",
       " [-1.0663122981054574,\n",
       "  2.0,\n",
       "  -0.09305688715119492,\n",
       "  0.22707507017532966,\n",
       "  -0.4797472825360214,\n",
       "  -0.003532873408621324,\n",
       "  1.05,\n",
       "  1.0033290374014987],\n",
       " [1.4452423324091097,\n",
       "  1.0,\n",
       "  -0.28155163867724586,\n",
       "  -1.4060265007587949,\n",
       "  0.9186918450652691,\n",
       "  -0.6039536203405994,\n",
       "  0.9,\n",
       "  -0.22712627513754458],\n",
       " [-1.1619697867521777,\n",
       "  2.0,\n",
       "  -0.5393915058470072,\n",
       "  -0.004661842518840518,\n",
       "  0.822599047147649,\n",
       "  -0.48661077858829316,\n",
       "  1.05,\n",
       "  0.5445072252950682],\n",
       " [-0.5188732793967812,\n",
       "  4.0,\n",
       "  0.0640792899764922,\n",
       "  0.8162588641566982,\n",
       "  0.17850976940023172,\n",
       "  0.8073895318184293,\n",
       "  1.2,\n",
       "  -0.24388575046592362],\n",
       " [0.03734703912815178,\n",
       "  1.0,\n",
       "  -1.5296366301053723,\n",
       "  -1.243150834336683,\n",
       "  0.19287995392906004,\n",
       "  0.7068722632128533,\n",
       "  0.9,\n",
       "  0.8589850048819564],\n",
       " [0.3025191517424343,\n",
       "  1.0,\n",
       "  -1.2638763132459134,\n",
       "  -0.9589753584017527,\n",
       "  0.8070424011740794,\n",
       "  1.752401923432473,\n",
       "  0.9,\n",
       "  0.2879973868791451],\n",
       " [-1.2756506613402407,\n",
       "  0.0,\n",
       "  0.6512404725089809,\n",
       "  0.293270168028024,\n",
       "  0.309614851806292,\n",
       "  0.7395448478277868,\n",
       "  1.1,\n",
       "  -0.1522111093436892],\n",
       " [-1.4010789979452598,\n",
       "  3.0,\n",
       "  0.6841052516501499,\n",
       "  -1.2524014751048578,\n",
       "  0.9957582594789457,\n",
       "  -0.8170899206655567,\n",
       "  0.95,\n",
       "  0.16998977986150474],\n",
       " [0.08561782283698542,\n",
       "  5.0,\n",
       "  -0.8946731220465153,\n",
       "  -0.7381901681681011,\n",
       "  -0.7834689856414474,\n",
       "  0.5508936132281816,\n",
       "  0.85,\n",
       "  0.5961678754592851],\n",
       " [-0.9214812367950569,\n",
       "  3.0,\n",
       "  -0.1804592193435033,\n",
       "  0.3721484255021902,\n",
       "  0.18433461797814896,\n",
       "  -0.0037062187834693322,\n",
       "  0.95,\n",
       "  -0.7099298034884639],\n",
       " [-1.7810535031786952,\n",
       "  5.0,\n",
       "  1.100194412245935,\n",
       "  0.7883840112235905,\n",
       "  0.60822743326998,\n",
       "  1.1773243156889237,\n",
       "  0.85,\n",
       "  -1.1738240736234067],\n",
       " [1.0949889466812905,\n",
       "  2.0,\n",
       "  -0.5564139943257619,\n",
       "  -1.3092355311378772,\n",
       "  0.8778821928279315,\n",
       "  1.018664521159892,\n",
       "  1.05,\n",
       "  -1.3759982033488778],\n",
       " [0.5429206082794622,\n",
       "  2.0,\n",
       "  1.644792223111781,\n",
       "  0.8913458663909004,\n",
       "  -0.8647236132203415,\n",
       "  0.11949292969938749,\n",
       "  1.05,\n",
       "  0.3912200984312927],\n",
       " [1.014361740377891,\n",
       "  0.0,\n",
       "  1.5621187682194184,\n",
       "  -0.21728267269802345,\n",
       "  -0.22572758262631296,\n",
       "  -1.1820617362738857,\n",
       "  1.1,\n",
       "  1.1160523127371356],\n",
       " [-1.5946478225551064,\n",
       "  0.0,\n",
       "  -1.3502396015091906,\n",
       "  0.035174878769833474,\n",
       "  0.4609109077381196,\n",
       "  -1.2482077659457727,\n",
       "  1.1,\n",
       "  0.5338505465187722],\n",
       " [-0.37988377611790375,\n",
       "  0.0,\n",
       "  -1.6308223250624463,\n",
       "  0.39702487396633557,\n",
       "  0.35555506694428923,\n",
       "  0.9221004506522408,\n",
       "  1.1,\n",
       "  -1.2623207120628317],\n",
       " [-1.4940082737670277,\n",
       "  2.0,\n",
       "  0.7149231102330801,\n",
       "  -1.3330820657724651,\n",
       "  -1.9151331920955739,\n",
       "  -0.41352615661964964,\n",
       "  1.05,\n",
       "  -0.30546394920392983],\n",
       " [-0.7613178829560602,\n",
       "  2.0,\n",
       "  -1.3374831561515572,\n",
       "  -0.6491806150101332,\n",
       "  -0.010811951074761234,\n",
       "  -0.15962372722787646,\n",
       "  1.05,\n",
       "  1.0641140373809732],\n",
       " [0.4598476951948422,\n",
       "  3.0,\n",
       "  -0.7981052940784216,\n",
       "  -1.130503824137066,\n",
       "  -0.5208698952849312,\n",
       "  -0.9496477121178306,\n",
       "  0.95,\n",
       "  1.0152705549374408],\n",
       " [-0.11105569175771746,\n",
       "  4.0,\n",
       "  1.6300191048292774,\n",
       "  -1.3908711372002032,\n",
       "  0.22968978736997514,\n",
       "  -0.14280702940197443,\n",
       "  1.2,\n",
       "  -0.6255789424054534],\n",
       " [0.9898485995153189,\n",
       "  5.0,\n",
       "  -1.096238820613453,\n",
       "  0.15093440289483798,\n",
       "  0.9439005712550516,\n",
       "  -0.2968523510260438,\n",
       "  0.85,\n",
       "  -1.7652884411643492],\n",
       " [1.7577309343788965,\n",
       "  2.0,\n",
       "  -0.8863228813532246,\n",
       "  1.2662495281698452,\n",
       "  0.005035827281027942,\n",
       "  -0.9111647587153151,\n",
       "  1.05,\n",
       "  -0.9874378383033517],\n",
       " [1.0731682716364161,\n",
       "  0.0,\n",
       "  0.7466382519524687,\n",
       "  -0.7602754964111038,\n",
       "  0.6767652471864434,\n",
       "  -1.30436828159133,\n",
       "  1.1,\n",
       "  -0.04025101383496789],\n",
       " [-0.027637807738357428,\n",
       "  4.0,\n",
       "  0.5559912919124393,\n",
       "  -1.0396032005474956,\n",
       "  0.9530762976743792,\n",
       "  1.7761515928999072,\n",
       "  1.2,\n",
       "  0.6182473660865883],\n",
       " [-0.7466425135857037,\n",
       "  1.0,\n",
       "  -1.3594222994305545,\n",
       "  -0.9296300815301799,\n",
       "  0.7621475197194914,\n",
       "  -1.1562226413182168,\n",
       "  0.9,\n",
       "  0.8291786713590586],\n",
       " [0.24132811880489569,\n",
       "  3.0,\n",
       "  -0.6624129761633782,\n",
       "  0.7535329583084792,\n",
       "  -1.818788882541627,\n",
       "  1.1634154940876065,\n",
       "  0.95,\n",
       "  -0.7878043310250245],\n",
       " [0.30921698513280227,\n",
       "  3.0,\n",
       "  0.5843116078560289,\n",
       "  0.5279956566900287,\n",
       "  -3.1701068967087833,\n",
       "  0.015575260130206103,\n",
       "  0.95,\n",
       "  0.8569347293950943],\n",
       " [0.26638458688153405,\n",
       "  3.0,\n",
       "  0.3604090337208882,\n",
       "  1.5390246203555784,\n",
       "  0.27828623206379,\n",
       "  -0.09315136863231697,\n",
       "  0.95,\n",
       "  -1.1674428000050368],\n",
       " [-0.8733935656377444,\n",
       "  1.0,\n",
       "  0.8622939015371597,\n",
       "  0.7263807450783075,\n",
       "  -0.8865475377404767,\n",
       "  1.7220236865175318,\n",
       "  0.9,\n",
       "  0.9539740477341172],\n",
       " [-0.478584297318596,\n",
       "  2.0,\n",
       "  1.4192738286153594,\n",
       "  0.9924580065550248,\n",
       "  -2.964572033472837,\n",
       "  1.3456516351333174,\n",
       "  1.05,\n",
       "  -0.9456628539853775],\n",
       " [-1.0702345994129658,\n",
       "  0.0,\n",
       "  1.2872059341444888,\n",
       "  0.3571697349701585,\n",
       "  0.9273038916939864,\n",
       "  0.569501229165737,\n",
       "  1.1,\n",
       "  0.8133163396877383],\n",
       " [0.9740045515050456,\n",
       "  4.0,\n",
       "  1.090336190774038,\n",
       "  1.2189977383465125,\n",
       "  0.7430189517033571,\n",
       "  1.5093131528986568,\n",
       "  1.2,\n",
       "  0.24663136310274061],\n",
       " [-1.156730403015144,\n",
       "  4.0,\n",
       "  1.3914021848062093,\n",
       "  -1.3243974159772804,\n",
       "  -0.3572937828084216,\n",
       "  -0.6213373403371344,\n",
       "  1.2,\n",
       "  0.6556803690284083],\n",
       " [0.45732239898411453,\n",
       "  4.0,\n",
       "  0.40838936718073804,\n",
       "  0.2441783860379277,\n",
       "  0.48780920813068435,\n",
       "  1.2277964854882266,\n",
       "  1.2,\n",
       "  0.3733158335071412],\n",
       " [0.09761795995441223,\n",
       "  3.0,\n",
       "  0.41531530405513034,\n",
       "  -0.7599209081025616,\n",
       "  0.3996040247277085,\n",
       "  0.47060074401265745,\n",
       "  0.95,\n",
       "  -1.5327224402412754],\n",
       " [0.4451376817751349,\n",
       "  0.0,\n",
       "  -1.5065392033859009,\n",
       "  1.4705489646891003,\n",
       "  0.33373869675900225,\n",
       "  -0.18892314551266096,\n",
       "  1.1,\n",
       "  1.0064031740760893],\n",
       " [0.37787674337818145,\n",
       "  0.0,\n",
       "  -0.36353041932029023,\n",
       "  -1.4095564483558354,\n",
       "  0.4259844872906187,\n",
       "  -0.6226387437869959,\n",
       "  1.1,\n",
       "  -1.236114659978253],\n",
       " [0.8900659030154933,\n",
       "  2.0,\n",
       "  -0.45522056782299986,\n",
       "  -1.2954552311792153,\n",
       "  -1.9731593513594494,\n",
       "  0.908933463230185,\n",
       "  1.05,\n",
       "  0.15109787419796133],\n",
       " [0.5929498657100153,\n",
       "  0.0,\n",
       "  -0.08596015397657004,\n",
       "  -0.889250563064577,\n",
       "  0.8102766159367442,\n",
       "  0.3406726362364771,\n",
       "  1.1,\n",
       "  0.7241568320104402],\n",
       " [-0.9076932075625154,\n",
       "  1.0,\n",
       "  1.09831257434175,\n",
       "  -0.2628511598991949,\n",
       "  0.8656609868013253,\n",
       "  -1.4065570184604677,\n",
       "  0.9,\n",
       "  -1.7827357058633904],\n",
       " [-0.3016667751033011,\n",
       "  5.0,\n",
       "  -1.1199056699979748,\n",
       "  0.946646571961376,\n",
       "  -2.5488205191687596,\n",
       "  1.3775235651688018,\n",
       "  0.85,\n",
       "  0.3256835943471336],\n",
       " [-0.8812793300088699,\n",
       "  5.0,\n",
       "  -0.5586692239846774,\n",
       "  -0.4927239164264923,\n",
       "  0.7314882472673626,\n",
       "  1.8023492458508887,\n",
       "  0.85,\n",
       "  0.9933340147497509],\n",
       " [0.828460304840753,\n",
       "  1.0,\n",
       "  0.9769546248469511,\n",
       "  0.22774149675955335,\n",
       "  -1.3519283649431642,\n",
       "  0.027949808009215014,\n",
       "  0.9,\n",
       "  -1.5695138726866324],\n",
       " [-0.03979817396262272,\n",
       "  1.0,\n",
       "  1.5521767006982337,\n",
       "  -1.3166776403679208,\n",
       "  -0.6411998315563183,\n",
       "  -1.080124582548176,\n",
       "  0.9,\n",
       "  0.17403893273933274],\n",
       " [1.5783653280625054,\n",
       "  4.0,\n",
       "  0.3153505821860504,\n",
       "  1.442997627700601,\n",
       "  0.23459635100787432,\n",
       "  -0.6875608794192464,\n",
       "  1.2,\n",
       "  0.41509808942650306],\n",
       " [1.237027337627646,\n",
       "  4.0,\n",
       "  -1.1919086449763412,\n",
       "  -1.3458951850529866,\n",
       "  -0.4688266461068641,\n",
       "  0.38541334389539017,\n",
       "  1.2,\n",
       "  1.0648256093902118],\n",
       " [-0.11092058376813299,\n",
       "  4.0,\n",
       "  -0.7414202445905094,\n",
       "  0.8546798416795959,\n",
       "  0.7146229828506662,\n",
       "  -0.4014975493273587,\n",
       "  1.2,\n",
       "  0.31603189728863285],\n",
       " [0.3983430134805617,\n",
       "  2.0,\n",
       "  0.48292732734454435,\n",
       "  1.6815767087022626,\n",
       "  -1.0084844278953107,\n",
       "  -1.8638923324209302,\n",
       "  1.05,\n",
       "  0.7408749483917417],\n",
       " [0.491790653848568,\n",
       "  3.0,\n",
       "  -1.6553873286236496,\n",
       "  -0.327090884720865,\n",
       "  -0.04222157981324894,\n",
       "  -0.5473272334409216,\n",
       "  0.95,\n",
       "  -0.2695555946607633],\n",
       " [-1.0954446707572512,\n",
       "  5.0,\n",
       "  -1.6606876518294593,\n",
       "  -1.2014538512184456,\n",
       "  -0.2536052853874515,\n",
       "  -0.13523293302435174,\n",
       "  0.85,\n",
       "  -1.2584564479328686],\n",
       " [1.2321368629931748,\n",
       "  4.0,\n",
       "  0.1985203765440774,\n",
       "  -0.8686134879937992,\n",
       "  -0.1962930115662845,\n",
       "  -1.3741744035620405,\n",
       "  1.2,\n",
       "  -0.36906107414495654],\n",
       " [0.23405530647633907,\n",
       "  4.0,\n",
       "  -1.6385063412910494,\n",
       "  0.10536304875273,\n",
       "  -1.119033960294123,\n",
       "  -1.8912130898454684,\n",
       "  1.2,\n",
       "  0.8646642936315305],\n",
       " [-1.752660121006759,\n",
       "  4.0,\n",
       "  1.4939122437048338,\n",
       "  -1.2767184737982564,\n",
       "  -0.48519237439371427,\n",
       "  1.771243016981474,\n",
       "  1.2,\n",
       "  0.7364829008516018],\n",
       " [1.352649118848714,\n",
       "  4.0,\n",
       "  -0.5630869579526593,\n",
       "  1.257201586237646,\n",
       "  0.5460340129148614,\n",
       "  -0.5147609448144919,\n",
       "  1.2,\n",
       "  0.9141308806168773],\n",
       " [-1.722498840182148,\n",
       "  2.0,\n",
       "  -1.3177487881269419,\n",
       "  1.352004145304576,\n",
       "  -0.5314995739820372,\n",
       "  1.0417139748871547,\n",
       "  1.05,\n",
       "  -1.939904415119868],\n",
       " [-0.16003045151884585,\n",
       "  4.0,\n",
       "  0.3180075179993426,\n",
       "  1.3871120857563972,\n",
       "  0.7825434381015975,\n",
       "  -0.25196177740353376,\n",
       "  1.2,\n",
       "  0.13026070019262165],\n",
       " [1.5663141389917283,\n",
       "  0.0,\n",
       "  -1.5808991224678326,\n",
       "  0.46582738008296837,\n",
       "  -2.2821846847903555,\n",
       "  -0.15916279860641208,\n",
       "  1.1,\n",
       "  -0.39721289553664],\n",
       " [-1.5459772614720726,\n",
       "  3.0,\n",
       "  0.33851471571138914,\n",
       "  0.396939953971549,\n",
       "  0.7201583948618538,\n",
       "  -0.0029191602413516852,\n",
       "  0.95,\n",
       "  0.22859008419699064],\n",
       " [1.0983145711141573,\n",
       "  1.0,\n",
       "  -1.5859668553974462,\n",
       "  0.3220335215750221,\n",
       "  -0.8964572746073777,\n",
       "  -0.8118437888080298,\n",
       "  0.9,\n",
       "  -0.023758932056365745],\n",
       " [-0.8597211329129512,\n",
       "  2.0,\n",
       "  -0.5365498109910956,\n",
       "  -0.6316121026073916,\n",
       "  -0.5875341996810897,\n",
       "  0.2112853065601322,\n",
       "  1.05,\n",
       "  0.5492919303832043],\n",
       " [-1.1173449164903186,\n",
       "  4.0,\n",
       "  1.6452219494264413,\n",
       "  -0.7366131981629908,\n",
       "  0.8199845474593539,\n",
       "  0.9348562120879136,\n",
       "  1.2,\n",
       "  -1.877930200123393],\n",
       " [-0.9382441632588964,\n",
       "  4.0,\n",
       "  1.02809648741474,\n",
       "  1.6818478794814027,\n",
       "  0.933582670737753,\n",
       "  -0.7321073974516219,\n",
       "  1.2,\n",
       "  0.45124117566985916],\n",
       " [-0.7847698592595782,\n",
       "  5.0,\n",
       "  -1.61147423756557,\n",
       "  -1.280243875978495,\n",
       "  -0.01714500053768739,\n",
       "  -1.382613081451074,\n",
       "  0.85,\n",
       "  0.3598771900034391],\n",
       " [0.897348055216277,\n",
       "  1.0,\n",
       "  -0.5589935926823235,\n",
       "  -0.022578139774536397,\n",
       "  0.7763430958530542,\n",
       "  0.05075578550816793,\n",
       "  0.9,\n",
       "  1.0569326738440175],\n",
       " [-0.8210779847157575,\n",
       "  4.0,\n",
       "  1.0799253061486462,\n",
       "  1.4970528507878125,\n",
       "  -0.1402904478744468,\n",
       "  -1.010881692629042,\n",
       "  1.2,\n",
       "  1.0177346203720652],\n",
       " [-0.18306068355853816,\n",
       "  0.0,\n",
       "  1.6146910648047512,\n",
       "  -0.8811543680000814,\n",
       "  0.06969521889966299,\n",
       "  1.5282058714384945,\n",
       "  1.1,\n",
       "  1.0625159252984124],\n",
       " [-1.6029951947484513,\n",
       "  1.0,\n",
       "  1.1386104335133975,\n",
       "  0.61059087712758,\n",
       "  0.42062876284331296,\n",
       "  -0.7660402086617077,\n",
       "  0.9,\n",
       "  0.3915863988158546],\n",
       " [0.28479947541806344,\n",
       "  2.0,\n",
       "  -1.2380554278026188,\n",
       "  -0.1069918705597615,\n",
       "  1.2309161401907183,\n",
       "  -0.6759618859573564,\n",
       "  1.05,\n",
       "  1.024783126846677],\n",
       " [1.4809089525066814,\n",
       "  2.0,\n",
       "  1.5410394017253803,\n",
       "  -0.36809012034790106,\n",
       "  0.6818248292516618,\n",
       "  0.7598085581274184,\n",
       "  1.05,\n",
       "  0.3256670737921142],\n",
       " [1.3827059139964326,\n",
       "  0.0,\n",
       "  -0.7400608683502076,\n",
       "  0.3330804616797822,\n",
       "  0.6597200113963659,\n",
       "  -1.0404921546320942,\n",
       "  1.1,\n",
       "  0.31028528833990576],\n",
       " [0.8789931180077302,\n",
       "  3.0,\n",
       "  1.6077096829596733,\n",
       "  0.6386939381184845,\n",
       "  0.6489712122206928,\n",
       "  -1.7130878043568942,\n",
       "  0.95,\n",
       "  0.13275040895232312],\n",
       " [-0.11303898371263212,\n",
       "  2.0,\n",
       "  -0.6398126829407007,\n",
       "  0.9614729070068813,\n",
       "  0.6416374965317545,\n",
       "  0.4520681799606618,\n",
       "  1.05,\n",
       "  -0.13996975864024835],\n",
       " [-1.1096860526581167,\n",
       "  3.0,\n",
       "  -0.9862069944258561,\n",
       "  -0.3947162181619661,\n",
       "  -1.0155667631897398,\n",
       "  -0.4502017132914956,\n",
       "  0.95,\n",
       "  0.9216600070358069],\n",
       " [-1.518463278504408,\n",
       "  2.0,\n",
       "  1.4734803538479921,\n",
       "  -0.73371897357642,\n",
       "  -1.1322168035364542,\n",
       "  1.2289634684244863,\n",
       "  1.05,\n",
       "  0.6519155431970364],\n",
       " [-0.6696134297237765,\n",
       "  3.0,\n",
       "  -1.3489567439584134,\n",
       "  -0.8021732514472063,\n",
       "  0.808246816072356,\n",
       "  0.606542944842789,\n",
       "  0.95,\n",
       "  -0.9763615519973351],\n",
       " [1.678589313941774,\n",
       "  3.0,\n",
       "  -1.0633994124258135,\n",
       "  -1.3843229443985479,\n",
       "  -3.861753998987718,\n",
       "  -0.1483213218739629,\n",
       "  0.95,\n",
       "  0.7980995589322257],\n",
       " [0.6819979869483456,\n",
       "  5.0,\n",
       "  -0.22225426044732755,\n",
       "  1.9758017856780112,\n",
       "  0.8035246558409666,\n",
       "  0.191781306138446,\n",
       "  0.85,\n",
       "  -1.1995346259855977],\n",
       " [1.7407822132231134,\n",
       "  0.0,\n",
       "  -1.1270747876123979,\n",
       "  -0.6510200658699208,\n",
       "  0.8329474338449872,\n",
       "  -1.6800477838402572,\n",
       "  1.1,\n",
       "  -1.049754720614096],\n",
       " [-1.8816216203954401,\n",
       "  4.0,\n",
       "  0.9607187110731531,\n",
       "  -0.8022646425201353,\n",
       "  -1.1061444705204364,\n",
       "  -1.786234313656117,\n",
       "  1.2,\n",
       "  -1.6340782694518803],\n",
       " [-0.9531007407269132,\n",
       "  2.0,\n",
       "  -0.5498552635392896,\n",
       "  0.963346660812341,\n",
       "  0.7321575573758466,\n",
       "  0.8152961515583216,\n",
       "  1.05,\n",
       "  3.2324489518560107],\n",
       " [-0.05308770261880738,\n",
       "  3.0,\n",
       "  1.247012344724609,\n",
       "  0.8969750065188331,\n",
       "  -3.1209702569100606,\n",
       "  -0.5573277904302743,\n",
       "  0.95,\n",
       "  -0.23448791121133025],\n",
       " [-0.9588874904514891,\n",
       "  3.0,\n",
       "  1.2157151620943112,\n",
       "  -0.2848498411129592,\n",
       "  0.25215294228389507,\n",
       "  -1.3142181815505927,\n",
       "  0.95,\n",
       "  0.6314366459973088],\n",
       " [0.6262048781663094,\n",
       "  3.0,\n",
       "  -1.5358528988643239,\n",
       "  0.13631638524170114,\n",
       "  0.9253074378977186,\n",
       "  1.9312170210115107,\n",
       "  0.95,\n",
       "  0.33479161236063354],\n",
       " [0.6963188988108361,\n",
       "  3.0,\n",
       "  -1.5146029468756477,\n",
       "  1.0294876548915808,\n",
       "  0.8452025152280694,\n",
       "  0.9110849262300713,\n",
       "  0.95,\n",
       "  0.6477252275608525],\n",
       " [0.23615754522879495,\n",
       "  3.0,\n",
       "  0.34262343187896405,\n",
       "  -1.344821751821239,\n",
       "  -1.4765284467323874,\n",
       "  -1.8546812665313641,\n",
       "  0.95,\n",
       "  0.8663302426653855],\n",
       " [-2.2077202333960955,\n",
       "  5.0,\n",
       "  0.5981437277791204,\n",
       "  -0.9090023748256832,\n",
       "  0.785137016639149,\n",
       "  0.42877468027718674,\n",
       "  0.85,\n",
       "  -0.13819941197364496],\n",
       " [0.052490806220141496,\n",
       "  3.0,\n",
       "  -1.0728822831676972,\n",
       "  0.46181112893609777,\n",
       "  0.4702274566568941,\n",
       "  0.097652004542439,\n",
       "  0.95,\n",
       "  0.9817886873260531],\n",
       " [-1.6587825980894186,\n",
       "  1.0,\n",
       "  -1.1334515274002994,\n",
       "  -0.19745537516305284,\n",
       "  0.7518605159889863,\n",
       "  1.1742779933084602,\n",
       "  0.9,\n",
       "  0.8354103725256959],\n",
       " [0.3785884373492642,\n",
       "  2.0,\n",
       "  -1.6509943976561847,\n",
       "  1.1238738090608091,\n",
       "  -1.079519750144467,\n",
       "  -0.9142739974748427,\n",
       "  1.05,\n",
       "  1.0449961641872623],\n",
       " [0.1948149363326597,\n",
       "  0.0,\n",
       "  -0.17627746731194946,\n",
       "  -0.26923735046395264,\n",
       "  0.12423301225533492,\n",
       "  -0.4060911183555994,\n",
       "  1.1,\n",
       "  0.4371197989008284],\n",
       " [1.4259501101671168,\n",
       "  4.0,\n",
       "  -0.873932238667551,\n",
       "  -0.5327756039269508,\n",
       "  0.5119036310919077,\n",
       "  -1.3494919891756954,\n",
       "  1.2,\n",
       "  0.1851163979909184],\n",
       " [1.5550869870837538,\n",
       "  4.0,\n",
       "  -0.47746326870531997,\n",
       "  0.9218006440134818,\n",
       "  0.8571285139468102,\n",
       "  1.0788551751418467,\n",
       "  1.2,\n",
       "  -0.8973250511327531],\n",
       " [0.00778217023439225,\n",
       "  4.0,\n",
       "  0.4387638629149765,\n",
       "  0.2739385800894296,\n",
       "  -0.6329611354001052,\n",
       "  0.2876422012892187,\n",
       "  1.2,\n",
       "  1.0590318039468807],\n",
       " [-1.4596884572874338,\n",
       "  1.0,\n",
       "  -1.1094313530397886,\n",
       "  0.006527982653902945,\n",
       "  0.7984605668753003,\n",
       "  -0.1686825798140939,\n",
       "  0.9,\n",
       "  -1.9277207543495234],\n",
       " [-0.040452682940066,\n",
       "  2.0,\n",
       "  0.24417528201670888,\n",
       "  -0.24981954338740694,\n",
       "  1.0197865252078653,\n",
       "  -0.06819385986100057,\n",
       "  1.05,\n",
       "  0.8353961450103873],\n",
       " [-1.4750538387129317,\n",
       "  0.0,\n",
       "  -1.3499367202598753,\n",
       "  1.7818915822596129,\n",
       "  0.7833480791322659,\n",
       "  0.31918206115702047,\n",
       "  1.1,\n",
       "  -1.2335898020242653],\n",
       " [-0.6827629084406285,\n",
       "  2.0,\n",
       "  1.0141578066211256,\n",
       "  1.0585039116863035,\n",
       "  0.8094660950492594,\n",
       "  -1.7491138794288297,\n",
       "  1.05,\n",
       "  0.28184735570169167],\n",
       " [1.0405384640538777,\n",
       "  3.0,\n",
       "  1.3756546112522985,\n",
       "  -0.23338331908233184,\n",
       "  -0.5225830123453812,\n",
       "  1.268230016618208,\n",
       "  0.95,\n",
       "  0.3952449002768793],\n",
       " [1.4622654520796767,\n",
       "  2.0,\n",
       "  -1.350853941812286,\n",
       "  -0.40669922207204495,\n",
       "  0.5317490704583185,\n",
       "  -1.8606288596614557,\n",
       "  1.05,\n",
       "  0.8364384716856771],\n",
       " [-1.736055262714754,\n",
       "  3.0,\n",
       "  0.41254722898657664,\n",
       "  -0.7398637635595583,\n",
       "  -0.7825908618546406,\n",
       "  1.391918686397177,\n",
       "  0.95,\n",
       "  -0.5056767700128323],\n",
       " [-0.5062758308349745,\n",
       "  5.0,\n",
       "  -1.5438427836981443,\n",
       "  0.48104652757921473,\n",
       "  0.7199719890148928,\n",
       "  1.966508594381102,\n",
       "  0.85,\n",
       "  -1.956946858653611],\n",
       " [-1.466413568367556,\n",
       "  5.0,\n",
       "  -1.1927188418125039,\n",
       "  0.540848656968469,\n",
       "  -0.8191665718282404,\n",
       "  1.2116852079657132,\n",
       "  0.85,\n",
       "  -0.4139232000982037],\n",
       " [-1.724757706534085,\n",
       "  5.0,\n",
       "  -1.1246852828916158,\n",
       "  -0.6634085602303873,\n",
       "  -0.5825501880821944,\n",
       "  1.2997487433767054,\n",
       "  0.85,\n",
       "  -0.9725206496134818],\n",
       " [1.2715677833050798,\n",
       "  1.0,\n",
       "  -1.45605548580399,\n",
       "  -0.3950544469129914,\n",
       "  -0.46605818099245894,\n",
       "  0.6538679884124698,\n",
       "  0.9,\n",
       "  0.5059861028023793],\n",
       " [-0.7847606694466386,\n",
       "  1.0,\n",
       "  0.9990682341597702,\n",
       "  -0.33415013871159566,\n",
       "  0.6004218014036529,\n",
       "  -1.687110587444446,\n",
       "  0.9,\n",
       "  0.9645173003614186],\n",
       " [0.36389789985885684,\n",
       "  3.0,\n",
       "  -1.573639107761042,\n",
       "  -0.3593767020903564,\n",
       "  0.04782911545581644,\n",
       "  -0.10608176023017128,\n",
       "  0.95,\n",
       "  -0.4257898481346905],\n",
       " [-0.9195473736985007,\n",
       "  5.0,\n",
       "  -0.7697953268148127,\n",
       "  -0.7777810322773031,\n",
       "  0.9427322337326325,\n",
       "  -0.47449033489474435,\n",
       "  0.85,\n",
       "  0.22986353024931605],\n",
       " [-0.900993725428262,\n",
       "  3.0,\n",
       "  -0.42177901213196556,\n",
       "  -0.054996107731275834,\n",
       "  0.5120792469941912,\n",
       "  -0.5974240958539514,\n",
       "  0.95,\n",
       "  0.40380025371207123],\n",
       " [1.0424463982317866,\n",
       "  0.0,\n",
       "  1.5538858610002513,\n",
       "  1.04917385350162,\n",
       "  -0.23596822187855374,\n",
       "  0.05545246984090133,\n",
       "  1.1,\n",
       "  0.40948245953937557],\n",
       " [-1.6118993999489448,\n",
       "  2.0,\n",
       "  1.0880442666523689,\n",
       "  1.1166115036667261,\n",
       "  -2.050977362650382,\n",
       "  0.823910309450777,\n",
       "  1.05,\n",
       "  0.2564879285962754],\n",
       " [-1.2158201530748658,\n",
       "  4.0,\n",
       "  -1.3824587517615599,\n",
       "  -1.1714137757589647,\n",
       "  0.8056390146852378,\n",
       "  -0.8418044321803722,\n",
       "  1.2,\n",
       "  0.025111524948801166],\n",
       " [-0.6938556152866362,\n",
       "  0.0,\n",
       "  0.5794917431240999,\n",
       "  -1.313059438357212,\n",
       "  0.4809042515837588,\n",
       "  0.08400414051164481,\n",
       "  1.1,\n",
       "  1.5960623705090875],\n",
       " [1.1553868282892272,\n",
       "  0.0,\n",
       "  1.484207771641686,\n",
       "  -0.5770169650600201,\n",
       "  0.8869920805305044,\n",
       "  1.6398000644249962,\n",
       "  1.1,\n",
       "  -1.2674171074648202],\n",
       " [0.9811472989747769,\n",
       "  0.0,\n",
       "  -0.3597113619119759,\n",
       "  -0.975235994332086,\n",
       "  -1.0342407920584435,\n",
       "  0.8454694951066133,\n",
       "  1.1,\n",
       "  -0.2996375609809445],\n",
       " [-0.27452453622769146,\n",
       "  2.0,\n",
       "  -1.2801853261667593,\n",
       "  0.6916552378197172,\n",
       "  -1.041574847610688,\n",
       "  0.1742043724534975,\n",
       "  1.05,\n",
       "  0.4651251250921518],\n",
       " [-0.44077129009130417,\n",
       "  3.0,\n",
       "  -0.8660248505134484,\n",
       "  1.614026292057592,\n",
       "  -0.7233671065250629,\n",
       "  -1.5531585987919139,\n",
       "  0.95,\n",
       "  -1.5426650659961427],\n",
       " [-0.84086847782412,\n",
       "  1.0,\n",
       "  -0.04080620308847791,\n",
       "  -1.2712059870034176,\n",
       "  -2.0120582731767502,\n",
       "  -0.5512154125864054,\n",
       "  0.9,\n",
       "  1.0200957394879444],\n",
       " [-1.3986678467432836,\n",
       "  3.0,\n",
       "  0.9810410770578795,\n",
       "  -1.2872396769272958,\n",
       "  0.5938077268046887,\n",
       "  0.5720877576094473,\n",
       "  0.95,\n",
       "  -0.4835792596073398],\n",
       " [0.9471287533803973,\n",
       "  3.0,\n",
       "  -0.020989415237749068,\n",
       "  1.2470143608866202,\n",
       "  -2.495101581400435,\n",
       "  1.025457360273103,\n",
       "  0.95,\n",
       "  -1.7072745009531338],\n",
       " [0.16522377800499433,\n",
       "  3.0,\n",
       "  -1.315833322438534,\n",
       "  -1.217071153815268,\n",
       "  -0.05424268374685463,\n",
       "  0.6773779706977837,\n",
       "  0.95,\n",
       "  0.4795766554271868],\n",
       " [0.2873157827602431,\n",
       "  2.0,\n",
       "  1.4265191473971985,\n",
       "  -1.181511532931277,\n",
       "  0.8898981294638579,\n",
       "  -1.7027156096913,\n",
       "  1.05,\n",
       "  -0.7995694245994897],\n",
       " [-0.18944655676534217,\n",
       "  5.0,\n",
       "  -0.6562339078521995,\n",
       "  -1.38992008832893,\n",
       "  -0.31854654805853144,\n",
       "  -1.8644545065518952,\n",
       "  0.85,\n",
       "  0.7302827563692976],\n",
       " [-0.13887379353478496,\n",
       "  0.0,\n",
       "  -0.8825594027839748,\n",
       "  0.7861094683619211,\n",
       "  0.247154209914467,\n",
       "  1.378668997223177,\n",
       "  1.1,\n",
       "  1.0126366742748116],\n",
       " [-0.7342587793677395,\n",
       "  0.0,\n",
       "  0.9998631146416727,\n",
       "  1.981073426798174,\n",
       "  0.028214310760787654,\n",
       "  0.22838712996705723,\n",
       "  1.1,\n",
       "  1.3531087620800488],\n",
       " [-1.0296959525330918,\n",
       "  4.0,\n",
       "  0.4665671492804989,\n",
       "  1.001329201508545,\n",
       "  1.0372079903172546,\n",
       "  -0.5706164975836293,\n",
       "  1.2,\n",
       "  -1.7904935735521141],\n",
       " [-0.05917511667594811,\n",
       "  4.0,\n",
       "  0.5217187850603188,\n",
       "  -1.2580752925257928,\n",
       "  0.9270217363096958,\n",
       "  -0.08135219804709717,\n",
       "  1.2,\n",
       "  0.28230218292431036],\n",
       " [-1.220368261706118,\n",
       "  0.0,\n",
       "  -1.3020769230760993,\n",
       "  0.8349036739850831,\n",
       "  0.429384287148407,\n",
       "  -0.7977920339184102,\n",
       "  1.1,\n",
       "  0.19486063795600406],\n",
       " [1.0633194705182427,\n",
       "  2.0,\n",
       "  -0.745499422256904,\n",
       "  0.4114137539008856,\n",
       "  0.014947384213895052,\n",
       "  -0.2673933528645686,\n",
       "  1.05,\n",
       "  0.8177656560605557],\n",
       " [-0.03511523571231017,\n",
       "  5.0,\n",
       "  1.362590505009104,\n",
       "  0.9672635950193116,\n",
       "  -0.40579735005701584,\n",
       "  0.16257100363616786,\n",
       "  0.85,\n",
       "  0.8954169907325622],\n",
       " [1.3031189075710037,\n",
       "  3.0,\n",
       "  -0.24439693937289864,\n",
       "  -0.5965802615090386,\n",
       "  0.9936931905154588,\n",
       "  -1.3326075037415843,\n",
       "  0.95,\n",
       "  -0.7925198838753411],\n",
       " [-1.089190050838789,\n",
       "  2.0,\n",
       "  0.8816282308797996,\n",
       "  0.5953745304751635,\n",
       "  0.3268321188392931,\n",
       "  -0.6377619006344781,\n",
       "  1.05,\n",
       "  0.578534737459487],\n",
       " [-0.047285460288333706,\n",
       "  2.0,\n",
       "  0.788127365019488,\n",
       "  1.605709063214643,\n",
       "  -0.9816798942957997,\n",
       "  -1.7738314038713348,\n",
       "  1.05,\n",
       "  -1.8062167433674317],\n",
       " [-0.07119452498814438,\n",
       "  2.0,\n",
       "  -1.2461456342402013,\n",
       "  0.43817069064111386,\n",
       "  -1.2095011306174603,\n",
       "  -0.24224708686673818,\n",
       "  1.05,\n",
       "  -0.10200094109834941],\n",
       " [1.0273468638116008,\n",
       "  1.0,\n",
       "  1.2635388429455578,\n",
       "  0.6704775487606567,\n",
       "  1.1454925624245123,\n",
       "  -0.4298026427809158,\n",
       "  0.9,\n",
       "  0.0014690028245977072],\n",
       " [-1.0263584244106703,\n",
       "  2.0,\n",
       "  1.6226433240583338,\n",
       "  0.8733448654435579,\n",
       "  0.30823092856598444,\n",
       "  1.4283315561633956,\n",
       "  1.05,\n",
       "  -1.2030892787476664],\n",
       " [0.6402421616248248,\n",
       "  4.0,\n",
       "  1.1174512878151621,\n",
       "  -0.8899074161534625,\n",
       "  -1.165214513216075,\n",
       "  -1.6064815639503325,\n",
       "  1.2,\n",
       "  0.5417850211006063],\n",
       " [0.868017757512002,\n",
       "  5.0,\n",
       "  -0.8794757720126475,\n",
       "  -0.4357304973414505,\n",
       "  0.8736601566388567,\n",
       "  -0.16157869010246667,\n",
       "  0.85,\n",
       "  1.0302707336617776],\n",
       " [-0.14584581736492822,\n",
       "  5.0,\n",
       "  0.6227649923015951,\n",
       "  1.9170820035044296,\n",
       "  -0.37895158742798035,\n",
       "  -1.7470307568993322,\n",
       "  0.85,\n",
       "  0.879349776325965],\n",
       " [0.904299803597797,\n",
       "  4.0,\n",
       "  -1.2797522873051048,\n",
       "  -1.39708595336577,\n",
       "  -0.16494823585411114,\n",
       "  1.8745887377113357,\n",
       "  1.2,\n",
       "  0.3666083691134232],\n",
       " [-1.7573109965816804,\n",
       "  2.0,\n",
       "  -0.9663683646212959,\n",
       "  -0.9406750478215328,\n",
       "  0.8638391625635302,\n",
       "  0.6985993683792321,\n",
       "  1.05,\n",
       "  0.44604729395015524],\n",
       " [0.1364988687316863,\n",
       "  1.0,\n",
       "  0.66141708045225,\n",
       "  -0.4762898393249936,\n",
       "  0.24872258222641036,\n",
       "  1.4708168263814065,\n",
       "  0.9,\n",
       "  -0.3521910515979105],\n",
       " [1.5792899463088907,\n",
       "  1.0,\n",
       "  -1.3854963281961856,\n",
       "  1.7433041317535263,\n",
       "  0.24314550597523035,\n",
       "  -0.38756553837211355,\n",
       "  0.9,\n",
       "  1.0346142281009485],\n",
       " [-0.6066407946134708,\n",
       "  3.0,\n",
       "  -0.2177647771311889,\n",
       "  0.3235376720823141,\n",
       "  -0.22481010347211952,\n",
       "  -0.6459455898132919,\n",
       "  0.95,\n",
       "  0.1583252275058394],\n",
       " [0.005795176302810385,\n",
       "  4.0,\n",
       "  1.1859691790868998,\n",
       "  -0.09401229912684243,\n",
       "  0.9663262399321626,\n",
       "  0.6243417778792641,\n",
       "  1.2,\n",
       "  -0.2594883384228659],\n",
       " [0.700369907792588,\n",
       "  4.0,\n",
       "  -1.0868533965866567,\n",
       "  -1.372326667507427,\n",
       "  -0.46587813951953605,\n",
       "  -1.5966105645581326,\n",
       "  1.2,\n",
       "  0.4665460038077594],\n",
       " [0.5288823855823185,\n",
       "  5.0,\n",
       "  0.041302221761985544,\n",
       "  -1.4062778910589557,\n",
       "  0.5304619964972062,\n",
       "  0.025700641646347163,\n",
       "  0.85,\n",
       "  0.3572807412998429],\n",
       " [1.2777616638890825,\n",
       "  1.0,\n",
       "  1.465027933730045,\n",
       "  -0.8176931036424772,\n",
       "  0.43856286044505444,\n",
       "  -0.259989789773329,\n",
       "  0.9,\n",
       "  0.5021582179887981],\n",
       " [-0.2526340212634309,\n",
       "  5.0,\n",
       "  -1.6793382259118947,\n",
       "  -1.2441578702982319,\n",
       "  0.28259739510323306,\n",
       "  -0.608286091432323,\n",
       "  0.85,\n",
       "  -0.3993667871694676],\n",
       " [0.8788562102119897,\n",
       "  0.0,\n",
       "  1.4645088040876912,\n",
       "  0.49681637910442383,\n",
       "  -0.5138558368630411,\n",
       "  -1.6759683551713795,\n",
       "  1.1,\n",
       "  0.8352668145696489],\n",
       " [0.24155412970849263,\n",
       "  3.0,\n",
       "  -0.7249908309625841,\n",
       "  0.8646169791072575,\n",
       "  0.09717641835777575,\n",
       "  -0.9841761930950513,\n",
       "  0.95,\n",
       "  1.063335639248712],\n",
       " [-1.6500386634428583,\n",
       "  0.0,\n",
       "  0.7311740836287219,\n",
       "  -1.3479048991991935,\n",
       "  -2.51863528468932,\n",
       "  1.3062750080068855,\n",
       "  1.1,\n",
       "  -0.052064712419478944],\n",
       " [0.31457615929669197,\n",
       "  1.0,\n",
       "  -0.4098677728820325,\n",
       "  0.8052411748184103,\n",
       "  0.7921744859907339,\n",
       "  1.3221717136029432,\n",
       "  0.9,\n",
       "  -0.8418782368029043],\n",
       " [0.15648772921275023,\n",
       "  2.0,\n",
       "  -1.2542581093067735,\n",
       "  0.7134966449213164,\n",
       "  0.638560993384397,\n",
       "  -0.08619061879585042,\n",
       "  1.05,\n",
       "  0.9504185123118418],\n",
       " [0.011272203021517374,\n",
       "  5.0,\n",
       "  0.7839157256555103,\n",
       "  -1.2190202895949465,\n",
       "  0.6140029787905198,\n",
       "  -1.4966470105019796,\n",
       "  0.85,\n",
       "  1.064576619981931],\n",
       " [-1.6253066692012834,\n",
       "  3.0,\n",
       "  0.587138567075297,\n",
       "  -1.0543320583026494,\n",
       "  0.9535372642296092,\n",
       "  1.1843959968895892,\n",
       "  0.95,\n",
       "  0.8828448164296573],\n",
       " [1.0237026045776128,\n",
       "  2.0,\n",
       "  -0.2104838368335436,\n",
       "  1.130915269851817,\n",
       "  -2.0715699889535415,\n",
       "  -1.3970466015294989,\n",
       "  1.05,\n",
       "  -0.1839242489844321],\n",
       " [0.3847979266452051,\n",
       "  2.0,\n",
       "  -0.7896422317448802,\n",
       "  0.6092345589215213,\n",
       "  0.3907242375735765,\n",
       "  -0.9439819799054074,\n",
       "  1.05,\n",
       "  0.29925616978077374],\n",
       " [1.3621912925896236,\n",
       "  0.0,\n",
       "  0.17196910374042718,\n",
       "  -0.6935702082060198,\n",
       "  -0.5075250800621136,\n",
       "  -0.11204667883162697,\n",
       "  1.1,\n",
       "  0.510771918885316],\n",
       " [1.0127486374793686,\n",
       "  0.0,\n",
       "  0.5179080896404265,\n",
       "  -1.3188609172115602,\n",
       "  0.48314411910141947,\n",
       "  0.5775247560355928,\n",
       "  1.1,\n",
       "  1.0646592284194791],\n",
       " [0.3650579566861733,\n",
       "  3.0,\n",
       "  -1.0038494506612046,\n",
       "  0.7911839382187547,\n",
       "  0.632083959762261,\n",
       "  0.7418149634822959,\n",
       "  0.95,\n",
       "  1.546298992127841],\n",
       " [1.2401735264022449,\n",
       "  4.0,\n",
       "  -1.2275651221254475,\n",
       "  1.9142841495080873,\n",
       "  0.5190038112885287,\n",
       "  -0.08828105271170682,\n",
       "  1.2,\n",
       "  -1.488030182208724],\n",
       " [-0.27548768265576645,\n",
       "  2.0,\n",
       "  0.5906617969909577,\n",
       "  -1.361393679880129,\n",
       "  -0.13090375656871703,\n",
       "  -0.7968418571389868,\n",
       "  1.05,\n",
       "  -0.6281439506880451],\n",
       " [1.1154423666179312,\n",
       "  5.0,\n",
       "  -0.09882648821942801,\n",
       "  0.5647701147530136,\n",
       "  -0.9357610895212992,\n",
       "  0.03978798922138101,\n",
       "  0.85,\n",
       "  1.0589589036474099],\n",
       " [-1.0011425442637458,\n",
       "  1.0,\n",
       "  -0.1037099595501006,\n",
       "  -1.1468170769649937,\n",
       "  1.2806748034896092,\n",
       "  1.0992383092912172,\n",
       "  0.9,\n",
       "  -1.941482384625376],\n",
       " [-0.4370908069673734,\n",
       "  0.0,\n",
       "  -0.6999203395361253,\n",
       "  -0.9246894666377679,\n",
       "  0.9241531803781692,\n",
       "  1.252204996515085,\n",
       "  1.1,\n",
       "  -0.5019057272709121],\n",
       " [0.08125871331584746,\n",
       "  3.0,\n",
       "  1.3390935289775991,\n",
       "  -0.9115856090951657,\n",
       "  0.2684537757552557,\n",
       "  -1.8103199636690959,\n",
       "  0.95,\n",
       "  -1.1170319267237705],\n",
       " [0.10804120931655758,\n",
       "  0.0,\n",
       "  1.4924344676853873,\n",
       "  0.5442498637242476,\n",
       "  -0.19577338758708515,\n",
       "  0.44579460188790104,\n",
       "  1.1,\n",
       "  -1.4023603477498257],\n",
       " [-1.3265611662280459,\n",
       "  0.0,\n",
       "  1.576107397314671,\n",
       "  1.5919907950812553,\n",
       "  0.6467241248974056,\n",
       "  -1.2243090683043367,\n",
       "  1.1,\n",
       "  -1.9796250397401074],\n",
       " [0.7187559168766527,\n",
       "  1.0,\n",
       "  -1.0812349618778336,\n",
       "  -1.3316255866081925,\n",
       "  0.1821141049192921,\n",
       "  -1.8063173072620624,\n",
       "  0.9,\n",
       "  0.25563023914847033],\n",
       " [1.5288335695373332,\n",
       "  2.0,\n",
       "  -1.6573160439885195,\n",
       "  0.22016499828344088,\n",
       "  -0.29240540674293763,\n",
       "  0.3757407441056754,\n",
       "  1.05,\n",
       "  0.4819457334936499],\n",
       " [1.5181075074495756,\n",
       "  3.0,\n",
       "  0.6305430751679376,\n",
       "  -0.04779688758082121,\n",
       "  0.8515834161273911,\n",
       "  1.3044113980310246,\n",
       "  0.95,\n",
       "  -0.8594933324682603],\n",
       " [-0.9190803778586444,\n",
       "  0.0,\n",
       "  1.6717146126400602,\n",
       "  1.4988791667996215,\n",
       "  0.9753673993438869,\n",
       "  0.4201064103234776,\n",
       "  1.1,\n",
       "  -0.7175033683482092],\n",
       " [-0.7186729963206611,\n",
       "  2.0,\n",
       "  -0.6171348350767218,\n",
       "  1.3854560344906244,\n",
       "  -2.1002769685960234,\n",
       "  1.6106746732606112,\n",
       "  1.05,\n",
       "  -1.9234198727747778],\n",
       " [-1.6548208172118224,\n",
       "  0.0,\n",
       "  0.49146201541637513,\n",
       "  0.3527629135314181,\n",
       "  0.5870977565310573,\n",
       "  1.9433192139476958,\n",
       "  1.1,\n",
       "  -0.9881932096923655],\n",
       " [-0.16013313345531785,\n",
       "  1.0,\n",
       "  -1.2993065256275573,\n",
       "  -1.1158655560452782,\n",
       "  0.8805323028522773,\n",
       "  0.8279108231224406,\n",
       "  0.9,\n",
       "  -0.6012525573719028],\n",
       " [-0.09919015804415947,\n",
       "  2.0,\n",
       "  -1.2700136195310763,\n",
       "  0.29524317280977663,\n",
       "  0.16553801797039813,\n",
       "  -0.7451887522974983,\n",
       "  1.05,\n",
       "  -1.1430800347065289],\n",
       " [0.9694622589900063,\n",
       "  3.0,\n",
       "  0.02653434799742952,\n",
       "  -0.8677966493716247,\n",
       "  0.583059914412544,\n",
       "  1.4885404605412305,\n",
       "  0.95,\n",
       "  -0.8643501977939245],\n",
       " [-1.529369876594212,\n",
       "  3.0,\n",
       "  -0.49495859200889103,\n",
       "  -0.7156632994758788,\n",
       "  1.1038851038606365,\n",
       "  -0.29169486705981923,\n",
       "  0.95,\n",
       "  -0.45028571266687645],\n",
       " [0.2056374239420773,\n",
       "  5.0,\n",
       "  -0.7614623276517685,\n",
       "  1.4100433604007516,\n",
       "  1.2614611482964113,\n",
       "  0.15786695561059877,\n",
       "  0.85,\n",
       "  1.046169004885334],\n",
       " [-0.2552596569112842,\n",
       "  3.0,\n",
       "  0.29454031382992446,\n",
       "  0.22162311159082285,\n",
       "  -1.1550230980268832,\n",
       "  1.8592908773160024,\n",
       "  0.95,\n",
       "  0.4269698816968086],\n",
       " [0.6709425796196014,\n",
       "  1.0,\n",
       "  1.0501911617373811,\n",
       "  0.24797497028952836,\n",
       "  0.26346351962686954,\n",
       "  1.6546290597089495,\n",
       "  0.9,\n",
       "  0.5742653355331729],\n",
       " [1.372271409491319,\n",
       "  4.0,\n",
       "  0.3243946815057822,\n",
       "  0.9199603603801333,\n",
       "  -1.5230608383547533,\n",
       "  -1.3971247922283831,\n",
       "  1.2,\n",
       "  -1.6421284467959618],\n",
       " [0.236487629497958,\n",
       "  2.0,\n",
       "  0.5608203216543316,\n",
       "  -0.453952839002991,\n",
       "  -0.02008579947205109,\n",
       "  0.04905985387617895,\n",
       "  1.05,\n",
       "  -1.0400874341330888],\n",
       " [1.2150183198211837,\n",
       "  2.0,\n",
       "  -1.3064526023980756,\n",
       "  1.4753978174101747,\n",
       "  0.28167738088809247,\n",
       "  -1.1611508493381284,\n",
       "  1.05,\n",
       "  0.8436402122811381],\n",
       " [1.7655066022154837,\n",
       "  1.0,\n",
       "  0.18639475861041382,\n",
       "  -1.1077869326107128,\n",
       "  0.032985413323036554,\n",
       "  -1.929140731232273,\n",
       "  0.9,\n",
       "  0.48532916512076046],\n",
       " [-1.138326500056104,\n",
       "  3.0,\n",
       "  -0.11151616829311932,\n",
       "  -0.8476222171417801,\n",
       "  0.48521845917917,\n",
       "  0.14402042438404844,\n",
       "  0.95,\n",
       "  -0.8872863551728423],\n",
       " [-0.010753584508483158,\n",
       "  5.0,\n",
       "  -1.0166614872650217,\n",
       "  1.2537302880457495,\n",
       "  0.6992285091733716,\n",
       "  -0.13038057109516418,\n",
       "  0.85,\n",
       "  -1.238952426661972],\n",
       " [1.2261335401355733,\n",
       "  1.0,\n",
       "  1.6189007776592443,\n",
       "  -0.5098381581280286,\n",
       "  0.5559438666958848,\n",
       "  0.028014239778642643,\n",
       "  0.9,\n",
       "  -0.46353618787067224],\n",
       " [1.0484847948438778,\n",
       "  5.0,\n",
       "  1.48694659457085,\n",
       "  0.7984764267968246,\n",
       "  -1.5021806108189502,\n",
       "  -1.8745334141402819,\n",
       "  0.85,\n",
       "  -0.19366146901909562],\n",
       " [1.4771643320934924,\n",
       "  2.0,\n",
       "  0.6059586465164415,\n",
       "  1.8314293573785543,\n",
       "  -1.3593513085480575,\n",
       "  1.3601874788727495,\n",
       "  1.05,\n",
       "  -1.9163970547147668],\n",
       " [-0.5002630713833658,\n",
       "  4.0,\n",
       "  0.3505071165530787,\n",
       "  -0.8471946645070985,\n",
       "  0.9205523670546619,\n",
       "  0.5697147191206924,\n",
       "  1.2,\n",
       "  1.0580746415457156],\n",
       " [1.630650217511813,\n",
       "  0.0,\n",
       "  1.2682184795447224,\n",
       "  -0.31649017625772297,\n",
       "  -1.921074807069261,\n",
       "  1.793671536685456,\n",
       "  1.1,\n",
       "  0.7577860693938892],\n",
       " [1.4273161967972503,\n",
       "  4.0,\n",
       "  -1.371633510639619,\n",
       "  0.503694017875816,\n",
       "  -0.506574077115974,\n",
       "  -1.097407976410774,\n",
       "  1.2,\n",
       "  0.38050328173876335],\n",
       " [1.2688064605086056,\n",
       "  3.0,\n",
       "  1.0051062741129924,\n",
       "  -1.1951663671578319,\n",
       "  0.753729527086067,\n",
       "  -0.024226156595136855,\n",
       "  0.95,\n",
       "  -0.759497636067751],\n",
       " [1.1917814643523807,\n",
       "  4.0,\n",
       "  0.7943195232872945,\n",
       "  -1.0284783265064081,\n",
       "  0.7244413871115093,\n",
       "  0.00787152707656381,\n",
       "  1.2,\n",
       "  -1.2390801342173003],\n",
       " [0.3189100044664627,\n",
       "  5.0,\n",
       "  0.9278139725502789,\n",
       "  1.0874160534267723,\n",
       "  0.8981323355460404,\n",
       "  1.1040786229049637,\n",
       "  0.85,\n",
       "  1.064609175695148],\n",
       " [-0.003382971444664566,\n",
       "  4.0,\n",
       "  0.44727724519238937,\n",
       "  0.010004180549160305,\n",
       "  0.882637868428431,\n",
       "  -0.15316841849309393,\n",
       "  1.2,\n",
       "  0.10847666891542454],\n",
       " [-0.9095454836917154,\n",
       "  5.0,\n",
       "  0.6628204654031041,\n",
       "  0.8145136664691438,\n",
       "  0.9014010059284446,\n",
       "  -1.497595855437351,\n",
       "  0.85,\n",
       "  0.5933909115640615],\n",
       " [-1.033363736826604,\n",
       "  1.0,\n",
       "  1.1015252958206934,\n",
       "  -0.6857430276337649,\n",
       "  -2.679448968515826,\n",
       "  1.9812405325329605,\n",
       "  0.9,\n",
       "  0.025427851608120205],\n",
       " [0.07859370394126043,\n",
       "  0.0,\n",
       "  -1.2477345802890885,\n",
       "  -0.5740949289604537,\n",
       "  0.18215253748348245,\n",
       "  0.628625482307805,\n",
       "  1.1,\n",
       "  0.7823378899649205],\n",
       " [1.5214980314732451,\n",
       "  1.0,\n",
       "  -1.5548913353094318,\n",
       "  -1.1386793317838322,\n",
       "  -2.505943341398384,\n",
       "  -0.7401429237644261,\n",
       "  0.9,\n",
       "  -0.7484899793567098],\n",
       " [-0.0637869676962124,\n",
       "  5.0,\n",
       "  -0.3026842981246014,\n",
       "  -0.2591416303027365,\n",
       "  1.564270940791215,\n",
       "  -0.3953452830841437,\n",
       "  0.85,\n",
       "  0.33042926259795463],\n",
       " [-0.9263397956310535,\n",
       "  4.0,\n",
       "  0.5013096088346748,\n",
       "  0.04966205680284739,\n",
       "  0.00917881918761521,\n",
       "  0.7652706564485792,\n",
       "  1.2,\n",
       "  0.7885433996605355],\n",
       " [-1.1715200886906223,\n",
       "  3.0,\n",
       "  0.4240383511232734,\n",
       "  0.9448676097769169,\n",
       "  -0.10671095225367623,\n",
       "  -0.5305442244973674,\n",
       "  0.95,\n",
       "  0.6044021254800428],\n",
       " [0.7861812763706184,\n",
       "  3.0,\n",
       "  1.2286432885410115,\n",
       "  0.3892917280011473,\n",
       "  0.29720910047382054,\n",
       "  0.29193078835308645,\n",
       "  0.95,\n",
       "  0.1235517861622389],\n",
       " [-0.3367536995029489,\n",
       "  5.0,\n",
       "  1.2031492934355097,\n",
       "  -1.3664122196550794,\n",
       "  0.6538100122920284,\n",
       "  1.3131159836821233,\n",
       "  0.85,\n",
       "  0.9759742006286624],\n",
       " [-0.6097005380420546,\n",
       "  3.0,\n",
       "  -1.3430524186068946,\n",
       "  1.8670769234570848,\n",
       "  -1.5645696487926206,\n",
       "  -1.7751674547267744,\n",
       "  0.95,\n",
       "  1.0638205905641474],\n",
       " [-0.3046597291626789,\n",
       "  5.0,\n",
       "  -1.0384922513009198,\n",
       "  0.0473720699390469,\n",
       "  0.7071075406646524,\n",
       "  0.5187180426452535,\n",
       "  0.85,\n",
       "  1.051745952479737],\n",
       " [1.2184723021123312,\n",
       "  5.0,\n",
       "  1.24751507748398,\n",
       "  -0.3671575716983399,\n",
       "  -1.2816054979912657,\n",
       "  0.8082886926794969,\n",
       "  0.85,\n",
       "  -0.9249577286900513],\n",
       " [-0.8851479053549393,\n",
       "  0.0,\n",
       "  -0.9753858630473976,\n",
       "  -1.3685933070303982,\n",
       "  -0.20824375780649662,\n",
       "  1.7663247942671507,\n",
       "  1.1,\n",
       "  0.34014099714514534],\n",
       " [-0.8955279419515388,\n",
       "  3.0,\n",
       "  0.06667632629039232,\n",
       "  -1.4099403199395883,\n",
       "  0.9160596966265447,\n",
       "  -0.26207127589565254,\n",
       "  0.95,\n",
       "  -1.887030776472222],\n",
       " [-0.42027707531993513,\n",
       "  4.0,\n",
       "  -1.519293524005454,\n",
       "  -0.910244213307467,\n",
       "  0.4485733693896478,\n",
       "  0.762472526415885,\n",
       "  1.2,\n",
       "  0.15484388549001327],\n",
       " [-0.4652404059075615,\n",
       "  3.0,\n",
       "  -0.13619374817475552,\n",
       "  0.956096484666022,\n",
       "  -0.05781564978835501,\n",
       "  0.45758894739085154,\n",
       "  0.95,\n",
       "  1.0453251335490545],\n",
       " [-0.26063498509354094,\n",
       "  3.0,\n",
       "  0.8706659452048573,\n",
       "  -0.7129263701010039,\n",
       "  0.8107234803966962,\n",
       "  -0.03566819359992643,\n",
       "  0.95,\n",
       "  0.6405275052873411],\n",
       " [-1.7856194280442204,\n",
       "  0.0,\n",
       "  -1.6598079686701186,\n",
       "  -0.36369614772908104,\n",
       "  -0.43602559019131165,\n",
       "  -1.4853610209204589,\n",
       "  1.1,\n",
       "  -0.028623447645006645],\n",
       " [-0.2885333008529291,\n",
       "  3.0,\n",
       "  0.30038475438270507,\n",
       "  1.9599275366140412,\n",
       "  0.45063825064038865,\n",
       "  0.49397091248163394,\n",
       "  0.95,\n",
       "  -1.2237670455018437],\n",
       " [0.7850345900850495,\n",
       "  2.0,\n",
       "  1.262704138049627,\n",
       "  1.9808344310355004,\n",
       "  -1.5616078080712017,\n",
       "  -0.27502084479397715,\n",
       "  1.05,\n",
       "  -0.6384620637607263],\n",
       " [-2.003127949395075,\n",
       "  2.0,\n",
       "  -1.4832504333578707,\n",
       "  0.9338965478178999,\n",
       "  -0.06585297148227855,\n",
       "  -1.7182859120054432,\n",
       "  1.05,\n",
       "  -0.8760218547295239],\n",
       " [-1.2876163604980166,\n",
       "  2.0,\n",
       "  0.31638343823711207,\n",
       "  -1.370143875803645,\n",
       "  -0.7954965414584773,\n",
       "  1.573921179348061,\n",
       "  1.05,\n",
       "  -0.23967230263339007],\n",
       " [0.9152723561063787,\n",
       "  3.0,\n",
       "  1.6048085016009321,\n",
       "  0.4078407997991351,\n",
       "  0.45449920695679025,\n",
       "  -1.6682864252277192,\n",
       "  0.95,\n",
       "  -1.7028500488043536],\n",
       " [-0.163910631197323,\n",
       "  0.0,\n",
       "  -0.2954858366315657,\n",
       "  -1.3809583641421392,\n",
       "  -0.9978966306825825,\n",
       "  -0.7552073626370622,\n",
       "  1.1,\n",
       "  -0.20647052138215108],\n",
       " [-0.7132573587524205,\n",
       "  3.0,\n",
       "  -0.7820320627827914,\n",
       "  -1.1944262073769165,\n",
       "  0.9533328604569838,\n",
       "  -0.32526276481685057,\n",
       "  0.95,\n",
       "  0.3391076087953538],\n",
       " [0.43527010684237455,\n",
       "  4.0,\n",
       "  -0.10285848136695781,\n",
       "  -0.020134859637318165,\n",
       "  0.7591266470106749,\n",
       "  1.6619766745708884,\n",
       "  1.2,\n",
       "  0.5238052844923835],\n",
       " [-2.0183331541227085,\n",
       "  2.0,\n",
       "  1.0432376589954582,\n",
       "  1.6480167836120598,\n",
       "  -0.3550157192832405,\n",
       "  -0.8070836325050641,\n",
       "  1.05,\n",
       "  -0.17204208263016346],\n",
       " [-1.4868166802666238,\n",
       "  2.0,\n",
       "  -0.9355068659866689,\n",
       "  1.6629429718803028,\n",
       "  0.10243977631872225,\n",
       "  0.8454288830433238,\n",
       "  1.05,\n",
       "  0.4510205002773962],\n",
       " [-1.5092957781634304,\n",
       "  3.0,\n",
       "  1.1812409591261348,\n",
       "  1.2686083344707464,\n",
       "  -0.03164937618921824,\n",
       "  -1.3729343807993406,\n",
       "  0.95,\n",
       "  -0.917287474122851],\n",
       " [-0.7215631454336136,\n",
       "  5.0,\n",
       "  -1.5346743052400384,\n",
       "  0.4214109325203935,\n",
       "  0.36608898804475015,\n",
       "  -0.38581355058930306,\n",
       "  0.85,\n",
       "  -1.0024202837832819],\n",
       " [-0.7606529745503345,\n",
       "  4.0,\n",
       "  0.15788844834523347,\n",
       "  -0.17310446213375916,\n",
       "  -0.8928374334980458,\n",
       "  -1.6559904191151147,\n",
       "  1.2,\n",
       "  0.38286801046668156],\n",
       " [-0.7214019336026762,\n",
       "  1.0,\n",
       "  1.5307261387437057,\n",
       "  -0.5536657686922161,\n",
       "  0.9582677005856015,\n",
       "  -1.786382034507612,\n",
       "  0.9,\n",
       "  0.6720818386728238],\n",
       " [-0.45009924499812176,\n",
       "  0.0,\n",
       "  -1.6376070742539772,\n",
       "  0.9748897270900307,\n",
       "  0.9528660766260594,\n",
       "  0.29905211302832013,\n",
       "  1.1,\n",
       "  -1.8159084513888182],\n",
       " [1.6814629501282974,\n",
       "  2.0,\n",
       "  -0.8211808648056441,\n",
       "  1.7476557391616272,\n",
       "  -0.0030299902897132666,\n",
       "  -0.8032185934703611,\n",
       "  1.05,\n",
       "  -1.5399497636335924],\n",
       " [-1.0745975027779198,\n",
       "  0.0,\n",
       "  0.19350113646088576,\n",
       "  1.0348622601652464,\n",
       "  -1.6379347155301913,\n",
       "  1.1278750195244875,\n",
       "  1.1,\n",
       "  1.0484011291843636],\n",
       " [0.7614866728669402,\n",
       "  0.0,\n",
       "  1.0553021538872662,\n",
       "  0.2233412387982564,\n",
       "  0.2775147322365168,\n",
       "  -0.05377006382052443,\n",
       "  1.1,\n",
       "  0.47810820511761615],\n",
       " [0.5537068794643121,\n",
       "  2.0,\n",
       "  0.9819821808020702,\n",
       "  0.5752019833291258,\n",
       "  0.5964930459502812,\n",
       "  1.9112636011369455,\n",
       "  1.05,\n",
       "  1.0481549568075201],\n",
       " [-1.5609061888115203,\n",
       "  3.0,\n",
       "  -1.1074821035678974,\n",
       "  0.5396492475351647,\n",
       "  0.307668338851691,\n",
       "  -0.2120991859676725,\n",
       "  0.95,\n",
       "  -0.15458796563492008],\n",
       " [0.6160374660767141,\n",
       "  0.0,\n",
       "  -1.0697519746941868,\n",
       "  -0.43757858127399263,\n",
       "  0.7611919467474527,\n",
       "  0.9007663608264258,\n",
       "  1.1,\n",
       "  0.9821238535671498],\n",
       " [-1.1672542053681239,\n",
       "  4.0,\n",
       "  -0.23119497431018002,\n",
       "  -1.1047661796366488,\n",
       "  -0.22414944918457952,\n",
       "  0.07408861171212773,\n",
       "  1.2,\n",
       "  1.0654102386963409],\n",
       " [-0.9270012710154251,\n",
       "  2.0,\n",
       "  -1.1039400657917162,\n",
       "  1.182698240636013,\n",
       "  -0.9025714456686309,\n",
       "  -0.02367709599944188,\n",
       "  1.05,\n",
       "  -1.1487230306864118],\n",
       " [1.1471956677218529,\n",
       "  5.0,\n",
       "  -1.3958687481444716,\n",
       "  0.7691503778525434,\n",
       "  0.8032269433271519,\n",
       "  -0.1020290429284958,\n",
       "  0.85,\n",
       "  1.0649034567916775],\n",
       " [-0.40526464863106565,\n",
       "  0.0,\n",
       "  1.196038097749653,\n",
       "  -0.7924238370765175,\n",
       "  -1.011549910192302,\n",
       "  -0.9722270826979861,\n",
       "  1.1,\n",
       "  0.47073652380395475],\n",
       " [-0.3695457898913765,\n",
       "  1.0,\n",
       "  -0.3947720986913442,\n",
       "  -0.7717829295617885,\n",
       "  0.26919570595130776,\n",
       "  -1.3353068249180755,\n",
       "  0.9,\n",
       "  0.46476026880357113],\n",
       " [-0.8642026438986725,\n",
       "  5.0,\n",
       "  1.142307361603519,\n",
       "  1.3486980167497498,\n",
       "  0.25100979602526907,\n",
       "  -0.8684351174694548,\n",
       "  0.85,\n",
       "  1.0611235577944909],\n",
       " [-0.3227562976366581,\n",
       "  5.0,\n",
       "  -1.116019640482523,\n",
       "  -0.5105369032734884,\n",
       "  0.7147838453086096,\n",
       "  -0.7382702573348074,\n",
       "  0.85,\n",
       "  -0.3301366570464841],\n",
       " [0.5160488365291049,\n",
       "  4.0,\n",
       "  -1.5278170367667623,\n",
       "  -1.108363206973666,\n",
       "  0.9033564480245861,\n",
       "  1.5474620638450771,\n",
       "  1.2,\n",
       "  -0.8095521224835209],\n",
       " [-1.3609474840033722,\n",
       "  5.0,\n",
       "  -0.22836738690501746,\n",
       "  0.8478458189452175,\n",
       "  -0.8731290078622416,\n",
       "  -0.040359248713714636,\n",
       "  0.85,\n",
       "  1.0534795902348808],\n",
       " [-0.15636052444981774,\n",
       "  4.0,\n",
       "  0.8088069553367283,\n",
       "  -1.1879445629802157,\n",
       "  -0.2488866471940649,\n",
       "  0.15468320886795045,\n",
       "  1.2,\n",
       "  -1.8600052286607627],\n",
       " [-0.9420462182181998,\n",
       "  1.0,\n",
       "  -0.11929813589513742,\n",
       "  1.0121767718670351,\n",
       "  -1.6971111454357783,\n",
       "  -1.1262516307164896,\n",
       "  0.9,\n",
       "  1.0887373812668453],\n",
       " [0.3214406381664024,\n",
       "  1.0,\n",
       "  -0.6406836449975166,\n",
       "  1.974489212418156,\n",
       "  0.7270618185491718,\n",
       "  -1.8960635799610823,\n",
       "  0.9,\n",
       "  0.3535116138857473],\n",
       " [-0.6799112550195967,\n",
       "  4.0,\n",
       "  0.4319239243587846,\n",
       "  1.571844825016883,\n",
       "  0.8925366700681858,\n",
       "  0.13935150814232877,\n",
       "  1.2,\n",
       "  -0.14682335438268646],\n",
       " [-1.3687056652723475,\n",
       "  1.0,\n",
       "  -1.485870206731647,\n",
       "  1.32152472516433,\n",
       "  -0.12160315304593118,\n",
       "  -1.2615867998512702,\n",
       "  0.9,\n",
       "  1.0652488827790247],\n",
       " [-0.6809878958501732,\n",
       "  5.0,\n",
       "  -0.4554950709589499,\n",
       "  1.65304795144033,\n",
       "  -1.0419857764273952,\n",
       "  1.225512533824852,\n",
       "  0.85,\n",
       "  -0.7009080512840807],\n",
       " [1.483822738987088,\n",
       "  3.0,\n",
       "  1.6110741887857072,\n",
       "  0.15687296860063002,\n",
       "  0.8663614639102618,\n",
       "  0.6472233626583778,\n",
       "  0.95,\n",
       "  -0.4150747833521121],\n",
       " [0.2953667844912327,\n",
       "  1.0,\n",
       "  1.7269495979971623,\n",
       "  1.5595393067074501,\n",
       "  0.4115263416816489,\n",
       "  -0.4232062404285524,\n",
       "  0.9,\n",
       "  1.0440841798383274],\n",
       " [0.41115165451869096,\n",
       "  0.0,\n",
       "  -0.5854428379821092,\n",
       "  -0.6162736913616393,\n",
       "  -0.3887532998784396,\n",
       "  0.5294783504490196,\n",
       "  1.1,\n",
       "  1.6445699045213784],\n",
       " [0.39063550732286645,\n",
       "  2.0,\n",
       "  -1.3131877383204449,\n",
       "  -0.5627568395329883,\n",
       "  0.5249501675731322,\n",
       "  -1.2373822153234666,\n",
       "  1.05,\n",
       "  0.835571567488962],\n",
       " [0.7590250357157039,\n",
       "  1.0,\n",
       "  -1.1034197757215114,\n",
       "  0.14979989615297432,\n",
       "  0.7205036306614467,\n",
       "  -1.9136851376006234,\n",
       "  0.9,\n",
       "  -1.4675415614242606],\n",
       " [1.1166403255187596,\n",
       "  3.0,\n",
       "  1.565174770351302,\n",
       "  -1.0776913069803091,\n",
       "  0.2100748818266289,\n",
       "  0.5897621973508839,\n",
       "  0.95,\n",
       "  -0.5611388654707516],\n",
       " [-0.06573278730477293,\n",
       "  2.0,\n",
       "  -0.4914229960252446,\n",
       "  -0.7069747690109596,\n",
       "  1.0048570543918556,\n",
       "  -1.1127469944039199,\n",
       "  1.05,\n",
       "  -0.6501300639223045],\n",
       " [-0.2411686727240338,\n",
       "  3.0,\n",
       "  0.9471094872509334,\n",
       "  0.9014881759219577,\n",
       "  1.0562311710584102,\n",
       "  -1.620323728403096,\n",
       "  0.95,\n",
       "  -1.3446154757636783],\n",
       " [1.453140004857796,\n",
       "  2.0,\n",
       "  0.9747032047354829,\n",
       "  0.0023652983639383964,\n",
       "  -1.1596518201989128,\n",
       "  -0.7238277999502796,\n",
       "  1.05,\n",
       "  1.0465771518239784],\n",
       " [-0.3304816625642662,\n",
       "  5.0,\n",
       "  -0.30229462400938445,\n",
       "  -1.0858166680035162,\n",
       "  0.440700998749957,\n",
       "  -0.7781093665518451,\n",
       "  0.85,\n",
       "  1.063913859550777],\n",
       " [-1.3624567610400795,\n",
       "  4.0,\n",
       "  -0.05954448169774824,\n",
       "  0.2267833960650831,\n",
       "  0.8016881056605542,\n",
       "  0.26094269619228383,\n",
       "  1.2,\n",
       "  -0.1499530904979494],\n",
       " [-0.7964411843599152,\n",
       "  5.0,\n",
       "  -0.19072125527439598,\n",
       "  -0.9847685557656187,\n",
       "  0.8008049174578604,\n",
       "  -1.0865247915607836,\n",
       "  0.85,\n",
       "  0.8217371024931118],\n",
       " [0.4432994434914182,\n",
       "  4.0,\n",
       "  -1.5886748826870036,\n",
       "  1.0137432715996548,\n",
       "  0.9311848819745135,\n",
       "  -0.7018812720628816,\n",
       "  1.2,\n",
       "  -0.4686356203948643],\n",
       " [0.45838758756099846,\n",
       "  4.0,\n",
       "  -0.3216053617193776,\n",
       "  0.8457418462960583,\n",
       "  -1.4968935803375725,\n",
       "  -0.2657048509728471,\n",
       "  1.2,\n",
       "  0.20919840671296086],\n",
       " [-0.07619110515326777,\n",
       "  3.0,\n",
       "  -0.18417479273015427,\n",
       "  0.3216518092079064,\n",
       "  -0.41011076787884054,\n",
       "  -0.2713564081151142,\n",
       "  0.95,\n",
       "  -0.07826098878289803],\n",
       " [-0.5419195865328109,\n",
       "  0.0,\n",
       "  0.9178042666344604,\n",
       "  -0.8493554771633263,\n",
       "  0.3020809411487802,\n",
       "  0.40275775918856294,\n",
       "  1.1,\n",
       "  -0.1477914735124376],\n",
       " [-0.37149906413994804,\n",
       "  4.0,\n",
       "  1.0517862358740437,\n",
       "  0.9192628859332221,\n",
       "  -0.02453797087118408,\n",
       "  -1.0198387805873244,\n",
       "  1.2,\n",
       "  0.8728001027840036],\n",
       " [0.9556422593942207,\n",
       "  3.0,\n",
       "  -1.50301979008423,\n",
       "  1.6778609215311742,\n",
       "  -0.5427989635231446,\n",
       "  -0.37844917201381983,\n",
       "  0.95,\n",
       "  -0.7297820041905001],\n",
       " [-0.8093631005909393,\n",
       "  1.0,\n",
       "  -1.4946800660961717,\n",
       "  1.296823983444245,\n",
       "  0.9037418038009688,\n",
       "  0.27513985392025886,\n",
       "  0.9,\n",
       "  -0.1906764962644295],\n",
       " [0.4577970202787378,\n",
       "  2.0,\n",
       "  -1.15556986018836,\n",
       "  1.6606914944615643,\n",
       "  -0.7164566439658852,\n",
       "  -0.3749604428572038,\n",
       "  1.05,\n",
       "  -0.9783763410274618],\n",
       " [-1.1246169887500896,\n",
       "  4.0,\n",
       "  1.0326153564914666,\n",
       "  0.9013248126867017,\n",
       "  0.06612785630470648,\n",
       "  -0.4143908336294229,\n",
       "  1.2,\n",
       "  -0.4188974138467808],\n",
       " [-1.4827488080715021,\n",
       "  1.0,\n",
       "  -0.5538499055458158,\n",
       "  -0.7471716484352275,\n",
       "  0.051822177796138125,\n",
       "  0.35513832874497175,\n",
       "  0.9,\n",
       "  -1.5950855663459746],\n",
       " [-0.7279819962736516,\n",
       "  0.0,\n",
       "  -1.254430458845546,\n",
       "  -0.3166784682878839,\n",
       "  -0.21494716909933448,\n",
       "  0.4046284399882394,\n",
       "  1.1,\n",
       "  -0.06983350623118004],\n",
       " [-0.33701247304057913,\n",
       "  2.0,\n",
       "  0.49173384309890567,\n",
       "  -0.21469795999875346,\n",
       "  -3.1839258254953307,\n",
       "  -0.0750664869193074,\n",
       "  1.05,\n",
       "  -1.2788494094797604],\n",
       " [1.169008676795268,\n",
       "  5.0,\n",
       "  0.4145266139589792,\n",
       "  -1.3323896747293882,\n",
       "  0.7299817948764848,\n",
       "  -1.793762034117163,\n",
       "  0.85,\n",
       "  -0.03613639595533416],\n",
       " [-0.8747992757184818,\n",
       "  3.0,\n",
       "  0.8368741556835227,\n",
       "  -0.48974602082875296,\n",
       "  0.8533402187110167,\n",
       "  0.09491106063462959,\n",
       "  0.95,\n",
       "  -0.31781302671000156],\n",
       " [-0.0335536138980881,\n",
       "  0.0,\n",
       "  0.08435303582642709,\n",
       "  -1.019980885489225,\n",
       "  -0.15583656900107015,\n",
       "  -1.3506744650587847,\n",
       "  1.1,\n",
       "  -1.917400456676548],\n",
       " [1.1486950299393048,\n",
       "  3.0,\n",
       "  -0.050401663784235926,\n",
       "  -1.1394763900464537,\n",
       "  0.5988512234991212,\n",
       "  -1.208996338636079,\n",
       "  0.95,\n",
       "  -0.14233727085695239],\n",
       " [0.12942750953179055,\n",
       "  3.0,\n",
       "  -1.4304117260396882,\n",
       "  -0.7347311036294535,\n",
       "  0.6547149111445417,\n",
       "  1.37848148423674,\n",
       "  0.95,\n",
       "  -0.19196420092336053],\n",
       " [0.3491565537528128,\n",
       "  5.0,\n",
       "  0.8133817633809417,\n",
       "  -1.3673815996156748,\n",
       "  0.9455057182285486,\n",
       "  -1.48259697102196,\n",
       "  0.85,\n",
       "  -0.6251648177626656],\n",
       " [1.4542409079797876,\n",
       "  4.0,\n",
       "  -0.4060323417107461,\n",
       "  1.9411323515851369,\n",
       "  0.6159871509497998,\n",
       "  0.21773771356846658,\n",
       "  1.2,\n",
       "  0.5671951737365962],\n",
       " [0.7710035820662214,\n",
       "  1.0,\n",
       "  1.662016259888536,\n",
       "  -1.4228818278382485,\n",
       "  0.7764920640079659,\n",
       "  -1.0866147708688834,\n",
       "  0.9,\n",
       "  -0.9808411025435319],\n",
       " [0.6414114243120849,\n",
       "  1.0,\n",
       "  -0.8885282770048801,\n",
       "  -0.16904413421402767,\n",
       "  0.3789488135329577,\n",
       "  -0.06308062163580384,\n",
       "  0.9,\n",
       "  -1.527001830507986],\n",
       " [-1.685798133197125,\n",
       "  4.0,\n",
       "  -0.13273660396067552,\n",
       "  0.7680208602875501,\n",
       "  0.794523311787619,\n",
       "  -1.190330978483007,\n",
       "  1.2,\n",
       "  0.7306487430998887],\n",
       " [-1.5269038989883716,\n",
       "  4.0,\n",
       "  1.2048726408125632,\n",
       "  0.6092513859132526,\n",
       "  -1.576434549698455,\n",
       "  0.06627874345858811,\n",
       "  1.2,\n",
       "  -1.9022798489360877],\n",
       " [-0.7270920754176099,\n",
       "  1.0,\n",
       "  0.814575900917021,\n",
       "  0.39578806754566864,\n",
       "  0.3718253872130295,\n",
       "  -0.01657020158123664,\n",
       "  0.9,\n",
       "  0.9816677221037474],\n",
       " [-0.7037292273105785,\n",
       "  1.0,\n",
       "  -0.3778870405866142,\n",
       "  0.34094835224020803,\n",
       "  -0.0326780803256951,\n",
       "  -0.4561118600700917,\n",
       "  0.9,\n",
       "  -0.6830563067466636],\n",
       " [0.26547521597819085,\n",
       "  1.0,\n",
       "  1.142449560070977,\n",
       "  1.5167670357644194,\n",
       "  0.18455211662870538,\n",
       "  0.1330745972984976,\n",
       "  0.9,\n",
       "  -1.2197569600684997],\n",
       " [-0.9099699876751466,\n",
       "  5.0,\n",
       "  -0.4360521899032297,\n",
       "  -0.7230447252870443,\n",
       "  0.9194415311305868,\n",
       "  -0.7627276634079033,\n",
       "  0.85,\n",
       "  0.1845400763802698],\n",
       " [1.8649324615402625,\n",
       "  5.0,\n",
       "  -0.9805871451632632,\n",
       "  0.2300691641998354,\n",
       "  -0.42377195269805057,\n",
       "  -0.05966086234205057,\n",
       "  0.85,\n",
       "  0.9123745596426196],\n",
       " [0.32351054014849634,\n",
       "  4.0,\n",
       "  -1.3206363446990477,\n",
       "  0.567156327069243,\n",
       "  0.9110164638359396,\n",
       "  0.4608094063377549,\n",
       "  1.2,\n",
       "  -0.7370448226160347],\n",
       " [1.003479104120991,\n",
       "  1.0,\n",
       "  -1.22244264294428,\n",
       "  0.3535478188248003,\n",
       "  1.005629123888775,\n",
       "  -1.196223518306188,\n",
       "  0.9,\n",
       "  0.9454780821881068],\n",
       " [0.34689584869833306,\n",
       "  0.0,\n",
       "  -0.18919510473555712,\n",
       "  1.7238175704647591,\n",
       "  0.7741640166435291,\n",
       "  0.06099218028040651,\n",
       "  1.1,\n",
       "  0.7273383900215873],\n",
       " [-0.47763865276036355,\n",
       "  3.0,\n",
       "  -1.3576637136370824,\n",
       "  0.3986607041072482,\n",
       "  0.6653704227635515,\n",
       "  -0.008292384545363556,\n",
       "  0.95,\n",
       "  -0.19877938761089345],\n",
       " [1.4174365077576434,\n",
       "  5.0,\n",
       "  1.0579713669718314,\n",
       "  -0.9297712241603577,\n",
       "  0.04921567405217152,\n",
       "  1.736177995519274,\n",
       "  0.85,\n",
       "  0.981227926301396],\n",
       " [-0.995199836405664,\n",
       "  0.0,\n",
       "  0.6234578276281595,\n",
       "  0.40273559525897745,\n",
       "  -2.613146726310498,\n",
       "  0.446129332625193,\n",
       "  1.1,\n",
       "  -0.5043402640856014],\n",
       " [1.1593563808226404,\n",
       "  0.0,\n",
       "  1.1319376886681494,\n",
       "  0.13750833541998117,\n",
       "  0.8406145820615214,\n",
       "  0.809672516828043,\n",
       "  1.1,\n",
       "  -1.3041359960956966],\n",
       " [1.444006020881322,\n",
       "  5.0,\n",
       "  -1.2246136737876396,\n",
       "  1.9319697834960714,\n",
       "  -0.18672453386180607,\n",
       "  0.24784310636988696,\n",
       "  0.85,\n",
       "  3.4491207021822543],\n",
       " [-1.3100764869197148,\n",
       "  3.0,\n",
       "  0.7356447194719234,\n",
       "  -1.430507951649944,\n",
       "  1.07437297722694,\n",
       "  1.0613815800071595,\n",
       "  0.95,\n",
       "  0.7413709755353086],\n",
       " [-1.2961074935933523,\n",
       "  3.0,\n",
       "  -1.5628684390658305,\n",
       "  -0.3494914654861724,\n",
       "  -0.20237091678568922,\n",
       "  -1.9002200271955183,\n",
       "  0.95,\n",
       "  -1.0968043631566524],\n",
       " [-0.43112889865802473,\n",
       "  3.0,\n",
       "  -1.505548904280559,\n",
       "  0.5046879806055216,\n",
       "  0.37060988554000956,\n",
       "  0.9515986827605684,\n",
       "  0.95,\n",
       "  0.5247008558705807],\n",
       " [-0.17787955604084524,\n",
       "  5.0,\n",
       "  0.3120757592630229,\n",
       "  1.7604042205278918,\n",
       "  -0.16364783719272405,\n",
       "  0.4775760718667197,\n",
       "  0.85,\n",
       "  -1.2674278660509648],\n",
       " [0.28675852679563557,\n",
       "  2.0,\n",
       "  0.8367598295524693,\n",
       "  -0.24193755073759549,\n",
       "  0.1546983314898918,\n",
       "  0.7086209725783043,\n",
       "  1.05,\n",
       "  -1.8629559262321012],\n",
       " [1.3628480868244581,\n",
       "  3.0,\n",
       "  -1.3081753431345886,\n",
       "  -1.3244437717015278,\n",
       "  0.34849300835657493,\n",
       "  0.3007289176492144,\n",
       "  0.95,\n",
       "  0.19798496169058757],\n",
       " [1.056234329182732,\n",
       "  3.0,\n",
       "  -0.0264516027407588,\n",
       "  1.26717362390417,\n",
       "  0.3881902291747879,\n",
       "  -0.36745630264074175,\n",
       "  0.95,\n",
       "  -1.0084837816553016],\n",
       " [0.6753834581512573,\n",
       "  0.0,\n",
       "  0.7913780260531247,\n",
       "  -0.9981243192033747,\n",
       "  -1.330775932275894,\n",
       "  0.3163115605392505,\n",
       "  1.1,\n",
       "  -1.3870245798794594],\n",
       " [-0.8143097845995908,\n",
       "  5.0,\n",
       "  0.346528686351874,\n",
       "  -0.2116925607487274,\n",
       "  -1.2003097397071596,\n",
       "  -0.563858157794853,\n",
       "  0.85,\n",
       "  -1.3178695815051402],\n",
       " [1.2727854369506908,\n",
       "  3.0,\n",
       "  -1.625560310954984,\n",
       "  -0.6901428360688621,\n",
       "  -0.21131430866474754,\n",
       "  1.1803472952202816,\n",
       "  0.95,\n",
       "  -1.7388798207793965],\n",
       " [0.714266926450305,\n",
       "  0.0,\n",
       "  -1.1303206073811616,\n",
       "  0.35909066510149384,\n",
       "  0.11738250758955802,\n",
       "  0.23960723460297134,\n",
       "  1.1,\n",
       "  -0.9352194789699583],\n",
       " [-0.9564460765196751,\n",
       "  1.0,\n",
       "  0.15483721322286675,\n",
       "  0.6055851015812784,\n",
       "  0.9521598005675066,\n",
       "  0.12354648459881325,\n",
       "  0.9,\n",
       "  -0.3181984570276672],\n",
       " [-1.138768440662833,\n",
       "  4.0,\n",
       "  0.7649732493889853,\n",
       "  1.7180520627033637,\n",
       "  0.7746651979894807,\n",
       "  -1.7123192710124029,\n",
       "  1.2,\n",
       "  0.45347517058057896],\n",
       " [-0.9549945962502219,\n",
       "  2.0,\n",
       "  0.40309675705260833,\n",
       "  -0.7907775086893707,\n",
       "  0.9016620812634795,\n",
       "  -0.6597195938296787,\n",
       "  1.05,\n",
       "  0.9823483509369343],\n",
       " [1.6635535100373875,\n",
       "  0.0,\n",
       "  1.1422789164824199,\n",
       "  -0.358111850884033,\n",
       "  1.1873986688793354,\n",
       "  0.5199428405456941,\n",
       "  1.1,\n",
       "  -1.528882821947056],\n",
       " [-0.5417415088248453,\n",
       "  1.0,\n",
       "  -1.3354817157374184,\n",
       "  -1.4062772726168078,\n",
       "  0.8764032866403196,\n",
       "  -1.9300304291882653,\n",
       "  0.9,\n",
       "  2.4481131791265907],\n",
       " [-0.3643696177122995,\n",
       "  5.0,\n",
       "  -0.2946792036039538,\n",
       "  0.5472350383653026,\n",
       "  0.5581138360591694,\n",
       "  -0.4414842081402024,\n",
       "  0.85,\n",
       "  3.2831924157988666],\n",
       " [-1.455388964245756,\n",
       "  2.0,\n",
       "  1.1008093925122286,\n",
       "  -1.4034199394622615,\n",
       "  -3.440044737839756,\n",
       "  0.6161366140566984,\n",
       "  1.05,\n",
       "  0.938753649575909],\n",
       " [0.5851102097504051,\n",
       "  3.0,\n",
       "  -0.6276305516746581,\n",
       "  -0.9422713922960283,\n",
       "  0.837907053281016,\n",
       "  -0.4990854959650881,\n",
       "  0.95,\n",
       "  -0.7800123609121535],\n",
       " [-0.6253407319265752,\n",
       "  3.0,\n",
       "  -0.9045962863141586,\n",
       "  -0.702304554683628,\n",
       "  1.59146166454394,\n",
       "  0.5456815858709372,\n",
       "  0.95,\n",
       "  -0.09268396251088885],\n",
       " [-0.5285616877666561,\n",
       "  5.0,\n",
       "  -1.6697121476925023,\n",
       "  1.6978360724740615,\n",
       "  0.241692964163697,\n",
       "  0.7283503510939995,\n",
       "  0.85,\n",
       "  0.39953470498998334],\n",
       " [1.7234099568443435,\n",
       "  1.0,\n",
       "  -1.474772771742449,\n",
       "  -0.9711929729204762,\n",
       "  0.6078278579765533,\n",
       "  0.6488580217820659,\n",
       "  0.9,\n",
       "  2.243077631910547],\n",
       " [1.3410723337627404,\n",
       "  4.0,\n",
       "  0.7649137388114804,\n",
       "  0.5774746292866332,\n",
       "  -2.1623095850335288,\n",
       "  -1.1117625457351128,\n",
       "  1.2,\n",
       "  1.0251527508708482],\n",
       " [-0.7410187473810346,\n",
       "  0.0,\n",
       "  1.2724432570829385,\n",
       "  -0.7743991455211005,\n",
       "  -0.09886514940755925,\n",
       "  1.131578092637394,\n",
       "  1.1,\n",
       "  1.1291169245995833],\n",
       " [0.6167865614965977,\n",
       "  5.0,\n",
       "  -0.8287404438766981,\n",
       "  -0.0027358828188534952,\n",
       "  0.4424299631778982,\n",
       "  0.151304073566889,\n",
       "  0.85,\n",
       "  -1.300739549727027],\n",
       " [-0.6958870790828725,\n",
       "  3.0,\n",
       "  1.4744687000654042,\n",
       "  -1.3180280814316325,\n",
       "  0.7856962030251561,\n",
       "  0.5171957192200166,\n",
       "  0.95,\n",
       "  -1.1955293599204428],\n",
       " [1.0105359354189385,\n",
       "  5.0,\n",
       "  1.0331186682362505,\n",
       "  0.9130617450098681,\n",
       "  -0.20807454298963474,\n",
       "  -1.749058449154098,\n",
       "  0.85,\n",
       "  1.0429452713740472],\n",
       " [1.6676906423157334,\n",
       "  1.0,\n",
       "  1.4485118246227116,\n",
       "  -0.2827246832507192,\n",
       "  -0.8291045691220555,\n",
       "  0.11292563434706152,\n",
       "  0.9,\n",
       "  -0.04965638162427437],\n",
       " [-0.714894404474047,\n",
       "  2.0,\n",
       "  0.6094287407182697,\n",
       "  -1.4006442234460763,\n",
       "  0.4203852308344833,\n",
       "  1.7892115709110918,\n",
       "  1.05,\n",
       "  0.5151321307376104],\n",
       " [0.44194423109086783,\n",
       "  5.0,\n",
       "  1.371455943906556,\n",
       "  1.5586234336161684,\n",
       "  0.4630627720654868,\n",
       "  0.8030343404434107,\n",
       "  0.85,\n",
       "  0.8970388731924669],\n",
       " [0.358495786673494,\n",
       "  4.0,\n",
       "  -0.38097333017783985,\n",
       "  -1.1398347433386002,\n",
       "  1.002556200984592,\n",
       "  1.318731769877941,\n",
       "  1.2,\n",
       "  0.027130371813949214],\n",
       " [-1.3811964795765175,\n",
       "  3.0,\n",
       "  0.5768262486307489,\n",
       "  -1.03158557573121,\n",
       "  -0.9729161728989906,\n",
       "  -1.0919558642446345,\n",
       "  0.95,\n",
       "  0.4901680496318381],\n",
       " [1.1168278377856247,\n",
       "  4.0,\n",
       "  0.9736727366440645,\n",
       "  0.711008172038101,\n",
       "  0.794416271250511,\n",
       "  -0.30914009416217647,\n",
       "  1.2,\n",
       "  0.5240052657608983],\n",
       " [-0.06990988285503044,\n",
       "  1.0,\n",
       "  -0.15022987116534328,\n",
       "  -0.2158929216896076,\n",
       "  0.8814248874907215,\n",
       "  -1.448378570012331,\n",
       "  0.9,\n",
       "  0.3187829146335452],\n",
       " [0.2280823498728584,\n",
       "  5.0,\n",
       "  -1.2832124207979052,\n",
       "  -1.1844131948065215,\n",
       "  -0.7216613279859854,\n",
       "  -0.9908290898573562,\n",
       "  0.85,\n",
       "  -1.4444978894892517],\n",
       " [0.513120698533739,\n",
       "  0.0,\n",
       "  -0.9771276836978668,\n",
       "  -1.1230749323676146,\n",
       "  -0.33081942198847836,\n",
       "  -1.168787276688418,\n",
       "  1.1,\n",
       "  0.4833423968393225],\n",
       " [1.3179521002654264,\n",
       "  3.0,\n",
       "  1.5853514599638467,\n",
       "  1.9223326906356073,\n",
       "  -0.30582409494293133,\n",
       "  1.1798210856519604,\n",
       "  0.95,\n",
       "  -0.21224672621183832],\n",
       " [0.18231883552191674,\n",
       "  1.0,\n",
       "  0.8889685961101154,\n",
       "  -1.3699340553952781,\n",
       "  0.9858172651211559,\n",
       "  -0.18243219286348344,\n",
       "  0.9,\n",
       "  -0.3875219728983513],\n",
       " [0.990599917768783,\n",
       "  4.0,\n",
       "  -0.9562924645115067,\n",
       "  1.0456952678377165,\n",
       "  0.29736531198706245,\n",
       "  -1.8382503230210907,\n",
       "  1.2,\n",
       "  -1.0791035787930263],\n",
       " [-0.30420869365316316,\n",
       "  0.0,\n",
       "  -0.7941543406645449,\n",
       "  1.7639254501622543,\n",
       "  0.14353222915231853,\n",
       "  -0.6246723112110697,\n",
       "  1.1,\n",
       "  0.49250016530107565],\n",
       " [0.4059523031745837,\n",
       "  3.0,\n",
       "  -1.2136960658149305,\n",
       "  -0.4847440072420962,\n",
       "  0.6312910532569264,\n",
       "  1.1524896599505667,\n",
       "  0.95,\n",
       "  0.7169555389011386],\n",
       " [-0.532503720071764,\n",
       "  1.0,\n",
       "  0.3811109317864663,\n",
       "  0.033801782575728426,\n",
       "  0.521733838467783,\n",
       "  -1.3550844748558288,\n",
       "  0.9,\n",
       "  0.5540735902242337],\n",
       " [0.6293434409123114,\n",
       "  3.0,\n",
       "  -1.1054122896647953,\n",
       "  -0.8644177078495999,\n",
       "  0.7409128460898112,\n",
       "  0.9093278577788532,\n",
       "  0.95,\n",
       "  -1.1409226820590717],\n",
       " [1.4451423855165053,\n",
       "  1.0,\n",
       "  1.1166567095450257,\n",
       "  1.0250542910520908,\n",
       "  -1.215944710692422,\n",
       "  0.3453111726325544,\n",
       "  0.9,\n",
       "  -1.8127814351724116],\n",
       " [1.3537307875122235,\n",
       "  3.0,\n",
       "  0.5275740268797044,\n",
       "  -1.2663498482115703,\n",
       "  0.5793540885465543,\n",
       "  -0.11333792960698735,\n",
       "  0.95,\n",
       "  0.8566210902306467],\n",
       " [1.8263632969772434,\n",
       "  4.0,\n",
       "  1.7310712853268513,\n",
       "  0.9924706538611223,\n",
       "  1.2700183492845265,\n",
       "  0.49971269085074915,\n",
       "  1.2,\n",
       "  1.0180562038672683],\n",
       " [0.42030942839260915,\n",
       "  4.0,\n",
       "  1.2089776534184737,\n",
       "  -0.8330240146709517,\n",
       "  -2.9478314345634127,\n",
       "  0.1911611434100023,\n",
       "  1.2,\n",
       "  1.037420393766465],\n",
       " [-0.7609568002239983,\n",
       "  5.0,\n",
       "  1.2739645519291063,\n",
       "  0.21373696672521938,\n",
       "  -0.4595991859237725,\n",
       "  0.11667617067478421,\n",
       "  0.85,\n",
       "  -0.01877376312934548],\n",
       " [0.5072833184951421,\n",
       "  2.0,\n",
       "  0.987464071612164,\n",
       "  0.061706336477645445,\n",
       "  0.5426085729756366,\n",
       "  -0.12345160731009329,\n",
       "  1.05,\n",
       "  -0.755092012456574],\n",
       " [1.2993409723534508,\n",
       "  0.0,\n",
       "  1.1502297146801284,\n",
       "  0.36436020957501375,\n",
       "  0.5241665724993698,\n",
       "  0.05843487700626891,\n",
       "  1.1,\n",
       "  -1.0434509308388777],\n",
       " [0.7226059619652815,\n",
       "  4.0,\n",
       "  -0.7909561665123404,\n",
       "  -1.2990610538065481,\n",
       "  -1.7931081597256868,\n",
       "  1.0550951791630363,\n",
       "  1.2,\n",
       "  0.7263882253781766],\n",
       " [-1.0012786150425257,\n",
       "  0.0,\n",
       "  -0.2756992051883602,\n",
       "  -1.4208629819702594,\n",
       "  0.8201110924718478,\n",
       "  -0.15234269406362008,\n",
       "  1.1,\n",
       "  0.36512860387975143],\n",
       " [1.1230955270493417,\n",
       "  5.0,\n",
       "  1.290723290165038,\n",
       "  -1.405443362359536,\n",
       "  1.1399968871927655,\n",
       "  -0.022053569814126477,\n",
       "  0.85,\n",
       "  0.3918323135929502],\n",
       " [1.1693150647236117,\n",
       "  4.0,\n",
       "  -0.43458482228241735,\n",
       "  0.8552297790006538,\n",
       "  0.4590854272825263,\n",
       "  1.6790761368579803,\n",
       "  1.2,\n",
       "  -0.267518632939729],\n",
       " [1.2497006348975175,\n",
       "  4.0,\n",
       "  1.1418582896124023,\n",
       "  0.21625772829954118,\n",
       "  0.18643752123859747,\n",
       "  1.0389793399811273,\n",
       "  1.2,\n",
       "  -1.84997589895176],\n",
       " [-0.34758862289535974,\n",
       "  2.0,\n",
       "  -0.6887493587168327,\n",
       "  0.506389075847068,\n",
       "  1.0212202807015884,\n",
       "  1.9473225168526545,\n",
       "  1.05,\n",
       "  1.065402178283011],\n",
       " [1.7630393200266343,\n",
       "  5.0,\n",
       "  0.2057631862135956,\n",
       "  1.866532996921355,\n",
       "  -1.6894842870974658,\n",
       "  -0.5131919138183909,\n",
       "  0.85,\n",
       "  0.0865071106478425],\n",
       " [0.4848295859514958,\n",
       "  1.0,\n",
       "  -1.2033863112229741,\n",
       "  -1.3774360628781381,\n",
       "  0.6284136183613797,\n",
       "  0.5225273131445614,\n",
       "  0.9,\n",
       "  -0.0021207811112955366],\n",
       " [0.2165245324475979,\n",
       "  5.0,\n",
       "  0.7101107900160581,\n",
       "  -0.80668037198808,\n",
       "  -2.6100373091671667,\n",
       "  -0.9053123836454651,\n",
       "  0.85,\n",
       "  -0.7576734856777056],\n",
       " [0.6084554487362783,\n",
       "  3.0,\n",
       "  0.7182774940502683,\n",
       "  -1.2442975235760516,\n",
       "  0.4977502953857736,\n",
       "  0.08818095643341073,\n",
       "  0.95,\n",
       "  0.504837670303752],\n",
       " [-1.7265622214840246,\n",
       "  3.0,\n",
       "  0.17129037381962184,\n",
       "  -0.055630126375377884,\n",
       "  0.571520869609235,\n",
       "  1.5036408217043382,\n",
       "  0.95,\n",
       "  -1.5286981119425154],\n",
       " [-0.558887095439029,\n",
       "  4.0,\n",
       "  -1.4463745614601433,\n",
       "  -0.6005696586505997,\n",
       "  0.1480496714539021,\n",
       "  -0.4851544244134377,\n",
       "  1.2,\n",
       "  1.08304561750498],\n",
       " [1.157604835579366,\n",
       "  0.0,\n",
       "  -1.5967885782985396,\n",
       "  1.2554630951393995,\n",
       "  0.5399281001526262,\n",
       "  1.4514257704411506,\n",
       "  1.1,\n",
       "  0.6778173920463112],\n",
       " [1.0224537687335258,\n",
       "  1.0,\n",
       "  0.43422174374570505,\n",
       "  1.521526238105276,\n",
       "  0.7949999443889426,\n",
       "  -0.6430344223416219,\n",
       "  0.9,\n",
       "  -0.9040840602017127],\n",
       " [-1.4759531500546386,\n",
       "  1.0,\n",
       "  -0.6155468424230514,\n",
       "  0.38716879918974134,\n",
       "  0.7441831682846439,\n",
       "  -0.41365257886467155,\n",
       "  0.9,\n",
       "  0.7179964987224364],\n",
       " [0.6618015065356412,\n",
       "  2.0,\n",
       "  -0.05882542528763181,\n",
       "  0.5688085137639598,\n",
       "  0.9291906757438061,\n",
       "  0.6864831117865735,\n",
       "  1.05,\n",
       "  0.9269339926663164],\n",
       " [-1.2326615568584252,\n",
       "  4.0,\n",
       "  0.3507357351818363,\n",
       "  -1.3485014240435478,\n",
       "  0.5097474327231654,\n",
       "  -0.5518864119534408,\n",
       "  1.2,\n",
       "  0.940256365386339],\n",
       " [1.0252988415464679,\n",
       "  0.0,\n",
       "  -1.0451896249958326,\n",
       "  -0.474835094196112,\n",
       "  -0.36417013298239603,\n",
       "  0.2652066266253889,\n",
       "  1.1,\n",
       "  -1.562678048023763],\n",
       " [1.3050797677494714,\n",
       "  5.0,\n",
       "  -1.4659836832160196,\n",
       "  -1.38700395834041,\n",
       "  -0.45590290765021413,\n",
       "  -1.400613190006859,\n",
       "  0.85,\n",
       "  -0.5103856402178654],\n",
       " [1.0872268816512485,\n",
       "  2.0,\n",
       "  -0.3539350740489747,\n",
       "  -0.8693713342640937,\n",
       "  1.2276172220762984,\n",
       "  -0.06530070372991058,\n",
       "  1.05,\n",
       "  1.0254292899294528],\n",
       " [0.5766594247565606,\n",
       "  4.0,\n",
       "  1.3113281970839934,\n",
       "  -1.401015596268232,\n",
       "  0.8186116673834798,\n",
       "  1.3848909256597897,\n",
       "  1.2,\n",
       "  -0.1454520878257133],\n",
       " [-1.006583733811464,\n",
       "  2.0,\n",
       "  -0.9822846751533547,\n",
       "  1.4815258452555866,\n",
       "  0.9713530390248687,\n",
       "  -1.3749770585598748,\n",
       "  1.05,\n",
       "  -1.2708147698792556],\n",
       " [-1.613890291598555,\n",
       "  3.0,\n",
       "  -1.486494416760662,\n",
       "  0.6180687660203729,\n",
       "  -0.643465209261386,\n",
       "  -0.040640553597128884,\n",
       "  0.95,\n",
       "  -1.237554280202542],\n",
       " [0.570364022122511,\n",
       "  4.0,\n",
       "  0.7072840072289813,\n",
       "  1.3319555127182223,\n",
       "  0.1135747201545549,\n",
       "  0.3845316329662199,\n",
       "  1.2,\n",
       "  0.04404232659949373],\n",
       " [-0.5386551630746524,\n",
       "  3.0,\n",
       "  0.5391325629781012,\n",
       "  1.8538718282209858,\n",
       "  1.2523666883895819,\n",
       "  -0.7997273050734244,\n",
       "  0.95,\n",
       "  -0.90590042051994],\n",
       " [0.806561884248176,\n",
       "  1.0,\n",
       "  -1.0470835701886356,\n",
       "  0.973410050403727,\n",
       "  1.1356426381024987,\n",
       "  0.7898080383177055,\n",
       "  0.9,\n",
       "  0.7972661731056753],\n",
       " [0.8650985531760678,\n",
       "  0.0,\n",
       "  -0.5665065912846791,\n",
       "  -0.4855549935609515,\n",
       "  -0.5174638682027807,\n",
       "  -0.19331630723823648,\n",
       "  1.1,\n",
       "  -0.9088092755534368],\n",
       " [0.9425523046915893,\n",
       "  1.0,\n",
       "  -1.4984843532669148,\n",
       "  -0.5083119749305323,\n",
       "  -0.6364178498559261,\n",
       "  1.2896270071137697,\n",
       "  0.9,\n",
       "  -1.1918561792054787],\n",
       " [0.9091421464396772,\n",
       "  2.0,\n",
       "  0.10384864712129122,\n",
       "  -0.8797131418379722,\n",
       "  -1.4064629202179886,\n",
       "  -0.4898917532986098,\n",
       "  1.05,\n",
       "  0.09310054768467957],\n",
       " [0.7403176074271883,\n",
       "  4.0,\n",
       "  0.3600910616396359,\n",
       "  1.2184511482265779,\n",
       "  -0.5155859140240725,\n",
       "  0.012654996906529402,\n",
       "  1.2,\n",
       "  -0.8746260344891893],\n",
       " [-1.4176896674688126,\n",
       "  1.0,\n",
       "  0.8627265966760788,\n",
       "  -0.1048877818101903,\n",
       "  0.03391744195984295,\n",
       "  1.238278168686099,\n",
       "  0.9,\n",
       "  -0.9809401500104196],\n",
       " [0.8145388414592253,\n",
       "  1.0,\n",
       "  -0.8463005231691753,\n",
       "  -1.0594354350511768,\n",
       "  -0.3035531572837429,\n",
       "  -1.9435181675363757,\n",
       "  0.9,\n",
       "  0.8127700612540545],\n",
       " [-1.9044987144940166,\n",
       "  3.0,\n",
       "  -0.5501459672887171,\n",
       "  0.004117428410485958,\n",
       "  -0.8475688178250369,\n",
       "  1.0021968472889127,\n",
       "  0.95,\n",
       "  -1.3257946562088447],\n",
       " [-0.18519773963685116,\n",
       "  2.0,\n",
       "  -0.6951417113092105,\n",
       "  0.8827951236388486,\n",
       "  -0.7522508510175226,\n",
       "  -1.2564033696606878,\n",
       "  1.05,\n",
       "  -0.33898888422292267],\n",
       " [1.2014557510010988,\n",
       "  0.0,\n",
       "  -0.5983685952464525,\n",
       "  1.7973417842764405,\n",
       "  1.5093565631788832,\n",
       "  -0.6456211696555856,\n",
       "  1.1,\n",
       "  1.0468646809954871],\n",
       " [0.14918942603783922,\n",
       "  2.0,\n",
       "  -0.4335911834318895,\n",
       "  -0.4968159322001908,\n",
       "  0.36415473923471064,\n",
       "  0.0037590006648153575,\n",
       "  1.05,\n",
       "  0.05447219755704691],\n",
       " [0.3475562434186241,\n",
       "  1.0,\n",
       "  -1.6022832182308584,\n",
       "  -0.5450101520275756,\n",
       "  0.2650557524633307,\n",
       "  1.5181856331126375,\n",
       "  0.9,\n",
       "  0.5616645835694152],\n",
       " [-0.522787161631004,\n",
       "  1.0,\n",
       "  -1.3737334549854616,\n",
       "  -0.7149512224802999,\n",
       "  0.2280724145240252,\n",
       "  -0.7300202606304591,\n",
       "  0.9,\n",
       "  0.6583721676623119],\n",
       " [1.292052366084772,\n",
       "  0.0,\n",
       "  0.9681610228714342,\n",
       "  1.5515315520889985,\n",
       "  0.8328751061458723,\n",
       "  0.6217462673267735,\n",
       "  1.1,\n",
       "  -1.7625446814546486],\n",
       " [-0.2611584313714806,\n",
       "  5.0,\n",
       "  -0.48821195362463077,\n",
       "  0.004377021112346212,\n",
       "  0.21917589589757785,\n",
       "  -1.5661400365813807,\n",
       "  0.85,\n",
       "  -1.2866817327315678],\n",
       " [0.8455514677092216,\n",
       "  1.0,\n",
       "  -1.4423704617836581,\n",
       "  -0.24357619088750412,\n",
       "  0.13690061229466904,\n",
       "  0.700361346213371,\n",
       "  0.9,\n",
       "  0.4519471841503985],\n",
       " [-0.8072021861880255,\n",
       "  1.0,\n",
       "  0.9011665999776748,\n",
       "  -0.0550803832509491,\n",
       "  0.6564397603353712,\n",
       "  -0.5622221010009271,\n",
       "  0.9,\n",
       "  -0.37673492847375173],\n",
       " [-0.16379649787171435,\n",
       "  3.0,\n",
       "  0.27759215252313,\n",
       "  1.0756485922085344,\n",
       "  0.8037009518876763,\n",
       "  1.5257667270347641,\n",
       "  0.95,\n",
       "  0.8849036607397045],\n",
       " [0.6190947649181594,\n",
       "  5.0,\n",
       "  0.12928094674275162,\n",
       "  -1.2531706063156214,\n",
       "  -0.6131258225766836,\n",
       "  -0.5178861579888848,\n",
       "  0.85,\n",
       "  -0.5474570689212418],\n",
       " [-0.4219775673364426,\n",
       "  4.0,\n",
       "  -1.6135854299914143,\n",
       "  1.2361526210063798,\n",
       "  0.4372175546742124,\n",
       "  -0.7329018713751928,\n",
       "  1.2,\n",
       "  0.9843667809666462],\n",
       " [0.7311480185886613,\n",
       "  5.0,\n",
       "  -1.4708704030409312,\n",
       "  -0.7501799452071624,\n",
       "  0.059375209476473345,\n",
       "  0.8976196331013326,\n",
       "  0.85,\n",
       "  1.057529172838136],\n",
       " [-0.3280188584007674,\n",
       "  0.0,\n",
       "  -1.271969287080708,\n",
       "  0.31722538343393664,\n",
       "  1.2246857546708718,\n",
       "  -0.25677252623107216,\n",
       "  1.1,\n",
       "  -0.7854100213708308],\n",
       " [-0.09908787041862985,\n",
       "  2.0,\n",
       "  0.8571617642124196,\n",
       "  1.8791259322452312,\n",
       "  0.8417901236018694,\n",
       "  -1.8706934551543022,\n",
       "  1.05,\n",
       "  0.5808226852213749],\n",
       " [-0.5240100176329628,\n",
       "  1.0,\n",
       "  -1.1377243508310393,\n",
       "  -0.6807566367882538,\n",
       "  -0.8027993905246881,\n",
       "  -0.20617257241366108,\n",
       "  0.9,\n",
       "  -0.5315084481590397],\n",
       " [-0.8603046241463191,\n",
       "  1.0,\n",
       "  0.8017076411394349,\n",
       "  -0.021944241857302146,\n",
       "  1.6330675436500486,\n",
       "  -1.9185212204210815,\n",
       "  0.9,\n",
       "  0.0901043672173015],\n",
       " [-0.7451939196056545,\n",
       "  1.0,\n",
       "  -0.0009919420025473824,\n",
       "  -0.5513459018373464,\n",
       "  -0.10277823089493485,\n",
       "  -0.15644069522772033,\n",
       "  0.9,\n",
       "  -1.8557607492699437],\n",
       " [-0.27514065824584927,\n",
       "  1.0,\n",
       "  0.5018982264554885,\n",
       "  -0.14620547838122336,\n",
       "  0.7232530348669436,\n",
       "  0.16326676588941652,\n",
       "  0.9,\n",
       "  1.062647307189938],\n",
       " [-1.4869077744732588,\n",
       "  2.0,\n",
       "  -1.343869314449522,\n",
       "  -0.9747179747600737,\n",
       "  -1.7906785298533083,\n",
       "  -0.9766336063800632,\n",
       "  1.05,\n",
       "  1.0242613151797388],\n",
       " [-0.9775159124691537,\n",
       "  3.0,\n",
       "  -0.3772376175145008,\n",
       "  1.4677611212159034,\n",
       "  0.4035589063297611,\n",
       "  1.356598882403113,\n",
       "  0.95,\n",
       "  1.0617905642038614],\n",
       " [-0.22099675781707087,\n",
       "  5.0,\n",
       "  -1.4448839333540413,\n",
       "  1.0263478316112418,\n",
       "  0.024290759112651494,\n",
       "  0.6832322119919537,\n",
       "  0.85,\n",
       "  0.3874096929731713],\n",
       " [-1.2875503570282412,\n",
       "  4.0,\n",
       "  -0.8380224824147009,\n",
       "  -0.8734859531487646,\n",
       "  1.0150252368038999,\n",
       "  0.5055476489882278,\n",
       "  1.2,\n",
       "  -1.1649213321771954],\n",
       " [0.3619964774868911,\n",
       "  0.0,\n",
       "  -1.5970258035215055,\n",
       "  0.9996951174821824,\n",
       "  -1.1504130988122077,\n",
       "  -0.2950570406986341,\n",
       "  1.1,\n",
       "  -1.0301311657595658],\n",
       " [0.5292060989119968,\n",
       "  5.0,\n",
       "  1.4277475690951549,\n",
       "  1.8241634797731887,\n",
       "  0.6598282266808474,\n",
       "  -1.7974320870305134,\n",
       "  0.85,\n",
       "  -1.2959016855063832],\n",
       " [0.865941471276237,\n",
       "  3.0,\n",
       "  -1.0493945472070623,\n",
       "  -1.0439849286623268,\n",
       "  -1.621713675452067,\n",
       "  -1.7992796788341257,\n",
       "  0.95,\n",
       "  0.8672711452050847],\n",
       " [-0.9819111405656936,\n",
       "  3.0,\n",
       "  0.3868448490514874,\n",
       "  -1.233463956821484,\n",
       "  -1.272267859789528,\n",
       "  -0.35282532062985433,\n",
       "  0.95,\n",
       "  -1.4851122728712736],\n",
       " [-0.47048590749715224,\n",
       "  0.0,\n",
       "  0.9973075986789057,\n",
       "  -1.1265886673461314,\n",
       "  0.011742598028711736,\n",
       "  -0.05057973013383544,\n",
       "  1.1,\n",
       "  -0.4773471127247787],\n",
       " [-0.4673625167340861,\n",
       "  4.0,\n",
       "  1.1530787209823952,\n",
       "  -1.1068295121460403,\n",
       "  0.5279858489809193,\n",
       "  0.9419392293819397,\n",
       "  1.2,\n",
       "  -0.6735040960973983],\n",
       " [-1.1058736485569425,\n",
       "  5.0,\n",
       "  -0.7349022703104835,\n",
       "  0.15350127182973866,\n",
       "  -0.44327215083708843,\n",
       "  0.7232041384032966,\n",
       "  0.85,\n",
       "  0.4698386768092152],\n",
       " [-1.2933612488820567,\n",
       "  1.0,\n",
       "  0.5335404227679862,\n",
       "  -0.9261238400576687,\n",
       "  1.7532968634930859,\n",
       "  0.29580798535063774,\n",
       "  0.9,\n",
       "  -0.2891140651621973],\n",
       " [-0.517085228511391,\n",
       "  3.0,\n",
       "  0.07768086571737393,\n",
       "  0.3812957997733146,\n",
       "  -0.4148307177141919,\n",
       "  0.06152762340969476,\n",
       "  0.95,\n",
       "  -1.6483626202519903],\n",
       " [0.7044649854714584,\n",
       "  0.0,\n",
       "  -0.6323749742816588,\n",
       "  -0.2814746939176357,\n",
       "  0.6759060800621278,\n",
       "  -0.05568665580626485,\n",
       "  1.1,\n",
       "  -1.3761312910930872],\n",
       " [-0.8942964008842472,\n",
       "  0.0,\n",
       "  0.7470451628329335,\n",
       "  -1.2540574281517378,\n",
       "  -0.34816013646713506,\n",
       "  0.835126110650355,\n",
       "  1.1,\n",
       "  -1.0576003866552175],\n",
       " [1.7960945105434143,\n",
       "  4.0,\n",
       "  -0.6503922812333192,\n",
       "  -1.3704963715906378,\n",
       "  -0.5474495563139296,\n",
       "  0.005039563032883112,\n",
       "  1.2,\n",
       "  -1.56933971405415],\n",
       " [-1.4984394604335076,\n",
       "  3.0,\n",
       "  -1.0089053238159325,\n",
       "  1.001253693814195,\n",
       "  -0.8928895969298376,\n",
       "  -1.524729576500044,\n",
       "  0.95,\n",
       "  -0.1316022765457561],\n",
       " [0.2673845080652616,\n",
       "  5.0,\n",
       "  0.6102988110246612,\n",
       "  0.5144130031842884,\n",
       "  1.415240324501335,\n",
       "  1.3706031463929538,\n",
       "  0.85,\n",
       "  0.8228087747592617],\n",
       " [0.15248272264355237,\n",
       "  0.0,\n",
       "  0.5318630333480056,\n",
       "  -0.7985535960163811,\n",
       "  0.657183142192981,\n",
       "  0.02234197350325143,\n",
       "  1.1,\n",
       "  0.48072118283787907],\n",
       " [0.5619978791159189,\n",
       "  0.0,\n",
       "  0.20938801552814001,\n",
       "  -1.3891191714821884,\n",
       "  0.29215826152560403,\n",
       "  -0.7361461048772453,\n",
       "  1.1,\n",
       "  -1.4689747347697484],\n",
       " [-1.7208967739692635,\n",
       "  4.0,\n",
       "  -1.4430774681406466,\n",
       "  -0.7838678708859401,\n",
       "  0.890946439124406,\n",
       "  0.6847761300162903,\n",
       "  1.2,\n",
       "  -1.7818729085004454],\n",
       " [0.48187491684070155,\n",
       "  2.0,\n",
       "  0.6774387525899865,\n",
       "  0.7469348874597621,\n",
       "  0.42372593797752767,\n",
       "  -0.5418880576436453,\n",
       "  1.05,\n",
       "  1.057247943998534],\n",
       " [-1.3837390447591147,\n",
       "  0.0,\n",
       "  0.8938549802807831,\n",
       "  -0.830099992186231,\n",
       "  -1.0357774810248985,\n",
       "  0.29321821389174524,\n",
       "  1.1,\n",
       "  1.0476540621499908],\n",
       " [0.44872841935142854,\n",
       "  5.0,\n",
       "  -1.4844211185745384,\n",
       "  -0.24797069735399155,\n",
       "  0.3000894965165044,\n",
       "  -1.084657590441608,\n",
       "  0.85,\n",
       "  0.9340278082848938],\n",
       " [1.540958100976634,\n",
       "  3.0,\n",
       "  -0.5099387746848582,\n",
       "  0.2814066706008622,\n",
       "  0.6097386671407351,\n",
       "  -0.19474725425977787,\n",
       "  0.95,\n",
       "  -1.67920312778977],\n",
       " [1.4055303444583922,\n",
       "  1.0,\n",
       "  1.1735109883561317,\n",
       "  -0.6273582603709852,\n",
       "  -2.133271832563127,\n",
       "  0.09990644095460038,\n",
       "  0.9,\n",
       "  0.4337975706198374],\n",
       " [0.2204112242032645,\n",
       "  2.0,\n",
       "  -1.3109347782326055,\n",
       "  -0.20892799951677252,\n",
       "  -0.5444460629264383,\n",
       "  -0.008998729308303689,\n",
       "  1.05,\n",
       "  -1.8404756139431686],\n",
       " [-1.123729507781983,\n",
       "  4.0,\n",
       "  -0.3748262740447872,\n",
       "  -1.356981099509357,\n",
       "  0.30064922292800106,\n",
       "  -0.4151385923923303,\n",
       "  1.2,\n",
       "  0.8199288674464297],\n",
       " [0.23132896600403752,\n",
       "  3.0,\n",
       "  0.31202294140071546,\n",
       "  -0.5399414036687538,\n",
       "  0.1671749333172223,\n",
       "  1.5732548002043873,\n",
       "  0.95,\n",
       "  1.0635504704307193],\n",
       " [1.4912130170706253,\n",
       "  0.0,\n",
       "  1.4579137229608339,\n",
       "  1.8503988663046766,\n",
       "  0.6144184529297588,\n",
       "  -1.1565755571102168,\n",
       "  1.1,\n",
       "  -1.7440217459370329],\n",
       " [0.455520075004315,\n",
       "  5.0,\n",
       "  0.20443401317690557,\n",
       "  -1.16255418044467,\n",
       "  -0.8813574431195959,\n",
       "  1.6448849725335315,\n",
       "  0.85,\n",
       "  0.15621167735982364],\n",
       " [1.4070050806913048,\n",
       "  2.0,\n",
       "  1.0547960707026471,\n",
       "  -1.2303975432647156,\n",
       "  -0.22437303570771272,\n",
       "  -1.3788734050788256,\n",
       "  1.05,\n",
       "  0.05961862457944163],\n",
       " [-0.2373012470743477,\n",
       "  2.0,\n",
       "  0.8565655020221874,\n",
       "  -1.0748028204663924,\n",
       "  -1.8894838249660357,\n",
       "  0.7713962250958796,\n",
       "  1.05,\n",
       "  -0.9952164418714641],\n",
       " [-0.041212013685103355,\n",
       "  4.0,\n",
       "  -1.4202152676251594,\n",
       "  0.06821188031036683,\n",
       "  0.7649888428682886,\n",
       "  1.1755630160227823,\n",
       "  1.2,\n",
       "  -1.0757672245167618],\n",
       " [1.1438614896114587,\n",
       "  5.0,\n",
       "  -0.611286967178654,\n",
       "  0.6254788766810582,\n",
       "  -0.30154323702774555,\n",
       "  1.0708034964791426,\n",
       "  0.85,\n",
       "  0.8172939479028098],\n",
       " [-0.510079395858538,\n",
       "  2.0,\n",
       "  -0.8323058970975546,\n",
       "  -1.2397976492084808,\n",
       "  0.35360946347432337,\n",
       "  -0.9315515607692259,\n",
       "  1.05,\n",
       "  1.024180560883282],\n",
       " [-1.394844695581638,\n",
       "  5.0,\n",
       "  0.033308010949851134,\n",
       "  -1.4031898662261268,\n",
       "  1.8255442939663586,\n",
       "  -0.8698770884433317,\n",
       "  0.85,\n",
       "  -1.3135721858150766],\n",
       " [-0.684079221947813,\n",
       "  2.0,\n",
       "  0.9839473479700303,\n",
       "  1.0872898610461974,\n",
       "  -1.302363755989401,\n",
       "  -1.3273165666494193,\n",
       "  1.05,\n",
       "  0.18470910031510604],\n",
       " [-0.5702214411472615,\n",
       "  0.0,\n",
       "  0.3327924744173116,\n",
       "  0.029639465591331987,\n",
       "  0.6457034605305261,\n",
       "  -0.5085049651757262,\n",
       "  1.1,\n",
       "  -0.3083320345941906],\n",
       " [1.255294981003659,\n",
       "  4.0,\n",
       "  1.2170867492361794,\n",
       "  1.7071263366771163,\n",
       "  0.44419533228045766,\n",
       "  0.2086490723146124,\n",
       "  1.2,\n",
       "  0.9225669885579619],\n",
       " [-0.2426907135689224,\n",
       "  0.0,\n",
       "  -0.3941184582401128,\n",
       "  0.052098069965417874,\n",
       "  0.6556804076424381,\n",
       "  -0.11543373517030155,\n",
       "  1.1,\n",
       "  -1.1453724269156202],\n",
       " [-0.7375827463437165,\n",
       "  1.0,\n",
       "  -0.0581264480388695,\n",
       "  -0.5792209701426796,\n",
       "  0.891880993078303,\n",
       "  -1.2274656526242949,\n",
       "  0.9,\n",
       "  -0.10217439603477202],\n",
       " [-0.03328309332785903,\n",
       "  4.0,\n",
       "  0.6254702564948827,\n",
       "  0.9775407824963469,\n",
       "  0.9327930772688428,\n",
       "  1.386422828392497,\n",
       "  1.2,\n",
       "  -0.5590626641042356],\n",
       " [1.317348538733362,\n",
       "  5.0,\n",
       "  -0.5512151307639627,\n",
       "  -0.9221637841013867,\n",
       "  0.45854557567120796,\n",
       "  0.27887623653004867,\n",
       "  0.85,\n",
       "  -1.4485700742179966],\n",
       " [1.6792538104923638,\n",
       "  4.0,\n",
       "  1.09457088829104,\n",
       "  -0.25522727163949643,\n",
       "  0.08366185932823098,\n",
       "  1.0437075521829984,\n",
       "  1.2,\n",
       "  1.0498134777960435],\n",
       " [-1.3060870215906843,\n",
       "  5.0,\n",
       "  0.758253631898627,\n",
       "  -0.862164233622335,\n",
       "  -2.701733358601569,\n",
       "  -1.8312491917324585,\n",
       "  0.85,\n",
       "  -1.390504015890237],\n",
       " [1.2249561830769293,\n",
       "  1.0,\n",
       "  -1.4697783690606059,\n",
       "  -0.8582381321312895,\n",
       "  0.5385289457264945,\n",
       "  0.12704405967966192,\n",
       "  0.9,\n",
       "  0.8069474163974156],\n",
       " [0.16253362121055454,\n",
       "  3.0,\n",
       "  0.11950685975484145,\n",
       "  -0.013511782115322848,\n",
       "  -3.265193072639618,\n",
       "  1.0551058933677557,\n",
       "  0.95,\n",
       "  0.797982466572503],\n",
       " [0.034487088055804666,\n",
       "  2.0,\n",
       "  -0.9146751507988001,\n",
       "  -0.7009267259166534,\n",
       "  0.33575910943633885,\n",
       "  0.5316017727541016,\n",
       "  1.05,\n",
       "  -1.9404155156165483],\n",
       " [1.4945650839705127,\n",
       "  3.0,\n",
       "  -0.25322000567243974,\n",
       "  1.1601655466883172,\n",
       "  -0.01481288895617725,\n",
       "  0.48034967470923595,\n",
       "  0.95,\n",
       "  1.1808704922211875],\n",
       " [0.9305515443819317,\n",
       "  2.0,\n",
       "  -0.558986027274777,\n",
       "  1.4062505530545844,\n",
       "  1.0803570842695254,\n",
       "  1.5613609920806157,\n",
       "  1.05,\n",
       "  0.9080086017998934],\n",
       " [-1.5179563258443047,\n",
       "  4.0,\n",
       "  -1.1961014596177957,\n",
       "  -1.4001250251510617,\n",
       "  -0.06415059386657662,\n",
       "  -0.057264481210736955,\n",
       "  1.2,\n",
       "  0.9789420230730892],\n",
       " [0.7458578331725885,\n",
       "  3.0,\n",
       "  0.7014614534012729,\n",
       "  -0.9891596363976974,\n",
       "  -0.46000174968843627,\n",
       "  -0.176772538339547,\n",
       "  0.95,\n",
       "  -0.5149001332790641],\n",
       " [-0.2100433938530032,\n",
       "  4.0,\n",
       "  1.4204195413277214,\n",
       "  -0.18062429155763324,\n",
       "  -0.10777463583523816,\n",
       "  -0.045797860130439835,\n",
       "  1.2,\n",
       "  -1.2694600307963284],\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[num_col_names] = scaler.fit_transform(x_train[num_col_names])\n",
    "x_train = x_train.values.tolist()\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d94c446-5579-410c-b781-a366b2d65c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.4488500648234495,\n",
       "  4.0,\n",
       "  0.6654989111305878,\n",
       "  -0.749668758255374,\n",
       "  0.23022909792501609,\n",
       "  -0.1004449107920046,\n",
       "  1.2,\n",
       "  0.23958766676359503],\n",
       " [0.6253768842982164,\n",
       "  4.0,\n",
       "  1.487195497195165,\n",
       "  1.579826148455208,\n",
       "  -1.8461716108942101,\n",
       "  -0.924179965829397,\n",
       "  1.2,\n",
       "  -0.9573274883852734],\n",
       " [-1.8661287701570886,\n",
       "  2.0,\n",
       "  -1.1689898449005474,\n",
       "  -1.4181963867503389,\n",
       "  0.9446618893125608,\n",
       "  1.9064640035496778,\n",
       "  1.05,\n",
       "  0.6092819416777023],\n",
       " [-0.7393671934771787,\n",
       "  2.0,\n",
       "  0.6657388550345037,\n",
       "  -1.2296149133433343,\n",
       "  0.955820165300199,\n",
       "  -0.5665839972455521,\n",
       "  1.05,\n",
       "  0.9906325225268472],\n",
       " [-1.5911981028739672,\n",
       "  4.0,\n",
       "  -0.653048385781452,\n",
       "  1.9217573288756,\n",
       "  0.6195711721250219,\n",
       "  -0.5054551335075861,\n",
       "  1.2,\n",
       "  0.037714277687966195],\n",
       " [0.5523845309129647,\n",
       "  3.0,\n",
       "  -0.9853439449457139,\n",
       "  0.04732397599031567,\n",
       "  0.520629540278814,\n",
       "  1.6785345657242894,\n",
       "  0.95,\n",
       "  -1.0414307256289947],\n",
       " [-0.4749277979825926,\n",
       "  2.0,\n",
       "  -1.0715673879241914,\n",
       "  1.230137312585087,\n",
       "  -0.09176066074759448,\n",
       "  -0.41721787398393667,\n",
       "  1.05,\n",
       "  -1.0293377802336332],\n",
       " [1.7279926855785306,\n",
       "  0.0,\n",
       "  -0.19922371440350176,\n",
       "  0.3311566590022522,\n",
       "  -0.17428124407991355,\n",
       "  -1.663798456431989,\n",
       "  1.1,\n",
       "  -1.3421897384352284],\n",
       " [0.169681792024782,\n",
       "  2.0,\n",
       "  0.5792043087223663,\n",
       "  -0.8686123495814022,\n",
       "  -1.3023951212538272,\n",
       "  -1.0420259143102462,\n",
       "  1.05,\n",
       "  0.17030237863488246],\n",
       " [-0.8541762016142393,\n",
       "  3.0,\n",
       "  1.5965213816631731,\n",
       "  -0.4842750861491917,\n",
       "  0.8936046393224228,\n",
       "  0.4894641151077346,\n",
       "  0.95,\n",
       "  0.3020620509117465],\n",
       " [1.254615290036109,\n",
       "  1.0,\n",
       "  1.4641514249991636,\n",
       "  -0.461701396050388,\n",
       "  -0.601420179833001,\n",
       "  -1.5379463368749993,\n",
       "  0.9,\n",
       "  1.0502956436767155],\n",
       " [-0.4142204733002428,\n",
       "  1.0,\n",
       "  -0.5528983834590705,\n",
       "  -1.0776445838860302,\n",
       "  0.12460122133433539,\n",
       "  0.6654591096705903,\n",
       "  0.9,\n",
       "  -1.31954131034552],\n",
       " [-1.0115510513791313,\n",
       "  0.0,\n",
       "  -1.4579349652532705,\n",
       "  -1.1976374853652472,\n",
       "  0.15942239433357905,\n",
       "  0.8041440386651152,\n",
       "  1.1,\n",
       "  1.006108216275113],\n",
       " [0.4124286889658119,\n",
       "  1.0,\n",
       "  0.03154724729069958,\n",
       "  -0.6587901621347005,\n",
       "  0.7429639919870541,\n",
       "  1.1219337503507623,\n",
       "  0.9,\n",
       "  -0.9229491137227703],\n",
       " [-0.5871741490775717,\n",
       "  0.0,\n",
       "  -1.3182799451285663,\n",
       "  1.5487304217259474,\n",
       "  0.1596046177932423,\n",
       "  1.1149185984344059,\n",
       "  1.1,\n",
       "  -1.8607533513284933],\n",
       " [0.14723816793051436,\n",
       "  1.0,\n",
       "  -0.42728149588954023,\n",
       "  1.7995969874015285,\n",
       "  0.0028461891073784376,\n",
       "  -1.4521049963579324,\n",
       "  0.9,\n",
       "  -0.9808681877875232],\n",
       " [0.36818555945047166,\n",
       "  0.0,\n",
       "  -0.33181007435664533,\n",
       "  0.6939649638635428,\n",
       "  0.8742551165477715,\n",
       "  -0.06978535222012362,\n",
       "  1.1,\n",
       "  0.30028318218938366],\n",
       " [0.9811985018299043,\n",
       "  0.0,\n",
       "  -1.1013878360170581,\n",
       "  -0.3814801545435994,\n",
       "  0.34491562017616567,\n",
       "  -1.2791945567301506,\n",
       "  1.1,\n",
       "  1.0585015348512719],\n",
       " [-1.1476568691256295,\n",
       "  5.0,\n",
       "  1.617238166327656,\n",
       "  -0.23916834427837905,\n",
       "  0.14850511021438975,\n",
       "  1.4475684893166314,\n",
       "  0.85,\n",
       "  0.6810009360756143],\n",
       " [-0.8998272606842772,\n",
       "  1.0,\n",
       "  -0.8298984375733407,\n",
       "  -1.1094057807515418,\n",
       "  -0.5752618295232111,\n",
       "  0.10088737960673987,\n",
       "  0.9,\n",
       "  0.9747171802355656],\n",
       " [-1.3148330835436786,\n",
       "  5.0,\n",
       "  -0.8282079528740199,\n",
       "  1.6697511443882385,\n",
       "  0.7781544785739907,\n",
       "  -1.2121421147366278,\n",
       "  0.85,\n",
       "  0.23031660876285015],\n",
       " [0.2300826851203166,\n",
       "  1.0,\n",
       "  0.2691748770829069,\n",
       "  1.832219212194818,\n",
       "  0.8097078376856749,\n",
       "  0.3895986018960916,\n",
       "  0.9,\n",
       "  -1.1966466428713212],\n",
       " [1.1366754913635182,\n",
       "  4.0,\n",
       "  0.4114562821047837,\n",
       "  -1.1610273045503767,\n",
       "  -0.4005600221329419,\n",
       "  0.1041777779507661,\n",
       "  1.2,\n",
       "  0.010065248047528329],\n",
       " [0.7180168872332718,\n",
       "  1.0,\n",
       "  -0.8404266743073088,\n",
       "  -1.1978979038644237,\n",
       "  0.5226858741211069,\n",
       "  0.559227621406672,\n",
       "  0.9,\n",
       "  -0.7433105872380456],\n",
       " [0.3482238136994872,\n",
       "  3.0,\n",
       "  1.2888182676280768,\n",
       "  0.12235388608568921,\n",
       "  -1.612704758008452,\n",
       "  0.3548405820498744,\n",
       "  0.95,\n",
       "  0.9521273947156307],\n",
       " [-1.7713410225204893,\n",
       "  5.0,\n",
       "  -0.37556408953083725,\n",
       "  0.23978475760834442,\n",
       "  -0.07793705958447975,\n",
       "  0.7344416070116627,\n",
       "  0.85,\n",
       "  0.970978355383092],\n",
       " [-0.7422927530386078,\n",
       "  4.0,\n",
       "  0.26667278453422055,\n",
       "  1.4438886497532806,\n",
       "  1.0884345073600947,\n",
       "  1.6728043549318234,\n",
       "  1.2,\n",
       "  0.501560068921587],\n",
       " [0.11794662398128367,\n",
       "  5.0,\n",
       "  1.0466618709039452,\n",
       "  -0.96489840662857,\n",
       "  -2.568359950043109,\n",
       "  -0.8907911632566929,\n",
       "  0.85,\n",
       "  1.0646227466184834],\n",
       " [-1.6282359508204909,\n",
       "  1.0,\n",
       "  1.1522220105446268,\n",
       "  -0.3607005846062395,\n",
       "  0.17112572902048268,\n",
       "  -0.6421696574914844,\n",
       "  0.9,\n",
       "  1.0548756027406911],\n",
       " [0.7110263697822997,\n",
       "  4.0,\n",
       "  -0.4690693116959508,\n",
       "  -1.3988622522534186,\n",
       "  1.383779911080209,\n",
       "  1.7973275960375323,\n",
       "  1.2,\n",
       "  1.0572614395532218],\n",
       " [-1.0170637845167523,\n",
       "  1.0,\n",
       "  0.35813785379699087,\n",
       "  -1.1003685915839372,\n",
       "  -0.8291709417001634,\n",
       "  -0.19507295966109725,\n",
       "  0.9,\n",
       "  0.6040602053898453],\n",
       " [-0.17116671332992617,\n",
       "  2.0,\n",
       "  0.27614572029031886,\n",
       "  -1.252693666628249,\n",
       "  -0.26057396876678324,\n",
       "  1.7178000317364144,\n",
       "  1.05,\n",
       "  1.0271577806525531],\n",
       " [-1.3154323848013456,\n",
       "  1.0,\n",
       "  1.1583995778651037,\n",
       "  1.443883642764886,\n",
       "  -2.174506831929439,\n",
       "  0.7422608954128026,\n",
       "  0.9,\n",
       "  0.05975570829532748],\n",
       " [-0.8080127673019555,\n",
       "  2.0,\n",
       "  -1.4358436141396909,\n",
       "  1.8269960973781443,\n",
       "  0.8864312036876384,\n",
       "  -1.6603929053750799,\n",
       "  1.05,\n",
       "  0.557514267439267],\n",
       " [-0.6175059330430811,\n",
       "  3.0,\n",
       "  -1.3968403543653503,\n",
       "  -1.3724237275819173,\n",
       "  0.1884526201822284,\n",
       "  0.08387133896162059,\n",
       "  0.95,\n",
       "  -1.9871071077639602],\n",
       " [-0.6783672105169092,\n",
       "  5.0,\n",
       "  0.0720463942546049,\n",
       "  -1.0881944575131302,\n",
       "  -3.9106666003302473,\n",
       "  -0.4580090245199559,\n",
       "  0.85,\n",
       "  -0.43575869101585146],\n",
       " [-0.5783575490686692,\n",
       "  1.0,\n",
       "  -1.3212054205652746,\n",
       "  -0.8980453633791747,\n",
       "  -2.032134169109918,\n",
       "  0.3210437892499275,\n",
       "  0.9,\n",
       "  0.4556598934529738],\n",
       " [0.8806126357104506,\n",
       "  1.0,\n",
       "  0.1994091167359746,\n",
       "  -1.281402788144871,\n",
       "  0.9715006374945241,\n",
       "  -0.5669277382217766,\n",
       "  0.9,\n",
       "  0.4632216453518239],\n",
       " [1.2050225062718503,\n",
       "  3.0,\n",
       "  0.05497395106117602,\n",
       "  -0.4733688507977917,\n",
       "  -0.10716719357131313,\n",
       "  -0.05563334490770021,\n",
       "  0.95,\n",
       "  -0.3290556111216076],\n",
       " [-0.11150728842275391,\n",
       "  3.0,\n",
       "  0.6560050759764564,\n",
       "  -1.0450743761158596,\n",
       "  -0.3544916927214556,\n",
       "  -0.7375723572297067,\n",
       "  0.95,\n",
       "  -0.35817522160625326],\n",
       " [0.20457516423624575,\n",
       "  4.0,\n",
       "  1.4096130705189251,\n",
       "  0.19097276780701974,\n",
       "  -0.5287137641972991,\n",
       "  1.8031264403547598,\n",
       "  1.2,\n",
       "  -1.9095772656866599],\n",
       " [0.33369499545854353,\n",
       "  4.0,\n",
       "  -1.6264655389098783,\n",
       "  1.0308962489380689,\n",
       "  0.7216841207186261,\n",
       "  0.38482445489526307,\n",
       "  1.2,\n",
       "  0.8865203318409947],\n",
       " [0.4811996760916407,\n",
       "  2.0,\n",
       "  -1.2180939841943674,\n",
       "  0.7570700690546316,\n",
       "  -2.023711371060852,\n",
       "  0.5851096241276084,\n",
       "  1.05,\n",
       "  1.0033349459680665],\n",
       " [1.454997592550039,\n",
       "  2.0,\n",
       "  0.5638722262625812,\n",
       "  -0.47933945961144137,\n",
       "  0.5885545921487138,\n",
       "  0.19434472909806735,\n",
       "  1.05,\n",
       "  1.0464644277621986],\n",
       " [0.7343097380977928,\n",
       "  5.0,\n",
       "  1.421217274342647,\n",
       "  1.325751423775754,\n",
       "  0.7974678473483527,\n",
       "  0.9068792697138772,\n",
       "  0.85,\n",
       "  0.2991964363447221],\n",
       " [1.2718145300021009,\n",
       "  5.0,\n",
       "  0.26858053384951747,\n",
       "  0.7202685131771239,\n",
       "  0.4615927710333864,\n",
       "  0.5830320887322319,\n",
       "  0.85,\n",
       "  -0.2566176987589006],\n",
       " [0.7828000246179703,\n",
       "  0.0,\n",
       "  0.5157397264039572,\n",
       "  1.7631011617082348,\n",
       "  -0.5835341445716155,\n",
       "  -0.059819018434078226,\n",
       "  1.1,\n",
       "  0.3994561355512596],\n",
       " [-0.13662574034164504,\n",
       "  2.0,\n",
       "  1.1347845257335523,\n",
       "  -0.24625405983180607,\n",
       "  0.8394516636846671,\n",
       "  -0.7912090355891067,\n",
       "  1.05,\n",
       "  0.030397561161434033],\n",
       " [-1.4287440722103013,\n",
       "  5.0,\n",
       "  -0.7906921039879924,\n",
       "  1.787101085098146,\n",
       "  0.5768627642976983,\n",
       "  1.0454035895082445,\n",
       "  0.85,\n",
       "  -1.7018026242229523],\n",
       " [1.6371169374635264,\n",
       "  5.0,\n",
       "  0.7386247829302502,\n",
       "  -0.5798398568863807,\n",
       "  0.8166665895799609,\n",
       "  -0.653341451334927,\n",
       "  0.85,\n",
       "  0.4342146640029014],\n",
       " [-1.633743593199644,\n",
       "  4.0,\n",
       "  0.5829764087280916,\n",
       "  -0.9498984008839475,\n",
       "  -0.10369646142364573,\n",
       "  0.5657582812036025,\n",
       "  1.2,\n",
       "  1.0220599873439078],\n",
       " [0.06828631442419889,\n",
       "  0.0,\n",
       "  -1.0416835788444632,\n",
       "  -0.9701219223630432,\n",
       "  -1.8984313768732628,\n",
       "  1.3091599327035393,\n",
       "  1.1,\n",
       "  -1.615250846894563],\n",
       " [1.4713205598064214,\n",
       "  4.0,\n",
       "  -0.43199965028762216,\n",
       "  -0.5121158539788776,\n",
       "  1.3435920236994459,\n",
       "  0.4792075724099444,\n",
       "  1.2,\n",
       "  -1.9794040061419234],\n",
       " [0.35835517250732407,\n",
       "  5.0,\n",
       "  -1.4497301348277876,\n",
       "  0.48323174588471407,\n",
       "  0.22248253010105618,\n",
       "  -1.8121872883142955,\n",
       "  0.85,\n",
       "  -0.3520470664781064],\n",
       " [-1.0712735903112016,\n",
       "  0.0,\n",
       "  -1.0354947101641798,\n",
       "  0.8853321154989219,\n",
       "  0.8285642568984235,\n",
       "  0.044025645277243425,\n",
       "  1.1,\n",
       "  0.8453553313223853],\n",
       " [0.33044020700186516,\n",
       "  4.0,\n",
       "  1.6468901974425199,\n",
       "  1.3566397840446565,\n",
       "  -0.49917287154899675,\n",
       "  0.8722819687029935,\n",
       "  1.2,\n",
       "  -1.394914673483645],\n",
       " [-1.6829547361832962,\n",
       "  3.0,\n",
       "  0.971683639280912,\n",
       "  -1.346249814741442,\n",
       "  0.5180811585595362,\n",
       "  -0.9749538818128791,\n",
       "  0.95,\n",
       "  0.9228711484757287],\n",
       " [-0.8761918148923741,\n",
       "  4.0,\n",
       "  -1.5878882715458613,\n",
       "  0.013486534124200755,\n",
       "  0.5380530429617004,\n",
       "  0.3608761575945673,\n",
       "  1.2,\n",
       "  0.8725299216961729],\n",
       " [-0.014021863286405244,\n",
       "  4.0,\n",
       "  0.19201663618450313,\n",
       "  0.06967781807959082,\n",
       "  -0.3429879355102856,\n",
       "  0.8960473604475169,\n",
       "  1.2,\n",
       "  -0.7793839093900207],\n",
       " [-1.7273351547357088,\n",
       "  4.0,\n",
       "  0.8238793384090951,\n",
       "  -0.7456727115857081,\n",
       "  -1.1247956691122551,\n",
       "  1.0194135718298722,\n",
       "  1.2,\n",
       "  -0.4986311998614426],\n",
       " [-1.7203223286269613,\n",
       "  1.0,\n",
       "  -0.9377502225502343,\n",
       "  -1.1380050325074464,\n",
       "  0.13668798646678096,\n",
       "  -1.498577590135563,\n",
       "  0.9,\n",
       "  0.4521470757881718],\n",
       " [1.3743439077854596,\n",
       "  4.0,\n",
       "  0.224481091968798,\n",
       "  -0.08689067310241737,\n",
       "  0.4086905283737672,\n",
       "  -1.821141996534018,\n",
       "  1.2,\n",
       "  0.9673024704910437],\n",
       " [0.6306052565899216,\n",
       "  3.0,\n",
       "  -1.351128980757933,\n",
       "  0.31241825961802544,\n",
       "  0.45529698464951873,\n",
       "  1.0936843957553208,\n",
       "  0.95,\n",
       "  3.720747400112593],\n",
       " [1.4150403393513542,\n",
       "  2.0,\n",
       "  0.845543919170106,\n",
       "  -0.38401134678018156,\n",
       "  0.49922032624310064,\n",
       "  1.471225133936781,\n",
       "  1.05,\n",
       "  -0.08074289550115508],\n",
       " [-1.8347336223753887,\n",
       "  5.0,\n",
       "  -1.5280421283653125,\n",
       "  -0.5376132505461594,\n",
       "  -0.46223442904170026,\n",
       "  0.25719028645964737,\n",
       "  0.85,\n",
       "  1.0032044428208118],\n",
       " [-0.4764790903254732,\n",
       "  1.0,\n",
       "  -0.8048874709486427,\n",
       "  0.7562002398756958,\n",
       "  -0.8616384609104352,\n",
       "  1.1564746114802238,\n",
       "  0.9,\n",
       "  -0.9468660600219483],\n",
       " [1.1212983449818457,\n",
       "  2.0,\n",
       "  -1.2183513786845206,\n",
       "  0.5348280868593414,\n",
       "  0.7338714242483093,\n",
       "  0.5351055094500613,\n",
       "  1.05,\n",
       "  0.8009410919305754],\n",
       " [-1.0349513209074743,\n",
       "  2.0,\n",
       "  -0.7593082476717208,\n",
       "  0.7091526574437308,\n",
       "  0.6586051707033677,\n",
       "  -1.3748122376245329,\n",
       "  1.05,\n",
       "  0.9280592760631441],\n",
       " [-0.7384437435378068,\n",
       "  1.0,\n",
       "  1.1971293021342444,\n",
       "  0.4244609861130543,\n",
       "  0.6850584645585079,\n",
       "  0.7536696447563485,\n",
       "  0.9,\n",
       "  -0.29245042937601906],\n",
       " [-0.06288266767570408,\n",
       "  4.0,\n",
       "  -1.1236739225576948,\n",
       "  0.08719050175654823,\n",
       "  -0.38690985223837193,\n",
       "  -0.08944783059956704,\n",
       "  1.2,\n",
       "  1.2163582986019184],\n",
       " [-0.37528163061533126,\n",
       "  3.0,\n",
       "  -0.47599217849061787,\n",
       "  0.8352424010519812,\n",
       "  1.0132408500889523,\n",
       "  0.8700265648000015,\n",
       "  0.95,\n",
       "  0.9581137249822297],\n",
       " [0.2345124828926171,\n",
       "  3.0,\n",
       "  -0.22258333843046818,\n",
       "  -0.815176575841083,\n",
       "  -1.1596947060969176,\n",
       "  0.9773374582215,\n",
       "  0.95,\n",
       "  0.8938025151787081],\n",
       " [1.4768386865197654,\n",
       "  4.0,\n",
       "  1.4442737282989526,\n",
       "  1.654072038470538,\n",
       "  1.6766602887773554,\n",
       "  0.6151008447270625,\n",
       "  1.2,\n",
       "  0.9850251346127892],\n",
       " [1.0109668302347,\n",
       "  5.0,\n",
       "  -1.0262142893307147,\n",
       "  -0.12959346832314134,\n",
       "  0.8337600499868311,\n",
       "  0.6475745896199422,\n",
       "  0.85,\n",
       "  -0.27708968022075836],\n",
       " [-1.3619666831608712,\n",
       "  2.0,\n",
       "  -1.3734900905245602,\n",
       "  -1.3167527881128087,\n",
       "  -1.2048948206171861,\n",
       "  1.5476053994075223,\n",
       "  1.05,\n",
       "  0.9474134010536525],\n",
       " [0.2995894832134221,\n",
       "  0.0,\n",
       "  0.3818650231051263,\n",
       "  1.9588686174940446,\n",
       "  0.764288976182033,\n",
       "  -0.45435925177390496,\n",
       "  1.1,\n",
       "  0.6830886480566947],\n",
       " [1.6034606902498598,\n",
       "  4.0,\n",
       "  -0.38923427207154665,\n",
       "  -0.951029001639426,\n",
       "  0.6942052888274778,\n",
       "  0.03196732356321633,\n",
       "  1.2,\n",
       "  -1.3918749145910376],\n",
       " [1.357205184855463,\n",
       "  0.0,\n",
       "  1.642203372408397,\n",
       "  -0.703408908798049,\n",
       "  0.5560225984313234,\n",
       "  1.0629318268280026,\n",
       "  1.1,\n",
       "  0.016234428712371955],\n",
       " [1.006849758473187,\n",
       "  4.0,\n",
       "  0.3281918512899739,\n",
       "  1.2371921446740461,\n",
       "  -0.3551553929875954,\n",
       "  0.2559049343831938,\n",
       "  1.2,\n",
       "  -1.0920879943208044],\n",
       " [0.6336020986803883,\n",
       "  1.0,\n",
       "  0.6140481556150819,\n",
       "  1.4988158171193935,\n",
       "  0.6120406745465601,\n",
       "  -0.7222128569172094,\n",
       "  0.9,\n",
       "  -0.6689744293162451],\n",
       " [-1.3205104227637943,\n",
       "  4.0,\n",
       "  -1.2913830772733759,\n",
       "  1.3140954961323292,\n",
       "  1.0975696817973908,\n",
       "  0.029390021393496134,\n",
       "  1.2,\n",
       "  0.9635120449349549],\n",
       " [1.6002018140241985,\n",
       "  1.0,\n",
       "  0.7640683591741059,\n",
       "  -0.4581775971862496,\n",
       "  0.6894840610302368,\n",
       "  -1.6875972212093908,\n",
       "  0.9,\n",
       "  0.7437266669362806],\n",
       " [0.9732539646965583,\n",
       "  3.0,\n",
       "  -0.030028340398424818,\n",
       "  0.0977891507998815,\n",
       "  -1.1118891072504777,\n",
       "  -0.09076150999058147,\n",
       "  0.95,\n",
       "  -1.0746713365861744],\n",
       " [1.2232640342965746,\n",
       "  1.0,\n",
       "  1.0888234427782413,\n",
       "  1.4447687642119424,\n",
       "  -0.1191645933112922,\n",
       "  -1.198525754055399,\n",
       "  0.9,\n",
       "  0.8043236070291541],\n",
       " [-1.5257536324802135,\n",
       "  2.0,\n",
       "  -1.1102230098649706,\n",
       "  1.0810757555897217,\n",
       "  0.6531946012215324,\n",
       "  -1.4981657556280126,\n",
       "  1.05,\n",
       "  -1.020453378921926],\n",
       " [-1.3008289325572018,\n",
       "  5.0,\n",
       "  1.6070777090287227,\n",
       "  -0.5193173056760303,\n",
       "  -1.2050628987860854,\n",
       "  -1.7613324301072582,\n",
       "  0.85,\n",
       "  -0.3452015098763257],\n",
       " [-1.0675220723264691,\n",
       "  1.0,\n",
       "  -1.2174286675394466,\n",
       "  0.03509354717468615,\n",
       "  0.8073945689745136,\n",
       "  -0.024265209195831295,\n",
       "  0.9,\n",
       "  -0.6117165896420037],\n",
       " [1.4928880938788816,\n",
       "  1.0,\n",
       "  1.4028444080314961,\n",
       "  0.7995945982272858,\n",
       "  -0.4548251689670388,\n",
       "  1.4458877663831025,\n",
       "  0.9,\n",
       "  0.6537948107822252],\n",
       " [1.471261922342241,\n",
       "  5.0,\n",
       "  -1.2968018224887892,\n",
       "  1.7095225139263492,\n",
       "  1.1041076201807116,\n",
       "  -0.29122184930529244,\n",
       "  0.85,\n",
       "  0.009565809520942072],\n",
       " [1.6935136605892147,\n",
       "  1.0,\n",
       "  1.67103970129889,\n",
       "  -0.6095907492161519,\n",
       "  -0.18527532001396638,\n",
       "  1.1543379388060404,\n",
       "  0.9,\n",
       "  0.34458713898577276],\n",
       " [-1.1336937079318412,\n",
       "  0.0,\n",
       "  1.0572148944886626,\n",
       "  -1.198289183504853,\n",
       "  1.238422735164134,\n",
       "  0.6466673682835803,\n",
       "  1.1,\n",
       "  -1.9113010712085605],\n",
       " [0.9358033248829202,\n",
       "  5.0,\n",
       "  0.14906949278598733,\n",
       "  0.09050375768539722,\n",
       "  -0.8148053000971807,\n",
       "  0.34762412594056,\n",
       "  0.85,\n",
       "  -0.5454730010661627],\n",
       " [1.004897443332723,\n",
       "  0.0,\n",
       "  -0.9902927535492883,\n",
       "  -0.4437479484032369,\n",
       "  1.3104231574808547,\n",
       "  -0.8641581109353763,\n",
       "  1.1,\n",
       "  -0.8105540610249061],\n",
       " [-1.8825086847675212,\n",
       "  2.0,\n",
       "  0.9898832384378053,\n",
       "  -1.1538193232973153,\n",
       "  -0.8354797182285785,\n",
       "  0.2677439576671565,\n",
       "  1.05,\n",
       "  -1.4045020008786426],\n",
       " [1.566336845377592,\n",
       "  0.0,\n",
       "  -1.0914845431821374,\n",
       "  -0.07605226986175535,\n",
       "  -3.242296547033616,\n",
       "  1.4896574381703267,\n",
       "  1.1,\n",
       "  -0.3710209687852274],\n",
       " [1.5847602136053125,\n",
       "  5.0,\n",
       "  -0.10898219960897983,\n",
       "  0.8074871537879774,\n",
       "  -1.9093701176694915,\n",
       "  0.31360248228843374,\n",
       "  0.85,\n",
       "  1.1432107824127014],\n",
       " [0.614496243825439,\n",
       "  2.0,\n",
       "  1.292017003640891,\n",
       "  -1.411439094024159,\n",
       "  0.6576562617997809,\n",
       "  0.9405814455497354,\n",
       "  1.05,\n",
       "  0.7653374397909531],\n",
       " [-1.54795455690353,\n",
       "  3.0,\n",
       "  -1.4787765611571033,\n",
       "  2.003065961417625,\n",
       "  -1.0999001003041948,\n",
       "  -0.581534259185651,\n",
       "  0.95,\n",
       "  0.48838343021465114],\n",
       " [1.0784365013248367,\n",
       "  1.0,\n",
       "  -0.9862093037378952,\n",
       "  0.7821101944543726,\n",
       "  -0.7165145695058861,\n",
       "  0.6812290681019209,\n",
       "  0.9,\n",
       "  1.0086867662677916],\n",
       " [-1.3566266179280337,\n",
       "  5.0,\n",
       "  -0.5440394672091512,\n",
       "  -1.3171482052930579,\n",
       "  -0.1372122493574614,\n",
       "  0.40967700499505555,\n",
       "  0.85,\n",
       "  0.3293047758825394],\n",
       " [0.2502467362367183,\n",
       "  2.0,\n",
       "  0.6011017146592913,\n",
       "  0.8591442085493984,\n",
       "  0.9252820535819851,\n",
       "  -1.5974086908847684,\n",
       "  1.05,\n",
       "  -0.8589467590462045],\n",
       " [1.1686223677670917,\n",
       "  0.0,\n",
       "  -0.7612708948073446,\n",
       "  -1.0461486060743295,\n",
       "  0.9683749831494434,\n",
       "  -0.4038466760704714,\n",
       "  1.1,\n",
       "  1.0472637990583726],\n",
       " [1.7544001181415247,\n",
       "  3.0,\n",
       "  -0.7528308253095212,\n",
       "  -0.6234437205753354,\n",
       "  0.4843610679766908,\n",
       "  0.04218490405400838,\n",
       "  0.95,\n",
       "  -0.15108601454734374],\n",
       " [-1.5306734181745794,\n",
       "  0.0,\n",
       "  0.35169723093746663,\n",
       "  -0.33099983888040035,\n",
       "  -1.32599758125926,\n",
       "  -1.0612944952762393,\n",
       "  1.1,\n",
       "  0.8861677099847918],\n",
       " [0.7220563738326045,\n",
       "  4.0,\n",
       "  -0.9731946903996662,\n",
       "  -1.3443358711432216,\n",
       "  0.7503405179359434,\n",
       "  0.4621406329008247,\n",
       "  1.2,\n",
       "  -0.8382080908642829],\n",
       " [1.7590476777789683,\n",
       "  1.0,\n",
       "  1.1431528790405026,\n",
       "  -0.8524229575099856,\n",
       "  0.7347943137789203,\n",
       "  0.49453080522195264,\n",
       "  0.9,\n",
       "  0.911964718657187],\n",
       " [0.37024199042014744,\n",
       "  1.0,\n",
       "  0.41510469170186387,\n",
       "  -0.7331611334211044,\n",
       "  0.8187447689724248,\n",
       "  -0.9216732067631713,\n",
       "  0.9,\n",
       "  -0.018678814090125923],\n",
       " [-1.4554194184297717,\n",
       "  5.0,\n",
       "  -1.020425429205778,\n",
       "  -0.7873440272885152,\n",
       "  0.1417755513065386,\n",
       "  -0.4641966083020697,\n",
       "  0.85,\n",
       "  0.4714727256456625],\n",
       " [1.165082299987126,\n",
       "  3.0,\n",
       "  -0.4559459945252952,\n",
       "  -0.7712185632341528,\n",
       "  0.3130935170247727,\n",
       "  -0.6346171181948096,\n",
       "  0.95,\n",
       "  1.0042005995240997],\n",
       " [0.7795568525504335,\n",
       "  4.0,\n",
       "  -1.48290388526758,\n",
       "  1.1424017380107427,\n",
       "  1.1525175313225888,\n",
       "  0.7637384581669232,\n",
       "  1.2,\n",
       "  -1.0756207863557055],\n",
       " [-0.3927156419045176,\n",
       "  0.0,\n",
       "  0.807572280285001,\n",
       "  1.087117431896203,\n",
       "  0.49826193114635325,\n",
       "  0.8362690538003978,\n",
       "  1.1,\n",
       "  -0.29483609417060197],\n",
       " [-0.03247251135593353,\n",
       "  4.0,\n",
       "  -1.351198976103657,\n",
       "  0.4306947228587188,\n",
       "  -0.03985244632429233,\n",
       "  0.6049716535409068,\n",
       "  1.2,\n",
       "  -0.5243988749607557],\n",
       " [-1.5964838332902656,\n",
       "  3.0,\n",
       "  0.7834597764155212,\n",
       "  0.7851961881228422,\n",
       "  0.578786553507237,\n",
       "  1.6424414871648425,\n",
       "  0.95,\n",
       "  -0.8488454408101788],\n",
       " [1.4888117051704581,\n",
       "  1.0,\n",
       "  -0.029465313998427316,\n",
       "  1.0701004871575495,\n",
       "  -0.3869001594916181,\n",
       "  1.5694673912226957,\n",
       "  0.9,\n",
       "  0.7269415654630782],\n",
       " [-1.3892721412680238,\n",
       "  4.0,\n",
       "  -0.07048088772922612,\n",
       "  -0.10157766409522036,\n",
       "  -0.5269865434140073,\n",
       "  -0.31869764601825384,\n",
       "  1.2,\n",
       "  0.0866861731882694],\n",
       " [0.9309774880960301,\n",
       "  0.0,\n",
       "  -1.5244080832767388,\n",
       "  1.4504073174074605,\n",
       "  0.6131675910226996,\n",
       "  0.8393866256421041,\n",
       "  1.1,\n",
       "  1.0306769399179696],\n",
       " [-1.2309081387125687,\n",
       "  2.0,\n",
       "  0.10756363275155266,\n",
       "  0.8001243002603756,\n",
       "  -0.1924849038054657,\n",
       "  -0.08686727622326923,\n",
       "  1.05,\n",
       "  0.5658434394304692],\n",
       " [-1.1338354552743355,\n",
       "  5.0,\n",
       "  -0.6197709746472558,\n",
       "  -1.2307779092611546,\n",
       "  0.5557921259012311,\n",
       "  1.2927986613145956,\n",
       "  0.85,\n",
       "  0.3719102392036808],\n",
       " [-1.4147194420338793,\n",
       "  3.0,\n",
       "  -0.8719534157240116,\n",
       "  0.39367114213322163,\n",
       "  1.0165065174330208,\n",
       "  -0.10412609784410701,\n",
       "  0.95,\n",
       "  0.010068115937744706],\n",
       " [-0.7447239321921552,\n",
       "  5.0,\n",
       "  0.9632742779808178,\n",
       "  -1.3024166605926513,\n",
       "  0.17066837909992316,\n",
       "  -0.10062401192963612,\n",
       "  0.85,\n",
       "  -0.1359227830408518],\n",
       " [1.4178043482476592,\n",
       "  5.0,\n",
       "  0.2712143001918737,\n",
       "  0.9329468877430191,\n",
       "  0.8790235795184392,\n",
       "  0.2639255742420505,\n",
       "  0.85,\n",
       "  -0.1263574537372205],\n",
       " [-0.17830150663183225,\n",
       "  4.0,\n",
       "  0.47921424591086514,\n",
       "  0.028374064145166387,\n",
       "  0.9232884549649679,\n",
       "  1.9418995771075065,\n",
       "  1.2,\n",
       "  0.3757757686191576],\n",
       " [1.2586406974707527,\n",
       "  4.0,\n",
       "  0.8356435538111066,\n",
       "  1.6521822390904182,\n",
       "  -0.8171602734212344,\n",
       "  -0.07163808781086918,\n",
       "  1.2,\n",
       "  1.0162643690660282],\n",
       " [1.3904103165568371,\n",
       "  3.0,\n",
       "  -1.5224350261683266,\n",
       "  -0.24451439697025382,\n",
       "  -1.3896919188386472,\n",
       "  -0.15697246967483575,\n",
       "  0.95,\n",
       "  -0.17281075578601185],\n",
       " [0.26573686318685785,\n",
       "  3.0,\n",
       "  0.9586391270504813,\n",
       "  0.8499844167150825,\n",
       "  -2.8279472027269286,\n",
       "  0.11473712706797663,\n",
       "  0.95,\n",
       "  -1.4292845751657046],\n",
       " [-1.3157340811246918,\n",
       "  1.0,\n",
       "  0.8268409091520007,\n",
       "  -0.5338066941633525,\n",
       "  0.8944450254098646,\n",
       "  -1.977165847726019,\n",
       "  0.9,\n",
       "  -1.0430663051832187],\n",
       " [-1.6484011950854065,\n",
       "  4.0,\n",
       "  -1.1740692016969327,\n",
       "  -0.7842266470550863,\n",
       "  0.6030663662426398,\n",
       "  -0.1475816286912626,\n",
       "  1.2,\n",
       "  0.07003220455826586],\n",
       " [-0.5701942099985181,\n",
       "  0.0,\n",
       "  -1.3648110743547022,\n",
       "  0.905532931562322,\n",
       "  -0.22288634921507933,\n",
       "  0.2502082426507231,\n",
       "  1.1,\n",
       "  0.24105477342747764],\n",
       " [-0.2561703486027567,\n",
       "  4.0,\n",
       "  -0.4594392536728554,\n",
       "  0.18477001262030462,\n",
       "  0.8636086601535173,\n",
       "  -1.0830230350317118,\n",
       "  1.2,\n",
       "  -1.444624515209622],\n",
       " [-1.6039334026916956,\n",
       "  0.0,\n",
       "  0.003867685565845677,\n",
       "  0.6355207731806911,\n",
       "  -0.880967701107278,\n",
       "  -0.06487179624769826,\n",
       "  1.1,\n",
       "  -1.0604951247383094],\n",
       " [-0.4776415581745463,\n",
       "  5.0,\n",
       "  -1.4981834783453327,\n",
       "  -1.0294752799223477,\n",
       "  -1.7799386158343269,\n",
       "  -0.03999639072049269,\n",
       "  0.85,\n",
       "  -0.6485736900482773],\n",
       " [-0.8668030989601362,\n",
       "  5.0,\n",
       "  -1.5216859224830437,\n",
       "  0.8539334020679514,\n",
       "  -0.408553902645482,\n",
       "  -1.4362619188453807,\n",
       "  0.85,\n",
       "  -0.7430634379132555],\n",
       " [1.2985811144884212,\n",
       "  0.0,\n",
       "  -1.2989448893342148,\n",
       "  -1.066053055485532,\n",
       "  -0.011887653330837623,\n",
       "  -0.958634419496075,\n",
       "  1.1,\n",
       "  0.8236178939489355],\n",
       " [1.1355632049505018,\n",
       "  3.0,\n",
       "  0.05357433559119738,\n",
       "  -0.3993195163054006,\n",
       "  -0.7318858500848088,\n",
       "  -0.06427264334652703,\n",
       "  0.95,\n",
       "  0.7177588337460492],\n",
       " [-0.8417420277059717,\n",
       "  3.0,\n",
       "  -0.19564682299014494,\n",
       "  -0.866010422750329,\n",
       "  0.473110134818971,\n",
       "  -1.3846845556920515,\n",
       "  0.95,\n",
       "  0.6414287669107432],\n",
       " [1.4196554254911644,\n",
       "  1.0,\n",
       "  0.03109281732167357,\n",
       "  0.9993849051088847,\n",
       "  -0.014158922849070733,\n",
       "  0.2636383051314401,\n",
       "  0.9,\n",
       "  0.9750355665517998],\n",
       " [1.0335333787773737,\n",
       "  2.0,\n",
       "  0.36320316122257207,\n",
       "  1.2873611402077205,\n",
       "  -1.2940217885007899,\n",
       "  0.8894478526568894,\n",
       "  1.05,\n",
       "  0.37086084014116977],\n",
       " [1.314392818027409,\n",
       "  5.0,\n",
       "  0.7684128459985603,\n",
       "  0.33403845076052074,\n",
       "  0.3634974965917338,\n",
       "  -1.4690577086651126,\n",
       "  0.85,\n",
       "  0.8804123336252997],\n",
       " [1.4904355479557712,\n",
       "  0.0,\n",
       "  1.3906111895821818,\n",
       "  0.9198422060468119,\n",
       "  0.7566668866174096,\n",
       "  -0.5535967442265135,\n",
       "  1.1,\n",
       "  1.0209642162806514],\n",
       " [0.62560489383188,\n",
       "  5.0,\n",
       "  0.40570002167766256,\n",
       "  -1.2325451936321992,\n",
       "  0.7032739452008446,\n",
       "  -1.3365664149482994,\n",
       "  0.85,\n",
       "  0.3440012371735873],\n",
       " [0.09098894893598622,\n",
       "  4.0,\n",
       "  -1.6162831553218635,\n",
       "  0.3219949568988088,\n",
       "  0.9536043956938235,\n",
       "  0.9956762576441199,\n",
       "  1.2,\n",
       "  0.982685819472447],\n",
       " [-0.07683648824031918,\n",
       "  5.0,\n",
       "  -1.179460447006267,\n",
       "  -1.237765533191701,\n",
       "  1.0471291278765669,\n",
       "  -1.6891240157333318,\n",
       "  0.85,\n",
       "  0.8331694016567737],\n",
       " [-0.6995244980753447,\n",
       "  5.0,\n",
       "  -0.17235334846347677,\n",
       "  1.4912479705886839,\n",
       "  0.8609896501700397,\n",
       "  -0.6211572421358469,\n",
       "  0.85,\n",
       "  0.33002744944185114],\n",
       " [0.5954402729001199,\n",
       "  2.0,\n",
       "  -0.08340434346720754,\n",
       "  1.3876578197313125,\n",
       "  0.5003291278544585,\n",
       "  0.7685999526466866,\n",
       "  1.05,\n",
       "  -0.03828978659821553],\n",
       " [-1.424348975941441,\n",
       "  1.0,\n",
       "  0.6913096042853314,\n",
       "  0.5924314195861378,\n",
       "  -0.34583946360182855,\n",
       "  0.4311683133123002,\n",
       "  0.9,\n",
       "  -0.8558418700929785],\n",
       " [-1.4637803578033677,\n",
       "  4.0,\n",
       "  -1.5647648928793318,\n",
       "  -0.5156196466804744,\n",
       "  -0.013239126038317959,\n",
       "  0.4477516691035703,\n",
       "  1.2,\n",
       "  -1.6548419585845173],\n",
       " [-0.4445935382520136,\n",
       "  4.0,\n",
       "  -1.2072377298031205,\n",
       "  -0.4135359898852089,\n",
       "  -0.007077865893872305,\n",
       "  0.7349237681508728,\n",
       "  1.2,\n",
       "  0.9682256104630483],\n",
       " [-0.6553620054069975,\n",
       "  2.0,\n",
       "  0.44317919317199983,\n",
       "  -0.11483035713543814,\n",
       "  0.7295574171350832,\n",
       "  1.0380715424044733,\n",
       "  1.05,\n",
       "  -1.116837265182039],\n",
       " [0.2799716527998145,\n",
       "  5.0,\n",
       "  -0.6777861427575691,\n",
       "  1.3949988338440364,\n",
       "  0.5735417958195477,\n",
       "  -0.03677812046869671,\n",
       "  0.85,\n",
       "  0.9725461319240563],\n",
       " [-0.19470084051268696,\n",
       "  1.0,\n",
       "  0.5022602970450704,\n",
       "  -0.37041611833607374,\n",
       "  0.5750540404113158,\n",
       "  -1.518430113906978,\n",
       "  0.9,\n",
       "  0.9731385153328098],\n",
       " [-0.317708530034691,\n",
       "  4.0,\n",
       "  0.7461524548777821,\n",
       "  -0.37237187244807796,\n",
       "  -0.3459747348553229,\n",
       "  0.4953454068757191,\n",
       "  1.2,\n",
       "  -0.26556047902448116],\n",
       " [0.50663065730535,\n",
       "  5.0,\n",
       "  0.8593311447531833,\n",
       "  -1.3227636833522187,\n",
       "  -0.22087503050438062,\n",
       "  0.6981793942215025,\n",
       "  0.85,\n",
       "  -1.9892963334326934],\n",
       " [-0.00828778498358171,\n",
       "  0.0,\n",
       "  -0.24912080061316352,\n",
       "  -1.2402316785875762,\n",
       "  0.7828815700042813,\n",
       "  -1.8927922384227605,\n",
       "  1.1,\n",
       "  0.7868059340305219],\n",
       " [1.3958295329306423,\n",
       "  3.0,\n",
       "  -1.7076099274027101,\n",
       "  1.7399598035786004,\n",
       "  0.5225472133179299,\n",
       "  0.7619308363611096,\n",
       "  0.95,\n",
       "  -0.818896412180227],\n",
       " [-1.7365423137460816,\n",
       "  1.0,\n",
       "  0.47178472906034674,\n",
       "  -0.5149814228161196,\n",
       "  -0.8020428327981315,\n",
       "  -0.4316453199762588,\n",
       "  0.9,\n",
       "  -1.3007959558288535],\n",
       " [-1.7399757625016454,\n",
       "  2.0,\n",
       "  1.1559561618183702,\n",
       "  -0.6847729071492156,\n",
       "  0.5125330589978664,\n",
       "  -0.831997616239797,\n",
       "  1.05,\n",
       "  0.05622227083365167],\n",
       " [-0.4968673373937098,\n",
       "  4.0,\n",
       "  -1.3763003967562364,\n",
       "  0.6647824430838689,\n",
       "  1.2204900737881337,\n",
       "  0.5504405707824821,\n",
       "  1.2,\n",
       "  -0.414985359345409],\n",
       " [0.8723314077722806,\n",
       "  4.0,\n",
       "  -0.9963130237359179,\n",
       "  -0.2094573363650999,\n",
       "  0.1267705394594485,\n",
       "  -0.12822890127885928,\n",
       "  1.2,\n",
       "  -0.3874357978469024],\n",
       " [-1.4422238076785843,\n",
       "  3.0,\n",
       "  1.1333898508114797,\n",
       "  0.815026503674464,\n",
       "  0.8222717214894727,\n",
       "  0.09056800029071636,\n",
       "  0.95,\n",
       "  2.481832498289658],\n",
       " [0.8193357299596087,\n",
       "  0.0,\n",
       "  -0.7969482331130083,\n",
       "  -0.1354464479044449,\n",
       "  -0.3142608906823997,\n",
       "  -0.1555343195713905,\n",
       "  1.1,\n",
       "  -1.1233042584570976],\n",
       " [-1.0815004448440162,\n",
       "  4.0,\n",
       "  1.443132679731376,\n",
       "  -0.8258928585801562,\n",
       "  -0.9655995625745212,\n",
       "  -1.0804292186675781,\n",
       "  1.2,\n",
       "  1.0335897878132556],\n",
       " [0.18993506174582914,\n",
       "  4.0,\n",
       "  -1.0839012427873986,\n",
       "  0.21094322400347681,\n",
       "  0.5807220839485074,\n",
       "  1.6373759069091445,\n",
       "  1.2,\n",
       "  0.83359523619375],\n",
       " [1.6376096593274534,\n",
       "  5.0,\n",
       "  -0.8607302186652774,\n",
       "  -0.4115033896412676,\n",
       "  -0.7691764455918307,\n",
       "  -1.5622242634347694,\n",
       "  0.85,\n",
       "  -0.027167126615508172],\n",
       " [-0.5027637199550076,\n",
       "  1.0,\n",
       "  1.4853458091771174,\n",
       "  -0.9895447369408121,\n",
       "  0.34034476682682047,\n",
       "  -1.300003538173641,\n",
       "  0.9,\n",
       "  1.054888710891924],\n",
       " [0.05547033108333458,\n",
       "  5.0,\n",
       "  -1.3811266260513229,\n",
       "  0.3230526201506988,\n",
       "  -0.9032268722703012,\n",
       "  -0.24135167425113047,\n",
       "  0.85,\n",
       "  -0.3956369805396033],\n",
       " [0.7771982627757046,\n",
       "  0.0,\n",
       "  -0.42029560520620346,\n",
       "  0.34885704193620887,\n",
       "  -0.4403587449908771,\n",
       "  0.8115125491167569,\n",
       "  1.1,\n",
       "  -1.754158732334567],\n",
       " [-1.51275512156803,\n",
       "  4.0,\n",
       "  1.4656031391799937,\n",
       "  -1.3605116365055416,\n",
       "  -0.5908378088515857,\n",
       "  0.22019145402525134,\n",
       "  1.2,\n",
       "  0.39562696522873037],\n",
       " [-0.4080139362186664,\n",
       "  1.0,\n",
       "  1.4814404396335168,\n",
       "  -1.22202804067711,\n",
       "  -0.2547003345120203,\n",
       "  -1.3484393866240796,\n",
       "  0.9,\n",
       "  0.049709878918860084],\n",
       " [-1.7799952365424245,\n",
       "  4.0,\n",
       "  0.35440648829141447,\n",
       "  1.831384489420955,\n",
       "  -1.9343909619330035,\n",
       "  0.6388929940821753,\n",
       "  1.2,\n",
       "  1.0573109739889883],\n",
       " [1.4701362436324725,\n",
       "  0.0,\n",
       "  -0.5238502079399776,\n",
       "  1.470447106916701,\n",
       "  -0.6065966999344101,\n",
       "  -0.21065973999998702,\n",
       "  1.1,\n",
       "  0.8109848116284788],\n",
       " [-0.11014827494039273,\n",
       "  3.0,\n",
       "  1.3205270917258918,\n",
       "  -0.02375912846898679,\n",
       "  0.29969883673442366,\n",
       "  -1.5391253480515334,\n",
       "  0.95,\n",
       "  0.19796683846510504],\n",
       " [-0.6060680891538098,\n",
       "  5.0,\n",
       "  0.08850044959244284,\n",
       "  -1.0809266844834378,\n",
       "  -3.4484963865126788,\n",
       "  1.828621562065365,\n",
       "  0.85,\n",
       "  1.0620253317029877],\n",
       " [-0.355522201007318,\n",
       "  1.0,\n",
       "  1.6550777282723539,\n",
       "  -1.112603338051689,\n",
       "  0.7478866925692406,\n",
       "  -1.1500880364696722,\n",
       "  0.9,\n",
       "  -0.9309968037186355],\n",
       " [1.4697684806333808,\n",
       "  2.0,\n",
       "  1.4550223761085486,\n",
       "  -0.7672668825835522,\n",
       "  0.115996024357498,\n",
       "  -0.4269661433754632,\n",
       "  1.05,\n",
       "  0.4253308640424523],\n",
       " [-1.2444271074526208,\n",
       "  5.0,\n",
       "  -1.166856491978807,\n",
       "  1.508979902587897,\n",
       "  -0.30962290633182693,\n",
       "  -0.8715020916515456,\n",
       "  0.85,\n",
       "  1.0247021991301357],\n",
       " [1.288258191706713,\n",
       "  3.0,\n",
       "  -0.34511170814226305,\n",
       "  -0.9615284539948027,\n",
       "  -0.966820472452061,\n",
       "  0.8538511034390873,\n",
       "  0.95,\n",
       "  2.9702710417777793],\n",
       " [0.6887573156015332,\n",
       "  2.0,\n",
       "  0.803859587499659,\n",
       "  -0.20338146684895556,\n",
       "  -0.08657384399452193,\n",
       "  -0.7886986193171517,\n",
       "  1.05,\n",
       "  1.065273119988887],\n",
       " [1.8461014234890833,\n",
       "  0.0,\n",
       "  -1.070429114082906,\n",
       "  -0.9303167012579697,\n",
       "  0.600509675696255,\n",
       "  0.33122670388736075,\n",
       "  1.1,\n",
       "  0.9073702824492551],\n",
       " [-1.2145648064427437,\n",
       "  4.0,\n",
       "  -0.15430594270313752,\n",
       "  -0.32285066845702964,\n",
       "  -0.01578041012760808,\n",
       "  0.4401764989315718,\n",
       "  1.2,\n",
       "  0.20135282793051118],\n",
       " [-1.6456112722489178,\n",
       "  0.0,\n",
       "  0.7877204171972817,\n",
       "  1.253950454988673,\n",
       "  1.1402438799445218,\n",
       "  0.5218120964793754,\n",
       "  1.1,\n",
       "  -0.4002809787838321],\n",
       " [0.08765194498285726,\n",
       "  4.0,\n",
       "  -0.9728861557729195,\n",
       "  1.8141974307175466,\n",
       "  0.39066847479870837,\n",
       "  0.28260437709050706,\n",
       "  1.2,\n",
       "  3.0679881524491206],\n",
       " [1.2171058991477166,\n",
       "  3.0,\n",
       "  -1.5752706345800311,\n",
       "  1.4790350816461217,\n",
       "  1.0484655156750586,\n",
       "  -1.1797044454997183,\n",
       "  0.95,\n",
       "  -0.9153091584224583],\n",
       " [0.48937976973169267,\n",
       "  0.0,\n",
       "  -0.3410930901117329,\n",
       "  -0.030759983634503874,\n",
       "  0.668102814084173,\n",
       "  -1.4426527864363818,\n",
       "  1.1,\n",
       "  -1.2673236883123955],\n",
       " [1.3161758487252382,\n",
       "  5.0,\n",
       "  0.11912905418097837,\n",
       "  0.7639714883272379,\n",
       "  0.3486125254832045,\n",
       "  0.25683344792081314,\n",
       "  0.85,\n",
       "  0.1801553131231746],\n",
       " [0.5952871269293931,\n",
       "  1.0,\n",
       "  1.119675040928582,\n",
       "  1.0339089470213578,\n",
       "  0.8789744003402064,\n",
       "  -0.013446081367707717,\n",
       "  0.9,\n",
       "  0.6346304851750663],\n",
       " [-0.8005479176812835,\n",
       "  2.0,\n",
       "  -1.3174992744908047,\n",
       "  1.3482318833931017,\n",
       "  -2.913152529804415,\n",
       "  0.02272860604617634,\n",
       "  1.05,\n",
       "  -0.50632455038822],\n",
       " [0.38354325509164233,\n",
       "  4.0,\n",
       "  1.2806666954512793,\n",
       "  1.24412626867701,\n",
       "  -0.9848000353539885,\n",
       "  -0.2677577901867371,\n",
       "  1.2,\n",
       "  0.9526992284607987],\n",
       " [-0.7209882359224057,\n",
       "  4.0,\n",
       "  0.46402008162860936,\n",
       "  -1.0104301594862228,\n",
       "  -1.7321435430789822,\n",
       "  -1.5061524240706692,\n",
       "  1.2,\n",
       "  0.11606399084954448],\n",
       " [1.5684526449155454,\n",
       "  2.0,\n",
       "  0.4246011743882886,\n",
       "  1.3069517976245728,\n",
       "  -0.5803281869070969,\n",
       "  1.3936718717290573,\n",
       "  1.05,\n",
       "  0.35037172397966393],\n",
       " [0.10547191975646622,\n",
       "  3.0,\n",
       "  -0.7775328504947866,\n",
       "  1.6777077502050661,\n",
       "  0.7067235344129058,\n",
       "  1.0170898932484302,\n",
       "  0.95,\n",
       "  -0.07087552234102369],\n",
       " [0.2566905730385184,\n",
       "  1.0,\n",
       "  -0.09329026585561222,\n",
       "  -1.1906488322479896,\n",
       "  1.6588443563547262,\n",
       "  -1.706375638726095,\n",
       "  0.9,\n",
       "  -0.7112114816821953],\n",
       " [-1.2899548645127892,\n",
       "  2.0,\n",
       "  -0.5520826367430988,\n",
       "  -0.7635486274584306,\n",
       "  -0.35294654197692893,\n",
       "  -0.6537110265385532,\n",
       "  1.05,\n",
       "  -1.0361962514093197],\n",
       " [-1.8194242270595251,\n",
       "  2.0,\n",
       "  -0.8070053570765704,\n",
       "  -1.181003264994727,\n",
       "  -0.7819083349048386,\n",
       "  -0.12329618722617237,\n",
       "  1.05,\n",
       "  -1.0562403381832084],\n",
       " [-1.8626402701402596,\n",
       "  5.0,\n",
       "  -1.4415768684573564,\n",
       "  1.4837475821939436,\n",
       "  0.6989624298027711,\n",
       "  0.0050965408620906455,\n",
       "  0.85,\n",
       "  0.919254829532607],\n",
       " [-0.35487896884844533,\n",
       "  1.0,\n",
       "  -0.1506459382370075,\n",
       "  1.9467001628232063,\n",
       "  0.7936729229443484,\n",
       "  -0.48074186557094956,\n",
       "  0.9,\n",
       "  0.04051644922947785],\n",
       " [-0.1882505897497508,\n",
       "  5.0,\n",
       "  -0.6180171321833263,\n",
       "  0.5685080708973843,\n",
       "  -0.07756678767059476,\n",
       "  0.35758524173555806,\n",
       "  0.85,\n",
       "  2.647756458061722],\n",
       " [-0.2261696312352346,\n",
       "  0.0,\n",
       "  1.5320936576364588,\n",
       "  -0.997549233682583,\n",
       "  0.27703418945958175,\n",
       "  -0.33605646839871656,\n",
       "  1.1,\n",
       "  0.08767460654887059],\n",
       " [0.12964727496090192,\n",
       "  4.0,\n",
       "  -1.5780794969268854,\n",
       "  -1.1201852618356591,\n",
       "  0.5577103339522764,\n",
       "  0.3571953707764197,\n",
       "  1.2,\n",
       "  -0.2596216531050345],\n",
       " [-1.0115200552764525,\n",
       "  5.0,\n",
       "  1.3108744071049878,\n",
       "  0.39590180762677857,\n",
       "  -0.6211848218296251,\n",
       "  1.0715938022347629,\n",
       "  0.85,\n",
       "  0.36542251204614395],\n",
       " [-0.7363267627778853,\n",
       "  5.0,\n",
       "  -0.8756149283147883,\n",
       "  0.8747967691780203,\n",
       "  -1.5467148920200495,\n",
       "  -0.7566695666948192,\n",
       "  0.85,\n",
       "  -1.4824786042219225],\n",
       " [0.4139780449413503,\n",
       "  0.0,\n",
       "  1.083782341080272,\n",
       "  -0.22893846235886628,\n",
       "  -1.5336652929929984,\n",
       "  -0.6730113463322012,\n",
       "  1.1,\n",
       "  0.9511837468055516],\n",
       " [1.5413990414421364,\n",
       "  3.0,\n",
       "  1.1983105038035093,\n",
       "  -0.28440585324584866,\n",
       "  -0.4508919929137332,\n",
       "  -0.34300756334795024,\n",
       "  0.95,\n",
       "  -0.44910481414980763],\n",
       " [1.7143828671738177,\n",
       "  3.0,\n",
       "  0.2607631395894183,\n",
       "  -0.5326048472050644,\n",
       "  -0.5203948827051494,\n",
       "  -1.3734512206949219,\n",
       "  0.95,\n",
       "  -1.9092742790949617],\n",
       " [0.0710167145480761,\n",
       "  3.0,\n",
       "  -1.2371208119146297,\n",
       "  -1.0238774286263828,\n",
       "  0.10937466999922664,\n",
       "  0.653519339711207,\n",
       "  0.95,\n",
       "  0.749191080450561],\n",
       " [-1.0634756390426034,\n",
       "  3.0,\n",
       "  0.009545313763658459,\n",
       "  -0.025087418089701267,\n",
       "  -1.2621019151817268,\n",
       "  -0.9940133230804225,\n",
       "  0.95,\n",
       "  -1.8063874928152646],\n",
       " [1.5015033781608136,\n",
       "  4.0,\n",
       "  -1.1015945269501164,\n",
       "  -0.37215407113554544,\n",
       "  0.79183653399167,\n",
       "  -0.5801370326565455,\n",
       "  1.2,\n",
       "  -0.7154065598569942],\n",
       " [-0.3555215131952591,\n",
       "  0.0,\n",
       "  -0.578681655208171,\n",
       "  0.8283879023543576,\n",
       "  0.9570883225684875,\n",
       "  0.5438435000883312,\n",
       "  1.1,\n",
       "  0.1659291863679963],\n",
       " [0.14173704842029383,\n",
       "  1.0,\n",
       "  -0.20124229849280786,\n",
       "  0.9846845116160681,\n",
       "  0.9493691926803713,\n",
       "  0.17905118789214744,\n",
       "  0.9,\n",
       "  -0.1911877198072253],\n",
       " [-0.500358303538329,\n",
       "  4.0,\n",
       "  -1.2356923660809414,\n",
       "  -0.662573340196017,\n",
       "  0.899074139412263,\n",
       "  0.46300768191323644,\n",
       "  1.2,\n",
       "  -0.7432699200602684],\n",
       " [1.3392594946409495,\n",
       "  4.0,\n",
       "  1.233038560622011,\n",
       "  1.5525106247893365,\n",
       "  0.9157031903096466,\n",
       "  0.34035833623182304,\n",
       "  1.2,\n",
       "  0.16905810366243204],\n",
       " [1.3284223179505337,\n",
       "  3.0,\n",
       "  0.46922458383494137,\n",
       "  -1.3409908328499607,\n",
       "  0.3288966199438368,\n",
       "  0.6902706329074527,\n",
       "  0.95,\n",
       "  0.7523819387899742],\n",
       " [1.10946064723759,\n",
       "  5.0,\n",
       "  -0.33885725804573824,\n",
       "  -1.3136970066574203,\n",
       "  -0.14437632067723327,\n",
       "  -1.8189849580574309,\n",
       "  0.85,\n",
       "  0.9411137646292095],\n",
       " [-0.5812801398388016,\n",
       "  0.0,\n",
       "  0.2842696096108832,\n",
       "  -0.8106762504608186,\n",
       "  -0.36377846634177924,\n",
       "  -0.4156594208738551,\n",
       "  1.1,\n",
       "  0.7906599654524928],\n",
       " [1.4791247414148954,\n",
       "  5.0,\n",
       "  -1.5361157633871396,\n",
       "  1.7706287547223805,\n",
       "  1.4214002326166817,\n",
       "  -0.19625203042340364,\n",
       "  0.85,\n",
       "  -0.18497665338498565],\n",
       " [-1.1326783092966897,\n",
       "  1.0,\n",
       "  -0.8938596226695839,\n",
       "  0.09707749063580559,\n",
       "  0.47972062056220605,\n",
       "  0.7392077293626219,\n",
       "  0.9,\n",
       "  1.051070556561971],\n",
       " [-1.390206490176042,\n",
       "  5.0,\n",
       "  0.36822671381813304,\n",
       "  -0.7386036281046433,\n",
       "  0.5449364630441359,\n",
       "  0.8025075661680771,\n",
       "  0.85,\n",
       "  0.8166993188480235],\n",
       " [-1.1346634920842111,\n",
       "  3.0,\n",
       "  1.6221822725773578,\n",
       "  -0.5133324678479197,\n",
       "  1.474602165186571,\n",
       "  -1.2615258265168678,\n",
       "  0.95,\n",
       "  -0.24590115671606952],\n",
       " [-1.5937623589602283,\n",
       "  1.0,\n",
       "  -0.8972681415312792,\n",
       "  0.7336196971285418,\n",
       "  0.7426321302214982,\n",
       "  0.7440182854587742,\n",
       "  0.9,\n",
       "  -0.23086113759354446],\n",
       " [-0.5304272474248449,\n",
       "  4.0,\n",
       "  -1.564085802761505,\n",
       "  0.4677257729261542,\n",
       "  -0.5666565787641503,\n",
       "  -0.6006582779890463,\n",
       "  1.2,\n",
       "  0.7586191568713883],\n",
       " [-1.661436752225307,\n",
       "  1.0,\n",
       "  0.12052964056549337,\n",
       "  -1.2463850857039422,\n",
       "  0.8032294500217609,\n",
       "  0.3283493440070041,\n",
       "  0.9,\n",
       "  0.6901889628385806],\n",
       " [-0.7725684019246979,\n",
       "  3.0,\n",
       "  -1.4784877659658289,\n",
       "  -1.1511858955523326,\n",
       "  0.6755531681641888,\n",
       "  -0.05554039487713741,\n",
       "  0.95,\n",
       "  0.9585099167178424],\n",
       " [0.8648570894522686,\n",
       "  3.0,\n",
       "  0.12150992222585683,\n",
       "  0.5568351845590256,\n",
       "  0.9721468571305116,\n",
       "  0.5450559169303656,\n",
       "  0.95,\n",
       "  1.053617531202334],\n",
       " [-1.6786387080879426,\n",
       "  0.0,\n",
       "  0.245555844248321,\n",
       "  1.4631802774891325,\n",
       "  -0.4663188914398267,\n",
       "  1.5849615783870141,\n",
       "  1.1,\n",
       "  -1.1455921176867156],\n",
       " [1.6121399710708637,\n",
       "  1.0,\n",
       "  -0.7828381325608049,\n",
       "  -0.21326392436767025,\n",
       "  0.5180101430744667,\n",
       "  -1.595846258327777,\n",
       "  0.9,\n",
       "  -0.8188178501853611],\n",
       " [0.5355227467747423,\n",
       "  0.0,\n",
       "  0.49225871975418484,\n",
       "  1.9069810722218137,\n",
       "  0.27575513021197134,\n",
       "  -0.29855828816864716,\n",
       "  1.1,\n",
       "  0.32084257142985606],\n",
       " [-1.451661757504134,\n",
       "  2.0,\n",
       "  0.6296982981436953,\n",
       "  -1.3334198873759284,\n",
       "  0.9134309607888562,\n",
       "  0.34705639988495995,\n",
       "  1.05,\n",
       "  0.35781709981874715],\n",
       " [-0.8777057849082416,\n",
       "  3.0,\n",
       "  -1.4240138570029006,\n",
       "  0.8842688015129992,\n",
       "  0.9371165097518407,\n",
       "  0.11957103623130488,\n",
       "  0.95,\n",
       "  0.5767486741119536],\n",
       " [1.4673131991261807,\n",
       "  4.0,\n",
       "  -1.0885244180645575,\n",
       "  -0.2232616377329783,\n",
       "  -0.7340303058859808,\n",
       "  -1.5234673909016094,\n",
       "  1.2,\n",
       "  -1.4390749619693552],\n",
       " [-0.03300848787931069,\n",
       "  2.0,\n",
       "  -0.1338703792900949,\n",
       "  1.7988321468589812,\n",
       "  0.4762051922345618,\n",
       "  1.8519079052904606,\n",
       "  1.05,\n",
       "  0.41858669901271356],\n",
       " [-0.753794928340331,\n",
       "  5.0,\n",
       "  -1.368318184580977,\n",
       "  -0.8801876167654141,\n",
       "  0.4464237800979028,\n",
       "  -0.8740082809191703,\n",
       "  0.85,\n",
       "  -1.74914314916948],\n",
       " [-0.12069146814953322,\n",
       "  3.0,\n",
       "  1.5320796230367866,\n",
       "  0.9704787431817666,\n",
       "  -0.8149363776029271,\n",
       "  -0.8448867489939752,\n",
       "  0.95,\n",
       "  0.339241190349065],\n",
       " [-0.013347953845354052,\n",
       "  0.0,\n",
       "  -1.4764746159514892,\n",
       "  -0.8568446319062948,\n",
       "  0.4049714078035037,\n",
       "  0.14038078539300217,\n",
       "  1.1,\n",
       "  0.7615186067749349],\n",
       " [0.7345105420442284,\n",
       "  0.0,\n",
       "  -0.22869684147742222,\n",
       "  -0.3552487752194449,\n",
       "  0.9643545248191224,\n",
       "  -0.5951698907811165,\n",
       "  1.1,\n",
       "  0.7579255043209501],\n",
       " [-1.5922186985857185,\n",
       "  2.0,\n",
       "  0.6747073896211117,\n",
       "  0.6817488932119434,\n",
       "  0.8340351363718507,\n",
       "  -0.1378395420536604,\n",
       "  1.05,\n",
       "  1.0649514226227665],\n",
       " [-1.5529543485618296,\n",
       "  2.0,\n",
       "  1.0464710626428126,\n",
       "  0.08699178291776104,\n",
       "  1.5534045559472376,\n",
       "  0.04138823870164495,\n",
       "  1.05,\n",
       "  0.9830297081686129],\n",
       " [0.21623357303202556,\n",
       "  5.0,\n",
       "  -1.5467498270065048,\n",
       "  -1.4074774631864602,\n",
       "  -0.956311053029794,\n",
       "  -0.10970331647351768,\n",
       "  0.85,\n",
       "  1.0649730925333252],\n",
       " [-1.381460277781169,\n",
       "  5.0,\n",
       "  -0.6913365120150622,\n",
       "  -1.280271378886803,\n",
       "  -0.5056113088241795,\n",
       "  0.7762543005237328,\n",
       "  0.85,\n",
       "  0.5396891304099393],\n",
       " [-0.3527938163593429,\n",
       "  5.0,\n",
       "  0.08905875941937408,\n",
       "  -0.40916103724686026,\n",
       "  -0.4781268307005968,\n",
       "  0.12563622113762865,\n",
       "  0.85,\n",
       "  -1.673041926945979],\n",
       " [0.11377417365654524,\n",
       "  0.0,\n",
       "  -0.5201134335668137,\n",
       "  0.8510243873632718,\n",
       "  -0.7006902022510453,\n",
       "  1.6489798772314268,\n",
       "  1.1,\n",
       "  1.0085778400052032],\n",
       " [-0.7192003252013515,\n",
       "  3.0,\n",
       "  0.20983325025068678,\n",
       "  0.41334800015202566,\n",
       "  -0.9409660556330923,\n",
       "  -0.8399750753726152,\n",
       "  0.95,\n",
       "  1.9275492039871431],\n",
       " [-1.6568969078719538,\n",
       "  5.0,\n",
       "  0.8492799043553716,\n",
       "  0.16180284728552025,\n",
       "  0.47386709456165294,\n",
       "  0.7765913446566555,\n",
       "  0.85,\n",
       "  0.12900904306730696],\n",
       " [0.9973077511887692,\n",
       "  1.0,\n",
       "  -1.01540277092306,\n",
       "  -1.2677599191240077,\n",
       "  -0.4839887957334219,\n",
       "  -1.666118688700228,\n",
       "  0.9,\n",
       "  -0.46390642108512814],\n",
       " [0.4642920895437803,\n",
       "  2.0,\n",
       "  -1.245054995324391,\n",
       "  -0.010573607718954697,\n",
       "  -2.4579203707950006,\n",
       "  0.707178996566709,\n",
       "  1.05,\n",
       "  0.9807911700464371],\n",
       " [-1.1527664688511203,\n",
       "  0.0,\n",
       "  0.09193814318995043,\n",
       "  -1.000716428240112,\n",
       "  -1.2849052962355771,\n",
       "  0.44109845454515956,\n",
       "  1.1,\n",
       "  -0.9246842816556287],\n",
       " [-1.3501455423143862,\n",
       "  1.0,\n",
       "  -0.9021661063541598,\n",
       "  -1.1542464500928251,\n",
       "  -0.8830461388848455,\n",
       "  1.1903953184504217,\n",
       "  0.9,\n",
       "  -1.526524859970341],\n",
       " [-0.5729515011019393,\n",
       "  3.0,\n",
       "  0.9204773429862463,\n",
       "  0.6612321871716523,\n",
       "  0.9446041714107468,\n",
       "  1.554124999026559,\n",
       "  0.95,\n",
       "  -0.041501927305129735],\n",
       " [1.1241730681507611,\n",
       "  3.0,\n",
       "  -1.2526317260127435,\n",
       "  -0.7929907954891691,\n",
       "  -2.250841965230183,\n",
       "  1.7673129135229126,\n",
       "  0.95,\n",
       "  -0.573242541638822],\n",
       " [0.5422486208253611,\n",
       "  5.0,\n",
       "  1.2205006876183349,\n",
       "  0.6503537555992347,\n",
       "  -0.11297630315747755,\n",
       "  -1.541544655735228,\n",
       "  0.85,\n",
       "  -0.43625320099173037],\n",
       " [1.2966906473104944,\n",
       "  3.0,\n",
       "  1.0438693054296746,\n",
       "  1.6344224820582642,\n",
       "  0.7483588115744096,\n",
       "  -0.641244448573746,\n",
       "  0.95,\n",
       "  0.6414804289893088],\n",
       " [-1.7783068267689133,\n",
       "  3.0,\n",
       "  -1.4507106450417797,\n",
       "  -1.2483421035664266,\n",
       "  -3.5268307208591154,\n",
       "  0.7538221183090044,\n",
       "  0.95,\n",
       "  2.074709031286382],\n",
       " [-0.37948667790825025,\n",
       "  4.0,\n",
       "  -0.8665878669759524,\n",
       "  -0.3322241429908154,\n",
       "  -0.7000017154838388,\n",
       "  -0.04154456526518273,\n",
       "  1.2,\n",
       "  1.0098481170108056],\n",
       " [0.46637062082622116,\n",
       "  1.0,\n",
       "  1.602958681046973,\n",
       "  0.007708311086615404,\n",
       "  0.8264429331140153,\n",
       "  0.20800011459260193,\n",
       "  0.9,\n",
       "  -1.6523994405726186],\n",
       " [0.2415385803362134,\n",
       "  5.0,\n",
       "  0.2512797495586952,\n",
       "  0.4805226393475079,\n",
       "  0.7499020918186937,\n",
       "  0.21424626125608,\n",
       "  0.85,\n",
       "  -1.9058483647931714],\n",
       " [0.8214170188412234,\n",
       "  1.0,\n",
       "  0.7631301407193579,\n",
       "  -0.8034057029768795,\n",
       "  1.5592183405758573,\n",
       "  1.6140611954183541,\n",
       "  0.9,\n",
       "  0.4147619957385663],\n",
       " [0.6768171022293653,\n",
       "  0.0,\n",
       "  0.5071418342984907,\n",
       "  -0.40302965343097047,\n",
       "  0.2773872878675214,\n",
       "  -0.35911578225447927,\n",
       "  1.1,\n",
       "  -0.12479460158385806],\n",
       " [0.721375192167117,\n",
       "  5.0,\n",
       "  -1.483585247751618,\n",
       "  -0.826416199312224,\n",
       "  0.5993125445185924,\n",
       "  -0.40003561170632934,\n",
       "  0.85,\n",
       "  0.4942341034510091],\n",
       " [-1.5179319255639923,\n",
       "  5.0,\n",
       "  -1.1740511198747756,\n",
       "  -0.545302683652948,\n",
       "  0.0763107761821011,\n",
       "  -0.4946398322112688,\n",
       "  0.85,\n",
       "  1.0604112858476011],\n",
       " [1.3130591550856223,\n",
       "  5.0,\n",
       "  0.2843889415564101,\n",
       "  -0.9767946595937513,\n",
       "  -0.3679137799650682,\n",
       "  0.12409659486953437,\n",
       "  0.85,\n",
       "  -0.11916917810629105],\n",
       " [-0.8717137951920338,\n",
       "  5.0,\n",
       "  -0.20439251128125432,\n",
       "  0.8549132473682771,\n",
       "  0.043461450947372665,\n",
       "  -0.5386433258984114,\n",
       "  0.85,\n",
       "  -0.2744330840085982],\n",
       " [0.9802554804772113,\n",
       "  5.0,\n",
       "  0.45740170238575134,\n",
       "  1.802073170418188,\n",
       "  0.8273635756550737,\n",
       "  0.32171134560738096,\n",
       "  0.85,\n",
       "  -0.15000823874593402],\n",
       " [0.5607199206047688,\n",
       "  5.0,\n",
       "  -1.582474870067698,\n",
       "  0.880363360268123,\n",
       "  0.9270836017556907,\n",
       "  -0.49675089932669875,\n",
       "  0.85,\n",
       "  1.065427692134635],\n",
       " [0.3078454255999122,\n",
       "  5.0,\n",
       "  1.6494962690785822,\n",
       "  -1.4011986275218435,\n",
       "  0.6511112260447984,\n",
       "  -0.29121688319450634,\n",
       "  0.85,\n",
       "  -0.6463953282577706],\n",
       " [1.5774269435842425,\n",
       "  0.0,\n",
       "  1.2474173471729009,\n",
       "  1.5315708113563886,\n",
       "  0.8943650548819064,\n",
       "  1.0958545212519073,\n",
       "  1.1,\n",
       "  -0.7902339287583904],\n",
       " [-0.26737975706059536,\n",
       "  1.0,\n",
       "  -1.4032817024831032,\n",
       "  -0.5504829097374065,\n",
       "  -0.1425763128042043,\n",
       "  -0.5400761235834122,\n",
       "  0.9,\n",
       "  0.8970304544932424],\n",
       " [1.6781222876649977,\n",
       "  3.0,\n",
       "  1.6216370347414741,\n",
       "  -0.9568057761045778,\n",
       "  -0.3946599796175776,\n",
       "  0.39002337678886084,\n",
       "  0.95,\n",
       "  1.0618471285744944],\n",
       " [-1.5519898733850406,\n",
       "  4.0,\n",
       "  -1.0157513023873412,\n",
       "  -1.1354841464664214,\n",
       "  -0.9413906954031139,\n",
       "  -1.7790885219958719,\n",
       "  1.2,\n",
       "  0.3927222938347827],\n",
       " [-1.1182904167337506,\n",
       "  1.0,\n",
       "  -0.5559554673384421,\n",
       "  -0.6226002974920433,\n",
       "  0.060370756496633024,\n",
       "  -0.8785547736905558,\n",
       "  0.9,\n",
       "  -0.4579029028979633],\n",
       " [0.47623194801297175,\n",
       "  4.0,\n",
       "  0.18327370146605773,\n",
       "  -0.20676707122927307,\n",
       "  -0.6226741893967273,\n",
       "  -1.3729065417115849,\n",
       "  1.2,\n",
       "  0.27282598016790716],\n",
       " [-0.8140268779507018,\n",
       "  2.0,\n",
       "  -0.6786396596004499,\n",
       "  -1.3299584901325927,\n",
       "  -0.7978315942186496,\n",
       "  -0.9244001292991637,\n",
       "  1.05,\n",
       "  -2.0062422908817266],\n",
       " [0.30096245537348276,\n",
       "  1.0,\n",
       "  0.24539881871498587,\n",
       "  -0.33216411706724547,\n",
       "  -1.9552874370118725,\n",
       "  0.08176315118128719,\n",
       "  0.9,\n",
       "  1.0636987374158557],\n",
       " [-0.995792165299489,\n",
       "  1.0,\n",
       "  0.5507079648324326,\n",
       "  1.018287782741898,\n",
       "  0.7806323249174859,\n",
       "  -0.940194435612089,\n",
       "  0.9,\n",
       "  0.22170740990224913],\n",
       " [0.4228296610229081,\n",
       "  5.0,\n",
       "  -1.3845782244035285,\n",
       "  -1.2766276630616624,\n",
       "  0.3874454008568857,\n",
       "  -1.6025453390292435,\n",
       "  0.85,\n",
       "  0.32041807916949094],\n",
       " [0.3414942683245127,\n",
       "  4.0,\n",
       "  0.5031385174273698,\n",
       "  -0.4232307013952863,\n",
       "  1.4848035820750818,\n",
       "  -0.6158316023587793,\n",
       "  1.2,\n",
       "  0.7266004330062148],\n",
       " [1.2789771557345095,\n",
       "  0.0,\n",
       "  -0.24245936856700123,\n",
       "  0.3023726272945504,\n",
       "  -0.268554735687469,\n",
       "  1.8701401434673277,\n",
       "  1.1,\n",
       "  -1.534075765804989],\n",
       " [1.1241637235213515,\n",
       "  4.0,\n",
       "  1.4916681086191603,\n",
       "  1.2626389837193226,\n",
       "  0.8107007574900807,\n",
       "  -0.3660671742727878,\n",
       "  1.2,\n",
       "  0.8853916861578713],\n",
       " [0.164922793160567,\n",
       "  4.0,\n",
       "  -0.12013818491479544,\n",
       "  -0.2978916935582627,\n",
       "  -0.1732999165840801,\n",
       "  -0.26331370215150174,\n",
       "  1.2,\n",
       "  -0.5338712975276848],\n",
       " [-0.2877310626005902,\n",
       "  5.0,\n",
       "  -0.9102541505857046,\n",
       "  -0.4534698009725742,\n",
       "  0.04899856634822024,\n",
       "  1.6346894511827208,\n",
       "  0.85,\n",
       "  1.065402864195864],\n",
       " [1.451262540462353,\n",
       "  4.0,\n",
       "  -0.3302276304088614,\n",
       "  -0.6511118665528635,\n",
       "  -0.8713348651361253,\n",
       "  -1.830936568242973,\n",
       "  1.2,\n",
       "  0.7356063228068197],\n",
       " [0.45180638645835003,\n",
       "  2.0,\n",
       "  0.7538132910184299,\n",
       "  -0.6854861596352617,\n",
       "  0.26029554895080415,\n",
       "  0.7684304841779678,\n",
       "  1.05,\n",
       "  -0.497177802810553],\n",
       " [0.09556216970192281,\n",
       "  1.0,\n",
       "  1.560568386391142,\n",
       "  -1.0394404586556882,\n",
       "  0.9491215338073499,\n",
       "  0.42056959446944087,\n",
       "  0.9,\n",
       "  1.0574036711764663],\n",
       " [-0.26100848648199987,\n",
       "  3.0,\n",
       "  -0.7146591050134453,\n",
       "  1.1125935437600014,\n",
       "  1.2914083423945706,\n",
       "  -1.2703939254636338,\n",
       "  0.95,\n",
       "  1.0172115204574834],\n",
       " [-0.9801520028299322,\n",
       "  3.0,\n",
       "  1.6531803810514196,\n",
       "  -1.1608157076146204,\n",
       "  -1.2401933955902447,\n",
       "  -0.049384077110991915,\n",
       "  0.95,\n",
       "  0.5194298243234278],\n",
       " [-1.316623140473835,\n",
       "  5.0,\n",
       "  -1.0753304478653978,\n",
       "  -0.10523528426648526,\n",
       "  0.20253145546835669,\n",
       "  0.32944474326965667,\n",
       "  0.85,\n",
       "  1.0210402993226233],\n",
       " [0.692759715023778,\n",
       "  3.0,\n",
       "  0.9771055458206404,\n",
       "  -1.1321547014983304,\n",
       "  -1.0257439072695829,\n",
       "  0.06568676718325282,\n",
       "  0.95,\n",
       "  1.0109162954691722],\n",
       " [-0.756183645776423,\n",
       "  0.0,\n",
       "  0.8412106324235803,\n",
       "  -0.8556471886839204,\n",
       "  0.346150277294095,\n",
       "  -0.07347735069327815,\n",
       "  1.1,\n",
       "  0.12738044874851745],\n",
       " [0.5805222022505248,\n",
       "  1.0,\n",
       "  -0.2822668518086302,\n",
       "  -1.4132214603140636,\n",
       "  -3.3330967722763623,\n",
       "  0.681924369587316,\n",
       "  0.9,\n",
       "  0.9033871191265898],\n",
       " [0.40988983117210825,\n",
       "  1.0,\n",
       "  0.38943192972998597,\n",
       "  0.2138406342013434,\n",
       "  -1.7113350536623235,\n",
       "  -1.5290089082874234,\n",
       "  0.9,\n",
       "  0.6246218500911603],\n",
       " [0.7046835566623697,\n",
       "  5.0,\n",
       "  -0.5672238840514976,\n",
       "  1.8526127439683808,\n",
       "  0.9271601820912526,\n",
       "  0.05060264140499433,\n",
       "  0.85,\n",
       "  0.6234023958556568],\n",
       " [0.18914351585333464,\n",
       "  0.0,\n",
       "  1.6847157860472426,\n",
       "  1.561048672999431,\n",
       "  1.3965759760723693,\n",
       "  -0.5778276442302733,\n",
       "  1.1,\n",
       "  1.0648164755347422],\n",
       " [-1.0333336299627924,\n",
       "  3.0,\n",
       "  -1.6174481034780424,\n",
       "  1.124979020985157,\n",
       "  0.40495774513236,\n",
       "  -0.9320586890606505,\n",
       "  0.95,\n",
       "  0.6493420288649134],\n",
       " [0.07573554189435285,\n",
       "  1.0,\n",
       "  -0.1347907953468817,\n",
       "  -1.1290495106945024,\n",
       "  0.8379346337844674,\n",
       "  -1.0005157619878475,\n",
       "  0.9,\n",
       "  -0.0010579594941371503],\n",
       " [-0.9960702646093754,\n",
       "  1.0,\n",
       "  -1.6522445911397305,\n",
       "  -1.0001031534617348,\n",
       "  -0.9366161607785832,\n",
       "  -1.6343471969369354,\n",
       "  0.9,\n",
       "  -1.4946905474597136],\n",
       " [-0.2771984464923906,\n",
       "  5.0,\n",
       "  -1.4893591580989065,\n",
       "  -1.3685462024280055,\n",
       "  -2.6659451458279264,\n",
       "  0.2999281349224248,\n",
       "  0.85,\n",
       "  -0.9727965776948996],\n",
       " [1.6877529298975658,\n",
       "  0.0,\n",
       "  0.4907843832073008,\n",
       "  0.056247239016234594,\n",
       "  0.2998816566750947,\n",
       "  -1.874407126369892,\n",
       "  1.1,\n",
       "  1.0215311230079285],\n",
       " [-1.675423035912241,\n",
       "  1.0,\n",
       "  -1.5092964837596827,\n",
       "  -0.5724712984116496,\n",
       "  0.4656983045407967,\n",
       "  0.381181466069629,\n",
       "  0.9,\n",
       "  -0.5642096245573457],\n",
       " [-0.07034418642418916,\n",
       "  3.0,\n",
       "  0.7338979889747441,\n",
       "  -1.3740144244967454,\n",
       "  1.6580802237112378,\n",
       "  0.8347694464881762,\n",
       "  0.95,\n",
       "  1.0535212848437165],\n",
       " [-0.8284729005616184,\n",
       "  1.0,\n",
       "  -1.3643012084187507,\n",
       "  -0.42495199533475425,\n",
       "  0.2774001334241944,\n",
       "  1.9481439446813817,\n",
       "  0.9,\n",
       "  0.9724156461500427],\n",
       " [-0.7202551581243531,\n",
       "  0.0,\n",
       "  0.09335420742225925,\n",
       "  -1.2997505240538014,\n",
       "  -2.2282768420949584,\n",
       "  -1.0937433574502327,\n",
       "  1.1,\n",
       "  1.0085467505567454],\n",
       " [1.2996998237003146,\n",
       "  1.0,\n",
       "  1.6459322577480595,\n",
       "  -1.3535949981259896,\n",
       "  0.6371298902923214,\n",
       "  0.9189468465974469,\n",
       "  0.9,\n",
       "  -1.381563452466367],\n",
       " [1.3665756342620692,\n",
       "  5.0,\n",
       "  1.050160623530801,\n",
       "  -0.1929177254509172,\n",
       "  0.9653072381591411,\n",
       "  0.10369171753846944,\n",
       "  0.85,\n",
       "  -1.034261691329387],\n",
       " [1.7768835813527146,\n",
       "  4.0,\n",
       "  0.6283566151772041,\n",
       "  1.822483657425896,\n",
       "  -0.2200532676821743,\n",
       "  -0.7546637279664622,\n",
       "  1.2,\n",
       "  0.7767307821759234],\n",
       " [-0.7766591277566854,\n",
       "  5.0,\n",
       "  0.6428259708120059,\n",
       "  0.18724485096365082,\n",
       "  -0.9237695842793092,\n",
       "  0.675616016987848,\n",
       "  0.85,\n",
       "  1.053614503323984],\n",
       " [0.4588122877932721,\n",
       "  2.0,\n",
       "  -0.08091426981353297,\n",
       "  0.8247139410700319,\n",
       "  1.6858169463964512,\n",
       "  1.8042971905777014,\n",
       "  1.05,\n",
       "  -0.7166286001188723],\n",
       " [0.013916271356078916,\n",
       "  4.0,\n",
       "  -1.464420465689552,\n",
       "  -1.3149474731230353,\n",
       "  -3.329355574339323,\n",
       "  1.7004100013422907,\n",
       "  1.2,\n",
       "  1.1364221669287058],\n",
       " [0.1828526278983533,\n",
       "  0.0,\n",
       "  -1.5534412138845861,\n",
       "  -1.31118274835753,\n",
       "  -0.4766287293664133,\n",
       "  0.42393370669296565,\n",
       "  1.1,\n",
       "  -1.0921751381515241],\n",
       " [-1.0068396343548642,\n",
       "  5.0,\n",
       "  -0.04985175101561459,\n",
       "  1.0151976700461416,\n",
       "  0.2498941689790239,\n",
       "  1.4690465524262843,\n",
       "  0.85,\n",
       "  -1.2496365762190702],\n",
       " [-0.6315619826256887,\n",
       "  4.0,\n",
       "  0.014642551221855945,\n",
       "  1.9072714584317425,\n",
       "  1.825813837889311,\n",
       "  1.8305964488809987,\n",
       "  1.2,\n",
       "  0.06987088547679553],\n",
       " [1.2711973449829732,\n",
       "  3.0,\n",
       "  -1.455093478593757,\n",
       "  1.4225930271737735,\n",
       "  0.3625680543094127,\n",
       "  -0.28714498273947503,\n",
       "  0.95,\n",
       "  0.9886270290735487],\n",
       " [-0.33799945730078934,\n",
       "  0.0,\n",
       "  -0.7468008004429373,\n",
       "  0.9869985665580419,\n",
       "  0.25241182091168846,\n",
       "  1.6868605130862644,\n",
       "  1.1,\n",
       "  0.9008111085070816],\n",
       " [-0.5989027442887035,\n",
       "  3.0,\n",
       "  1.6705779685858948,\n",
       "  0.9787477271980934,\n",
       "  0.02476686753432395,\n",
       "  1.5463186237711402,\n",
       "  0.95,\n",
       "  -1.7791516370911784],\n",
       " [-0.5448681663421728,\n",
       "  4.0,\n",
       "  -0.21531559034483574,\n",
       "  1.205775905111611,\n",
       "  -2.2810154275583123,\n",
       "  -0.8168295066619101,\n",
       "  1.2,\n",
       "  0.12536110004453724],\n",
       " [1.1273054468340677,\n",
       "  1.0,\n",
       "  0.46761936291816,\n",
       "  -1.1607180467840341,\n",
       "  0.3005527930326758,\n",
       "  -0.04378604164270885,\n",
       "  0.9,\n",
       "  1.0265367028244894],\n",
       " [-0.00012628617585409152,\n",
       "  5.0,\n",
       "  0.18346853107557937,\n",
       "  0.5043843554682172,\n",
       "  0.9465975277007914,\n",
       "  0.024078603468672,\n",
       "  0.85,\n",
       "  0.3738187969295063],\n",
       " [-0.40908234273336486,\n",
       "  4.0,\n",
       "  -1.6070373818101926,\n",
       "  -1.1150272498226492,\n",
       "  -0.9048707469746233,\n",
       "  -0.995088940862832,\n",
       "  1.2,\n",
       "  0.25675736143648187],\n",
       " [0.2440132568239527,\n",
       "  1.0,\n",
       "  -1.6364904887863179,\n",
       "  -0.7567394977022931,\n",
       "  0.9491344243745913,\n",
       "  0.8387572574281885,\n",
       "  0.9,\n",
       "  -0.6286280360245244],\n",
       " [0.9140478030675244,\n",
       "  1.0,\n",
       "  0.4693493394176882,\n",
       "  -0.2005853470492429,\n",
       "  -2.002799036494611,\n",
       "  1.1968938881807214,\n",
       "  0.9,\n",
       "  -1.0345727366081812],\n",
       " [-0.6522892612452279,\n",
       "  1.0,\n",
       "  0.9197141635728014,\n",
       "  -0.6525617178262805,\n",
       "  -3.085486125373496,\n",
       "  -0.1343307767777792,\n",
       "  0.9,\n",
       "  0.7826240423037568],\n",
       " [0.7060453809724421,\n",
       "  5.0,\n",
       "  1.7361617272769871,\n",
       "  0.9332287505189684,\n",
       "  0.10753061470318753,\n",
       "  -0.39986094672749345,\n",
       "  0.85,\n",
       "  1.0401735653906992],\n",
       " [1.4286585338356066,\n",
       "  5.0,\n",
       "  -0.47536799499898036,\n",
       "  0.8776780283579183,\n",
       "  0.880136960306316,\n",
       "  1.3141572393464833,\n",
       "  0.85,\n",
       "  -0.8684042797716298],\n",
       " [-0.3870665270030454,\n",
       "  5.0,\n",
       "  0.6154410351228449,\n",
       "  -1.3695830793140107,\n",
       "  0.3201674508342306,\n",
       "  1.3223966204783277,\n",
       "  0.85,\n",
       "  -0.7563170390099956],\n",
       " [0.718855959522297,\n",
       "  1.0,\n",
       "  -0.9960686928039045,\n",
       "  -0.7096344234165995,\n",
       "  0.8093217001040169,\n",
       "  -1.4376473685859876,\n",
       "  0.9,\n",
       "  -0.4493695718740605],\n",
       " [-0.47505067449741983,\n",
       "  0.0,\n",
       "  -1.6678484096885393,\n",
       "  1.2604476908618514,\n",
       "  -1.1380225346797406,\n",
       "  1.0855170090459998,\n",
       "  1.1,\n",
       "  -0.8459603100657511],\n",
       " [0.06885447100793814,\n",
       "  0.0,\n",
       "  -0.9330441478756613,\n",
       "  1.3278009908727308,\n",
       "  -0.5148300283280085,\n",
       "  -1.1273987766760476,\n",
       "  1.1,\n",
       "  1.1095543503171788],\n",
       " [-1.417837789843411,\n",
       "  0.0,\n",
       "  0.5176348706403792,\n",
       "  1.8682281389177684,\n",
       "  0.8384264828043124,\n",
       "  -1.4721016047237852,\n",
       "  1.1,\n",
       "  -1.8079114454591159],\n",
       " [0.04771958643443899,\n",
       "  5.0,\n",
       "  -0.021416171020703957,\n",
       "  1.0988687651413356,\n",
       "  0.07595641410316947,\n",
       "  -1.8835514408848404,\n",
       "  0.85,\n",
       "  -1.5571153924657282],\n",
       " [0.38874484254273106,\n",
       "  5.0,\n",
       "  0.42038046927634176,\n",
       "  1.2492565341433317,\n",
       "  0.26889980103543637,\n",
       "  1.221154142612018,\n",
       "  0.85,\n",
       "  -1.583694427830401],\n",
       " [1.2351677552412346,\n",
       "  1.0,\n",
       "  0.9559304644507424,\n",
       "  0.5080731280811022,\n",
       "  0.21025601940222102,\n",
       "  1.03651798891166,\n",
       "  0.9,\n",
       "  -1.5510244456032682],\n",
       " [1.4749957528810083,\n",
       "  0.0,\n",
       "  1.3082421577604755,\n",
       "  -0.7374556755337881,\n",
       "  0.11268689254247284,\n",
       "  -0.06596776778291719,\n",
       "  1.1,\n",
       "  -0.5981703749978153],\n",
       " [-0.8514819145899906,\n",
       "  3.0,\n",
       "  -0.08213451900009927,\n",
       "  -1.3899415692707713,\n",
       "  0.8934537698395383,\n",
       "  -0.9093392076952899,\n",
       "  0.95,\n",
       "  -1.279540864238473],\n",
       " [0.21234095902281577,\n",
       "  3.0,\n",
       "  1.7168550720907676,\n",
       "  0.6108019598770424,\n",
       "  -0.54869820830541,\n",
       "  -1.147708221657159,\n",
       "  0.95,\n",
       "  -0.2380673885395923],\n",
       " [-1.0008741728905082,\n",
       "  4.0,\n",
       "  -1.6391106053758027,\n",
       "  -1.2143992638564605,\n",
       "  0.30835574535360816,\n",
       "  -0.334744685456214,\n",
       "  1.2,\n",
       "  0.4479846037937974],\n",
       " [-0.2652762470100519,\n",
       "  3.0,\n",
       "  0.9206937161866628,\n",
       "  0.6517139903099555,\n",
       "  -0.019728741653996996,\n",
       "  0.6646216690419602,\n",
       "  0.95,\n",
       "  -0.9818653098678062],\n",
       " [-0.19994713230733824,\n",
       "  2.0,\n",
       "  -1.2364588333082738,\n",
       "  -0.9879932445244008,\n",
       "  -1.8397886388375173,\n",
       "  0.389014269948822,\n",
       "  1.05,\n",
       "  0.9077000003519673],\n",
       " [-0.4063615182309117,\n",
       "  3.0,\n",
       "  -0.45408639877662593,\n",
       "  0.9248342535678257,\n",
       "  0.6170535564341753,\n",
       "  0.23119804289225104,\n",
       "  0.95,\n",
       "  -0.3945739093578271],\n",
       " [1.3510931867573213,\n",
       "  2.0,\n",
       "  -0.19055042828626215,\n",
       "  1.5035954837664671,\n",
       "  0.9548716993925834,\n",
       "  -1.9191557028191362,\n",
       "  1.05,\n",
       "  -0.5973359480848731],\n",
       " [1.3743417307314632,\n",
       "  1.0,\n",
       "  0.029852209117872133,\n",
       "  -0.7065910415880017,\n",
       "  0.8196303374452913,\n",
       "  1.7969958562548733,\n",
       "  0.9,\n",
       "  1.0596623910202176],\n",
       " [0.7672586927900235,\n",
       "  1.0,\n",
       "  -0.05830773045797949,\n",
       "  0.9996933555328252,\n",
       "  -0.7750435956798859,\n",
       "  0.8676930956286503,\n",
       "  0.9,\n",
       "  1.065062106106921],\n",
       " [1.3486472179544324,\n",
       "  2.0,\n",
       "  -0.38525233104398837,\n",
       "  -0.31049783563862526,\n",
       "  0.907798339561859,\n",
       "  -1.3290337835175117,\n",
       "  1.05,\n",
       "  -0.7913951242930947],\n",
       " [-0.3149827230034034,\n",
       "  2.0,\n",
       "  -1.2933032644203213,\n",
       "  0.32949982563569596,\n",
       "  0.5342102187194355,\n",
       "  -0.051915717951260314,\n",
       "  1.05,\n",
       "  -0.2686270624176767],\n",
       " [-0.18051693060065593,\n",
       "  5.0,\n",
       "  0.4598791743239848,\n",
       "  -1.2899837146423845,\n",
       "  -0.8934511560556078,\n",
       "  -0.06432686558306333,\n",
       "  0.85,\n",
       "  -1.5501254124575248],\n",
       " [1.2947005957595048,\n",
       "  5.0,\n",
       "  0.4525774033505136,\n",
       "  0.8231413727537802,\n",
       "  0.4058092248996654,\n",
       "  -0.4789651702868821,\n",
       "  0.85,\n",
       "  -1.3464568032841313],\n",
       " [-1.442973210398186,\n",
       "  3.0,\n",
       "  0.23574358906637258,\n",
       "  1.3106570851266364,\n",
       "  0.6069234394549846,\n",
       "  0.5327340208666141,\n",
       "  0.95,\n",
       "  -1.6209915538196444],\n",
       " [-0.8205439621069418,\n",
       "  5.0,\n",
       "  -1.3192591707168726,\n",
       "  0.06552985554237929,\n",
       "  0.633282130651707,\n",
       "  1.7119236047940904,\n",
       "  0.85,\n",
       "  0.8894764518847403],\n",
       " [-0.18172791537391464,\n",
       "  0.0,\n",
       "  -1.1428854348066884,\n",
       "  0.7508123282302199,\n",
       "  0.8152891588726933,\n",
       "  -0.35562377058310113,\n",
       "  1.1,\n",
       "  -0.6293794890033212],\n",
       " [-0.4804945557576987,\n",
       "  0.0,\n",
       "  -1.623216056240717,\n",
       "  -0.6180646418608864,\n",
       "  0.7237768054915558,\n",
       "  -0.037005965002659506,\n",
       "  1.1,\n",
       "  -1.7780715093779778],\n",
       " [-1.0852727366833554,\n",
       "  0.0,\n",
       "  0.5395655387005994,\n",
       "  -0.2680178897580276,\n",
       "  0.17451511701373107,\n",
       "  -0.45247614853497214,\n",
       "  1.1,\n",
       "  0.5360827978775323],\n",
       " [1.401591454797394,\n",
       "  1.0,\n",
       "  -0.19905918685543333,\n",
       "  -0.9657896239730676,\n",
       "  0.7935610246467525,\n",
       "  -1.0416172026453536,\n",
       "  0.9,\n",
       "  0.7063621278021447],\n",
       " [-1.3218623818156876,\n",
       "  5.0,\n",
       "  -1.0337952996319524,\n",
       "  -1.109177659874018,\n",
       "  -0.9784191116029685,\n",
       "  0.3511332039940034,\n",
       "  0.85,\n",
       "  0.08240696047436522],\n",
       " [1.4250223201310355,\n",
       "  5.0,\n",
       "  1.7634015129753882,\n",
       "  -0.8058150365084286,\n",
       "  0.581273831966611,\n",
       "  -0.3361129221664433,\n",
       "  0.85,\n",
       "  -1.5583075063430027],\n",
       " [0.7909912616349574,\n",
       "  4.0,\n",
       "  -0.7476682051119355,\n",
       "  -0.7258995290343845,\n",
       "  -0.4695738734715138,\n",
       "  -1.096912142617055,\n",
       "  1.2,\n",
       "  -0.3748718123898757],\n",
       " [-1.5242385170756687,\n",
       "  4.0,\n",
       "  0.3604018672714644,\n",
       "  0.3086495671948567,\n",
       "  0.44836548951592925,\n",
       "  1.1814886552534254,\n",
       "  1.2,\n",
       "  0.8947519908912505],\n",
       " [1.2066059190412217,\n",
       "  3.0,\n",
       "  -1.3992737374565771,\n",
       "  -1.380492380178109,\n",
       "  -0.17252528697849248,\n",
       "  0.15109203292159273,\n",
       "  0.95,\n",
       "  0.6091937724022691],\n",
       " [-0.04264687592894416,\n",
       "  4.0,\n",
       "  0.7865245546640607,\n",
       "  0.932064882137186,\n",
       "  -0.4182478071415802,\n",
       "  -0.7279918220809398,\n",
       "  1.2,\n",
       "  -0.389609321447496],\n",
       " [-1.0068564954885633,\n",
       "  4.0,\n",
       "  -1.6146093842606921,\n",
       "  0.7119983235072754,\n",
       "  -1.6265145603022162,\n",
       "  0.033152398147513196,\n",
       "  1.2,\n",
       "  0.24456451406952137],\n",
       " [0.6433559453710957,\n",
       "  2.0,\n",
       "  0.9649277309563808,\n",
       "  -0.6601687979247243,\n",
       "  0.9344259827199819,\n",
       "  0.2868221387117728,\n",
       "  1.05,\n",
       "  0.41536600332727863],\n",
       " [1.2920599913023447,\n",
       "  3.0,\n",
       "  -1.6033516251649733,\n",
       "  -1.017758517641819,\n",
       "  0.7326216399634128,\n",
       "  -1.2685811693134708,\n",
       "  0.95,\n",
       "  -0.005124842608652109],\n",
       " [-0.5728839460283546,\n",
       "  0.0,\n",
       "  1.2855978368299368,\n",
       "  -1.0338409126396442,\n",
       "  0.583098568078121,\n",
       "  -1.6106073555865814,\n",
       "  1.1,\n",
       "  0.29940623438507163],\n",
       " [1.276776558750571,\n",
       "  1.0,\n",
       "  -0.04044328804038569,\n",
       "  0.35221529734730883,\n",
       "  -1.4556526717636589,\n",
       "  -0.3636976938122236,\n",
       "  0.9,\n",
       "  -0.726952539461887],\n",
       " [0.7246321676597812,\n",
       "  1.0,\n",
       "  -1.3904491579035418,\n",
       "  -1.419445408904453,\n",
       "  -0.5082512369765975,\n",
       "  1.64797259476429,\n",
       "  0.9,\n",
       "  -0.9999985561087725],\n",
       " [0.4483840091025352,\n",
       "  0.0,\n",
       "  -0.6542596019350269,\n",
       "  -0.8331775151600693,\n",
       "  -0.9626358222576278,\n",
       "  0.7467384139348191,\n",
       "  1.1,\n",
       "  -0.6007710473538118],\n",
       " [-0.5119688592495047,\n",
       "  1.0,\n",
       "  -0.9811779132003302,\n",
       "  1.847874602231466,\n",
       "  -0.023885537942877337,\n",
       "  1.6930254057573537,\n",
       "  0.9,\n",
       "  -0.27332583912658237],\n",
       " [1.5005184844831019,\n",
       "  3.0,\n",
       "  0.8505588245276134,\n",
       "  1.5705272180552547,\n",
       "  -2.056648450918049,\n",
       "  1.8000500499564387,\n",
       "  0.95,\n",
       "  0.8006531070378926],\n",
       " [1.322287895560942,\n",
       "  2.0,\n",
       "  0.7754215488018688,\n",
       "  0.8675511729164794,\n",
       "  -0.018133763702392735,\n",
       "  -0.30005406140860735,\n",
       "  1.05,\n",
       "  0.8953079796069715],\n",
       " [-0.18657963312225634,\n",
       "  1.0,\n",
       "  -1.4928854429261205,\n",
       "  0.562735430739061,\n",
       "  0.7723067122625893,\n",
       "  -0.44396716560809407,\n",
       "  0.9,\n",
       "  -1.1398717826701767],\n",
       " [0.3976677462520777,\n",
       "  3.0,\n",
       "  0.217422595299437,\n",
       "  -0.0309056054888531,\n",
       "  -0.017357015690082644,\n",
       "  1.6115580953330721,\n",
       "  0.95,\n",
       "  0.3662366878425819],\n",
       " [0.7330324102128458,\n",
       "  5.0,\n",
       "  -0.9168151101096307,\n",
       "  1.5744209231625699,\n",
       "  0.6712332325623958,\n",
       "  0.05454960340888288,\n",
       "  0.85,\n",
       "  0.40835040041633786],\n",
       " [0.6272031896004766,\n",
       "  2.0,\n",
       "  1.2732851997246404,\n",
       "  1.4809395951407296,\n",
       "  -1.1302885920807795,\n",
       "  -1.3566589055841571,\n",
       "  1.05,\n",
       "  -0.050227439691833936],\n",
       " [0.5394833839224714,\n",
       "  5.0,\n",
       "  -1.1093564184845397,\n",
       "  1.704252354999512,\n",
       "  -0.8920010792426056,\n",
       "  -1.709965561982945,\n",
       "  0.85,\n",
       "  0.9992362075891391],\n",
       " [-1.1395669433421596,\n",
       "  5.0,\n",
       "  -1.3335012185169035,\n",
       "  -0.8498295669219174,\n",
       "  0.35582912784093457,\n",
       "  -0.13160099907319836,\n",
       "  0.85,\n",
       "  1.0027292488615511],\n",
       " [1.2613203806174786,\n",
       "  5.0,\n",
       "  -0.845860906348314,\n",
       "  1.4105184545231573,\n",
       "  0.3808220750486115,\n",
       "  0.3591999507575442,\n",
       "  0.85,\n",
       "  -0.7450226986673942],\n",
       " [-1.2964463481217938,\n",
       "  0.0,\n",
       "  0.172660357022911,\n",
       "  -0.49513865198921886,\n",
       "  0.625073606140623,\n",
       "  0.11134775711683127,\n",
       "  1.1,\n",
       "  3.07859601599406],\n",
       " [1.4402857678230028,\n",
       "  4.0,\n",
       "  0.20571787566269237,\n",
       "  -0.23563579462968523,\n",
       "  0.46644162105901066,\n",
       "  1.7957413947162197,\n",
       "  1.2,\n",
       "  0.8550907998575665],\n",
       " [-0.1781083650388144,\n",
       "  3.0,\n",
       "  1.3078359857239008,\n",
       "  -1.0540639807890058,\n",
       "  -0.12527572526699038,\n",
       "  -1.3665699770452895,\n",
       "  0.95,\n",
       "  1.060550277862508],\n",
       " [0.4071483551954405,\n",
       "  3.0,\n",
       "  1.299312486433131,\n",
       "  -0.5126603568368078,\n",
       "  0.338673837294393,\n",
       "  0.9099738168648012,\n",
       "  0.95,\n",
       "  0.9656859944945121],\n",
       " [-0.6361193271350086,\n",
       "  1.0,\n",
       "  0.18889899475822203,\n",
       "  0.2157156271818083,\n",
       "  0.6398680520352257,\n",
       "  -1.001795461770066,\n",
       "  0.9,\n",
       "  0.37210581306382196],\n",
       " [1.1541093740793669,\n",
       "  4.0,\n",
       "  -0.9366777565218225,\n",
       "  1.4595762369596406,\n",
       "  0.8015967039696068,\n",
       "  -0.39884866311473277,\n",
       "  1.2,\n",
       "  -1.1960113849992327],\n",
       " [-0.01947192755673911,\n",
       "  4.0,\n",
       "  -0.1455600808695288,\n",
       "  -0.5234591736670963,\n",
       "  0.13752629368816421,\n",
       "  1.42374615674566,\n",
       "  1.2,\n",
       "  0.7569907068170311],\n",
       " [-0.7469902241683105,\n",
       "  1.0,\n",
       "  1.724983655097891,\n",
       "  -1.0107340276258838,\n",
       "  -0.13156040746825076,\n",
       "  1.3402244830715562,\n",
       "  0.9,\n",
       "  1.0464592544797549],\n",
       " [1.2845481644223624,\n",
       "  5.0,\n",
       "  1.0688099532558095,\n",
       "  1.0377109342599102,\n",
       "  -0.432367145245773,\n",
       "  -1.4876193245519993,\n",
       "  0.85,\n",
       "  0.10970920625707282],\n",
       " [0.7030551411487398,\n",
       "  1.0,\n",
       "  -0.8679960660336244,\n",
       "  -0.06614804886832784,\n",
       "  0.2590654785165814,\n",
       "  1.6345509726012188,\n",
       "  0.9,\n",
       "  0.36195020286661816],\n",
       " [0.47821465169607985,\n",
       "  5.0,\n",
       "  0.4107780324744275,\n",
       "  -0.31814135793277953,\n",
       "  -1.2562273941063613,\n",
       "  -1.1728355006291986,\n",
       "  0.85,\n",
       "  -1.8777916033897886],\n",
       " [0.30853960567193583,\n",
       "  3.0,\n",
       "  0.5162500587862606,\n",
       "  0.5438095280774536,\n",
       "  0.5802091469584206,\n",
       "  0.5779319782117442,\n",
       "  0.95,\n",
       "  0.3840939518806448],\n",
       " [-1.4610754016137792,\n",
       "  1.0,\n",
       "  -0.9326621142010519,\n",
       "  -1.1900421147930054,\n",
       "  -0.0034947861743463964,\n",
       "  -1.069344214758855,\n",
       "  0.9,\n",
       "  0.525855321389728],\n",
       " [-1.6506538252587706,\n",
       "  1.0,\n",
       "  1.0669972091574385,\n",
       "  -1.136573134817023,\n",
       "  0.07781822241902711,\n",
       "  -0.331019302969756,\n",
       "  0.9,\n",
       "  -0.06420420560117639],\n",
       " [-0.9635195723584031,\n",
       "  2.0,\n",
       "  -0.1256195926142351,\n",
       "  0.21695320619538025,\n",
       "  -1.4317220828026418,\n",
       "  -0.7037556021437368,\n",
       "  1.05,\n",
       "  0.30957637444510544],\n",
       " [-1.1000872099373697,\n",
       "  5.0,\n",
       "  1.5075827310924201,\n",
       "  1.7655547667599913,\n",
       "  0.5159440524154485,\n",
       "  -0.3830867560240315,\n",
       "  0.85,\n",
       "  1.0240124659350065],\n",
       " [-0.5798806403457533,\n",
       "  0.0,\n",
       "  -1.5202242511037267,\n",
       "  1.6648976096074475,\n",
       "  -0.40471391470227985,\n",
       "  1.1164868234324998,\n",
       "  1.1,\n",
       "  1.0329371669052128],\n",
       " [0.07270471510904458,\n",
       "  0.0,\n",
       "  -1.2228458479052475,\n",
       "  0.8468630160848581,\n",
       "  -0.11964263380568062,\n",
       "  -0.031586306195116404,\n",
       "  1.1,\n",
       "  1.0607283263977396],\n",
       " [0.5566245368737124,\n",
       "  0.0,\n",
       "  1.0712330012988374,\n",
       "  -0.823885658951959,\n",
       "  0.9357735297125042,\n",
       "  1.753331947378776,\n",
       "  1.1,\n",
       "  -0.3584177980029123],\n",
       " [0.07993560022763979,\n",
       "  1.0,\n",
       "  0.574345165476538,\n",
       "  -0.07924909403561756,\n",
       "  0.20876732190541106,\n",
       "  -1.6414671212012162,\n",
       "  0.9,\n",
       "  0.7024858911583737],\n",
       " [-0.11264401522556158,\n",
       "  0.0,\n",
       "  -0.4370662422127398,\n",
       "  1.3473638946201996,\n",
       "  0.2899265368178374,\n",
       "  0.23982462138681018,\n",
       "  1.1,\n",
       "  0.021649069861627967],\n",
       " [0.888007005465077,\n",
       "  1.0,\n",
       "  1.2272381329720767,\n",
       "  -0.5841323692044403,\n",
       "  0.43763780447767875,\n",
       "  0.8579092683394123,\n",
       "  0.9,\n",
       "  0.1812744468251172],\n",
       " [-0.12022449844269098,\n",
       "  5.0,\n",
       "  1.4934243289090208,\n",
       "  0.34307247394985346,\n",
       "  -0.2515906415095676,\n",
       "  1.9182849224958567,\n",
       "  0.85,\n",
       "  -1.6259799130334252],\n",
       " [1.3175394520330233,\n",
       "  2.0,\n",
       "  0.40433325727606223,\n",
       "  1.9933703086622465,\n",
       "  -1.0207427614478914,\n",
       "  0.2922851104725293,\n",
       "  1.05,\n",
       "  0.26598049279162533],\n",
       " [-1.433454559613552,\n",
       "  4.0,\n",
       "  -0.6311113882868122,\n",
       "  0.8771523551558638,\n",
       "  0.7410469029356483,\n",
       "  0.02375014691011382,\n",
       "  1.2,\n",
       "  0.2509538710060647],\n",
       " [-1.6537093751441987,\n",
       "  0.0,\n",
       "  1.51050627032314,\n",
       "  1.844926733387715,\n",
       "  0.8224365993803224,\n",
       "  -0.9218351786578621,\n",
       "  1.1,\n",
       "  -1.2177603402566233],\n",
       " [0.3251285973506736,\n",
       "  4.0,\n",
       "  0.8964908684632427,\n",
       "  1.5841688548593211,\n",
       "  0.9891298681259764,\n",
       "  -1.4375117809676237,\n",
       "  1.2,\n",
       "  1.0546866073929617],\n",
       " [0.5696730751435465,\n",
       "  3.0,\n",
       "  -1.0072927260178561,\n",
       "  -0.7376958882199754,\n",
       "  0.6280092095679075,\n",
       "  1.2759183867085369,\n",
       "  0.95,\n",
       "  1.0577090354642003],\n",
       " [-0.3831328183453348,\n",
       "  2.0,\n",
       "  1.497197200698984,\n",
       "  -0.8060047622796229,\n",
       "  0.31707186977556245,\n",
       "  0.42021924023881485,\n",
       "  1.05,\n",
       "  -1.5909486331679121],\n",
       " [1.2418304574090615,\n",
       "  4.0,\n",
       "  -0.4979078131917337,\n",
       "  -1.3883113109533045,\n",
       "  0.7921616793344189,\n",
       "  0.21867541760455997,\n",
       "  1.2,\n",
       "  -0.7845715933523132],\n",
       " [1.2452500423575716,\n",
       "  4.0,\n",
       "  1.0748926613770593,\n",
       "  -1.04770503451506,\n",
       "  0.7261287609730014,\n",
       "  1.5182379098257903,\n",
       "  1.2,\n",
       "  1.0148193177758402],\n",
       " [-0.7400337775708302,\n",
       "  1.0,\n",
       "  -1.3237198033011521,\n",
       "  0.0440948211408665,\n",
       "  0.6731970176236698,\n",
       "  -0.6968698730210937,\n",
       "  0.9,\n",
       "  1.054540782553938],\n",
       " [1.1451830331852175,\n",
       "  5.0,\n",
       "  0.8093570674021181,\n",
       "  0.39509472953054275,\n",
       "  0.30168817433510825,\n",
       "  -0.2598236869816293,\n",
       "  0.85,\n",
       "  0.9845175672493257],\n",
       " [-0.7081380116362982,\n",
       "  2.0,\n",
       "  0.3670686099629179,\n",
       "  1.6251127981803997,\n",
       "  0.28607798311287247,\n",
       "  1.2231826824579242,\n",
       "  1.05,\n",
       "  -1.246311304635697],\n",
       " [0.05190985086193985,\n",
       "  0.0,\n",
       "  0.07524180409506948,\n",
       "  -1.3282306128285795,\n",
       "  0.37186077074364726,\n",
       "  -0.7379010207092438,\n",
       "  1.1,\n",
       "  1.0603079657199237],\n",
       " [-1.5734863114848705,\n",
       "  2.0,\n",
       "  0.059768858243124195,\n",
       "  1.5787562266753392,\n",
       "  0.4769856767736085,\n",
       "  0.3628967296528991,\n",
       "  1.05,\n",
       "  0.3966535323995758],\n",
       " [-1.0885949890780222,\n",
       "  5.0,\n",
       "  -1.2138363576079463,\n",
       "  1.576271710074349,\n",
       "  0.6175293755646138,\n",
       "  -0.7789697317028956,\n",
       "  0.85,\n",
       "  2.422819854891199],\n",
       " [0.695527089707556,\n",
       "  2.0,\n",
       "  -0.9930342031040987,\n",
       "  1.514954519461771,\n",
       "  -0.13764262186838605,\n",
       "  -1.7412792517739901,\n",
       "  1.05,\n",
       "  0.871335162971373],\n",
       " [-1.4311991535588027,\n",
       "  4.0,\n",
       "  0.2331002075729808,\n",
       "  1.1679352051054703,\n",
       "  0.6598471656490643,\n",
       "  1.1276256572518322,\n",
       "  1.2,\n",
       "  0.19253335550605633],\n",
       " [0.13555208705832747,\n",
       "  3.0,\n",
       "  -0.42143691689605794,\n",
       "  1.3382946120080683,\n",
       "  0.8724579221171073,\n",
       "  -0.25636288491744763,\n",
       "  0.95,\n",
       "  -1.603480005717966],\n",
       " [-0.22233128891472081,\n",
       "  5.0,\n",
       "  1.2647882859748256,\n",
       "  -0.4670750626549473,\n",
       "  1.2820084457659744,\n",
       "  0.1123386114778016,\n",
       "  0.85,\n",
       "  0.5493953086753162],\n",
       " [-0.1576267338932968,\n",
       "  1.0,\n",
       "  0.4661645519693397,\n",
       "  1.3511044045250196,\n",
       "  -1.4967074698268816,\n",
       "  -0.4034832994754829,\n",
       "  0.9,\n",
       "  1.0598590608408642],\n",
       " [-0.5222973899451829,\n",
       "  4.0,\n",
       "  -0.6159812523500557,\n",
       "  -0.8164290150840422,\n",
       "  0.4468450564257083,\n",
       "  1.412788751666944,\n",
       "  1.2,\n",
       "  -0.03821108104005655],\n",
       " [1.090965487956237,\n",
       "  1.0,\n",
       "  -1.669134758214157,\n",
       "  1.5447216069545653,\n",
       "  -2.739822269787745,\n",
       "  1.4435051741188523,\n",
       "  0.9,\n",
       "  0.9496796190814399],\n",
       " [0.736433823113511,\n",
       "  2.0,\n",
       "  -0.42432045139192487,\n",
       "  0.3636249534328035,\n",
       "  0.2900076253052791,\n",
       "  1.8135514651388414,\n",
       "  1.05,\n",
       "  -0.9395157974949614],\n",
       " [-0.3046178741816918,\n",
       "  3.0,\n",
       "  0.7657908409448065,\n",
       "  -1.3057380641508507,\n",
       "  0.8497897125663261,\n",
       "  -1.0940421575752464,\n",
       "  0.95,\n",
       "  1.0579111916445925],\n",
       " [-0.9703739679013808,\n",
       "  3.0,\n",
       "  -0.6874074967648787,\n",
       "  -0.11336823178174778,\n",
       "  0.9373432702427218,\n",
       "  -0.9637206764625899,\n",
       "  0.95,\n",
       "  -0.025434528185106924],\n",
       " [-0.8380320354331703,\n",
       "  0.0,\n",
       "  1.6878142757007568,\n",
       "  -0.43592896605431114,\n",
       "  0.7623555091607711,\n",
       "  0.1799540312478135,\n",
       "  1.1,\n",
       "  1.047312786685543],\n",
       " [0.9287634050500174,\n",
       "  3.0,\n",
       "  1.3863942722445795,\n",
       "  -1.0373906206099823,\n",
       "  0.5727853653939227,\n",
       "  -1.837066606393613,\n",
       "  0.95,\n",
       "  0.7999225230097352],\n",
       " [-0.9268807022533075,\n",
       "  0.0,\n",
       "  -0.191856501289378,\n",
       "  1.817652292402005,\n",
       "  0.8429374481322841,\n",
       "  -1.7667141906472141,\n",
       "  1.1,\n",
       "  -1.402943956684025],\n",
       " [1.1937005814612138,\n",
       "  1.0,\n",
       "  -0.018371755537090143,\n",
       "  0.502263552490059,\n",
       "  -0.4383370315555947,\n",
       "  -0.6124706319031601,\n",
       "  0.9,\n",
       "  0.6350398698256199],\n",
       " [1.610880541952435,\n",
       "  3.0,\n",
       "  -0.12230545677114443,\n",
       "  -0.9261400232257058,\n",
       "  -0.3564895288368926,\n",
       "  -0.7733659439602909,\n",
       "  0.95,\n",
       "  0.45259400275156914],\n",
       " [1.0152243452036975,\n",
       "  2.0,\n",
       "  1.5818753115432798,\n",
       "  -1.0872635700246673,\n",
       "  0.7040506581391814,\n",
       "  0.04139139590959763,\n",
       "  1.05,\n",
       "  0.8123471467417906],\n",
       " [0.8916244501391429,\n",
       "  2.0,\n",
       "  0.5360482437052797,\n",
       "  0.42558525896706145,\n",
       "  0.968595706251381,\n",
       "  0.27167199611186205,\n",
       "  1.05,\n",
       "  0.2027527989172261],\n",
       " [-0.988678966839227,\n",
       "  0.0,\n",
       "  -0.21344386172452082,\n",
       "  -0.7773003806841562,\n",
       "  0.8766598317466473,\n",
       "  -0.8942628488381019,\n",
       "  1.1,\n",
       "  -1.5306079421950571],\n",
       " [-0.8518848336192156,\n",
       "  3.0,\n",
       "  -0.6818676276463906,\n",
       "  -0.23271301717548706,\n",
       "  0.5799040024767932,\n",
       "  -0.992487361508067,\n",
       "  0.95,\n",
       "  -0.7274104671626325],\n",
       " [-1.8209480437342347,\n",
       "  2.0,\n",
       "  0.3340306624221036,\n",
       "  1.6453201907365802,\n",
       "  0.0014829848641488197,\n",
       "  -1.9391754647176145,\n",
       "  1.05,\n",
       "  -0.7367077390502085],\n",
       " [-0.8174939772330794,\n",
       "  3.0,\n",
       "  1.1236610181454916,\n",
       "  -0.7363198061608099,\n",
       "  -0.7980951942263643,\n",
       "  -1.1871037800527102,\n",
       "  0.95,\n",
       "  0.23731700030029038],\n",
       " [1.3573423261373585,\n",
       "  0.0,\n",
       "  0.3624856685507864,\n",
       "  -0.42897190420032255,\n",
       "  -0.5905473805732632,\n",
       "  -0.6800751603938062,\n",
       "  1.1,\n",
       "  -0.22934939422547937],\n",
       " [-1.4657665321812454,\n",
       "  5.0,\n",
       "  -0.6829299618222374,\n",
       "  1.77215907164264,\n",
       "  -1.5820021587362028,\n",
       "  -0.5004675096198302,\n",
       "  0.85,\n",
       "  0.8276537376514094],\n",
       " [-0.7429444792006279,\n",
       "  2.0,\n",
       "  0.8913639955149666,\n",
       "  -0.9911814302213198,\n",
       "  0.5083700170452329,\n",
       "  0.34107936111102616,\n",
       "  1.05,\n",
       "  0.9686339159818229],\n",
       " [0.4498303686683505,\n",
       "  0.0,\n",
       "  -0.41327556788257763,\n",
       "  1.9545374829543005,\n",
       "  0.27424051890866846,\n",
       "  -0.2552973922004907,\n",
       "  1.1,\n",
       "  -1.353044876872303],\n",
       " [-0.265346281453678,\n",
       "  4.0,\n",
       "  0.7409903481769305,\n",
       "  1.4546758076676158,\n",
       "  0.48217136935203864,\n",
       "  -1.1832554936436732,\n",
       "  1.2,\n",
       "  0.08392654538391234],\n",
       " [0.0027032248364387296,\n",
       "  5.0,\n",
       "  -1.4091280068120895,\n",
       "  -0.6905239348452582,\n",
       "  0.9037041682670469,\n",
       "  -0.639773722598369,\n",
       "  0.85,\n",
       "  -1.014890698878377],\n",
       " [-0.8045172616527483,\n",
       "  1.0,\n",
       "  -0.9718933315363486,\n",
       "  -1.0005924541636464,\n",
       "  -0.16637130730382174,\n",
       "  1.107425900384263,\n",
       "  0.9,\n",
       "  -1.840911922048328],\n",
       " [1.129053362760224,\n",
       "  3.0,\n",
       "  0.7785784645788675,\n",
       "  -0.37761923210830756,\n",
       "  0.6430541632675538,\n",
       "  -0.9118600329723768,\n",
       "  0.95,\n",
       "  0.6850614309905233],\n",
       " [0.3450097103882738,\n",
       "  4.0,\n",
       "  -1.215769754441026,\n",
       "  -1.1903363016834878,\n",
       "  0.9356654717130216,\n",
       "  1.0907780445577189,\n",
       "  1.2,\n",
       "  0.4572705093870592],\n",
       " [1.4094237278708213,\n",
       "  3.0,\n",
       "  1.144278929167163,\n",
       "  1.2187866055903769,\n",
       "  0.9123420365428874,\n",
       "  -0.03329108604984029,\n",
       "  0.95,\n",
       "  1.0494437627359958],\n",
       " [0.4597991512611995,\n",
       "  3.0,\n",
       "  0.5071175162154765,\n",
       "  -1.3509332733923067,\n",
       "  0.710793561508265,\n",
       "  0.9811425252477535,\n",
       "  0.95,\n",
       "  0.06176272662954221],\n",
       " [0.8782931464934248,\n",
       "  2.0,\n",
       "  0.5389129046475705,\n",
       "  -0.42730157438408717,\n",
       "  -1.208821464300043,\n",
       "  0.033078716644056955,\n",
       "  1.05,\n",
       "  -0.47625225263758525],\n",
       " [-1.0043628377658709,\n",
       "  1.0,\n",
       "  0.8087488429529764,\n",
       "  1.6789646187840495,\n",
       "  -1.1476904510660393,\n",
       "  -0.3567349631767685,\n",
       "  0.9,\n",
       "  0.1913301725343283],\n",
       " [-0.143046151135369,\n",
       "  2.0,\n",
       "  -1.49453192235819,\n",
       "  -0.9978245658375676,\n",
       "  -0.6235652930705917,\n",
       "  -0.11589587086659618,\n",
       "  1.05,\n",
       "  0.5561825557987428],\n",
       " [-0.610813632212828,\n",
       "  0.0,\n",
       "  -0.5037502969340165,\n",
       "  1.7771494127422418,\n",
       "  0.5495113311430811,\n",
       "  -0.6749483091282615,\n",
       "  1.1,\n",
       "  1.041769078316967],\n",
       " [0.7703503977256281,\n",
       "  1.0,\n",
       "  -1.1191166853964634,\n",
       "  0.4496246308525054,\n",
       "  0.5620633986911884,\n",
       "  1.332511622487631,\n",
       "  0.9,\n",
       "  0.9830103812736035],\n",
       " [-1.419560371303514,\n",
       "  1.0,\n",
       "  0.422581456086972,\n",
       "  -1.4130524658699068,\n",
       "  -1.1170738748485942,\n",
       "  0.07161792475721704,\n",
       "  0.9,\n",
       "  0.4573151017988777],\n",
       " [0.0757697790443624,\n",
       "  1.0,\n",
       "  -1.3553460807614444,\n",
       "  0.418286088122033,\n",
       "  0.8680697293964131,\n",
       "  -0.6980701526295259,\n",
       "  0.9,\n",
       "  1.0580458049274515],\n",
       " [1.7191865084226217,\n",
       "  2.0,\n",
       "  0.8812190960421973,\n",
       "  1.156080530737776,\n",
       "  0.749302042745979,\n",
       "  0.5537577779093514,\n",
       "  1.05,\n",
       "  0.17944712791099277],\n",
       " [-1.2748852680402307,\n",
       "  3.0,\n",
       "  -0.5890247158765163,\n",
       "  -1.0765601776199687,\n",
       "  0.45837269212897175,\n",
       "  -0.2421352425397693,\n",
       "  0.95,\n",
       "  -0.6195042172571829],\n",
       " [0.8485284930751218,\n",
       "  5.0,\n",
       "  0.5286133916548242,\n",
       "  -1.1559803037863394,\n",
       "  0.289937780738511,\n",
       "  -1.4142833957752379,\n",
       "  0.85,\n",
       "  -0.2846791629724496],\n",
       " [-0.21206672504994187,\n",
       "  2.0,\n",
       "  1.472562938521537,\n",
       "  -0.7972687918896411,\n",
       "  -0.14449621639398524,\n",
       "  -0.3754119152345678,\n",
       "  1.05,\n",
       "  -1.3288523923363516],\n",
       " [0.3294968216303174,\n",
       "  0.0,\n",
       "  -0.6845519955904278,\n",
       "  1.4241610896036505,\n",
       "  -2.292855979841475,\n",
       "  -0.4806272682952541,\n",
       "  1.1,\n",
       "  -1.6256157555812552],\n",
       " [-0.7827998950914897,\n",
       "  4.0,\n",
       "  0.8212340502071406,\n",
       "  1.4623982732244842,\n",
       "  0.15367913448305395,\n",
       "  0.6873100851107926,\n",
       "  1.2,\n",
       "  -1.7702035973795276],\n",
       " [0.9104620986983253,\n",
       "  4.0,\n",
       "  -1.1815049394935573,\n",
       "  -0.01146802165698022,\n",
       "  0.9871616457739726,\n",
       "  0.01946409187772871,\n",
       "  1.2,\n",
       "  0.46033972488542774],\n",
       " [-1.0008688631512093,\n",
       "  1.0,\n",
       "  1.644353089310327,\n",
       "  -1.3083470226893452,\n",
       "  0.089142440883808,\n",
       "  1.4299376261596655,\n",
       "  0.9,\n",
       "  1.5589888706077597],\n",
       " [1.2315884677260982,\n",
       "  2.0,\n",
       "  0.1937312876054238,\n",
       "  1.63511138794116,\n",
       "  0.7615565633800059,\n",
       "  1.9626361408998922,\n",
       "  1.05,\n",
       "  0.3618835830006985],\n",
       " [-1.3302227711519155,\n",
       "  3.0,\n",
       "  -1.466459007233247,\n",
       "  -1.4200309682680563,\n",
       "  0.278414356260057,\n",
       "  -0.5632921312269894,\n",
       "  0.95,\n",
       "  -1.4226616782160255],\n",
       " [1.311208946408681,\n",
       "  2.0,\n",
       "  1.2987204918357107,\n",
       "  0.8959379256775017,\n",
       "  0.8443089630338686,\n",
       "  -0.20436109579002334,\n",
       "  1.05,\n",
       "  0.8188624406226439],\n",
       " [-0.3208438691416748,\n",
       "  5.0,\n",
       "  1.1859906115777759,\n",
       "  -0.7967997407910442,\n",
       "  1.4408879841586388,\n",
       "  1.2589424833664673,\n",
       "  0.85,\n",
       "  0.8674612677672168],\n",
       " [-0.6812591687236321,\n",
       "  5.0,\n",
       "  -1.496954323226883,\n",
       "  -0.4087867083376069,\n",
       "  0.7832378251273308,\n",
       "  0.010765736865388141,\n",
       "  0.85,\n",
       "  -0.9382454490738037],\n",
       " [1.34458052782842,\n",
       "  5.0,\n",
       "  1.2477379025868411,\n",
       "  -1.0056106261262023,\n",
       "  0.015779880784505783,\n",
       "  0.06661056401719179,\n",
       "  0.85,\n",
       "  1.109707676878114],\n",
       " [-0.7432213365738896,\n",
       "  1.0,\n",
       "  -1.4827277817638018,\n",
       "  -1.4160275467414585,\n",
       "  -0.29375527522113193,\n",
       "  -0.42044585101947685,\n",
       "  0.9,\n",
       "  0.8140652743329454],\n",
       " [-1.1779520118011375,\n",
       "  2.0,\n",
       "  0.775737140432095,\n",
       "  -0.4976290003551222,\n",
       "  0.9832816908179364,\n",
       "  -0.7232695477334952,\n",
       "  1.05,\n",
       "  -1.642795664444771],\n",
       " [1.3853569313905245,\n",
       "  5.0,\n",
       "  -1.3182311317818856,\n",
       "  1.133106480241086,\n",
       "  0.04512683992311527,\n",
       "  0.37237573814869707,\n",
       "  0.85,\n",
       "  -0.6281191383658239],\n",
       " [1.4932392613353762,\n",
       "  1.0,\n",
       "  -0.44481635067598335,\n",
       "  1.1081438997047564,\n",
       "  -0.08330890749384592,\n",
       "  -0.4032769766779948,\n",
       "  0.9,\n",
       "  0.39938773205530304],\n",
       " [0.010388663928780592,\n",
       "  0.0,\n",
       "  1.0061999588218813,\n",
       "  -0.869157629532558,\n",
       "  -0.5267991332512029,\n",
       "  1.9589338284464333,\n",
       "  1.1,\n",
       "  0.5389631620922346],\n",
       " [0.5685800559335686,\n",
       "  5.0,\n",
       "  0.5872964384507161,\n",
       "  0.2489073371251182,\n",
       "  -0.3201104346608678,\n",
       "  0.12358250522871274,\n",
       "  0.85,\n",
       "  0.06031057264824048],\n",
       " [-1.0666396327632715,\n",
       "  5.0,\n",
       "  -0.8200332446727738,\n",
       "  0.3024696194183166,\n",
       "  -0.7056002389703595,\n",
       "  -1.2718097729809446,\n",
       "  0.85,\n",
       "  1.7395001923626117],\n",
       " [0.20751246973068913,\n",
       "  2.0,\n",
       "  0.20945785731797426,\n",
       "  0.7827660567537775,\n",
       "  0.9862613854498934,\n",
       "  0.1322933765720183,\n",
       "  1.05,\n",
       "  -1.9880406707732845],\n",
       " [0.8382619647797201,\n",
       "  0.0,\n",
       "  1.0531793420555342,\n",
       "  -0.9812164429391373,\n",
       "  0.8275268635573864,\n",
       "  1.7885754708368773,\n",
       "  1.1,\n",
       "  1.0100068033153027],\n",
       " [-1.544246499124729,\n",
       "  5.0,\n",
       "  -1.637341994197538,\n",
       "  -0.601318206189362,\n",
       "  0.3007289304155747,\n",
       "  -1.6346594183466276,\n",
       "  0.85,\n",
       "  1.4636182185141176],\n",
       " [-1.220584071340921,\n",
       "  5.0,\n",
       "  -0.9662358248751991,\n",
       "  0.6598188903206026,\n",
       "  0.739958959395598,\n",
       "  -1.3677366859040214,\n",
       "  0.85,\n",
       "  -0.24123761699314955],\n",
       " [-0.22000597471497046,\n",
       "  2.0,\n",
       "  0.39827315622232656,\n",
       "  -1.0293821102046388,\n",
       "  0.46430045689280597,\n",
       "  0.6161570493567234,\n",
       "  1.05,\n",
       "  -1.4440297587334452],\n",
       " [0.1488422956786502,\n",
       "  2.0,\n",
       "  0.4190139882198628,\n",
       "  -0.5568635961152508,\n",
       "  0.7678877342370396,\n",
       "  0.4120431956163724,\n",
       "  1.05,\n",
       "  0.73146816680501],\n",
       " [-0.9052976644693516,\n",
       "  1.0,\n",
       "  1.0745801946947622,\n",
       "  1.1200269581708207,\n",
       "  -0.9554170430229753,\n",
       "  1.4382469693225752,\n",
       "  0.9,\n",
       "  -1.8623420226549017],\n",
       " [-0.11647361947523859,\n",
       "  2.0,\n",
       "  0.7764716385442154,\n",
       "  -1.3935286836948957,\n",
       "  -0.82721364245925,\n",
       "  1.077152508248161,\n",
       "  1.05,\n",
       "  1.0315638802978655],\n",
       " [-1.6593406598689149,\n",
       "  0.0,\n",
       "  0.06234991300585994,\n",
       "  -1.222108904014395,\n",
       "  1.3806476507402463,\n",
       "  0.9034701753302425,\n",
       "  1.1,\n",
       "  0.07744680876181122],\n",
       " [-1.3453937553150157,\n",
       "  2.0,\n",
       "  1.5289863246446207,\n",
       "  -1.0896485464833197,\n",
       "  0.888958488762056,\n",
       "  1.0784385795860407,\n",
       "  1.05,\n",
       "  0.4051270220127962],\n",
       " [-1.3752609494308992,\n",
       "  2.0,\n",
       "  0.9578247235465976,\n",
       "  0.27968403031618955,\n",
       "  0.2613250846855407,\n",
       "  1.9423580293936675,\n",
       "  1.05,\n",
       "  -0.12881154152329402],\n",
       " [-1.422925281311893,\n",
       "  5.0,\n",
       "  1.6391881777168091,\n",
       "  -0.2929834550581017,\n",
       "  0.8142071821259971,\n",
       "  0.886398790889823,\n",
       "  0.85,\n",
       "  -1.3299258713990714],\n",
       " [0.3899088101502615,\n",
       "  0.0,\n",
       "  1.5488985473468782,\n",
       "  -1.3252473137386651,\n",
       "  0.43307038615438265,\n",
       "  1.4391717259295618,\n",
       "  1.1,\n",
       "  0.48642919334641144],\n",
       " [0.33896577284979357,\n",
       "  5.0,\n",
       "  -1.2191266861046763,\n",
       "  -1.3779093373207292,\n",
       "  0.2639123125305904,\n",
       "  -1.5301101438408486,\n",
       "  0.85,\n",
       "  2.3717673035706803],\n",
       " [-1.6390125165401241,\n",
       "  5.0,\n",
       "  0.7436894920018128,\n",
       "  1.934157443163245,\n",
       "  0.8633034340434798,\n",
       "  -1.2903173186174381,\n",
       "  0.85,\n",
       "  1.0359869548703626],\n",
       " [-1.3811993255030957,\n",
       "  4.0,\n",
       "  0.3310642923097056,\n",
       "  0.24214603893692213,\n",
       "  0.5042915877163914,\n",
       "  1.1528167446522497,\n",
       "  1.2,\n",
       "  1.0479566860511],\n",
       " [1.5417175973162913,\n",
       "  5.0,\n",
       "  0.8083855846523701,\n",
       "  -0.9512050385791165,\n",
       "  -1.63832043775325,\n",
       "  -0.55080324007542,\n",
       "  0.85,\n",
       "  0.4465696513413943],\n",
       " [-0.9738646674897389,\n",
       "  2.0,\n",
       "  -0.4909251648147208,\n",
       "  0.0026211552713983955,\n",
       "  -0.9879720908274273,\n",
       "  0.016017705463472812,\n",
       "  1.05,\n",
       "  -1.6147186568846426],\n",
       " [-1.3657321097820951,\n",
       "  3.0,\n",
       "  0.4425664976498276,\n",
       "  -0.7779319255874549,\n",
       "  0.9061254719404535,\n",
       "  -0.3117549153914538,\n",
       "  0.95,\n",
       "  0.9117194845423722],\n",
       " [-1.5201423596935522,\n",
       "  4.0,\n",
       "  0.5956212330778329,\n",
       "  1.4182326272413206,\n",
       "  0.7844528800392773,\n",
       "  -0.97331627600409,\n",
       "  1.2,\n",
       "  0.9955176668208952],\n",
       " [-0.7636206548522828,\n",
       "  2.0,\n",
       "  1.1008735709756166,\n",
       "  0.4075807456099246,\n",
       "  0.5098836532870339,\n",
       "  1.8967236281296165,\n",
       "  1.05,\n",
       "  -1.1487237054242927],\n",
       " [0.4275250379570821,\n",
       "  5.0,\n",
       "  -1.1887232312923866,\n",
       "  -0.19894139395898458,\n",
       "  0.5622786374148995,\n",
       "  0.6597834886928847,\n",
       "  0.85,\n",
       "  1.1346685902227598],\n",
       " [1.6940319015030516,\n",
       "  2.0,\n",
       "  -0.5633117388398772,\n",
       "  -1.2412200533365354,\n",
       "  0.8927047085687465,\n",
       "  0.05407989699309502,\n",
       "  1.05,\n",
       "  0.2691356576083788],\n",
       " [1.434471465284937,\n",
       "  0.0,\n",
       "  0.11959787047119824,\n",
       "  -0.8013273742258632,\n",
       "  0.6660484222250009,\n",
       "  1.848792180441565,\n",
       "  1.1,\n",
       "  0.8799847709502397],\n",
       " [-0.27380550734054876,\n",
       "  3.0,\n",
       "  0.15697823213717768,\n",
       "  1.2340684218698135,\n",
       "  0.35960315865607967,\n",
       "  -1.9388966587425696,\n",
       "  0.95,\n",
       "  0.9387741313180197],\n",
       " [0.9304373022652613,\n",
       "  5.0,\n",
       "  0.45061704768748484,\n",
       "  -0.9666255188069298,\n",
       "  0.80735997735673,\n",
       "  -1.4576932069373616,\n",
       "  0.85,\n",
       "  1.060024156890865],\n",
       " [0.8161191589470981,\n",
       "  1.0,\n",
       "  0.28127796600026833,\n",
       "  1.098068330294246,\n",
       "  0.06836979066225227,\n",
       "  0.8975352720015342,\n",
       "  0.9,\n",
       "  0.9549777614886407],\n",
       " [-1.0164112755309254,\n",
       "  4.0,\n",
       "  -1.4633662771203357,\n",
       "  -0.8915069877019718,\n",
       "  0.9518312016749408,\n",
       "  1.5636182017204652,\n",
       "  1.2,\n",
       "  0.4387334615054108],\n",
       " [-1.8978594387306114,\n",
       "  3.0,\n",
       "  1.154006586557286,\n",
       "  0.4648214800839875,\n",
       "  -0.5905597770946137,\n",
       "  0.1796096703002259,\n",
       "  0.95,\n",
       "  0.14001388517906713],\n",
       " [-1.3167317271975443,\n",
       "  5.0,\n",
       "  0.3660231868627788,\n",
       "  -0.1829026297900047,\n",
       "  1.018262265588569,\n",
       "  0.11911502813127117,\n",
       "  0.85,\n",
       "  1.0396266625526887],\n",
       " [-0.886164565627443,\n",
       "  5.0,\n",
       "  0.7151772935516691,\n",
       "  0.7482107990897956,\n",
       "  0.7308650300599822,\n",
       "  0.13188042680297418,\n",
       "  0.85,\n",
       "  0.855323340284064],\n",
       " [-1.2749033605172004,\n",
       "  0.0,\n",
       "  -0.17666085777831508,\n",
       "  1.9731037896847698,\n",
       "  1.1934382700996748,\n",
       "  0.08317939764678188,\n",
       "  1.1,\n",
       "  -1.9770041816928534],\n",
       " [0.4176409820921885,\n",
       "  5.0,\n",
       "  0.8716985600470537,\n",
       "  -0.23834651904741713,\n",
       "  0.4375064808290938,\n",
       "  1.288394075633884,\n",
       "  0.85,\n",
       "  -1.1901627277879774],\n",
       " [0.840283225493053,\n",
       "  0.0,\n",
       "  0.3816721680891153,\n",
       "  -1.0787936097159072,\n",
       "  1.5589753769752497,\n",
       "  -0.7463308800902959,\n",
       "  1.1,\n",
       "  0.21442252351379634],\n",
       " [1.3506366730541226,\n",
       "  0.0,\n",
       "  -1.0075788756206512,\n",
       "  -1.4328303582400899,\n",
       "  -0.3258919329742921,\n",
       "  0.40719755668123736,\n",
       "  1.1,\n",
       "  0.9341986823325732],\n",
       " [-1.1961890367516177,\n",
       "  4.0,\n",
       "  -0.010505527735142082,\n",
       "  1.5652020909416928,\n",
       "  -0.3071837312865901,\n",
       "  0.6259249543263014,\n",
       "  1.2,\n",
       "  0.7380892129761324],\n",
       " [-0.6828345199964619,\n",
       "  1.0,\n",
       "  -0.9798791172126595,\n",
       "  -0.3377039916295093,\n",
       "  0.621639357052793,\n",
       "  0.5470473144655991,\n",
       "  0.9,\n",
       "  0.10800413786453113],\n",
       " [0.5107177450146354,\n",
       "  5.0,\n",
       "  0.4333919133485502,\n",
       "  -0.8064445095162783,\n",
       "  -0.12628368752823288,\n",
       "  -1.2309335186793529,\n",
       "  0.85,\n",
       "  -1.0980834005977844],\n",
       " [0.04984492514287786,\n",
       "  1.0,\n",
       "  -0.3258453754140237,\n",
       "  1.6541474720976763,\n",
       "  0.4412452554101751,\n",
       "  -0.3934083854768709,\n",
       "  0.9,\n",
       "  0.42854313384621295],\n",
       " [-1.2747686024189118,\n",
       "  5.0,\n",
       "  0.45195974466265476,\n",
       "  -0.40991939137198175,\n",
       "  0.4123527374753774,\n",
       "  -1.8205502186172706,\n",
       "  0.85,\n",
       "  -0.7248680897483463],\n",
       " [-1.3609355739118878,\n",
       "  2.0,\n",
       "  -0.8785412438082877,\n",
       "  1.8615545748944848,\n",
       "  0.574613874655211,\n",
       "  0.13462044625582195,\n",
       "  1.05,\n",
       "  -0.8574645701577848],\n",
       " [-0.33753557076242974,\n",
       "  0.0,\n",
       "  -0.4428036867067347,\n",
       "  -1.0748868578012707,\n",
       "  -0.650010476119676,\n",
       "  0.16428358563011944,\n",
       "  1.1,\n",
       "  -1.2385307681135846],\n",
       " [0.6831428585252078,\n",
       "  2.0,\n",
       "  -0.6649732609935443,\n",
       "  0.11098232475973652,\n",
       "  -0.8216249612959662,\n",
       "  -1.4045728304993628,\n",
       "  1.05,\n",
       "  -0.14618936879115302],\n",
       " [-0.4736843323068224,\n",
       "  4.0,\n",
       "  -0.7892525024329257,\n",
       "  0.374216498528304,\n",
       "  1.7968784086652292,\n",
       "  -1.7251024945032194,\n",
       "  1.2,\n",
       "  -1.616829860438703],\n",
       " [-0.2777717682588632,\n",
       "  5.0,\n",
       "  1.0046686804801026,\n",
       "  -0.34062650492040114,\n",
       "  -2.1151321948629715,\n",
       "  0.9157232570297691,\n",
       "  0.85,\n",
       "  -0.8951891770065717],\n",
       " [-1.3564493113891565,\n",
       "  2.0,\n",
       "  1.2879344574007936,\n",
       "  1.1835132577701193,\n",
       "  -0.11231848851876151,\n",
       "  -1.4021442367638643,\n",
       "  1.05,\n",
       "  0.9362277010685409],\n",
       " [-1.6536479110960671,\n",
       "  4.0,\n",
       "  -1.6608547315341486,\n",
       "  -1.3678602607925756,\n",
       "  0.9393457420092302,\n",
       "  0.6954493558618068,\n",
       "  1.2,\n",
       "  1.0320941999444473],\n",
       " [-0.4272387754389459,\n",
       "  5.0,\n",
       "  0.2400707013633158,\n",
       "  -1.0105528616886499,\n",
       "  0.40631228164481353,\n",
       "  1.6452250199262122,\n",
       "  0.85,\n",
       "  0.9406718503588496],\n",
       " [-1.456666002714944,\n",
       "  5.0,\n",
       "  -0.7074258414052063,\n",
       "  -1.1824818692953198,\n",
       "  0.4272114969066653,\n",
       "  -1.9458636365102278,\n",
       "  0.85,\n",
       "  1.0115363448691899],\n",
       " [-0.012463128258091791,\n",
       "  5.0,\n",
       "  -0.3800292728336247,\n",
       "  -0.8440366873973075,\n",
       "  -1.0891773144998047,\n",
       "  -0.4739716423689253,\n",
       "  0.85,\n",
       "  1.0650485004130976],\n",
       " [-0.6580927435901868,\n",
       "  5.0,\n",
       "  0.7097756571377385,\n",
       "  -0.6316835689117584,\n",
       "  0.9784063865444491,\n",
       "  0.8424547651181341,\n",
       "  0.85,\n",
       "  -1.0539618093265617],\n",
       " [0.22669315088995542,\n",
       "  0.0,\n",
       "  -0.4302365477870081,\n",
       "  -1.071256380090607,\n",
       "  -2.4984645945814314,\n",
       "  -0.3960953082844184,\n",
       "  1.1,\n",
       "  0.07573214882210243],\n",
       " [-0.6753607632545338,\n",
       "  0.0,\n",
       "  1.325328367120882,\n",
       "  -1.4169286264243084,\n",
       "  0.6366053984450406,\n",
       "  1.7885132260364984,\n",
       "  1.1,\n",
       "  0.3002570234369761],\n",
       " [1.2561766435671458,\n",
       "  4.0,\n",
       "  0.07162616505145178,\n",
       "  0.4628026806023986,\n",
       "  0.5928221938334881,\n",
       "  0.11049323070653891,\n",
       "  1.2,\n",
       "  0.8802997043827769],\n",
       " [1.1921446209757778,\n",
       "  3.0,\n",
       "  0.7811303995224111,\n",
       "  -1.4050480817730007,\n",
       "  -0.5371705825690507,\n",
       "  -0.49239293460517686,\n",
       "  0.95,\n",
       "  0.9092762411415477],\n",
       " [-0.6287614607660882,\n",
       "  4.0,\n",
       "  -0.9549607286351186,\n",
       "  0.03027201163753713,\n",
       "  0.21944248438119293,\n",
       "  0.7107660705972217,\n",
       "  1.2,\n",
       "  0.39569384318971457],\n",
       " [-0.6909894668208794,\n",
       "  0.0,\n",
       "  -0.9959263967893918,\n",
       "  -0.818566490778856,\n",
       "  0.2388000013859208,\n",
       "  -0.8096429344272024,\n",
       "  1.1,\n",
       "  1.0624783330527188],\n",
       " [-1.54172804260251,\n",
       "  4.0,\n",
       "  -0.6593495207079818,\n",
       "  -1.297078661698546,\n",
       "  0.8678482065162261,\n",
       "  1.4246769246643676,\n",
       "  1.2,\n",
       "  -0.1564314603937365],\n",
       " [0.022041659574998814,\n",
       "  3.0,\n",
       "  -1.5173134706595628,\n",
       "  1.8832284355110394,\n",
       "  -0.07923929411116751,\n",
       "  -0.22973648053417775,\n",
       "  0.95,\n",
       "  0.3430918583077907],\n",
       " [-1.0983090255919747,\n",
       "  0.0,\n",
       "  -0.4648448452271695,\n",
       "  0.1602092717289311,\n",
       "  -1.1717679357719093,\n",
       "  1.7322351143595394,\n",
       "  1.1,\n",
       "  -1.630235912605879],\n",
       " [-0.044338923348275966,\n",
       "  4.0,\n",
       "  1.0890733063001765,\n",
       "  0.9344660163569095,\n",
       "  0.37854991905794,\n",
       "  -0.014724192828883384,\n",
       "  1.2,\n",
       "  0.2073021279325344],\n",
       " [1.5677342643981182,\n",
       "  2.0,\n",
       "  -0.9303362519758515,\n",
       "  1.2679206730269463,\n",
       "  0.9487968181574551,\n",
       "  1.388223745275996,\n",
       "  1.05,\n",
       "  -0.04829083712695501],\n",
       " [-0.629472559856991,\n",
       "  4.0,\n",
       "  -0.8493519260106153,\n",
       "  -1.1909636114328643,\n",
       "  1.2899736664878667,\n",
       "  1.4891797582760071,\n",
       "  1.2,\n",
       "  -0.6627317562734406],\n",
       " [-1.4918531925970278,\n",
       "  2.0,\n",
       "  0.6888467830199863,\n",
       "  0.439853813180015,\n",
       "  0.9072745516797678,\n",
       "  1.764330112815943,\n",
       "  1.05,\n",
       "  -0.2823650602408239],\n",
       " [0.8693295293212092,\n",
       "  5.0,\n",
       "  -0.9019590038018883,\n",
       "  0.0783549796528362,\n",
       "  -0.7462305076525426,\n",
       "  -0.49044832433072383,\n",
       "  0.85,\n",
       "  -0.3393196142630449],\n",
       " [0.6343461129846818,\n",
       "  4.0,\n",
       "  0.6111711021232745,\n",
       "  -1.024373441305656,\n",
       "  1.2566162397329779,\n",
       "  -1.9367169978719025,\n",
       "  1.2,\n",
       "  0.8825027414622183],\n",
       " [-1.0110536756714963,\n",
       "  4.0,\n",
       "  -0.19322371161647925,\n",
       "  1.2179381541311682,\n",
       "  0.12709097572446681,\n",
       "  -0.9054164271323003,\n",
       "  1.2,\n",
       "  0.4111087772058439],\n",
       " [-1.6678988409382052,\n",
       "  3.0,\n",
       "  0.8645718794957056,\n",
       "  0.6747989293837608,\n",
       "  0.9877852399882106,\n",
       "  0.03842419658029123,\n",
       "  0.95,\n",
       "  -0.566108509927332],\n",
       " [-1.443467143635005,\n",
       "  2.0,\n",
       "  0.7732435821149719,\n",
       "  1.2215184935913563,\n",
       "  0.6135310606849994,\n",
       "  0.2708450703618718,\n",
       "  1.05,\n",
       "  -1.6872963760951114],\n",
       " [-1.2825716683215094,\n",
       "  0.0,\n",
       "  1.0355095324175045,\n",
       "  -0.9929068330853967,\n",
       "  0.22725937389082376,\n",
       "  1.872049891463473,\n",
       "  1.1,\n",
       "  0.6497609159264782],\n",
       " [0.9178114453125035,\n",
       "  2.0,\n",
       "  0.23990377751521522,\n",
       "  0.8020321317311392,\n",
       "  0.5725079980361908,\n",
       "  0.42868554728220004,\n",
       "  1.05,\n",
       "  -1.554763840151278],\n",
       " [-0.8086026459626948,\n",
       "  0.0,\n",
       "  -0.16440617639384583,\n",
       "  -1.300983228803448,\n",
       "  0.548487553827949,\n",
       "  1.0523365745184263,\n",
       "  1.1,\n",
       "  1.055533774883865],\n",
       " [1.5577206629169738,\n",
       "  2.0,\n",
       "  -0.6085540884541047,\n",
       "  1.024689188165129,\n",
       "  0.8402754790294694,\n",
       "  1.2098911109464423,\n",
       "  1.05,\n",
       "  0.9325549113004598],\n",
       " [-0.02274448184777088,\n",
       "  4.0,\n",
       "  -0.6089096229723513,\n",
       "  0.04159525050455698,\n",
       "  0.9751728752718762,\n",
       "  -0.44760889893719313,\n",
       "  1.2,\n",
       "  -1.1316793533365197],\n",
       " [-0.2878275557083881,\n",
       "  5.0,\n",
       "  -0.7283769386234598,\n",
       "  0.7936541403211782,\n",
       "  0.035749041945396264,\n",
       "  0.371569105619158,\n",
       "  0.85,\n",
       "  0.8176198677586294],\n",
       " [-0.21502034495876435,\n",
       "  2.0,\n",
       "  -0.9977676499111225,\n",
       "  -0.2691904170110583,\n",
       "  -1.1239466687006863,\n",
       "  -0.43168589073566177,\n",
       "  1.05,\n",
       "  -0.7922807612136734],\n",
       " [-0.40969919219100515,\n",
       "  5.0,\n",
       "  -0.52644991894692,\n",
       "  -0.4831430901604079,\n",
       "  -0.8111625084856786,\n",
       "  1.5836755808396745,\n",
       "  0.85,\n",
       "  1.0644439378352697],\n",
       " [-0.13715027145162664,\n",
       "  0.0,\n",
       "  0.6912909449580866,\n",
       "  -0.3072720807068615,\n",
       "  -1.3655591023864726,\n",
       "  -0.970942438900918,\n",
       "  1.1,\n",
       "  0.1486962416241312],\n",
       " [-1.9034463394229046,\n",
       "  0.0,\n",
       "  0.24784728046587706,\n",
       "  -1.1678332107489708,\n",
       "  0.162926666110635,\n",
       "  -0.29719229399593794,\n",
       "  1.1,\n",
       "  -1.59925504069117],\n",
       " [-0.41326269371229923,\n",
       "  0.0,\n",
       "  -0.6101844728646074,\n",
       "  -1.1771738172508783,\n",
       "  0.8651903504338732,\n",
       "  1.3621484169644675,\n",
       "  1.1,\n",
       "  0.9962444282614243],\n",
       " [-1.2369401712679557,\n",
       "  5.0,\n",
       "  0.7522339094950241,\n",
       "  -0.759556233659525,\n",
       "  0.21313321251195974,\n",
       "  0.4449558253993089,\n",
       "  0.85,\n",
       "  1.0960452734276431],\n",
       " [-1.7975683615586417,\n",
       "  5.0,\n",
       "  1.0465214938653609,\n",
       "  1.188872404268378,\n",
       "  0.4534173548276652,\n",
       "  -1.4982019818260779,\n",
       "  0.85,\n",
       "  0.25917718668685735],\n",
       " [-1.056367179652472,\n",
       "  0.0,\n",
       "  0.20384350507038534,\n",
       "  -0.6739508143051692,\n",
       "  -0.3114736004040144,\n",
       "  -1.1316907914286223,\n",
       "  1.1,\n",
       "  0.5797410781096316],\n",
       " [-0.815435791981914,\n",
       "  0.0,\n",
       "  0.9442326627833718,\n",
       "  -0.4846886979676148,\n",
       "  -0.6835411756229918,\n",
       "  0.353139449595583,\n",
       "  1.1,\n",
       "  0.9063930339611357],\n",
       " [0.13749700393649097,\n",
       "  2.0,\n",
       "  1.0201335248096153,\n",
       "  0.9290127376683827,\n",
       "  -3.2577598252453934,\n",
       "  0.5759556413149518,\n",
       "  1.05,\n",
       "  -0.6544202267008052],\n",
       " [0.0419074433999058,\n",
       "  2.0,\n",
       "  0.333318078205298,\n",
       "  -0.5920226815275329,\n",
       "  0.7336888603586388,\n",
       "  0.3202549670346314,\n",
       "  1.05,\n",
       "  0.11701539774983757],\n",
       " [-0.10774205720545262,\n",
       "  4.0,\n",
       "  -0.38284627304165014,\n",
       "  0.22624835628161558,\n",
       "  1.0010907509207456,\n",
       "  -1.0994650628098692,\n",
       "  1.2,\n",
       "  1.0311707297544126],\n",
       " [-0.17071880744090406,\n",
       "  1.0,\n",
       "  0.8483427686023616,\n",
       "  -1.024243569297473,\n",
       "  0.664778984956773,\n",
       "  -0.9206157729144246,\n",
       "  0.9,\n",
       "  1.0591989253739682],\n",
       " [-0.6190465242269608,\n",
       "  1.0,\n",
       "  -0.23424072639958224,\n",
       "  0.6968175474222944,\n",
       "  -0.05040549750181092,\n",
       "  1.8072698333477664,\n",
       "  0.9,\n",
       "  0.5356813028596316],\n",
       " [0.1909511526594579,\n",
       "  0.0,\n",
       "  -1.484285056669643,\n",
       "  1.238779934954915,\n",
       "  0.8444732184367155,\n",
       "  1.3203654377308045,\n",
       "  1.1,\n",
       "  0.935117034981291],\n",
       " [1.3279387675899277,\n",
       "  1.0,\n",
       "  -1.5076839691115518,\n",
       "  0.7217380834323982,\n",
       "  0.773547169729334,\n",
       "  0.03711645089902788,\n",
       "  0.9,\n",
       "  0.03786607503254252],\n",
       " [-1.3850911925909655,\n",
       "  3.0,\n",
       "  -1.655782581582355,\n",
       "  -1.3149905118130212,\n",
       "  0.5201965376147322,\n",
       "  -1.9303905099323955,\n",
       "  0.95,\n",
       "  0.7274558681260799],\n",
       " [-0.574783771514393,\n",
       "  1.0,\n",
       "  -0.8672475467058212,\n",
       "  -0.8222201995449174,\n",
       "  0.17082970265874908,\n",
       "  0.14749088868836296,\n",
       "  0.9,\n",
       "  0.77773695276313],\n",
       " [0.7007753946354882,\n",
       "  0.0,\n",
       "  0.9698398150266928,\n",
       "  -0.16710626419218422,\n",
       "  -0.5473198920342582,\n",
       "  1.1509039583691574,\n",
       "  1.1,\n",
       "  0.8491926172484631],\n",
       " [1.5842245479278754,\n",
       "  1.0,\n",
       "  -0.009235061955434705,\n",
       "  -0.6784559516843129,\n",
       "  0.7192148069224129,\n",
       "  -0.7674783928969002,\n",
       "  0.9,\n",
       "  0.8183379203468418],\n",
       " [0.6519400895513188,\n",
       "  4.0,\n",
       "  -0.785051002685034,\n",
       "  -0.6100622981420205,\n",
       "  0.6042673997681524,\n",
       "  -1.4045035686330727,\n",
       "  1.2,\n",
       "  -1.77273019198551],\n",
       " [1.6571673107261913,\n",
       "  3.0,\n",
       "  1.2788411773838706,\n",
       "  0.7326121221224547,\n",
       "  0.8376517351368482,\n",
       "  -0.027575598712828046,\n",
       "  0.95,\n",
       "  -0.12908255729132279],\n",
       " [0.5135062076635251,\n",
       "  2.0,\n",
       "  0.6855597232959317,\n",
       "  1.6403903114653093,\n",
       "  0.20425795436072286,\n",
       "  0.008539260399762971,\n",
       "  1.05,\n",
       "  0.13828779759664805],\n",
       " [0.6489893211936638,\n",
       "  5.0,\n",
       "  0.8621238380149379,\n",
       "  1.8187618550265818,\n",
       "  1.3458241829496762,\n",
       "  -0.2748190092102175,\n",
       "  0.85,\n",
       "  1.0485890344224411],\n",
       " [1.0223268375653265,\n",
       "  1.0,\n",
       "  1.4144351863397862,\n",
       "  0.6384826851163312,\n",
       "  0.8049986852794256,\n",
       "  -0.728525969823303,\n",
       "  0.9,\n",
       "  -0.7807938173454582],\n",
       " [-1.4462244408862672,\n",
       "  5.0,\n",
       "  -1.0986739529564922,\n",
       "  -0.423453577828789,\n",
       "  0.9695594753495042,\n",
       "  0.5871131007385616,\n",
       "  0.85,\n",
       "  0.7860089154752581],\n",
       " [1.4356165123198747,\n",
       "  1.0,\n",
       "  -0.7945014330197705,\n",
       "  -0.7555065536571037,\n",
       "  0.3358590313803005,\n",
       "  -0.2884869454637447,\n",
       "  0.9,\n",
       "  -1.289506558795335],\n",
       " [0.8058105957667642,\n",
       "  3.0,\n",
       "  -1.1243447302811975,\n",
       "  0.12580856487647704,\n",
       "  -1.9763651311841322,\n",
       "  -0.2736990470356211,\n",
       "  0.95,\n",
       "  0.5253214813860185],\n",
       " [0.8818947572798912,\n",
       "  5.0,\n",
       "  -0.5758590899504084,\n",
       "  -0.4256942873964351,\n",
       "  0.7097996621069967,\n",
       "  1.7360769899183355,\n",
       "  0.85,\n",
       "  -1.2917024596167181],\n",
       " [-1.1842805199396815,\n",
       "  3.0,\n",
       "  -1.5226923528162746,\n",
       "  -1.0252797412413064,\n",
       "  0.26155520993478554,\n",
       "  0.20486412069444498,\n",
       "  0.95,\n",
       "  -0.45239577187562496],\n",
       " [-0.3832104619187482,\n",
       "  4.0,\n",
       "  1.068178531687896,\n",
       "  0.2227167060260901,\n",
       "  0.6773266490903819,\n",
       "  0.2627189242890841,\n",
       "  1.2,\n",
       "  0.6487886319423101],\n",
       " [1.1558344775539513,\n",
       "  5.0,\n",
       "  1.673611948655398,\n",
       "  -0.1572807226875543,\n",
       "  0.04127626643758894,\n",
       "  0.02996224689499427,\n",
       "  0.85,\n",
       "  1.0375150873706838],\n",
       " [-0.5078243400023428,\n",
       "  2.0,\n",
       "  -0.5278973359832414,\n",
       "  1.3882453916376651,\n",
       "  -0.7518394641336525,\n",
       "  -0.4428889757589022,\n",
       "  1.05,\n",
       "  0.43245222714984705],\n",
       " [0.4001422423642954,\n",
       "  4.0,\n",
       "  0.6647740625076138,\n",
       "  1.166773193084204,\n",
       "  0.44274801132305436,\n",
       "  0.7263230764926653,\n",
       "  1.2,\n",
       "  -0.7167954641760053],\n",
       " [-1.2607659824960713,\n",
       "  2.0,\n",
       "  -1.6823953087168317,\n",
       "  1.5161277116699012,\n",
       "  1.1211094977192504,\n",
       "  1.8386327481615017,\n",
       "  1.05,\n",
       "  -1.6644827100174249],\n",
       " [1.2940766755478867,\n",
       "  5.0,\n",
       "  -0.39372457818607853,\n",
       "  -0.7140494051659467,\n",
       "  -0.5343060162067279,\n",
       "  0.6550369334640871,\n",
       "  0.85,\n",
       "  -1.6723313740796155],\n",
       " [-1.397984720875754,\n",
       "  4.0,\n",
       "  1.067374851947803,\n",
       "  -0.8058897868764643,\n",
       "  -0.8241751121151921,\n",
       "  0.07554114097481303,\n",
       "  1.2,\n",
       "  1.0418286298944102],\n",
       " [0.17671549009091075,\n",
       "  0.0,\n",
       "  0.06111711066709335,\n",
       "  -1.0134554078644615,\n",
       "  0.07078048870526171,\n",
       "  0.22893976947010916,\n",
       "  1.1,\n",
       "  -0.26321371126661863],\n",
       " [0.8889495896111511,\n",
       "  4.0,\n",
       "  -0.8892537329870331,\n",
       "  -1.1552455424467236,\n",
       "  -1.4109553751024047,\n",
       "  -0.7698258560602265,\n",
       "  1.2,\n",
       "  -1.1925779656654163],\n",
       " [-0.6875841574705581,\n",
       "  0.0,\n",
       "  -0.026551332049740948,\n",
       "  -1.3903526592834021,\n",
       "  -0.9642400001300215,\n",
       "  1.0808802134196012,\n",
       "  1.1,\n",
       "  0.8719195841362862],\n",
       " [0.6939091950080599,\n",
       "  0.0,\n",
       "  -0.08175156271373157,\n",
       "  1.186517493613272,\n",
       "  0.6518530840380609,\n",
       "  -1.105753650298603,\n",
       "  1.1,\n",
       "  0.10690270440659269],\n",
       " [0.5477731830220035,\n",
       "  1.0,\n",
       "  -0.10705197539590325,\n",
       "  -1.278114806362511,\n",
       "  0.34729552153336235,\n",
       "  1.2090673938643357,\n",
       "  0.9,\n",
       "  -0.36442749429798843],\n",
       " [-0.01240085502058253,\n",
       "  3.0,\n",
       "  0.15989135727899612,\n",
       "  -0.3449180670936605,\n",
       "  -0.7582782455385934,\n",
       "  0.10019312449364531,\n",
       "  0.95,\n",
       "  0.1278182405946403],\n",
       " [1.1876047516814727,\n",
       "  0.0,\n",
       "  -1.3175431940174012,\n",
       "  -0.6128617804169998,\n",
       "  0.8240224285377133,\n",
       "  1.7098988664057277,\n",
       "  1.1,\n",
       "  0.38715797766446614],\n",
       " [-0.3051715129833663,\n",
       "  3.0,\n",
       "  -1.1580764962975552,\n",
       "  -0.27943612663626455,\n",
       "  -0.02415805669777556,\n",
       "  -0.20123932519884388,\n",
       "  0.95,\n",
       "  -0.7531553327284488],\n",
       " [0.21887720567184554,\n",
       "  0.0,\n",
       "  -0.6281183704032558,\n",
       "  -0.3359914441280788,\n",
       "  0.7637231958665927,\n",
       "  -1.4148715816565993,\n",
       "  1.1,\n",
       "  -0.8685161142021719],\n",
       " [0.5823127880893804,\n",
       "  1.0,\n",
       "  0.10428629137777648,\n",
       "  0.4676922542548184,\n",
       "  0.7516449897097189,\n",
       "  -0.012845701262955042,\n",
       "  0.9,\n",
       "  -0.3315495751373742],\n",
       " [-0.21399042263730522,\n",
       "  2.0,\n",
       "  -0.17873373495641803,\n",
       "  -0.3628771395650574,\n",
       "  0.6665952838502177,\n",
       "  -1.3278441820817464,\n",
       "  1.05,\n",
       "  0.8906969612125719],\n",
       " [-0.3099666497840758,\n",
       "  4.0,\n",
       "  0.24140444726871682,\n",
       "  0.9344452070471208,\n",
       "  -0.5304436726828464,\n",
       "  -0.6831207074278065,\n",
       "  1.2,\n",
       "  -0.33640636034769683],\n",
       " [1.3585746473913438,\n",
       "  4.0,\n",
       "  1.3767153046242113,\n",
       "  -1.142512905299146,\n",
       "  0.8035701178193928,\n",
       "  -0.5250341599942278,\n",
       "  1.2,\n",
       "  -0.9649086684343728],\n",
       " [1.3358613855233417,\n",
       "  1.0,\n",
       "  -0.42785193807207567,\n",
       "  1.7861934759023372,\n",
       "  0.8311425619763371,\n",
       "  0.15256944875451336,\n",
       "  0.9,\n",
       "  -0.22474642565083774],\n",
       " [-0.4442438702769619,\n",
       "  3.0,\n",
       "  -0.8088306810114477,\n",
       "  1.0010826821431975,\n",
       "  -0.7435384799777326,\n",
       "  -0.6436090199291997,\n",
       "  0.95,\n",
       "  0.3847560398536545],\n",
       " [-1.2113055635107424,\n",
       "  3.0,\n",
       "  1.1012062229843487,\n",
       "  -1.1847521169194106,\n",
       "  -0.9886151392756015,\n",
       "  -1.648383889818362,\n",
       "  0.95,\n",
       "  -1.2508789602024213],\n",
       " [0.16382794308446536,\n",
       "  4.0,\n",
       "  -1.4146986017727337,\n",
       "  1.0785873679835232,\n",
       "  1.0374747587265025,\n",
       "  1.6743523244060794,\n",
       "  1.2,\n",
       "  0.6512961220572847],\n",
       " [-1.9546567105455865,\n",
       "  1.0,\n",
       "  0.6874352367719762,\n",
       "  -0.2099815574423758,\n",
       "  0.11799688107733151,\n",
       "  0.6321939814417459,\n",
       "  0.9,\n",
       "  0.802365441012455],\n",
       " [1.5645470224695488,\n",
       "  4.0,\n",
       "  -0.8930920762168173,\n",
       "  -1.0839824123688453,\n",
       "  0.8883305792416947,\n",
       "  0.0347871658370183,\n",
       "  1.2,\n",
       "  1.059558489113728],\n",
       " [-0.8878182279603947,\n",
       "  2.0,\n",
       "  0.8737920703783656,\n",
       "  0.14906616823302712,\n",
       "  0.04019114772411904,\n",
       "  1.5022105349465333,\n",
       "  1.05,\n",
       "  -1.0328342776127075],\n",
       " [-0.8994729724406223,\n",
       "  4.0,\n",
       "  -0.835642591263937,\n",
       "  -1.0517024183485437,\n",
       "  0.9298719836781809,\n",
       "  -0.039237562510032,\n",
       "  1.2,\n",
       "  -1.0376376286121873]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[num_col_names] = scaler.transform(x_test[num_col_names])\n",
    "x_test = x_test.values.tolist()\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471101f5-8c1e-4cca-9c2f-03422c3be5a3",
   "metadata": {},
   "source": [
    "### Variáveis de entrada mais importantes para as tomadas de decisão do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e69cad-b5c7-45d3-9374-252e50b9b44c",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f9cb1f5-9e9b-42c1-8b33-ddeeebb86066",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'classifier':\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # Realizando Random Forest para identificar a relevância das variáveis.\n",
    "    # Feature Extraction by Random Forest\n",
    "    model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                           criterion='gini', max_depth=None, max_features=3, # nao sei o que eh este max_features\n",
    "                           max_leaf_nodes=None, max_samples=None,\n",
    "                           min_impurity_decrease=0.0,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=10,\n",
    "                           n_jobs=None, oob_score=False, random_state=None,\n",
    "                           verbose=0, warm_start=False)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    feature_importances_val = model.feature_importances_\n",
    "    pd.options.display.float_format = '{:.10f}'.format\n",
    "    \n",
    "    x_pd = pd.DataFrame(x_train, columns=col_names_order[:-1])\n",
    "    feature_importances = pd.DataFrame(feature_importances_val,\n",
    "                                       index = x_pd.columns,\n",
    "                                       columns=['importance']).sort_values('importance', ascending = False)\n",
    "    print(f'Accuracy: {model.score(x_test, y_test) * 100}')\n",
    "    print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e73007-2f3d-4a6e-925e-08f49f3ac156",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34b57b03-3f6d-475d-8003-e1baa11ac100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 14.97715580489841\n",
      "0-feature_1, Score: 0.2278484666859862\n",
      "1-feature_2, Score: 0.0\n",
      "2-feature_3, Score: 0.246248200717604\n",
      "3-feature_4, Score: 0.17786548467249905\n",
      "4-feature_5, Score: 0.0\n",
      "5-feature_6, Score: 0.0\n",
      "6-feature_7, Score: 0.0\n",
      "7-feature_8, Score: 0.34803784792391074\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    model = DecisionTreeClassifier(max_depth=3)\n",
    "else:\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    model = DecisionTreeRegressor(max_depth=3)    \n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    print(f'Accuracy: {model.score(x_test, y_test) * 100}')\n",
    "    print(f'Confusion matrix: {confusion_matrix(model.predict(x_test), y_test)}')\n",
    "else:\n",
    "    print(f'MSE: {mean_squared_error(model.predict(x_test), y_test)}')\n",
    "\n",
    "importance = model.feature_importances_\n",
    "for idx, score in enumerate(importance):\n",
    "    print(f'{idx}-{df.keys()[idx]}, Score: {score}')\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7a775-07df-43ad-b57c-a90dae2dc6ef",
   "metadata": {},
   "source": [
    "## Treinar diversos estimators disponíveis no Sklearn\n",
    "https://scikit-learn.org/stable/supervised_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "174d9ef1-cf9f-495a-bc0f-14ad12fc7900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ARDRegression\n",
      "Appending AdaBoostRegressor\n",
      "Appending BaggingRegressor\n",
      "Appending BayesianRidge\n",
      "Appending CCA\n",
      "Appending DecisionTreeRegressor\n",
      "Appending DummyRegressor\n",
      "Appending ElasticNet\n",
      "Appending ElasticNetCV\n",
      "Appending ExtraTreeRegressor\n",
      "Appending ExtraTreesRegressor\n",
      "Appending GammaRegressor\n",
      "Appending GaussianProcessRegressor\n",
      "Appending GradientBoostingRegressor\n",
      "Appending HistGradientBoostingRegressor\n",
      "Appending HuberRegressor\n",
      "Appending IsotonicRegression\n",
      "Appending KNeighborsRegressor\n",
      "Appending KernelRidge\n",
      "Appending Lars\n",
      "Appending LarsCV\n",
      "Appending Lasso\n",
      "Appending LassoCV\n",
      "Appending LassoLars\n",
      "Appending LassoLarsCV\n",
      "Appending LassoLarsIC\n",
      "Appending LinearRegression\n",
      "Appending LinearSVR\n",
      "Appending MLPRegressor\n",
      "Appending MultiOutputRegressor\n",
      "MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultiTaskElasticNet\n",
      "Appending MultiTaskElasticNetCV\n",
      "Appending MultiTaskLasso\n",
      "Appending MultiTaskLassoCV\n",
      "Appending NuSVR\n",
      "Appending OrthogonalMatchingPursuit\n",
      "Appending OrthogonalMatchingPursuitCV\n",
      "Appending PLSCanonical\n",
      "Appending PLSRegression\n",
      "Appending PassiveAggressiveRegressor\n",
      "Appending PoissonRegressor\n",
      "Appending QuantileRegressor\n",
      "Appending RANSACRegressor\n",
      "Appending RadiusNeighborsRegressor\n",
      "Appending RandomForestRegressor\n",
      "Appending RegressorChain\n",
      "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending Ridge\n",
      "Appending RidgeCV\n",
      "Appending SGDRegressor\n",
      "Appending SVR\n",
      "Appending StackingRegressor\n",
      "StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending TheilSenRegressor\n",
      "Appending TransformedTargetRegressor\n",
      "Appending TweedieRegressor\n",
      "Appending VotingRegressor\n",
      "VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# classifier, regressor, cluster, transformer\n",
    "estimators = all_estimators(type_filter=model_type)\n",
    "\n",
    "all_estimators = {}\n",
    "for name, estimator in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        est = estimator()\n",
    "        all_estimators[name] = est\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a626346-eda4-4754-be86-e8dbaddb3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_sklearn_estimators(estimators, x_train, y_train, x_test, y_test, model_type='classifier'):\n",
    "    if model_type == 'classifier':\n",
    "        best_acc = ['', 0.0]  # [estimator_name, accuracy]\n",
    "    else:\n",
    "        best_acc = ['', np.inf]  # [estimator_name, error]\n",
    "    \n",
    "    for estimator_name, estimator in estimators.items():\n",
    "        try:\n",
    "            print(f'##### {estimator_name} #####')\n",
    "\n",
    "            estimator.fit(x_train, y_train)\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                print('Train ACC: %.3f%%' % (estimator.score(x_train, y_train) * 100.00))\n",
    "            else:\n",
    "                train_mse = mean_squared_error(estimator.predict(x_train), y_train)\n",
    "                print('Train MSE: %.3f' % (train_mse))\n",
    "                print(f'Train inference error (RMSE): ±{math.sqrt(train_mse)}')\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                test_acc = estimator.score(x_test, y_test) * 100.00\n",
    "                print('Test ACC: %.3f%%' % (test_acc))\n",
    "            else:\n",
    "                test_mse = mean_squared_error(estimator.predict(x_test), y_test)\n",
    "                print('Test MSE: %.3f' % (test_mse))\n",
    "                print(f'Test inference error (RMSE): ±{math.sqrt(test_mse)}')\n",
    "            print()\n",
    "            print(test_mse)\n",
    "            if model_type == 'classifier' and test_acc > best_acc[1]:\n",
    "                best_acc = [estimator_name, test_acc]\n",
    "            elif model_type == 'regressor' and test_mse < best_acc[1]:\n",
    "                best_acc = [estimator_name, test_mse, math.sqrt(test_mse)]\n",
    "            \n",
    "            # Confusion Matrix\n",
    "            if model_type == 'classifier':\n",
    "                preds = estimator.predict(x_test)\n",
    "                matrix = confusion_matrix(y_test, preds)\n",
    "                print('Confusion Matrix Test:')\n",
    "                print(matrix)\n",
    "        except Exception as e:\n",
    "            print(f'Error ({estimator_name}): {e}')\n",
    "\n",
    "    print('########## Best Estimator ##########')\n",
    "    print(best_acc)\n",
    "    \n",
    "    return estimators, best_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c94079be-a30a-4a7b-97f4-7785c869ac03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ARDRegression #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.6158464492163773\n",
      "Test MSE: 7.220\n",
      "Test inference error (RMSE): ±2.6869854381604505\n",
      "\n",
      "7.219890744886308\n",
      "##### AdaBoostRegressor #####\n",
      "Train MSE: 4.895\n",
      "Train inference error (RMSE): ±2.212475395755202\n",
      "Test MSE: 7.101\n",
      "Test inference error (RMSE): ±2.6647190277905404\n",
      "\n",
      "7.100727497068962\n",
      "##### BaggingRegressor #####\n",
      "Train MSE: 0.758\n",
      "Train inference error (RMSE): ±0.8704221831575791\n",
      "Test MSE: 4.727\n",
      "Test inference error (RMSE): ±2.174275658904506\n",
      "\n",
      "4.7274746409046235\n",
      "##### BayesianRidge #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.6145450885771258\n",
      "Test MSE: 7.234\n",
      "Test inference error (RMSE): ±2.689609127284447\n",
      "\n",
      "7.233997257571804\n",
      "##### CCA #####\n",
      "Error (CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0\n",
      "Test MSE: 8.435\n",
      "Test inference error (RMSE): ±2.9043854763662535\n",
      "\n",
      "8.43545499532723\n",
      "##### DummyRegressor #####\n",
      "Train MSE: 22.053\n",
      "Train inference error (RMSE): ±4.69604139437622\n",
      "Test MSE: 23.544\n",
      "Test inference error (RMSE): ±4.85225811721616\n",
      "\n",
      "23.544408836090117\n",
      "##### ElasticNet #####\n",
      "Train MSE: 11.064\n",
      "Train inference error (RMSE): ±3.3263329234893715\n",
      "Test MSE: 12.209\n",
      "Test inference error (RMSE): ±3.494149796201499\n",
      "\n",
      "12.209082798294979\n",
      "##### ElasticNetCV #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.61588262672324\n",
      "Test MSE: 7.231\n",
      "Test inference error (RMSE): ±2.6891001815865567\n",
      "\n",
      "7.231259786608852\n",
      "##### ExtraTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0\n",
      "Test MSE: 10.365\n",
      "Test inference error (RMSE): ±3.2195040491807627\n",
      "\n",
      "10.365206322691327\n",
      "##### ExtraTreesRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.319166147233616e-15\n",
      "Test MSE: 3.714\n",
      "Test inference error (RMSE): ±1.9271789936866275\n",
      "\n",
      "3.7140188737070026\n",
      "##### GammaRegressor #####\n",
      "Error (GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GaussianProcessRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.9666693300707673e-10\n",
      "Test MSE: 4.820\n",
      "Test inference error (RMSE): ±2.195424958478551\n",
      "\n",
      "4.819890748310547\n",
      "##### GradientBoostingRegressor #####\n",
      "Train MSE: 0.901\n",
      "Train inference error (RMSE): ±0.9492914631137053\n",
      "Test MSE: 3.583\n",
      "Test inference error (RMSE): ±1.8928515191030508\n",
      "\n",
      "3.5828868733707275\n",
      "##### HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.319\n",
      "Train inference error (RMSE): ±0.5644741877730173\n",
      "Test MSE: 2.615\n",
      "Test inference error (RMSE): ±1.6169481301342206\n",
      "\n",
      "2.6145212555445525\n",
      "##### HuberRegressor #####\n",
      "Train MSE: 7.025\n",
      "Train inference error (RMSE): ±2.6505641762994707\n",
      "Test MSE: 7.734\n",
      "Test inference error (RMSE): ±2.7810081607961044\n",
      "\n",
      "7.734006390414532\n",
      "##### IsotonicRegression #####\n",
      "Error (IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### KNeighborsRegressor #####\n",
      "Train MSE: 2.926\n",
      "Train inference error (RMSE): ±1.710488403842964\n",
      "Test MSE: 5.285\n",
      "Test inference error (RMSE): ±2.2990097023389056\n",
      "\n",
      "5.285445611448424\n",
      "##### KernelRidge #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.6145569170814373\n",
      "Test MSE: 7.229\n",
      "Test inference error (RMSE): ±2.688631319287201\n",
      "\n",
      "7.228738371052036\n",
      "##### Lars #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.614512758466052\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.690003724931947\n",
      "\n",
      "7.23612004014775\n",
      "##### LarsCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153037843541025\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.686851544858022\n",
      "\n",
      "7.219171224105941\n",
      "##### Lasso #####\n",
      "Train MSE: 11.984\n",
      "Train inference error (RMSE): ±3.4617677541911545\n",
      "Test MSE: 13.408\n",
      "Test inference error (RMSE): ±3.661729326082717\n",
      "\n",
      "13.408261657494188\n",
      "##### LassoCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153224305984146\n",
      "Test MSE: 7.220\n",
      "Test inference error (RMSE): ±2.6869977119132096\n",
      "\n",
      "7.219956703826822\n",
      "##### LassoLars #####\n",
      "Train MSE: 11.984\n",
      "Train inference error (RMSE): ±3.4617677788458177\n",
      "Test MSE: 13.408\n",
      "Test inference error (RMSE): ±3.6617293427989464\n",
      "\n",
      "13.408261779914804\n",
      "##### LassoLarsCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153037843541025\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.686851544858022\n",
      "\n",
      "7.219171224105941\n",
      "##### LassoLarsIC #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6151837850165744\n",
      "Test MSE: 7.213\n",
      "Test inference error (RMSE): ±2.685648934992958\n",
      "\n",
      "7.212710202028811\n",
      "##### LinearRegression #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.614512758466052\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.690003724931946\n",
      "\n",
      "7.2361200401477435\n",
      "##### LinearSVR #####\n",
      "Train MSE: 7.077\n",
      "Train inference error (RMSE): ±2.660245126190913\n",
      "Test MSE: 7.856\n",
      "Test inference error (RMSE): ±2.8028556767787496\n",
      "\n",
      "7.855999944850863\n",
      "##### MLPRegressor #####\n",
      "Train MSE: 1.499\n",
      "Train inference error (RMSE): ±1.2244382245603562\n",
      "Test MSE: 2.319\n",
      "Test inference error (RMSE): ±1.522741659890153\n",
      "\n",
      "2.3187421627650187\n",
      "##### MultiTaskElasticNet #####\n",
      "Train MSE: 11.064\n",
      "Train inference error (RMSE): ±3.3263329234893715\n",
      "Test MSE: 12.209\n",
      "Test inference error (RMSE): ±3.494149796201499\n",
      "\n",
      "12.209082798294979\n",
      "##### MultiTaskElasticNetCV #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.61588262672324\n",
      "Test MSE: 7.231\n",
      "Test inference error (RMSE): ±2.6891001815865567\n",
      "\n",
      "7.231259786608852\n",
      "##### MultiTaskLasso #####\n",
      "Train MSE: 11.984\n",
      "Train inference error (RMSE): ±3.461767754191155\n",
      "Test MSE: 13.408\n",
      "Test inference error (RMSE): ±3.661729326082718\n",
      "\n",
      "13.408261657494196\n",
      "##### MultiTaskLassoCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153224305984146\n",
      "Test MSE: 7.220\n",
      "Test inference error (RMSE): ±2.6869977119132096\n",
      "\n",
      "7.219956703826822\n",
      "##### NuSVR #####\n",
      "Train MSE: 3.399\n",
      "Train inference error (RMSE): ±1.8435682919173808\n",
      "Test MSE: 4.580\n",
      "Test inference error (RMSE): ±2.140058999138655\n",
      "\n",
      "4.579852519794343\n",
      "##### OrthogonalMatchingPursuit #####\n",
      "Train MSE: 17.799\n",
      "Train inference error (RMSE): ±4.218866045711959\n",
      "Test MSE: 19.910\n",
      "Test inference error (RMSE): ±4.462116885636721\n",
      "\n",
      "19.91048710108435\n",
      "##### OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 7.049\n",
      "Train inference error (RMSE): ±2.6549054136825814\n",
      "Test MSE: 7.596\n",
      "Test inference error (RMSE): ±2.756012181964678\n",
      "\n",
      "7.595603147137707\n",
      "##### PLSCanonical #####\n",
      "Error (PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614839628164346\n",
      "Test MSE: 7.244\n",
      "Test inference error (RMSE): ±2.691531099808594\n",
      "\n",
      "7.24433966123686\n",
      "##### PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.744\n",
      "Train inference error (RMSE): ±3.4269298453513017\n",
      "Test MSE: 11.310\n",
      "Test inference error (RMSE): ±3.362965360232946\n",
      "\n",
      "11.30953601412671\n",
      "##### PoissonRegressor #####\n",
      "Error (PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### QuantileRegressor #####\n",
      "Train MSE: 22.056\n",
      "Train inference error (RMSE): ±4.696428602526515\n",
      "Test MSE: 23.545\n",
      "Test inference error (RMSE): ±4.852329923308288\n",
      "\n",
      "23.54510568463301\n",
      "##### RANSACRegressor #####\n",
      "Train MSE: 8.596\n",
      "Train inference error (RMSE): ±2.931848600175211\n",
      "Test MSE: 10.346\n",
      "Test inference error (RMSE): ±3.2164512818721214\n",
      "\n",
      "10.345558848656813\n",
      "##### RadiusNeighborsRegressor #####\n",
      "Train MSE: 0.376\n",
      "Train inference error (RMSE): ±0.6132251849928873\n",
      "Error (RadiusNeighborsRegressor): Input contains NaN.\n",
      "##### RandomForestRegressor #####\n",
      "Train MSE: 0.500\n",
      "Train inference error (RMSE): ±0.7073633770970105\n",
      "Test MSE: 4.096\n",
      "Test inference error (RMSE): ±2.0237806486005656\n",
      "\n",
      "4.095688113650126\n",
      "##### Ridge #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.614515531209291\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.6898544161505313\n",
      "\n",
      "7.235316780084516\n",
      "##### RidgeCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614716712128365\n",
      "Test MSE: 7.234\n",
      "Test inference error (RMSE): ±2.6895970595287104\n",
      "\n",
      "7.233932342625485\n",
      "##### SGDRegressor #####\n",
      "Train MSE: 6.853\n",
      "Train inference error (RMSE): ±2.6178172047715895\n",
      "Test MSE: 7.286\n",
      "Test inference error (RMSE): ±2.6992983880498715\n",
      "\n",
      "7.286211787728635\n",
      "##### SVR #####\n",
      "Train MSE: 3.467\n",
      "Train inference error (RMSE): ±1.8620213516090756\n",
      "Test MSE: 4.751\n",
      "Test inference error (RMSE): ±2.1796774451167584\n",
      "\n",
      "4.750993764750719\n",
      "##### TheilSenRegressor #####\n",
      "Train MSE: 7.010\n",
      "Train inference error (RMSE): ±2.6477004728572373\n",
      "Test MSE: 7.715\n",
      "Test inference error (RMSE): ±2.777515416211715\n",
      "\n",
      "7.714591887293737\n",
      "##### TransformedTargetRegressor #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.614512758466052\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.690003724931946\n",
      "\n",
      "7.2361200401477435\n",
      "##### TweedieRegressor #####\n",
      "Train MSE: 10.531\n",
      "Train inference error (RMSE): ±3.2451523242908444\n",
      "Test MSE: 11.456\n",
      "Test inference error (RMSE): ±3.384675336420445\n",
      "\n",
      "11.456027132972853\n",
      "########## Best Estimator ##########\n",
      "['MLPRegressor', 2.3187421627650187, 1.522741659890153]\n",
      "Total time: 3.826639413833618\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimators_trained, best_estimator_name = run_sklearn_estimators(\n",
    "    all_estimators,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    model_type\n",
    ")\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fda6aea5-fd41-49f6-b7da-a5ef7d849c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_trained[best_estimator_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9bb95-4f93-497e-a7bd-fe9ce5e291d8",
   "metadata": {},
   "source": [
    "### Save Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f2b4f21-99f9-42af-89c1-dd2a21e11b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(estimators_trained[best_estimator_name], open('results/estimator_sklearn.sav', 'wb'))\n",
    "\n",
    "# Scaler\n",
    "pickle.dump(scaler, open('results/scaler.pkl','wb'))\n",
    "\n",
    "# Save columns names and informations\n",
    "data_to_save = {\n",
    "    'col_names_order': col_names_order,\n",
    "    'num_col_names': num_col_names,\n",
    "    'cat_col_names': cat_col_names,\n",
    "    'date_col_names': date_col_names,\n",
    "    'target_cols': target_cols,\n",
    "    'category_mappings': category_mappings,\n",
    "    'window_size': window_size\n",
    "}\n",
    "with open('results/columns_metadata_sklearn.json', 'w') as json_file:\n",
    "    json.dump(data_to_save, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70756f5f-6703-4179-91f9-9a2ee059e073",
   "metadata": {},
   "source": [
    "## Stacking estimators\n",
    "Classificador: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier\n",
    "\n",
    "Regressor: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37139066-befd-458e-919e-9e21bffceed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ARDRegression\n",
      "Appending AdaBoostRegressor\n",
      "Appending BaggingRegressor\n",
      "Appending BayesianRidge\n",
      "Appending CCA\n",
      "Appending DecisionTreeRegressor\n",
      "Appending DummyRegressor\n",
      "Appending ElasticNet\n",
      "Appending ElasticNetCV\n",
      "Appending ExtraTreeRegressor\n",
      "Appending ExtraTreesRegressor\n",
      "Appending GammaRegressor\n",
      "Appending GaussianProcessRegressor\n",
      "Appending GradientBoostingRegressor\n",
      "Appending HistGradientBoostingRegressor\n",
      "Appending HuberRegressor\n",
      "Appending IsotonicRegression\n",
      "Appending KNeighborsRegressor\n",
      "Appending KernelRidge\n",
      "Appending Lars\n",
      "Appending LarsCV\n",
      "Appending Lasso\n",
      "Appending LassoCV\n",
      "Appending LassoLars\n",
      "Appending LassoLarsCV\n",
      "Appending LassoLarsIC\n",
      "Appending LinearRegression\n",
      "Appending LinearSVR\n",
      "Appending MLPRegressor\n",
      "Appending MultiOutputRegressor\n",
      "MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultiTaskElasticNet\n",
      "Appending MultiTaskElasticNetCV\n",
      "Appending MultiTaskLasso\n",
      "Appending MultiTaskLassoCV\n",
      "Appending NuSVR\n",
      "Appending OrthogonalMatchingPursuit\n",
      "Appending OrthogonalMatchingPursuitCV\n",
      "Appending PLSCanonical\n",
      "Appending PLSRegression\n",
      "Appending PassiveAggressiveRegressor\n",
      "Appending PoissonRegressor\n",
      "Appending QuantileRegressor\n",
      "Appending RANSACRegressor\n",
      "Appending RadiusNeighborsRegressor\n",
      "Appending RandomForestRegressor\n",
      "Appending RegressorChain\n",
      "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending Ridge\n",
      "Appending RidgeCV\n",
      "Appending SGDRegressor\n",
      "Appending SVR\n",
      "Appending StackingRegressor\n",
      "StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending TheilSenRegressor\n",
      "Appending TransformedTargetRegressor\n",
      "Appending TweedieRegressor\n",
      "Appending VotingRegressor\n",
      "VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# classifier, regressor, cluster, transformer\n",
    "estimators = all_estimators(type_filter=model_type)\n",
    "\n",
    "all_estimators = {}\n",
    "for name, estimator in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        est = estimator()\n",
    "        all_estimators[name] = est\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "837e27c3-4b1c-4ba2-94a1-d1040bad2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_sklearn_estimators_with_stacking(estimators, x_train, y_train, x_test, y_test, model_type):\n",
    "    if model_type == 'classifier':\n",
    "        best_acc = ['', 0.0]  # [estimator_name, accuracy]\n",
    "    else:\n",
    "        best_acc = ['', np.inf]  # [estimator_name, error]\n",
    "    estimators_stacked_trained = {}\n",
    "    \n",
    "    idx = 0\n",
    "    for estimator_name, estimator in estimators.items():\n",
    "        count = 0\n",
    "        for estimator_name2, estimator2 in estimators.items():\n",
    "            if count <= idx:\n",
    "                count += 1\n",
    "                continue\n",
    "            try:\n",
    "                print(f'##### {estimator_name} - {estimator_name2} #####')\n",
    "\n",
    "                if model_type == 'classifier':\n",
    "                    stack = StackingClassifier([(estimator_name, copy.deepcopy(estimator)), (estimator_name2, copy.deepcopy(estimator2))],\n",
    "                                              final_estimator=LogisticRegression())\n",
    "                else:\n",
    "                    stack = StackingRegressor([(estimator_name, copy.deepcopy(estimator)), (estimator_name2, copy.deepcopy(estimator2))],\n",
    "                                              final_estimator=RidgeCV())\n",
    "\n",
    "                stack.fit(x_train, y_train)\n",
    "                \n",
    "                if model_type == 'classifier':\n",
    "                    print('Train ACC: %.3f%%' % (stack.score(x_train, y_train) * 100.00))\n",
    "                else:\n",
    "                    train_mse = mean_squared_error(stack.predict(x_train), y_train)\n",
    "                    print('Train MSE: %.3f' % (train_mse))\n",
    "                    print(f'Train inference error (RMSE): ±{math.sqrt(train_mse)}')\n",
    "                \n",
    "                if model_type == 'classifier':\n",
    "                    test_acc = stack.score(x_test, y_test) * 100.00\n",
    "                    print('Test ACC: %.3f%%' % (test_acc))\n",
    "                else:\n",
    "                    test_mse = mean_squared_error(stack.predict(x_test), y_test)\n",
    "                    print('Test MSE: %.3f' % (test_mse))\n",
    "                    print(f'Test inference error (RMSE): ±{math.sqrt(test_mse)}')\n",
    "        \n",
    "                if model_type == 'classifier' and test_acc > best_acc[1]:\n",
    "                    best_acc = [f'{estimator_name}-{estimator_name2}', test_acc]\n",
    "                elif model_type == 'regressor' and test_mse < best_acc[1]:\n",
    "                    best_acc = [f'{estimator_name}-{estimator_name2}', test_mse, math.sqrt(test_mse)]\n",
    "                \n",
    "                # Confusion Matrix\n",
    "                if model_type == 'classifier':\n",
    "                    preds = stack.predict(x_test)\n",
    "                    matrix = confusion_matrix(y_test, preds)\n",
    "                    print('Confusion Matrix Test:')\n",
    "                    print(matrix)\n",
    "\n",
    "                estimators_stacked_trained[f'{estimator_name}-{estimator_name2}'] = copy.deepcopy(stack)\n",
    "            except Exception as e:\n",
    "                print(f'Error ({estimator_name}-{estimator_name2}): {e}')\n",
    "                continue\n",
    "        \n",
    "        idx += 1\n",
    "\n",
    "    print('########## Best Estimator ##########')\n",
    "    print(best_acc)\n",
    "    \n",
    "    return estimators_stacked_trained, best_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f4d5044-760a-421c-9eee-908ad2d38951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ARDRegression - AdaBoostRegressor #####\n",
      "Train MSE: 3.353\n",
      "Train inference error (RMSE): ±1.8312042324809361\n",
      "Test MSE: 5.022\n",
      "Test inference error (RMSE): ±2.2410755048478372\n",
      "##### ARDRegression - BaggingRegressor #####\n",
      "Train MSE: 0.811\n",
      "Train inference error (RMSE): ±0.900632123182309\n",
      "Test MSE: 4.047\n",
      "Test inference error (RMSE): ±2.011812935785035\n",
      "##### ARDRegression - BayesianRidge #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6152174827031818\n",
      "Test MSE: 7.228\n",
      "Test inference error (RMSE): ±2.6885286677566413\n",
      "##### ARDRegression - CCA #####\n",
      "Error (ARDRegression-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ARDRegression - DecisionTreeRegressor #####\n",
      "Train MSE: 2.651\n",
      "Train inference error (RMSE): ±1.6281627130478848\n",
      "Test MSE: 5.623\n",
      "Test inference error (RMSE): ±2.3713667443814486\n",
      "##### ARDRegression - DummyRegressor #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.6159575754176663\n",
      "Test MSE: 7.225\n",
      "Test inference error (RMSE): ±2.6878620490998006\n",
      "##### ARDRegression - ElasticNet #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.6159610131203084\n",
      "Test MSE: 7.223\n",
      "Test inference error (RMSE): ±2.6875708716980573\n",
      "##### ARDRegression - ElasticNetCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.61533627773801\n",
      "Test MSE: 7.220\n",
      "Test inference error (RMSE): ±2.6870692400096066\n",
      "##### ARDRegression - ExtraTreeRegressor #####\n",
      "Train MSE: 3.447\n",
      "Train inference error (RMSE): ±1.8566050224646078\n",
      "Test MSE: 5.987\n",
      "Test inference error (RMSE): ±2.4469282263288195\n",
      "##### ARDRegression - ExtraTreesRegressor #####\n",
      "Train MSE: 0.896\n",
      "Train inference error (RMSE): ±0.9466293215505621\n",
      "Test MSE: 2.919\n",
      "Test inference error (RMSE): ±1.708506382565872\n",
      "##### ARDRegression - GammaRegressor #####\n",
      "Error (ARDRegression-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ARDRegression - GaussianProcessRegressor #####\n",
      "Train MSE: 0.457\n",
      "Train inference error (RMSE): ±0.6757279180305553\n",
      "Test MSE: 4.226\n",
      "Test inference error (RMSE): ±2.0556310346162623\n",
      "##### ARDRegression - GradientBoostingRegressor #####\n",
      "Train MSE: 0.801\n",
      "Train inference error (RMSE): ±0.8949433693126507\n",
      "Test MSE: 3.335\n",
      "Test inference error (RMSE): ±1.8263297965915455\n",
      "##### ARDRegression - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5810883836632166\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718641685287786\n",
      "##### ARDRegression - HuberRegressor #####\n",
      "Train MSE: 6.856\n",
      "Train inference error (RMSE): ±2.618314004613171\n",
      "Test MSE: 7.312\n",
      "Test inference error (RMSE): ±2.704137420600579\n",
      "##### ARDRegression - IsotonicRegression #####\n",
      "Error (ARDRegression-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ARDRegression - KNeighborsRegressor #####\n",
      "Train MSE: 2.760\n",
      "Train inference error (RMSE): ±1.6613991173503688\n",
      "Test MSE: 4.705\n",
      "Test inference error (RMSE): ±2.169040572325325\n",
      "##### ARDRegression - KernelRidge #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6148917810238617\n",
      "Test MSE: 7.230\n",
      "Test inference error (RMSE): ±2.688908047028544\n",
      "##### ARDRegression - Lars #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153059182215297\n",
      "Test MSE: 7.229\n",
      "Test inference error (RMSE): ±2.688637028947527\n",
      "##### ARDRegression - LarsCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153759895892095\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.686893128009901\n",
      "##### ARDRegression - Lasso #####\n",
      "Train MSE: 6.844\n",
      "Train inference error (RMSE): ±2.6160683391456723\n",
      "Test MSE: 7.205\n",
      "Test inference error (RMSE): ±2.6842843570213195\n",
      "##### ARDRegression - LassoCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153821609274455\n",
      "Test MSE: 7.220\n",
      "Test inference error (RMSE): ±2.6869598123894574\n",
      "##### ARDRegression - LassoLars #####\n",
      "Train MSE: 6.844\n",
      "Train inference error (RMSE): ±2.6160683390198765\n",
      "Test MSE: 7.205\n",
      "Test inference error (RMSE): ±2.6842843592397805\n",
      "##### ARDRegression - LassoLarsCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153759895892095\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.686893128009901\n",
      "##### ARDRegression - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615408051909675\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.686798703063438\n",
      "##### ARDRegression - LinearRegression #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153059182214484\n",
      "Test MSE: 7.229\n",
      "Test inference error (RMSE): ±2.688637028947113\n",
      "##### ARDRegression - LinearSVR #####\n",
      "Train MSE: 6.858\n",
      "Train inference error (RMSE): ±2.618866945724187\n",
      "Test MSE: 7.338\n",
      "Test inference error (RMSE): ±2.708803377476659\n",
      "##### ARDRegression - MLPRegressor #####\n",
      "Train MSE: 1.404\n",
      "Train inference error (RMSE): ±1.185110229019228\n",
      "Test MSE: 2.211\n",
      "Test inference error (RMSE): ±1.4868202222889844\n",
      "##### ARDRegression - MultiTaskElasticNet #####\n",
      "Error (ARDRegression-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ARDRegression - MultiTaskElasticNetCV #####\n",
      "Error (ARDRegression-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ARDRegression - MultiTaskLasso #####\n",
      "Error (ARDRegression-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ARDRegression - MultiTaskLassoCV #####\n",
      "Error (ARDRegression-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ARDRegression - NuSVR #####\n",
      "Train MSE: 2.845\n",
      "Train inference error (RMSE): ±1.6865688211850705\n",
      "Test MSE: 4.010\n",
      "Test inference error (RMSE): ±2.0023998023938567\n",
      "##### ARDRegression - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.6159911857710387\n",
      "Test MSE: 7.226\n",
      "Test inference error (RMSE): ±2.6880463688853187\n",
      "##### ARDRegression - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.846\n",
      "Train inference error (RMSE): ±2.6164621773018517\n",
      "Test MSE: 7.242\n",
      "Test inference error (RMSE): ±2.691068065814859\n",
      "##### ARDRegression - PLSCanonical #####\n",
      "Error (ARDRegression-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ARDRegression - PLSRegression #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6150602616357586\n",
      "Test MSE: 7.231\n",
      "Test inference error (RMSE): ±2.688971761797154\n",
      "##### ARDRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.907\n",
      "Train inference error (RMSE): ±2.628161048445681\n",
      "Test MSE: 7.255\n",
      "Test inference error (RMSE): ±2.693572880627733\n",
      "##### ARDRegression - PoissonRegressor #####\n",
      "Error (ARDRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ARDRegression - QuantileRegressor #####\n",
      "Train MSE: 6.844\n",
      "Train inference error (RMSE): ±2.616166208769563\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.686560416133844\n",
      "##### ARDRegression - RANSACRegressor #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.618123271472062\n",
      "Test MSE: 7.274\n",
      "Test inference error (RMSE): ±2.697071235084895\n",
      "##### ARDRegression - RadiusNeighborsRegressor #####\n",
      "Error (ARDRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ARDRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.479\n",
      "Train inference error (RMSE): ±0.6921579077988653\n",
      "Test MSE: 3.625\n",
      "Test inference error (RMSE): ±1.9038702022730698\n",
      "##### ARDRegression - Ridge #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615273295250439\n",
      "Test MSE: 7.229\n",
      "Test inference error (RMSE): ±2.68861866415745\n",
      "##### ARDRegression - RidgeCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615128646969667\n",
      "Test MSE: 7.227\n",
      "Test inference error (RMSE): ±2.688256381865505\n",
      "##### ARDRegression - SGDRegressor #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.615662141465785\n",
      "Test MSE: 7.229\n",
      "Test inference error (RMSE): ±2.688653972726255\n",
      "##### ARDRegression - SVR #####\n",
      "Train MSE: 2.839\n",
      "Train inference error (RMSE): ±1.6847970894282327\n",
      "Test MSE: 4.119\n",
      "Test inference error (RMSE): ±2.0295691154733846\n",
      "##### ARDRegression - TheilSenRegressor #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6175338827908345\n",
      "Test MSE: 7.285\n",
      "Test inference error (RMSE): ±2.6990873462616056\n",
      "##### ARDRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153059182214484\n",
      "Test MSE: 7.229\n",
      "Test inference error (RMSE): ±2.688637028947113\n",
      "##### ARDRegression - TweedieRegressor #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.6158341149666438\n",
      "Test MSE: 7.230\n",
      "Test inference error (RMSE): ±2.688888959250772\n",
      "##### AdaBoostRegressor - BaggingRegressor #####\n",
      "Train MSE: 1.096\n",
      "Train inference error (RMSE): ±1.0469134241776223\n",
      "Test MSE: 3.696\n",
      "Test inference error (RMSE): ±1.9225868390814322\n",
      "##### AdaBoostRegressor - BayesianRidge #####\n",
      "Train MSE: 3.245\n",
      "Train inference error (RMSE): ±1.8013331609914833\n",
      "Test MSE: 4.698\n",
      "Test inference error (RMSE): ±2.1674275537123675\n",
      "##### AdaBoostRegressor - CCA #####\n",
      "Error (AdaBoostRegressor-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### AdaBoostRegressor - DecisionTreeRegressor #####\n",
      "Train MSE: 1.859\n",
      "Train inference error (RMSE): ±1.3633598477377877\n",
      "Test MSE: 4.814\n",
      "Test inference error (RMSE): ±2.194119609001773\n",
      "##### AdaBoostRegressor - DummyRegressor #####\n",
      "Train MSE: 3.519\n",
      "Train inference error (RMSE): ±1.87577722622381\n",
      "Test MSE: 5.131\n",
      "Test inference error (RMSE): ±2.2651810660190184\n",
      "##### AdaBoostRegressor - ElasticNet #####\n",
      "Train MSE: 3.541\n",
      "Train inference error (RMSE): ±1.8816916818434224\n",
      "Test MSE: 5.308\n",
      "Test inference error (RMSE): ±2.3039503785070066\n",
      "##### AdaBoostRegressor - ElasticNetCV #####\n",
      "Train MSE: 3.206\n",
      "Train inference error (RMSE): ±1.7906226378686372\n",
      "Test MSE: 4.728\n",
      "Test inference error (RMSE): ±2.174343976591146\n",
      "##### AdaBoostRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 2.276\n",
      "Train inference error (RMSE): ±1.508564339519878\n",
      "Test MSE: 5.086\n",
      "Test inference error (RMSE): ±2.255149996875013\n",
      "##### AdaBoostRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.510\n",
      "Train inference error (RMSE): ±0.714055199328537\n",
      "Test MSE: 2.953\n",
      "Test inference error (RMSE): ±1.7182863748793156\n",
      "##### AdaBoostRegressor - GammaRegressor #####\n",
      "Error (AdaBoostRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### AdaBoostRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.8954903008522428\n",
      "Test MSE: 3.484\n",
      "Test inference error (RMSE): ±1.8666649596314635\n",
      "##### AdaBoostRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.911\n",
      "Train inference error (RMSE): ±0.954514824446692\n",
      "Test MSE: 3.204\n",
      "Test inference error (RMSE): ±1.7899006284356502\n",
      "##### AdaBoostRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.391\n",
      "Train inference error (RMSE): ±0.625429410806266\n",
      "Test MSE: 2.480\n",
      "Test inference error (RMSE): ±1.5747703721829236\n",
      "##### AdaBoostRegressor - HuberRegressor #####\n",
      "Train MSE: 3.307\n",
      "Train inference error (RMSE): ±1.8183940207642788\n",
      "Test MSE: 4.803\n",
      "Test inference error (RMSE): ±2.1915489034212308\n",
      "##### AdaBoostRegressor - IsotonicRegression #####\n",
      "Error (AdaBoostRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### AdaBoostRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 1.785\n",
      "Train inference error (RMSE): ±1.335932438877113\n",
      "Test MSE: 3.446\n",
      "Test inference error (RMSE): ±1.8564045752181384\n",
      "##### AdaBoostRegressor - KernelRidge #####\n",
      "Train MSE: 3.454\n",
      "Train inference error (RMSE): ±1.8585596857409672\n",
      "Test MSE: 4.917\n",
      "Test inference error (RMSE): ±2.2175062599607567\n",
      "##### AdaBoostRegressor - Lars #####\n",
      "Train MSE: 2.923\n",
      "Train inference error (RMSE): ±1.7096632095895874\n",
      "Test MSE: 4.548\n",
      "Test inference error (RMSE): ±2.132675454934173\n",
      "##### AdaBoostRegressor - LarsCV #####\n",
      "Train MSE: 3.294\n",
      "Train inference error (RMSE): ±1.8148285099047625\n",
      "Test MSE: 4.825\n",
      "Test inference error (RMSE): ±2.1965793912894025\n",
      "##### AdaBoostRegressor - Lasso #####\n",
      "Train MSE: 3.378\n",
      "Train inference error (RMSE): ±1.8380215892405212\n",
      "Test MSE: 5.550\n",
      "Test inference error (RMSE): ±2.355881950866973\n",
      "##### AdaBoostRegressor - LassoCV #####\n",
      "Train MSE: 3.050\n",
      "Train inference error (RMSE): ±1.7465592974286772\n",
      "Test MSE: 4.462\n",
      "Test inference error (RMSE): ±2.112319771831695\n",
      "##### AdaBoostRegressor - LassoLars #####\n",
      "Train MSE: 3.368\n",
      "Train inference error (RMSE): ±1.8351815450486026\n",
      "Test MSE: 4.961\n",
      "Test inference error (RMSE): ±2.2273430071281104\n",
      "##### AdaBoostRegressor - LassoLarsCV #####\n",
      "Train MSE: 3.113\n",
      "Train inference error (RMSE): ±1.764501375862407\n",
      "Test MSE: 4.430\n",
      "Test inference error (RMSE): ±2.1046710265827846\n",
      "##### AdaBoostRegressor - LassoLarsIC #####\n",
      "Train MSE: 2.912\n",
      "Train inference error (RMSE): ±1.7064318265358067\n",
      "Test MSE: 4.273\n",
      "Test inference error (RMSE): ±2.067119245294052\n",
      "##### AdaBoostRegressor - LinearRegression #####\n",
      "Train MSE: 3.144\n",
      "Train inference error (RMSE): ±1.7730645226651622\n",
      "Test MSE: 4.667\n",
      "Test inference error (RMSE): ±2.160347128038581\n",
      "##### AdaBoostRegressor - LinearSVR #####\n",
      "Train MSE: 3.280\n",
      "Train inference error (RMSE): ±1.8110909625798386\n",
      "Test MSE: 4.873\n",
      "Test inference error (RMSE): ±2.207538278420067\n",
      "##### AdaBoostRegressor - MLPRegressor #####\n",
      "Train MSE: 1.286\n",
      "Train inference error (RMSE): ±1.1341491252091975\n",
      "Test MSE: 2.149\n",
      "Test inference error (RMSE): ±1.4658693230169708\n",
      "##### AdaBoostRegressor - MultiTaskElasticNet #####\n",
      "Error (AdaBoostRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### AdaBoostRegressor - MultiTaskElasticNetCV #####\n",
      "Error (AdaBoostRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### AdaBoostRegressor - MultiTaskLasso #####\n",
      "Error (AdaBoostRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### AdaBoostRegressor - MultiTaskLassoCV #####\n",
      "Error (AdaBoostRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### AdaBoostRegressor - NuSVR #####\n",
      "Train MSE: 2.043\n",
      "Train inference error (RMSE): ±1.4292824618144355\n",
      "Test MSE: 3.417\n",
      "Test inference error (RMSE): ±1.848499716139301\n",
      "##### AdaBoostRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 3.709\n",
      "Train inference error (RMSE): ±1.9258278182992474\n",
      "Test MSE: 5.448\n",
      "Test inference error (RMSE): ±2.3341300638394333\n",
      "##### AdaBoostRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 3.542\n",
      "Train inference error (RMSE): ±1.8819004755703987\n",
      "Test MSE: 5.165\n",
      "Test inference error (RMSE): ±2.272685470392676\n",
      "##### AdaBoostRegressor - PLSCanonical #####\n",
      "Error (AdaBoostRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### AdaBoostRegressor - PLSRegression #####\n",
      "Train MSE: 3.104\n",
      "Train inference error (RMSE): ±1.761921526426737\n",
      "Test MSE: 4.436\n",
      "Test inference error (RMSE): ±2.106269404039246\n",
      "##### AdaBoostRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 3.697\n",
      "Train inference error (RMSE): ±1.9228200739219148\n",
      "Test MSE: 5.770\n",
      "Test inference error (RMSE): ±2.4021009363954344\n",
      "##### AdaBoostRegressor - PoissonRegressor #####\n",
      "Error (AdaBoostRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### AdaBoostRegressor - QuantileRegressor #####\n",
      "Train MSE: 3.550\n",
      "Train inference error (RMSE): ±1.8841621424492596\n",
      "Test MSE: 5.071\n",
      "Test inference error (RMSE): ±2.251929967714119\n",
      "##### AdaBoostRegressor - RANSACRegressor #####\n",
      "Train MSE: 3.060\n",
      "Train inference error (RMSE): ±1.7493794043783606\n",
      "Test MSE: 4.495\n",
      "Test inference error (RMSE): ±2.1202555576364173\n",
      "##### AdaBoostRegressor - RadiusNeighborsRegressor #####\n",
      "Error (AdaBoostRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### AdaBoostRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.718\n",
      "Train inference error (RMSE): ±0.8475312456019769\n",
      "Test MSE: 3.292\n",
      "Test inference error (RMSE): ±1.814309099625592\n",
      "##### AdaBoostRegressor - Ridge #####\n",
      "Train MSE: 3.381\n",
      "Train inference error (RMSE): ±1.8386282784778454\n",
      "Test MSE: 5.024\n",
      "Test inference error (RMSE): ±2.241403054395022\n",
      "##### AdaBoostRegressor - RidgeCV #####\n",
      "Train MSE: 3.178\n",
      "Train inference error (RMSE): ±1.78281487402385\n",
      "Test MSE: 4.894\n",
      "Test inference error (RMSE): ±2.212236810458469\n",
      "##### AdaBoostRegressor - SGDRegressor #####\n",
      "Train MSE: 3.136\n",
      "Train inference error (RMSE): ±1.7709171089512918\n",
      "Test MSE: 4.597\n",
      "Test inference error (RMSE): ±2.1441616910713113\n",
      "##### AdaBoostRegressor - SVR #####\n",
      "Train MSE: 1.922\n",
      "Train inference error (RMSE): ±1.3863970546076767\n",
      "Test MSE: 3.324\n",
      "Test inference error (RMSE): ±1.8231797057280064\n",
      "##### AdaBoostRegressor - TheilSenRegressor #####\n",
      "Train MSE: 2.875\n",
      "Train inference error (RMSE): ±1.6954532013145354\n",
      "Test MSE: 4.540\n",
      "Test inference error (RMSE): ±2.1306120856721154\n",
      "##### AdaBoostRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 3.046\n",
      "Train inference error (RMSE): ±1.7451472766293832\n",
      "Test MSE: 4.612\n",
      "Test inference error (RMSE): ±2.147650648554917\n",
      "##### AdaBoostRegressor - TweedieRegressor #####\n",
      "Train MSE: 3.436\n",
      "Train inference error (RMSE): ±1.8537013134119114\n",
      "Test MSE: 4.897\n",
      "Test inference error (RMSE): ±2.2130087871598856\n",
      "##### BaggingRegressor - BayesianRidge #####\n",
      "Train MSE: 0.946\n",
      "Train inference error (RMSE): ±0.9725232616642053\n",
      "Test MSE: 4.032\n",
      "Test inference error (RMSE): ±2.0080872298872112\n",
      "##### BaggingRegressor - CCA #####\n",
      "Error (BaggingRegressor-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BaggingRegressor - DecisionTreeRegressor #####\n",
      "Train MSE: 0.711\n",
      "Train inference error (RMSE): ±0.8430600135670597\n",
      "Test MSE: 4.013\n",
      "Test inference error (RMSE): ±2.0033265998481182\n",
      "##### BaggingRegressor - DummyRegressor #####\n",
      "Train MSE: 0.698\n",
      "Train inference error (RMSE): ±0.8354623477165971\n",
      "Test MSE: 3.908\n",
      "Test inference error (RMSE): ±1.9768774769048472\n",
      "##### BaggingRegressor - ElasticNet #####\n",
      "Train MSE: 1.042\n",
      "Train inference error (RMSE): ±1.0205555248952793\n",
      "Test MSE: 3.891\n",
      "Test inference error (RMSE): ±1.9726791970017044\n",
      "##### BaggingRegressor - ElasticNetCV #####\n",
      "Train MSE: 1.047\n",
      "Train inference error (RMSE): ±1.023264914633761\n",
      "Test MSE: 4.159\n",
      "Test inference error (RMSE): ±2.039250631244861\n",
      "##### BaggingRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.558\n",
      "Train inference error (RMSE): ±0.7472435262942895\n",
      "Test MSE: 4.464\n",
      "Test inference error (RMSE): ±2.1128725519712512\n",
      "##### BaggingRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.606\n",
      "Train inference error (RMSE): ±0.7786769175703175\n",
      "Test MSE: 3.226\n",
      "Test inference error (RMSE): ±1.7961908440462246\n",
      "##### BaggingRegressor - GammaRegressor #####\n",
      "Error (BaggingRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### BaggingRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.565\n",
      "Train inference error (RMSE): ±0.7514114602797395\n",
      "Test MSE: 3.524\n",
      "Test inference error (RMSE): ±1.8773202131178621\n",
      "##### BaggingRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.792\n",
      "Train inference error (RMSE): ±0.8897937573606443\n",
      "Test MSE: 3.238\n",
      "Test inference error (RMSE): ±1.7995555703770307\n",
      "##### BaggingRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.334\n",
      "Train inference error (RMSE): ±0.5782920543570518\n",
      "Test MSE: 2.465\n",
      "Test inference error (RMSE): ±1.5699488682706357\n",
      "##### BaggingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.902\n",
      "Train inference error (RMSE): ±0.9495069498682333\n",
      "Test MSE: 4.248\n",
      "Test inference error (RMSE): ±2.061020891409107\n",
      "##### BaggingRegressor - IsotonicRegression #####\n",
      "Error (BaggingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### BaggingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 1.047\n",
      "Train inference error (RMSE): ±1.0230411120960907\n",
      "Test MSE: 3.494\n",
      "Test inference error (RMSE): ±1.8691370756765973\n",
      "##### BaggingRegressor - KernelRidge #####\n",
      "Train MSE: 0.938\n",
      "Train inference error (RMSE): ±0.9684760699726987\n",
      "Test MSE: 4.021\n",
      "Test inference error (RMSE): ±2.0051647087443243\n",
      "##### BaggingRegressor - Lars #####\n",
      "Train MSE: 0.852\n",
      "Train inference error (RMSE): ±0.9232971607862009\n",
      "Test MSE: 3.851\n",
      "Test inference error (RMSE): ±1.9623057689147632\n",
      "##### BaggingRegressor - LarsCV #####\n",
      "Train MSE: 1.008\n",
      "Train inference error (RMSE): ±1.004152997859695\n",
      "Test MSE: 4.288\n",
      "Test inference error (RMSE): ±2.0706335358706807\n",
      "##### BaggingRegressor - Lasso #####\n",
      "Train MSE: 0.740\n",
      "Train inference error (RMSE): ±0.8600865376128329\n",
      "Test MSE: 4.778\n",
      "Test inference error (RMSE): ±2.1858402324121577\n",
      "##### BaggingRegressor - LassoCV #####\n",
      "Train MSE: 0.944\n",
      "Train inference error (RMSE): ±0.971755876790281\n",
      "Test MSE: 4.388\n",
      "Test inference error (RMSE): ±2.0948106666042565\n",
      "##### BaggingRegressor - LassoLars #####\n",
      "Train MSE: 0.841\n",
      "Train inference error (RMSE): ±0.9170737949495094\n",
      "Test MSE: 4.572\n",
      "Test inference error (RMSE): ±2.138296820923621\n",
      "##### BaggingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.911\n",
      "Train inference error (RMSE): ±0.9543104751037577\n",
      "Test MSE: 3.770\n",
      "Test inference error (RMSE): ±1.9417119517660641\n",
      "##### BaggingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.916\n",
      "Train inference error (RMSE): ±0.9568972574747121\n",
      "Test MSE: 4.344\n",
      "Test inference error (RMSE): ±2.084343330981242\n",
      "##### BaggingRegressor - LinearRegression #####\n",
      "Train MSE: 0.908\n",
      "Train inference error (RMSE): ±0.952882663311389\n",
      "Test MSE: 4.658\n",
      "Test inference error (RMSE): ±2.158132585453886\n",
      "##### BaggingRegressor - LinearSVR #####\n",
      "Train MSE: 0.826\n",
      "Train inference error (RMSE): ±0.9085960719690975\n",
      "Test MSE: 4.643\n",
      "Test inference error (RMSE): ±2.154712247743259\n",
      "##### BaggingRegressor - MLPRegressor #####\n",
      "Train MSE: 1.112\n",
      "Train inference error (RMSE): ±1.0544667514092865\n",
      "Test MSE: 2.238\n",
      "Test inference error (RMSE): ±1.495958071608091\n",
      "##### BaggingRegressor - MultiTaskElasticNet #####\n",
      "Error (BaggingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### BaggingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (BaggingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### BaggingRegressor - MultiTaskLasso #####\n",
      "Error (BaggingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### BaggingRegressor - MultiTaskLassoCV #####\n",
      "Error (BaggingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### BaggingRegressor - NuSVR #####\n",
      "Train MSE: 1.362\n",
      "Train inference error (RMSE): ±1.167229437530375\n",
      "Test MSE: 3.568\n",
      "Test inference error (RMSE): ±1.888998440051692\n",
      "##### BaggingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.682\n",
      "Train inference error (RMSE): ±0.825972556794702\n",
      "Test MSE: 4.846\n",
      "Test inference error (RMSE): ±2.2013560205330123\n",
      "##### BaggingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.855\n",
      "Train inference error (RMSE): ±0.924896493953966\n",
      "Test MSE: 4.056\n",
      "Test inference error (RMSE): ±2.0138760735132952\n",
      "##### BaggingRegressor - PLSCanonical #####\n",
      "Error (BaggingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BaggingRegressor - PLSRegression #####\n",
      "Train MSE: 1.013\n",
      "Train inference error (RMSE): ±1.0062610351397832\n",
      "Test MSE: 4.438\n",
      "Test inference error (RMSE): ±2.10669099078576\n",
      "##### BaggingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.867\n",
      "Train inference error (RMSE): ±0.9312537165198473\n",
      "Test MSE: 3.946\n",
      "Test inference error (RMSE): ±1.9863765292406665\n",
      "##### BaggingRegressor - PoissonRegressor #####\n",
      "Error (BaggingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### BaggingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.798\n",
      "Train inference error (RMSE): ±0.8931801163941934\n",
      "Test MSE: 4.438\n",
      "Test inference error (RMSE): ±2.106542443087388\n",
      "##### BaggingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.896\n",
      "Train inference error (RMSE): ±0.9463897411830249\n",
      "Test MSE: 4.910\n",
      "Test inference error (RMSE): ±2.215741986877106\n",
      "##### BaggingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (BaggingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### BaggingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.417\n",
      "Train inference error (RMSE): ±0.6459899801987088\n",
      "Test MSE: 3.566\n",
      "Test inference error (RMSE): ±1.8883486952196913\n",
      "##### BaggingRegressor - Ridge #####\n",
      "Train MSE: 1.017\n",
      "Train inference error (RMSE): ±1.0087082900684423\n",
      "Test MSE: 4.438\n",
      "Test inference error (RMSE): ±2.1067302356261712\n",
      "##### BaggingRegressor - RidgeCV #####\n",
      "Train MSE: 0.995\n",
      "Train inference error (RMSE): ±0.9977281901250962\n",
      "Test MSE: 3.859\n",
      "Test inference error (RMSE): ±1.964313407811522\n",
      "##### BaggingRegressor - SGDRegressor #####\n",
      "Train MSE: 1.145\n",
      "Train inference error (RMSE): ±1.0702421885892155\n",
      "Test MSE: 3.994\n",
      "Test inference error (RMSE): ±1.9984972945717536\n",
      "##### BaggingRegressor - SVR #####\n",
      "Train MSE: 1.650\n",
      "Train inference error (RMSE): ±1.2845312067154988\n",
      "Test MSE: 3.510\n",
      "Test inference error (RMSE): ±1.8734435206797873\n",
      "##### BaggingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.981\n",
      "Train inference error (RMSE): ±0.9903323272664918\n",
      "Test MSE: 4.517\n",
      "Test inference error (RMSE): ±2.1253879133100706\n",
      "##### BaggingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.942\n",
      "Train inference error (RMSE): ±0.9705647853370597\n",
      "Test MSE: 3.996\n",
      "Test inference error (RMSE): ±1.9990723446747065\n",
      "##### BaggingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.793\n",
      "Train inference error (RMSE): ±0.8906229304528723\n",
      "Test MSE: 4.016\n",
      "Test inference error (RMSE): ±2.0038941980063867\n",
      "##### BayesianRidge - CCA #####\n",
      "Error (BayesianRidge-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BayesianRidge - DecisionTreeRegressor #####\n",
      "Train MSE: 2.619\n",
      "Train inference error (RMSE): ±1.6183368420519888\n",
      "Test MSE: 5.550\n",
      "Test inference error (RMSE): ±2.3558466868343246\n",
      "##### BayesianRidge - DummyRegressor #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.6146546536035777\n",
      "Test MSE: 7.238\n",
      "Test inference error (RMSE): ±2.6903823921985888\n",
      "##### BayesianRidge - ElasticNet #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147278098195885\n",
      "Test MSE: 7.250\n",
      "Test inference error (RMSE): ±2.692505418875561\n",
      "##### BayesianRidge - ElasticNetCV #####\n",
      "Train MSE: 6.850\n",
      "Train inference error (RMSE): ±2.617279287492352\n",
      "Test MSE: 7.205\n",
      "Test inference error (RMSE): ±2.684212113800658\n",
      "##### BayesianRidge - ExtraTreeRegressor #####\n",
      "Train MSE: 3.351\n",
      "Train inference error (RMSE): ±1.8305305285550753\n",
      "Test MSE: 6.754\n",
      "Test inference error (RMSE): ±2.598915645907148\n",
      "##### BayesianRidge - ExtraTreesRegressor #####\n",
      "Train MSE: 0.963\n",
      "Train inference error (RMSE): ±0.9814116058976377\n",
      "Test MSE: 2.950\n",
      "Test inference error (RMSE): ±1.7175263956559503\n",
      "##### BayesianRidge - GammaRegressor #####\n",
      "Error (BayesianRidge-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### BayesianRidge - GaussianProcessRegressor #####\n",
      "Train MSE: 0.457\n",
      "Train inference error (RMSE): ±0.6759879225390418\n",
      "Test MSE: 4.226\n",
      "Test inference error (RMSE): ±2.0556119983705807\n",
      "##### BayesianRidge - GradientBoostingRegressor #####\n",
      "Train MSE: 0.804\n",
      "Train inference error (RMSE): ±0.8967808191188963\n",
      "Test MSE: 3.332\n",
      "Test inference error (RMSE): ±1.8252960888965393\n",
      "##### BayesianRidge - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812464186438552\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.57182519758832\n",
      "##### BayesianRidge - HuberRegressor #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6173884055100665\n",
      "Test MSE: 7.330\n",
      "Test inference error (RMSE): ±2.7074820129975783\n",
      "##### BayesianRidge - IsotonicRegression #####\n",
      "Error (BayesianRidge-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### BayesianRidge - KNeighborsRegressor #####\n",
      "Train MSE: 2.759\n",
      "Train inference error (RMSE): ±1.6611612082195022\n",
      "Test MSE: 4.703\n",
      "Test inference error (RMSE): ±2.1685874297399015\n",
      "##### BayesianRidge - KernelRidge #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6150626053850594\n",
      "Test MSE: 7.223\n",
      "Test inference error (RMSE): ±2.687534841592384\n",
      "##### BayesianRidge - Lars #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.61497294797678\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.686410382467708\n",
      "##### BayesianRidge - LarsCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150064336739782\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6874083518939966\n",
      "##### BayesianRidge - Lasso #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147190415288284\n",
      "Test MSE: 7.229\n",
      "Test inference error (RMSE): ±2.6885929060112272\n",
      "##### BayesianRidge - LassoCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150144170177563\n",
      "Test MSE: 7.223\n",
      "Test inference error (RMSE): ±2.687480979666328\n",
      "##### BayesianRidge - LassoLars #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614719041442322\n",
      "Test MSE: 7.229\n",
      "Test inference error (RMSE): ±2.6885929078971125\n",
      "##### BayesianRidge - LassoLarsCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150064336739782\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6874083518939966\n",
      "##### BayesianRidge - LassoLarsIC #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150376556457986\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687343077705662\n",
      "##### BayesianRidge - LinearRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614972947976883\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.686410382468577\n",
      "##### BayesianRidge - LinearSVR #####\n",
      "Train MSE: 6.856\n",
      "Train inference error (RMSE): ±2.618302422398738\n",
      "Test MSE: 7.359\n",
      "Test inference error (RMSE): ±2.7127971253218712\n",
      "##### BayesianRidge - MLPRegressor #####\n",
      "Train MSE: 1.545\n",
      "Train inference error (RMSE): ±1.2429932539234998\n",
      "Test MSE: 2.347\n",
      "Test inference error (RMSE): ±1.5319110247049441\n",
      "##### BayesianRidge - MultiTaskElasticNet #####\n",
      "Error (BayesianRidge-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### BayesianRidge - MultiTaskElasticNetCV #####\n",
      "Error (BayesianRidge-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### BayesianRidge - MultiTaskLasso #####\n",
      "Error (BayesianRidge-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### BayesianRidge - MultiTaskLassoCV #####\n",
      "Error (BayesianRidge-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### BayesianRidge - NuSVR #####\n",
      "Train MSE: 2.847\n",
      "Train inference error (RMSE): ±1.6873946844926626\n",
      "Test MSE: 4.009\n",
      "Test inference error (RMSE): ±2.002240630761813\n",
      "##### BayesianRidge - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614698561315988\n",
      "Test MSE: 7.239\n",
      "Test inference error (RMSE): ±2.6906292719114364\n",
      "##### BayesianRidge - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6154183922277756\n",
      "Test MSE: 7.261\n",
      "Test inference error (RMSE): ±2.694593081447941\n",
      "##### BayesianRidge - PLSCanonical #####\n",
      "Error (BayesianRidge-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BayesianRidge - PLSRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147104916056603\n",
      "Test MSE: 7.243\n",
      "Test inference error (RMSE): ±2.6913183786070602\n",
      "##### BayesianRidge - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6148284836441174\n",
      "Test MSE: 7.255\n",
      "Test inference error (RMSE): ±2.6935179561938543\n",
      "##### BayesianRidge - PoissonRegressor #####\n",
      "Error (BayesianRidge-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### BayesianRidge - QuantileRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6148836737737553\n",
      "Test MSE: 7.231\n",
      "Test inference error (RMSE): ±2.6890241125331524\n",
      "##### BayesianRidge - RANSACRegressor #####\n",
      "Train MSE: 6.858\n",
      "Train inference error (RMSE): ±2.6188729789081795\n",
      "Test MSE: 7.230\n",
      "Test inference error (RMSE): ±2.6889192389016765\n",
      "##### BayesianRidge - RadiusNeighborsRegressor #####\n",
      "Error (BayesianRidge-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### BayesianRidge - RandomForestRegressor #####\n",
      "Train MSE: 0.502\n",
      "Train inference error (RMSE): ±0.7084506737084906\n",
      "Test MSE: 3.575\n",
      "Test inference error (RMSE): ±1.8908301639940994\n",
      "##### BayesianRidge - Ridge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147786282477212\n",
      "Test MSE: 7.224\n",
      "Test inference error (RMSE): ±2.687827938754208\n",
      "##### BayesianRidge - RidgeCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615200438663281\n",
      "Test MSE: 7.210\n",
      "Test inference error (RMSE): ±2.6851241320475823\n",
      "##### BayesianRidge - SGDRegressor #####\n",
      "Train MSE: 6.878\n",
      "Train inference error (RMSE): ±2.6225662052457763\n",
      "Test MSE: 7.238\n",
      "Test inference error (RMSE): ±2.6902810031857847\n",
      "##### BayesianRidge - SVR #####\n",
      "Train MSE: 2.843\n",
      "Train inference error (RMSE): ±1.686132308762916\n",
      "Test MSE: 4.120\n",
      "Test inference error (RMSE): ±2.029846439806188\n",
      "##### BayesianRidge - TheilSenRegressor #####\n",
      "Train MSE: 6.848\n",
      "Train inference error (RMSE): ±2.6168676684497947\n",
      "Test MSE: 7.305\n",
      "Test inference error (RMSE): ±2.702847149748503\n",
      "##### BayesianRidge - TransformedTargetRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614972947976883\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.686410382468577\n",
      "##### BayesianRidge - TweedieRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614702217753744\n",
      "Test MSE: 7.245\n",
      "Test inference error (RMSE): ±2.691592441325946\n",
      "##### CCA - DecisionTreeRegressor #####\n",
      "Error (CCA-DecisionTreeRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - DummyRegressor #####\n",
      "Error (CCA-DummyRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ElasticNet #####\n",
      "Error (CCA-ElasticNet): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ElasticNetCV #####\n",
      "Error (CCA-ElasticNetCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ExtraTreeRegressor #####\n",
      "Error (CCA-ExtraTreeRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ExtraTreesRegressor #####\n",
      "Error (CCA-ExtraTreesRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GammaRegressor #####\n",
      "Error (CCA-GammaRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GaussianProcessRegressor #####\n",
      "Error (CCA-GaussianProcessRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GradientBoostingRegressor #####\n",
      "Error (CCA-GradientBoostingRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - HistGradientBoostingRegressor #####\n",
      "Error (CCA-HistGradientBoostingRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - HuberRegressor #####\n",
      "Error (CCA-HuberRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - IsotonicRegression #####\n",
      "Error (CCA-IsotonicRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - KNeighborsRegressor #####\n",
      "Error (CCA-KNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - KernelRidge #####\n",
      "Error (CCA-KernelRidge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Lars #####\n",
      "Error (CCA-Lars): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LarsCV #####\n",
      "Error (CCA-LarsCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Lasso #####\n",
      "Error (CCA-Lasso): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoCV #####\n",
      "Error (CCA-LassoCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLars #####\n",
      "Error (CCA-LassoLars): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLarsCV #####\n",
      "Error (CCA-LassoLarsCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLarsIC #####\n",
      "Error (CCA-LassoLarsIC): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LinearRegression #####\n",
      "Error (CCA-LinearRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LinearSVR #####\n",
      "Error (CCA-LinearSVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MLPRegressor #####\n",
      "Error (CCA-MLPRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskElasticNet #####\n",
      "Error (CCA-MultiTaskElasticNet): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskElasticNetCV #####\n",
      "Error (CCA-MultiTaskElasticNetCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskLasso #####\n",
      "Error (CCA-MultiTaskLasso): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskLassoCV #####\n",
      "Error (CCA-MultiTaskLassoCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - NuSVR #####\n",
      "Error (CCA-NuSVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - OrthogonalMatchingPursuit #####\n",
      "Error (CCA-OrthogonalMatchingPursuit): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - OrthogonalMatchingPursuitCV #####\n",
      "Error (CCA-OrthogonalMatchingPursuitCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PLSCanonical #####\n",
      "Error (CCA-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PLSRegression #####\n",
      "Error (CCA-PLSRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PassiveAggressiveRegressor #####\n",
      "Error (CCA-PassiveAggressiveRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PoissonRegressor #####\n",
      "Error (CCA-PoissonRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - QuantileRegressor #####\n",
      "Error (CCA-QuantileRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RANSACRegressor #####\n",
      "Error (CCA-RANSACRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RadiusNeighborsRegressor #####\n",
      "Error (CCA-RadiusNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RandomForestRegressor #####\n",
      "Error (CCA-RandomForestRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Ridge #####\n",
      "Error (CCA-Ridge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RidgeCV #####\n",
      "Error (CCA-RidgeCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - SGDRegressor #####\n",
      "Error (CCA-SGDRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - SVR #####\n",
      "Error (CCA-SVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TheilSenRegressor #####\n",
      "Error (CCA-TheilSenRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TransformedTargetRegressor #####\n",
      "Error (CCA-TransformedTargetRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TweedieRegressor #####\n",
      "Error (CCA-TweedieRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor - DummyRegressor #####\n",
      "Train MSE: 0.695\n",
      "Train inference error (RMSE): ±0.8335944380271586\n",
      "Test MSE: 8.320\n",
      "Test inference error (RMSE): ±2.8845143559300577\n",
      "##### DecisionTreeRegressor - ElasticNet #####\n",
      "Train MSE: 2.609\n",
      "Train inference error (RMSE): ±1.615288107594517\n",
      "Test MSE: 6.153\n",
      "Test inference error (RMSE): ±2.4804620485820057\n",
      "##### DecisionTreeRegressor - ElasticNetCV #####\n",
      "Train MSE: 2.547\n",
      "Train inference error (RMSE): ±1.5960049144804775\n",
      "Test MSE: 5.467\n",
      "Test inference error (RMSE): ±2.338257561466796\n",
      "##### DecisionTreeRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.054\n",
      "Train inference error (RMSE): ±0.23304503195504142\n",
      "Test MSE: 6.177\n",
      "Test inference error (RMSE): ±2.4853547397295177\n",
      "##### DecisionTreeRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.561\n",
      "Train inference error (RMSE): ±0.7489594301961507\n",
      "Test MSE: 2.969\n",
      "Test inference error (RMSE): ±1.7231977948555224\n",
      "##### DecisionTreeRegressor - GammaRegressor #####\n",
      "Error (DecisionTreeRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### DecisionTreeRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.550\n",
      "Train inference error (RMSE): ±0.7417991254145073\n",
      "Test MSE: 4.123\n",
      "Test inference error (RMSE): ±2.030572092035064\n",
      "##### DecisionTreeRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.838\n",
      "Train inference error (RMSE): ±0.9154347280379991\n",
      "Test MSE: 3.344\n",
      "Test inference error (RMSE): ±1.8287392015633819\n",
      "##### DecisionTreeRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.352\n",
      "Train inference error (RMSE): ±0.5934311669739823\n",
      "Test MSE: 2.474\n",
      "Test inference error (RMSE): ±1.5730260839695764\n",
      "##### DecisionTreeRegressor - HuberRegressor #####\n",
      "Train MSE: 2.727\n",
      "Train inference error (RMSE): ±1.6512741482918933\n",
      "Test MSE: 5.975\n",
      "Test inference error (RMSE): ±2.4443388350531268\n",
      "##### DecisionTreeRegressor - IsotonicRegression #####\n",
      "Error (DecisionTreeRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### DecisionTreeRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 1.448\n",
      "Train inference error (RMSE): ±1.203483777932182\n",
      "Test MSE: 4.412\n",
      "Test inference error (RMSE): ±2.1005283996935957\n",
      "##### DecisionTreeRegressor - KernelRidge #####\n",
      "Train MSE: 2.410\n",
      "Train inference error (RMSE): ±1.552346755996046\n",
      "Test MSE: 5.538\n",
      "Test inference error (RMSE): ±2.3532659790328214\n",
      "##### DecisionTreeRegressor - Lars #####\n",
      "Train MSE: 2.674\n",
      "Train inference error (RMSE): ±1.635221423025726\n",
      "Test MSE: 5.452\n",
      "Test inference error (RMSE): ±2.3350498100069097\n",
      "##### DecisionTreeRegressor - LarsCV #####\n",
      "Train MSE: 2.551\n",
      "Train inference error (RMSE): ±1.5971103091730612\n",
      "Test MSE: 5.528\n",
      "Test inference error (RMSE): ±2.3510922398760576\n",
      "##### DecisionTreeRegressor - Lasso #####\n",
      "Train MSE: 2.281\n",
      "Train inference error (RMSE): ±1.5101473932367224\n",
      "Test MSE: 6.536\n",
      "Test inference error (RMSE): ±2.5564929163957766\n",
      "##### DecisionTreeRegressor - LassoCV #####\n",
      "Train MSE: 2.359\n",
      "Train inference error (RMSE): ±1.5360246130239052\n",
      "Test MSE: 5.662\n",
      "Test inference error (RMSE): ±2.379422510759206\n",
      "##### DecisionTreeRegressor - LassoLars #####\n",
      "Train MSE: 2.211\n",
      "Train inference error (RMSE): ±1.4868599123384172\n",
      "Test MSE: 6.532\n",
      "Test inference error (RMSE): ±2.555740046287942\n",
      "##### DecisionTreeRegressor - LassoLarsCV #####\n",
      "Train MSE: 2.563\n",
      "Train inference error (RMSE): ±1.6009977068878538\n",
      "Test MSE: 5.341\n",
      "Test inference error (RMSE): ±2.3110912848180587\n",
      "##### DecisionTreeRegressor - LassoLarsIC #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.531090645718789\n",
      "Test MSE: 5.582\n",
      "Test inference error (RMSE): ±2.362720690680099\n",
      "##### DecisionTreeRegressor - LinearRegression #####\n",
      "Train MSE: 2.419\n",
      "Train inference error (RMSE): ±1.5551964453327871\n",
      "Test MSE: 5.626\n",
      "Test inference error (RMSE): ±2.3719203693617317\n",
      "##### DecisionTreeRegressor - LinearSVR #####\n",
      "Train MSE: 2.670\n",
      "Train inference error (RMSE): ±1.6340287627520553\n",
      "Test MSE: 5.881\n",
      "Test inference error (RMSE): ±2.425052978409683\n",
      "##### DecisionTreeRegressor - MLPRegressor #####\n",
      "Train MSE: 1.343\n",
      "Train inference error (RMSE): ±1.1590395434771035\n",
      "Test MSE: 2.232\n",
      "Test inference error (RMSE): ±1.4940730588091513\n",
      "##### DecisionTreeRegressor - MultiTaskElasticNet #####\n",
      "Error (DecisionTreeRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### DecisionTreeRegressor - MultiTaskElasticNetCV #####\n",
      "Error (DecisionTreeRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### DecisionTreeRegressor - MultiTaskLasso #####\n",
      "Error (DecisionTreeRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### DecisionTreeRegressor - MultiTaskLassoCV #####\n",
      "Error (DecisionTreeRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### DecisionTreeRegressor - NuSVR #####\n",
      "Train MSE: 2.195\n",
      "Train inference error (RMSE): ±1.4814649049232613\n",
      "Test MSE: 3.853\n",
      "Test inference error (RMSE): ±1.9630097769345836\n",
      "##### DecisionTreeRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.967\n",
      "Train inference error (RMSE): ±0.9834446480497739\n",
      "Test MSE: 7.903\n",
      "Test inference error (RMSE): ±2.8111615810160417\n",
      "##### DecisionTreeRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 2.537\n",
      "Train inference error (RMSE): ±1.592706681683565\n",
      "Test MSE: 5.669\n",
      "Test inference error (RMSE): ±2.3808754181325273\n",
      "##### DecisionTreeRegressor - PLSCanonical #####\n",
      "Error (DecisionTreeRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor - PLSRegression #####\n",
      "Train MSE: 2.390\n",
      "Train inference error (RMSE): ±1.5458718968604923\n",
      "Test MSE: 5.559\n",
      "Test inference error (RMSE): ±2.3577632027382065\n",
      "##### DecisionTreeRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 2.161\n",
      "Train inference error (RMSE): ±1.4701332712564443\n",
      "Test MSE: 6.900\n",
      "Test inference error (RMSE): ±2.6268331033540333\n",
      "##### DecisionTreeRegressor - PoissonRegressor #####\n",
      "Error (DecisionTreeRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### DecisionTreeRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.615\n",
      "Train inference error (RMSE): ±0.784484223474794\n",
      "Test MSE: 7.418\n",
      "Test inference error (RMSE): ±2.7236394464340887\n",
      "##### DecisionTreeRegressor - RANSACRegressor #####\n",
      "Train MSE: 2.485\n",
      "Train inference error (RMSE): ±1.5763695739640526\n",
      "Test MSE: 6.131\n",
      "Test inference error (RMSE): ±2.4761701583103792\n",
      "##### DecisionTreeRegressor - RadiusNeighborsRegressor #####\n",
      "Error (DecisionTreeRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### DecisionTreeRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.440\n",
      "Train inference error (RMSE): ±0.6631530902424618\n",
      "Test MSE: 3.847\n",
      "Test inference error (RMSE): ±1.9614614142557876\n",
      "##### DecisionTreeRegressor - Ridge #####\n",
      "Train MSE: 2.611\n",
      "Train inference error (RMSE): ±1.6159272576275054\n",
      "Test MSE: 5.750\n",
      "Test inference error (RMSE): ±2.3980102042271283\n",
      "##### DecisionTreeRegressor - RidgeCV #####\n",
      "Train MSE: 2.447\n",
      "Train inference error (RMSE): ±1.5641516852215844\n",
      "Test MSE: 5.831\n",
      "Test inference error (RMSE): ±2.4147963369073038\n",
      "##### DecisionTreeRegressor - SGDRegressor #####\n",
      "Train MSE: 2.676\n",
      "Train inference error (RMSE): ±1.6359339786324507\n",
      "Test MSE: 5.725\n",
      "Test inference error (RMSE): ±2.392725654425421\n",
      "##### DecisionTreeRegressor - SVR #####\n",
      "Train MSE: 2.260\n",
      "Train inference error (RMSE): ±1.5034060837834224\n",
      "Test MSE: 3.941\n",
      "Test inference error (RMSE): ±1.9850884102612127\n",
      "##### DecisionTreeRegressor - TheilSenRegressor #####\n",
      "Train MSE: 2.516\n",
      "Train inference error (RMSE): ±1.586168445910827\n",
      "Test MSE: 5.876\n",
      "Test inference error (RMSE): ±2.4239451823636524\n",
      "##### DecisionTreeRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 2.428\n",
      "Train inference error (RMSE): ±1.5581232747790894\n",
      "Test MSE: 5.688\n",
      "Test inference error (RMSE): ±2.3850423754127137\n",
      "##### DecisionTreeRegressor - TweedieRegressor #####\n",
      "Train MSE: 2.527\n",
      "Train inference error (RMSE): ±1.5896033409883483\n",
      "Test MSE: 5.664\n",
      "Test inference error (RMSE): ±2.379951073888425\n",
      "##### DummyRegressor - ElasticNet #####\n",
      "Train MSE: 7.197\n",
      "Train inference error (RMSE): ±2.682711342309985\n",
      "Test MSE: 7.994\n",
      "Test inference error (RMSE): ±2.8273660232921793\n",
      "##### DummyRegressor - ElasticNetCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152744298041424\n",
      "Test MSE: 7.220\n",
      "Test inference error (RMSE): ±2.6869270267613836\n",
      "##### DummyRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 1.540\n",
      "Train inference error (RMSE): ±1.2409621392611652\n",
      "Test MSE: 10.733\n",
      "Test inference error (RMSE): ±3.276143457726498\n",
      "##### DummyRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.570\n",
      "Train inference error (RMSE): ±0.75517931298882\n",
      "Test MSE: 3.188\n",
      "Test inference error (RMSE): ±1.7853831989739768\n",
      "##### DummyRegressor - GammaRegressor #####\n",
      "Error (DummyRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### DummyRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.473\n",
      "Train inference error (RMSE): ±0.6876110130973686\n",
      "Test MSE: 4.440\n",
      "Test inference error (RMSE): ±2.1072265185990906\n",
      "##### DummyRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.849\n",
      "Train inference error (RMSE): ±0.921461463480651\n",
      "Test MSE: 3.309\n",
      "Test inference error (RMSE): ±1.8189907228973152\n",
      "##### DummyRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.342\n",
      "Train inference error (RMSE): ±0.5845577168074012\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5719377207939464\n",
      "##### DummyRegressor - HuberRegressor #####\n",
      "Train MSE: 6.997\n",
      "Train inference error (RMSE): ±2.645106881338082\n",
      "Test MSE: 7.662\n",
      "Test inference error (RMSE): ±2.7679824651092453\n",
      "##### DummyRegressor - IsotonicRegression #####\n",
      "Error (DummyRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### DummyRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 2.592\n",
      "Train inference error (RMSE): ±1.6099295888200433\n",
      "Test MSE: 4.927\n",
      "Test inference error (RMSE): ±2.2197213968005847\n",
      "##### DummyRegressor - KernelRidge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6146850626384115\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.6897307212495916\n",
      "##### DummyRegressor - Lars #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614670710102594\n",
      "Test MSE: 7.243\n",
      "Test inference error (RMSE): ±2.6913598340498597\n",
      "##### DummyRegressor - LarsCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615235789517462\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.6865161705986385\n",
      "##### DummyRegressor - Lasso #####\n",
      "Train MSE: 8.157\n",
      "Train inference error (RMSE): ±2.856040801999066\n",
      "Test MSE: 9.272\n",
      "Test inference error (RMSE): ±3.0450756515779838\n",
      "##### DummyRegressor - LassoCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152444927396474\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.6866215110866514\n",
      "##### DummyRegressor - LassoLars #####\n",
      "Train MSE: 8.157\n",
      "Train inference error (RMSE): ±2.856040801182712\n",
      "Test MSE: 9.272\n",
      "Test inference error (RMSE): ±3.0450756262387078\n",
      "##### DummyRegressor - LassoLarsCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615235789517462\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.6865161705986385\n",
      "##### DummyRegressor - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615286846916665\n",
      "Test MSE: 7.216\n",
      "Test inference error (RMSE): ±2.686344008491116\n",
      "##### DummyRegressor - LinearRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6146707101024673\n",
      "Test MSE: 7.243\n",
      "Test inference error (RMSE): ±2.691359834049237\n",
      "##### DummyRegressor - LinearSVR #####\n",
      "Train MSE: 7.022\n",
      "Train inference error (RMSE): ±2.6498923372459715\n",
      "Test MSE: 7.751\n",
      "Test inference error (RMSE): ±2.78411972717639\n",
      "##### DummyRegressor - MLPRegressor #####\n",
      "Train MSE: 1.511\n",
      "Train inference error (RMSE): ±1.2291213225039372\n",
      "Test MSE: 2.300\n",
      "Test inference error (RMSE): ±1.5165818742040105\n",
      "##### DummyRegressor - MultiTaskElasticNet #####\n",
      "Error (DummyRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### DummyRegressor - MultiTaskElasticNetCV #####\n",
      "Error (DummyRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### DummyRegressor - MultiTaskLasso #####\n",
      "Error (DummyRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### DummyRegressor - MultiTaskLassoCV #####\n",
      "Error (DummyRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### DummyRegressor - NuSVR #####\n",
      "Train MSE: 3.061\n",
      "Train inference error (RMSE): ±1.7495204579368069\n",
      "Test MSE: 4.121\n",
      "Test inference error (RMSE): ±2.030111062388235\n",
      "##### DummyRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 17.799\n",
      "Train inference error (RMSE): ±4.218869078420589\n",
      "Test MSE: 19.910\n",
      "Test inference error (RMSE): ±4.462031851071673\n",
      "##### DummyRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 7.049\n",
      "Train inference error (RMSE): ±2.6550185684157617\n",
      "Test MSE: 7.601\n",
      "Test inference error (RMSE): ±2.7569755914221914\n",
      "##### DummyRegressor - PLSCanonical #####\n",
      "Error (DummyRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DummyRegressor - PLSRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6149898707461814\n",
      "Test MSE: 7.251\n",
      "Test inference error (RMSE): ±2.6928334789849173\n",
      "##### DummyRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 8.419\n",
      "Train inference error (RMSE): ±2.901601646095267\n",
      "Test MSE: 9.291\n",
      "Test inference error (RMSE): ±3.0481163388001375\n",
      "##### DummyRegressor - PoissonRegressor #####\n",
      "Error (DummyRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### DummyRegressor - QuantileRegressor #####\n",
      "Train MSE: 22.053\n",
      "Train inference error (RMSE): ±4.696049924044417\n",
      "Test MSE: 23.544\n",
      "Test inference error (RMSE): ±4.852221408925542\n",
      "##### DummyRegressor - RANSACRegressor #####\n",
      "Train MSE: 7.612\n",
      "Train inference error (RMSE): ±2.759029280952607\n",
      "Test MSE: 8.568\n",
      "Test inference error (RMSE): ±2.92711845794371\n",
      "##### DummyRegressor - RadiusNeighborsRegressor #####\n",
      "Error (DummyRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### DummyRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.415\n",
      "Train inference error (RMSE): ±0.6439135895967653\n",
      "Test MSE: 3.452\n",
      "Test inference error (RMSE): ±1.8578964165379772\n",
      "##### DummyRegressor - Ridge #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.614662702424458\n",
      "Test MSE: 7.242\n",
      "Test inference error (RMSE): ±2.6910490228199357\n",
      "##### DummyRegressor - RidgeCV #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.6146597728145937\n",
      "Test MSE: 7.232\n",
      "Test inference error (RMSE): ±2.6892627991514564\n",
      "##### DummyRegressor - SGDRegressor #####\n",
      "Train MSE: 6.846\n",
      "Train inference error (RMSE): ±2.61639668548764\n",
      "Test MSE: 7.245\n",
      "Test inference error (RMSE): ±2.6917310817122835\n",
      "##### DummyRegressor - SVR #####\n",
      "Train MSE: 3.037\n",
      "Train inference error (RMSE): ±1.7428366442523535\n",
      "Test MSE: 4.191\n",
      "Test inference error (RMSE): ±2.047125452080605\n",
      "##### DummyRegressor - TheilSenRegressor #####\n",
      "Train MSE: 7.040\n",
      "Train inference error (RMSE): ±2.653247593170623\n",
      "Test MSE: 7.608\n",
      "Test inference error (RMSE): ±2.758207519688548\n",
      "##### DummyRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6146707101024673\n",
      "Test MSE: 7.243\n",
      "Test inference error (RMSE): ±2.691359834049237\n",
      "##### DummyRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.858\n",
      "Train inference error (RMSE): ±2.618687573888055\n",
      "Test MSE: 7.330\n",
      "Test inference error (RMSE): ±2.707367737795605\n",
      "##### ElasticNet - ElasticNetCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615280400769514\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.6866648223897815\n",
      "##### ElasticNet - ExtraTreeRegressor #####\n",
      "Train MSE: 3.036\n",
      "Train inference error (RMSE): ±1.7424896833529855\n",
      "Test MSE: 6.505\n",
      "Test inference error (RMSE): ±2.550473074977053\n",
      "##### ElasticNet - ExtraTreesRegressor #####\n",
      "Train MSE: 1.038\n",
      "Train inference error (RMSE): ±1.0186100168444803\n",
      "Test MSE: 2.893\n",
      "Test inference error (RMSE): ±1.7007715933339127\n",
      "##### ElasticNet - GammaRegressor #####\n",
      "Error (ElasticNet-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ElasticNet - GaussianProcessRegressor #####\n",
      "Train MSE: 0.419\n",
      "Train inference error (RMSE): ±0.6475399248992543\n",
      "Test MSE: 4.365\n",
      "Test inference error (RMSE): ±2.089287693667493\n",
      "##### ElasticNet - GradientBoostingRegressor #####\n",
      "Train MSE: 0.807\n",
      "Train inference error (RMSE): ±0.8981895706375408\n",
      "Test MSE: 3.296\n",
      "Test inference error (RMSE): ±1.8155046907017092\n",
      "##### ElasticNet - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.337\n",
      "Train inference error (RMSE): ±0.5806088567770505\n",
      "Test MSE: 2.454\n",
      "Test inference error (RMSE): ±1.56644303124858\n",
      "##### ElasticNet - HuberRegressor #####\n",
      "Train MSE: 6.991\n",
      "Train inference error (RMSE): ±2.6439872068058907\n",
      "Test MSE: 7.622\n",
      "Test inference error (RMSE): ±2.760814378969452\n",
      "##### ElasticNet - IsotonicRegression #####\n",
      "Error (ElasticNet-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ElasticNet - KNeighborsRegressor #####\n",
      "Train MSE: 2.730\n",
      "Train inference error (RMSE): ±1.6521915806380578\n",
      "Test MSE: 4.840\n",
      "Test inference error (RMSE): ±2.200034812182744\n",
      "##### ElasticNet - KernelRidge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147159860915727\n",
      "Test MSE: 7.241\n",
      "Test inference error (RMSE): ±2.690827978604251\n",
      "##### ElasticNet - Lars #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614762798868431\n",
      "Test MSE: 7.257\n",
      "Test inference error (RMSE): ±2.693877521616671\n",
      "##### ElasticNet - LarsCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.61523457667249\n",
      "Test MSE: 7.215\n",
      "Test inference error (RMSE): ±2.686140983592706\n",
      "##### ElasticNet - Lasso #####\n",
      "Train MSE: 7.061\n",
      "Train inference error (RMSE): ±2.6572425928800993\n",
      "Test MSE: 7.642\n",
      "Test inference error (RMSE): ±2.7644783482435633\n",
      "##### ElasticNet - LassoCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615242076697267\n",
      "Test MSE: 7.216\n",
      "Test inference error (RMSE): ±2.686209143622396\n",
      "##### ElasticNet - LassoLars #####\n",
      "Train MSE: 7.061\n",
      "Train inference error (RMSE): ±2.657242598012163\n",
      "Test MSE: 7.642\n",
      "Test inference error (RMSE): ±2.764478376527584\n",
      "##### ElasticNet - LassoLarsCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.61523457667249\n",
      "Test MSE: 7.215\n",
      "Test inference error (RMSE): ±2.686140983592706\n",
      "##### ElasticNet - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153139293289986\n",
      "Test MSE: 7.220\n",
      "Test inference error (RMSE): ±2.6869629902799943\n",
      "##### ElasticNet - LinearRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147627988683957\n",
      "Test MSE: 7.257\n",
      "Test inference error (RMSE): ±2.6938775216165083\n",
      "##### ElasticNet - LinearSVR #####\n",
      "Train MSE: 7.019\n",
      "Train inference error (RMSE): ±2.64941759018853\n",
      "Test MSE: 7.727\n",
      "Test inference error (RMSE): ±2.7797996731159333\n",
      "##### ElasticNet - MLPRegressor #####\n",
      "Train MSE: 1.568\n",
      "Train inference error (RMSE): ±1.2523066361650506\n",
      "Test MSE: 2.364\n",
      "Test inference error (RMSE): ±1.5375102419043778\n",
      "##### ElasticNet - MultiTaskElasticNet #####\n",
      "Error (ElasticNet-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNet - MultiTaskElasticNetCV #####\n",
      "Error (ElasticNet-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ElasticNet - MultiTaskLasso #####\n",
      "Error (ElasticNet-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNet - MultiTaskLassoCV #####\n",
      "Error (ElasticNet-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ElasticNet - NuSVR #####\n",
      "Train MSE: 2.801\n",
      "Train inference error (RMSE): ±1.673573245263369\n",
      "Test MSE: 3.851\n",
      "Test inference error (RMSE): ±1.9624685894243392\n",
      "##### ElasticNet - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 7.185\n",
      "Train inference error (RMSE): ±2.6804678588206814\n",
      "Test MSE: 7.983\n",
      "Test inference error (RMSE): ±2.825432720877768\n",
      "##### ElasticNet - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 7.050\n",
      "Train inference error (RMSE): ±2.655125695556681\n",
      "Test MSE: 7.587\n",
      "Test inference error (RMSE): ±2.7544466739593476\n",
      "##### ElasticNet - PLSCanonical #####\n",
      "Error (ElasticNet-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ElasticNet - PLSRegression #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615070081885444\n",
      "Test MSE: 7.266\n",
      "Test inference error (RMSE): ±2.695475281302172\n",
      "##### ElasticNet - PassiveAggressiveRegressor #####\n",
      "Train MSE: 7.183\n",
      "Train inference error (RMSE): ±2.6801162870825532\n",
      "Test MSE: 8.010\n",
      "Test inference error (RMSE): ±2.8302325827143915\n",
      "##### ElasticNet - PoissonRegressor #####\n",
      "Error (ElasticNet-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ElasticNet - QuantileRegressor #####\n",
      "Train MSE: 7.198\n",
      "Train inference error (RMSE): ±2.6829099607368194\n",
      "Test MSE: 7.989\n",
      "Test inference error (RMSE): ±2.826427000935959\n",
      "##### ElasticNet - RANSACRegressor #####\n",
      "Train MSE: 7.003\n",
      "Train inference error (RMSE): ±2.6462250813848778\n",
      "Test MSE: 7.680\n",
      "Test inference error (RMSE): ±2.7713438181264367\n",
      "##### ElasticNet - RadiusNeighborsRegressor #####\n",
      "Error (ElasticNet-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ElasticNet - RandomForestRegressor #####\n",
      "Train MSE: 0.436\n",
      "Train inference error (RMSE): ±0.6604463536571539\n",
      "Test MSE: 3.694\n",
      "Test inference error (RMSE): ±1.921968906601835\n",
      "##### ElasticNet - Ridge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614747979276573\n",
      "Test MSE: 7.255\n",
      "Test inference error (RMSE): ±2.6934308670267884\n",
      "##### ElasticNet - RidgeCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614714059514436\n",
      "Test MSE: 7.241\n",
      "Test inference error (RMSE): ±2.690959418638309\n",
      "##### ElasticNet - SGDRegressor #####\n",
      "Train MSE: 6.862\n",
      "Train inference error (RMSE): ±2.6195243434889024\n",
      "Test MSE: 7.350\n",
      "Test inference error (RMSE): ±2.7110231517387042\n",
      "##### ElasticNet - SVR #####\n",
      "Train MSE: 2.757\n",
      "Train inference error (RMSE): ±1.6603402230798259\n",
      "Test MSE: 3.932\n",
      "Test inference error (RMSE): ±1.9828060257567888\n",
      "##### ElasticNet - TheilSenRegressor #####\n",
      "Train MSE: 6.986\n",
      "Train inference error (RMSE): ±2.6431694628474354\n",
      "Test MSE: 7.584\n",
      "Test inference error (RMSE): ±2.7539433514599456\n",
      "##### ElasticNet - TransformedTargetRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147627988683957\n",
      "Test MSE: 7.257\n",
      "Test inference error (RMSE): ±2.6938775216165083\n",
      "##### ElasticNet - TweedieRegressor #####\n",
      "Train MSE: 6.861\n",
      "Train inference error (RMSE): ±2.619336056905721\n",
      "Test MSE: 7.358\n",
      "Test inference error (RMSE): ±2.712490491155287\n",
      "##### ElasticNetCV - ExtraTreeRegressor #####\n",
      "Train MSE: 3.095\n",
      "Train inference error (RMSE): ±1.7593650150660798\n",
      "Test MSE: 6.055\n",
      "Test inference error (RMSE): ±2.4605899744609356\n",
      "##### ElasticNetCV - ExtraTreesRegressor #####\n",
      "Train MSE: 0.912\n",
      "Train inference error (RMSE): ±0.9551153139931073\n",
      "Test MSE: 2.944\n",
      "Test inference error (RMSE): ±1.7156705682864122\n",
      "##### ElasticNetCV - GammaRegressor #####\n",
      "Error (ElasticNetCV-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ElasticNetCV - GaussianProcessRegressor #####\n",
      "Train MSE: 0.457\n",
      "Train inference error (RMSE): ±0.6762116642080778\n",
      "Test MSE: 4.225\n",
      "Test inference error (RMSE): ±2.055545043489672\n",
      "##### ElasticNetCV - GradientBoostingRegressor #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.8956542022641408\n",
      "Test MSE: 3.308\n",
      "Test inference error (RMSE): ±1.8188081072479674\n",
      "##### ElasticNetCV - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812182509422873\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718237470999785\n",
      "##### ElasticNetCV - HuberRegressor #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6173702956668268\n",
      "Test MSE: 7.301\n",
      "Test inference error (RMSE): ±2.7020167921592093\n",
      "##### ElasticNetCV - IsotonicRegression #####\n",
      "Error (ElasticNetCV-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ElasticNetCV - KNeighborsRegressor #####\n",
      "Train MSE: 2.761\n",
      "Train inference error (RMSE): ±1.6616285910327895\n",
      "Test MSE: 4.702\n",
      "Test inference error (RMSE): ±2.168370374771719\n",
      "##### ElasticNetCV - KernelRidge #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6149572638154597\n",
      "Test MSE: 7.225\n",
      "Test inference error (RMSE): ±2.6879816156769976\n",
      "##### ElasticNetCV - Lars #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6175026964185926\n",
      "Test MSE: 7.202\n",
      "Test inference error (RMSE): ±2.6837117321757273\n",
      "##### ElasticNetCV - LarsCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152639137891684\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.6868086319724154\n",
      "##### ElasticNetCV - Lasso #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153766373663117\n",
      "Test MSE: 7.200\n",
      "Test inference error (RMSE): ±2.683232348091169\n",
      "##### ElasticNetCV - LassoCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615267092999028\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.68684476571642\n",
      "##### ElasticNetCV - LassoLars #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153766372504847\n",
      "Test MSE: 7.200\n",
      "Test inference error (RMSE): ±2.6832323503297446\n",
      "##### ElasticNetCV - LassoLarsCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152639137891684\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.6868086319724154\n",
      "##### ElasticNetCV - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615282531384622\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.6867632202178298\n",
      "##### ElasticNetCV - LinearRegression #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6175026964188217\n",
      "Test MSE: 7.202\n",
      "Test inference error (RMSE): ±2.6837117321769264\n",
      "##### ElasticNetCV - LinearSVR #####\n",
      "Train MSE: 6.856\n",
      "Train inference error (RMSE): ±2.618302689994469\n",
      "Test MSE: 7.336\n",
      "Test inference error (RMSE): ±2.708574853107491\n",
      "##### ElasticNetCV - MLPRegressor #####\n",
      "Train MSE: 1.495\n",
      "Train inference error (RMSE): ±1.2225117263213054\n",
      "Test MSE: 2.241\n",
      "Test inference error (RMSE): ±1.4968642553314775\n",
      "##### ElasticNetCV - MultiTaskElasticNet #####\n",
      "Error (ElasticNetCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNetCV - MultiTaskElasticNetCV #####\n",
      "Error (ElasticNetCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ElasticNetCV - MultiTaskLasso #####\n",
      "Error (ElasticNetCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNetCV - MultiTaskLassoCV #####\n",
      "Error (ElasticNetCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ElasticNetCV - NuSVR #####\n",
      "Train MSE: 2.846\n",
      "Train inference error (RMSE): ±1.6871336829622001\n",
      "Test MSE: 4.007\n",
      "Test inference error (RMSE): ±2.0017558319985467\n",
      "##### ElasticNetCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.61531241554792\n",
      "Test MSE: 7.221\n",
      "Test inference error (RMSE): ±2.6871341489524223\n",
      "##### ElasticNetCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.6157493228325537\n",
      "Test MSE: 7.237\n",
      "Test inference error (RMSE): ±2.690166168109518\n",
      "##### ElasticNetCV - PLSCanonical #####\n",
      "Error (ElasticNetCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ElasticNetCV - PLSRegression #####\n",
      "Train MSE: 6.846\n",
      "Train inference error (RMSE): ±2.6164729251456604\n",
      "Test MSE: 7.207\n",
      "Test inference error (RMSE): ±2.684644367368102\n",
      "##### ElasticNetCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.854\n",
      "Train inference error (RMSE): ±2.6180543693360305\n",
      "Test MSE: 7.212\n",
      "Test inference error (RMSE): ±2.6854341095162617\n",
      "##### ElasticNetCV - PoissonRegressor #####\n",
      "Error (ElasticNetCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ElasticNetCV - QuantileRegressor #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6154964677324055\n",
      "Test MSE: 7.212\n",
      "Test inference error (RMSE): ±2.6855458417853173\n",
      "##### ElasticNetCV - RANSACRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153635405959106\n",
      "Test MSE: 7.228\n",
      "Test inference error (RMSE): ±2.688489434083778\n",
      "##### ElasticNetCV - RadiusNeighborsRegressor #####\n",
      "Error (ElasticNetCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ElasticNetCV - RandomForestRegressor #####\n",
      "Train MSE: 0.487\n",
      "Train inference error (RMSE): ±0.6978550719688007\n",
      "Test MSE: 3.490\n",
      "Test inference error (RMSE): ±1.868059375212833\n",
      "##### ElasticNetCV - Ridge #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6174441783355937\n",
      "Test MSE: 7.203\n",
      "Test inference error (RMSE): ±2.683852475453096\n",
      "##### ElasticNetCV - RidgeCV #####\n",
      "Train MSE: 6.848\n",
      "Train inference error (RMSE): ±2.6168261494168092\n",
      "Test MSE: 7.210\n",
      "Test inference error (RMSE): ±2.6850924066218935\n",
      "##### ElasticNetCV - SGDRegressor #####\n",
      "Train MSE: 6.850\n",
      "Train inference error (RMSE): ±2.6171729246649384\n",
      "Test MSE: 7.194\n",
      "Test inference error (RMSE): ±2.682129104165958\n",
      "##### ElasticNetCV - SVR #####\n",
      "Train MSE: 2.841\n",
      "Train inference error (RMSE): ±1.6855008513390541\n",
      "Test MSE: 4.117\n",
      "Test inference error (RMSE): ±2.029012888837406\n",
      "##### ElasticNetCV - TheilSenRegressor #####\n",
      "Train MSE: 6.845\n",
      "Train inference error (RMSE): ±2.616303725531594\n",
      "Test MSE: 7.272\n",
      "Test inference error (RMSE): ±2.6966230641084783\n",
      "##### ElasticNetCV - TransformedTargetRegressor #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6175026964188217\n",
      "Test MSE: 7.202\n",
      "Test inference error (RMSE): ±2.6837117321769264\n",
      "##### ElasticNetCV - TweedieRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153049526102845\n",
      "Test MSE: 7.215\n",
      "Test inference error (RMSE): ±2.6861157537858227\n",
      "##### ExtraTreeRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.563\n",
      "Train inference error (RMSE): ±0.7501538115773394\n",
      "Test MSE: 3.114\n",
      "Test inference error (RMSE): ±1.7647805670118397\n",
      "##### ExtraTreeRegressor - GammaRegressor #####\n",
      "Error (ExtraTreeRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ExtraTreeRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.527\n",
      "Train inference error (RMSE): ±0.7256841434279098\n",
      "Test MSE: 4.302\n",
      "Test inference error (RMSE): ±2.0741031570610575\n",
      "##### ExtraTreeRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.807\n",
      "Train inference error (RMSE): ±0.8980604312362191\n",
      "Test MSE: 3.274\n",
      "Test inference error (RMSE): ±1.809525696510716\n",
      "##### ExtraTreeRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.329\n",
      "Train inference error (RMSE): ±0.5737377922243259\n",
      "Test MSE: 2.467\n",
      "Test inference error (RMSE): ±1.5707326072767673\n",
      "##### ExtraTreeRegressor - HuberRegressor #####\n",
      "Train MSE: 3.378\n",
      "Train inference error (RMSE): ±1.8379406800894869\n",
      "Test MSE: 5.894\n",
      "Test inference error (RMSE): ±2.4278449736570566\n",
      "##### ExtraTreeRegressor - IsotonicRegression #####\n",
      "Error (ExtraTreeRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ExtraTreeRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 1.517\n",
      "Train inference error (RMSE): ±1.2317128131743205\n",
      "Test MSE: 4.374\n",
      "Test inference error (RMSE): ±2.0913593134126702\n",
      "##### ExtraTreeRegressor - KernelRidge #####\n",
      "Train MSE: 2.931\n",
      "Train inference error (RMSE): ±1.7120057719022417\n",
      "Test MSE: 6.340\n",
      "Test inference error (RMSE): ±2.5179371001406694\n",
      "##### ExtraTreeRegressor - Lars #####\n",
      "Train MSE: 2.677\n",
      "Train inference error (RMSE): ±1.6360497281808324\n",
      "Test MSE: 5.949\n",
      "Test inference error (RMSE): ±2.4391039380383104\n",
      "##### ExtraTreeRegressor - LarsCV #####\n",
      "Train MSE: 3.006\n",
      "Train inference error (RMSE): ±1.7339118410589156\n",
      "Test MSE: 5.647\n",
      "Test inference error (RMSE): ±2.3762407981588596\n",
      "##### ExtraTreeRegressor - Lasso #####\n",
      "Train MSE: 2.672\n",
      "Train inference error (RMSE): ±1.6347683619592894\n",
      "Test MSE: 7.508\n",
      "Test inference error (RMSE): ±2.740015051818752\n",
      "##### ExtraTreeRegressor - LassoCV #####\n",
      "Train MSE: 2.476\n",
      "Train inference error (RMSE): ±1.5733745538643322\n",
      "Test MSE: 6.012\n",
      "Test inference error (RMSE): ±2.4519270149482013\n",
      "##### ExtraTreeRegressor - LassoLars #####\n",
      "Train MSE: 2.659\n",
      "Train inference error (RMSE): ±1.6306695240847926\n",
      "Test MSE: 7.708\n",
      "Test inference error (RMSE): ±2.776266889235383\n",
      "##### ExtraTreeRegressor - LassoLarsCV #####\n",
      "Train MSE: 3.017\n",
      "Train inference error (RMSE): ±1.7370003283723414\n",
      "Test MSE: 6.015\n",
      "Test inference error (RMSE): ±2.4524961441877724\n",
      "##### ExtraTreeRegressor - LassoLarsIC #####\n",
      "Train MSE: 3.166\n",
      "Train inference error (RMSE): ±1.7793885662896445\n",
      "Test MSE: 6.343\n",
      "Test inference error (RMSE): ±2.5185823070579745\n",
      "##### ExtraTreeRegressor - LinearRegression #####\n",
      "Train MSE: 3.022\n",
      "Train inference error (RMSE): ±1.7385019667106179\n",
      "Test MSE: 6.021\n",
      "Test inference error (RMSE): ±2.4538255521377574\n",
      "##### ExtraTreeRegressor - LinearSVR #####\n",
      "Train MSE: 2.637\n",
      "Train inference error (RMSE): ±1.6239192941861655\n",
      "Test MSE: 5.550\n",
      "Test inference error (RMSE): ±2.3558303785638914\n",
      "##### ExtraTreeRegressor - MLPRegressor #####\n",
      "Train MSE: 1.193\n",
      "Train inference error (RMSE): ±1.0921884490854672\n",
      "Test MSE: 2.142\n",
      "Test inference error (RMSE): ±1.4634410959586979\n",
      "##### ExtraTreeRegressor - MultiTaskElasticNet #####\n",
      "Error (ExtraTreeRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreeRegressor - MultiTaskElasticNetCV #####\n",
      "Error (ExtraTreeRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ExtraTreeRegressor - MultiTaskLasso #####\n",
      "Error (ExtraTreeRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreeRegressor - MultiTaskLassoCV #####\n",
      "Error (ExtraTreeRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ExtraTreeRegressor - NuSVR #####\n",
      "Train MSE: 2.216\n",
      "Train inference error (RMSE): ±1.4887849807875098\n",
      "Test MSE: 4.292\n",
      "Test inference error (RMSE): ±2.071814115293417\n",
      "##### ExtraTreeRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 1.961\n",
      "Train inference error (RMSE): ±1.400341666551888\n",
      "Test MSE: 9.900\n",
      "Test inference error (RMSE): ±3.146440550093972\n",
      "##### ExtraTreeRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 2.766\n",
      "Train inference error (RMSE): ±1.6631833354559045\n",
      "Test MSE: 6.283\n",
      "Test inference error (RMSE): ±2.5065339729874205\n",
      "##### ExtraTreeRegressor - PLSCanonical #####\n",
      "Error (ExtraTreeRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ExtraTreeRegressor - PLSRegression #####\n",
      "Train MSE: 2.819\n",
      "Train inference error (RMSE): ±1.6789248158697532\n",
      "Test MSE: 5.530\n",
      "Test inference error (RMSE): ±2.3516486666197287\n",
      "##### ExtraTreeRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 2.164\n",
      "Train inference error (RMSE): ±1.4709133779582464\n",
      "Test MSE: 9.410\n",
      "Test inference error (RMSE): ±3.0675374926251378\n",
      "##### ExtraTreeRegressor - PoissonRegressor #####\n",
      "Error (ExtraTreeRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ExtraTreeRegressor - QuantileRegressor #####\n",
      "Train MSE: 1.285\n",
      "Train inference error (RMSE): ±1.1334314140834612\n",
      "Test MSE: 8.389\n",
      "Test inference error (RMSE): ±2.8963720451808377\n",
      "##### ExtraTreeRegressor - RANSACRegressor #####\n",
      "Train MSE: 3.236\n",
      "Train inference error (RMSE): ±1.7990188305965693\n",
      "Test MSE: 6.532\n",
      "Test inference error (RMSE): ±2.5558242632883337\n",
      "##### ExtraTreeRegressor - RadiusNeighborsRegressor #####\n",
      "Error (ExtraTreeRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ExtraTreeRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.450\n",
      "Train inference error (RMSE): ±0.6711879228362774\n",
      "Test MSE: 3.611\n",
      "Test inference error (RMSE): ±1.9001789693088718\n",
      "##### ExtraTreeRegressor - Ridge #####\n",
      "Train MSE: 3.273\n",
      "Train inference error (RMSE): ±1.8091280938120442\n",
      "Test MSE: 6.378\n",
      "Test inference error (RMSE): ±2.525465991439465\n",
      "##### ExtraTreeRegressor - RidgeCV #####\n",
      "Train MSE: 3.000\n",
      "Train inference error (RMSE): ±1.7319671145464923\n",
      "Test MSE: 6.710\n",
      "Test inference error (RMSE): ±2.5903888959701455\n",
      "##### ExtraTreeRegressor - SGDRegressor #####\n",
      "Train MSE: 3.069\n",
      "Train inference error (RMSE): ±1.7517861076053654\n",
      "Test MSE: 6.604\n",
      "Test inference error (RMSE): ±2.5698695295464677\n",
      "##### ExtraTreeRegressor - SVR #####\n",
      "Train MSE: 2.473\n",
      "Train inference error (RMSE): ±1.5727144361602896\n",
      "Test MSE: 3.947\n",
      "Test inference error (RMSE): ±1.98659970583609\n",
      "##### ExtraTreeRegressor - TheilSenRegressor #####\n",
      "Train MSE: 3.393\n",
      "Train inference error (RMSE): ±1.842084497870563\n",
      "Test MSE: 6.680\n",
      "Test inference error (RMSE): ±2.5845076952076305\n",
      "##### ExtraTreeRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 3.429\n",
      "Train inference error (RMSE): ±1.8518756190019388\n",
      "Test MSE: 6.189\n",
      "Test inference error (RMSE): ±2.4878431033487094\n",
      "##### ExtraTreeRegressor - TweedieRegressor #####\n",
      "Train MSE: 3.010\n",
      "Train inference error (RMSE): ±1.734906703723389\n",
      "Test MSE: 5.146\n",
      "Test inference error (RMSE): ±2.268471048102815\n",
      "##### ExtraTreesRegressor - GammaRegressor #####\n",
      "Error (ExtraTreesRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ExtraTreesRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.784\n",
      "Train inference error (RMSE): ±0.8852383607979543\n",
      "Test MSE: 3.013\n",
      "Test inference error (RMSE): ±1.7356911503732335\n",
      "##### ExtraTreesRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.404\n",
      "Train inference error (RMSE): ±0.6357482298569513\n",
      "Test MSE: 2.913\n",
      "Test inference error (RMSE): ±1.7068134494356786\n",
      "##### ExtraTreesRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.285\n",
      "Train inference error (RMSE): ±0.5340865128936609\n",
      "Test MSE: 2.380\n",
      "Test inference error (RMSE): ±1.5425751861371297\n",
      "##### ExtraTreesRegressor - HuberRegressor #####\n",
      "Train MSE: 0.919\n",
      "Train inference error (RMSE): ±0.9586691890587825\n",
      "Test MSE: 3.085\n",
      "Test inference error (RMSE): ±1.7564032118583928\n",
      "##### ExtraTreesRegressor - IsotonicRegression #####\n",
      "Error (ExtraTreesRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ExtraTreesRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.488\n",
      "Train inference error (RMSE): ±0.6983002968974932\n",
      "Test MSE: 3.161\n",
      "Test inference error (RMSE): ±1.7779705759438915\n",
      "##### ExtraTreesRegressor - KernelRidge #####\n",
      "Train MSE: 0.891\n",
      "Train inference error (RMSE): ±0.9441120322879121\n",
      "Test MSE: 3.020\n",
      "Test inference error (RMSE): ±1.7377572377130044\n",
      "##### ExtraTreesRegressor - Lars #####\n",
      "Train MSE: 0.856\n",
      "Train inference error (RMSE): ±0.9249449644014371\n",
      "Test MSE: 3.090\n",
      "Test inference error (RMSE): ±1.7577665309328\n",
      "##### ExtraTreesRegressor - LarsCV #####\n",
      "Train MSE: 0.902\n",
      "Train inference error (RMSE): ±0.9499637686974056\n",
      "Test MSE: 2.958\n",
      "Test inference error (RMSE): ±1.7198656724575718\n",
      "##### ExtraTreesRegressor - Lasso #####\n",
      "Train MSE: 1.248\n",
      "Train inference error (RMSE): ±1.1170426803168028\n",
      "Test MSE: 2.827\n",
      "Test inference error (RMSE): ±1.6814930550480338\n",
      "##### ExtraTreesRegressor - LassoCV #####\n",
      "Train MSE: 0.755\n",
      "Train inference error (RMSE): ±0.869039626766937\n",
      "Test MSE: 3.050\n",
      "Test inference error (RMSE): ±1.746367006377192\n",
      "##### ExtraTreesRegressor - LassoLars #####\n",
      "Train MSE: 1.137\n",
      "Train inference error (RMSE): ±1.0665106973348808\n",
      "Test MSE: 2.825\n",
      "Test inference error (RMSE): ±1.6807724302544245\n",
      "##### ExtraTreesRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.806\n",
      "Train inference error (RMSE): ±0.8980074167049347\n",
      "Test MSE: 2.951\n",
      "Test inference error (RMSE): ±1.7179201829804431\n",
      "##### ExtraTreesRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.827\n",
      "Train inference error (RMSE): ±0.9094520910801838\n",
      "Test MSE: 3.099\n",
      "Test inference error (RMSE): ±1.7605285456738906\n",
      "##### ExtraTreesRegressor - LinearRegression #####\n",
      "Train MSE: 0.855\n",
      "Train inference error (RMSE): ±0.9247083216954878\n",
      "Test MSE: 3.419\n",
      "Test inference error (RMSE): ±1.8489552741063366\n",
      "##### ExtraTreesRegressor - LinearSVR #####\n",
      "Train MSE: 0.987\n",
      "Train inference error (RMSE): ±0.9933730268102839\n",
      "Test MSE: 3.045\n",
      "Test inference error (RMSE): ±1.7449973928273894\n",
      "##### ExtraTreesRegressor - MLPRegressor #####\n",
      "Train MSE: 0.642\n",
      "Train inference error (RMSE): ±0.8010627051368757\n",
      "Test MSE: 2.261\n",
      "Test inference error (RMSE): ±1.5036783501902538\n",
      "##### ExtraTreesRegressor - MultiTaskElasticNet #####\n",
      "Error (ExtraTreesRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreesRegressor - MultiTaskElasticNetCV #####\n",
      "Error (ExtraTreesRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ExtraTreesRegressor - MultiTaskLasso #####\n",
      "Error (ExtraTreesRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreesRegressor - MultiTaskLassoCV #####\n",
      "Error (ExtraTreesRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ExtraTreesRegressor - NuSVR #####\n",
      "Train MSE: 0.415\n",
      "Train inference error (RMSE): ±0.6444773373992692\n",
      "Test MSE: 3.152\n",
      "Test inference error (RMSE): ±1.7753014978550534\n",
      "##### ExtraTreesRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.660\n",
      "Train inference error (RMSE): ±0.8124300594438955\n",
      "Test MSE: 3.073\n",
      "Test inference error (RMSE): ±1.752929791250265\n",
      "##### ExtraTreesRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.970\n",
      "Train inference error (RMSE): ±0.9848437752435963\n",
      "Test MSE: 3.041\n",
      "Test inference error (RMSE): ±1.7438059686184522\n",
      "##### ExtraTreesRegressor - PLSCanonical #####\n",
      "Error (ExtraTreesRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ExtraTreesRegressor - PLSRegression #####\n",
      "Train MSE: 0.789\n",
      "Train inference error (RMSE): ±0.8883730904911201\n",
      "Test MSE: 2.936\n",
      "Test inference error (RMSE): ±1.713343362208311\n",
      "##### ExtraTreesRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.763\n",
      "Train inference error (RMSE): ±0.8737823423226269\n",
      "Test MSE: 3.145\n",
      "Test inference error (RMSE): ±1.7734384285085893\n",
      "##### ExtraTreesRegressor - PoissonRegressor #####\n",
      "Error (ExtraTreesRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ExtraTreesRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.605\n",
      "Train inference error (RMSE): ±0.7776177927334023\n",
      "Test MSE: 3.036\n",
      "Test inference error (RMSE): ±1.7424133137268185\n",
      "##### ExtraTreesRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.857\n",
      "Train inference error (RMSE): ±0.925505109990922\n",
      "Test MSE: 2.953\n",
      "Test inference error (RMSE): ±1.7182848081904987\n",
      "##### ExtraTreesRegressor - RadiusNeighborsRegressor #####\n",
      "Error (ExtraTreesRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ExtraTreesRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.710\n",
      "Train inference error (RMSE): ±0.8425831757726879\n",
      "Test MSE: 3.113\n",
      "Test inference error (RMSE): ±1.764455946442426\n",
      "##### ExtraTreesRegressor - Ridge #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.895657364025122\n",
      "Test MSE: 2.965\n",
      "Test inference error (RMSE): ±1.7218099787996044\n",
      "##### ExtraTreesRegressor - RidgeCV #####\n",
      "Train MSE: 0.901\n",
      "Train inference error (RMSE): ±0.9493127953326513\n",
      "Test MSE: 3.071\n",
      "Test inference error (RMSE): ±1.752316599029744\n",
      "##### ExtraTreesRegressor - SGDRegressor #####\n",
      "Train MSE: 0.879\n",
      "Train inference error (RMSE): ±0.9375714723760079\n",
      "Test MSE: 3.064\n",
      "Test inference error (RMSE): ±1.750351439505568\n",
      "##### ExtraTreesRegressor - SVR #####\n",
      "Train MSE: 0.430\n",
      "Train inference error (RMSE): ±0.6556803845024975\n",
      "Test MSE: 3.064\n",
      "Test inference error (RMSE): ±1.7504702096132163\n",
      "##### ExtraTreesRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.918\n",
      "Train inference error (RMSE): ±0.9583092388615536\n",
      "Test MSE: 3.211\n",
      "Test inference error (RMSE): ±1.791985266690741\n",
      "##### ExtraTreesRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.896\n",
      "Train inference error (RMSE): ±0.9465419619225103\n",
      "Test MSE: 2.881\n",
      "Test inference error (RMSE): ±1.6972206172887794\n",
      "##### ExtraTreesRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.852\n",
      "Train inference error (RMSE): ±0.9228116443117713\n",
      "Test MSE: 3.077\n",
      "Test inference error (RMSE): ±1.7540551688475212\n",
      "##### GammaRegressor - GaussianProcessRegressor #####\n",
      "Error (GammaRegressor-GaussianProcessRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - GradientBoostingRegressor #####\n",
      "Error (GammaRegressor-GradientBoostingRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - HistGradientBoostingRegressor #####\n",
      "Error (GammaRegressor-HistGradientBoostingRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - HuberRegressor #####\n",
      "Error (GammaRegressor-HuberRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - IsotonicRegression #####\n",
      "Error (GammaRegressor-IsotonicRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - KNeighborsRegressor #####\n",
      "Error (GammaRegressor-KNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - KernelRidge #####\n",
      "Error (GammaRegressor-KernelRidge): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Lars #####\n",
      "Error (GammaRegressor-Lars): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LarsCV #####\n",
      "Error (GammaRegressor-LarsCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Lasso #####\n",
      "Error (GammaRegressor-Lasso): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoCV #####\n",
      "Error (GammaRegressor-LassoCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLars #####\n",
      "Error (GammaRegressor-LassoLars): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLarsCV #####\n",
      "Error (GammaRegressor-LassoLarsCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLarsIC #####\n",
      "Error (GammaRegressor-LassoLarsIC): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LinearRegression #####\n",
      "Error (GammaRegressor-LinearRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LinearSVR #####\n",
      "Error (GammaRegressor-LinearSVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MLPRegressor #####\n",
      "Error (GammaRegressor-MLPRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskElasticNet #####\n",
      "Error (GammaRegressor-MultiTaskElasticNet): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GammaRegressor-MultiTaskElasticNetCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskLasso #####\n",
      "Error (GammaRegressor-MultiTaskLasso): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskLassoCV #####\n",
      "Error (GammaRegressor-MultiTaskLassoCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - NuSVR #####\n",
      "Error (GammaRegressor-NuSVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - OrthogonalMatchingPursuit #####\n",
      "Error (GammaRegressor-OrthogonalMatchingPursuit): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Error (GammaRegressor-OrthogonalMatchingPursuitCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PLSCanonical #####\n",
      "Error (GammaRegressor-PLSCanonical): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PLSRegression #####\n",
      "Error (GammaRegressor-PLSRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PassiveAggressiveRegressor #####\n",
      "Error (GammaRegressor-PassiveAggressiveRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PoissonRegressor #####\n",
      "Error (GammaRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - QuantileRegressor #####\n",
      "Error (GammaRegressor-QuantileRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RANSACRegressor #####\n",
      "Error (GammaRegressor-RANSACRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GammaRegressor-RadiusNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RandomForestRegressor #####\n",
      "Error (GammaRegressor-RandomForestRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Ridge #####\n",
      "Error (GammaRegressor-Ridge): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RidgeCV #####\n",
      "Error (GammaRegressor-RidgeCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - SGDRegressor #####\n",
      "Error (GammaRegressor-SGDRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - SVR #####\n",
      "Error (GammaRegressor-SVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TheilSenRegressor #####\n",
      "Error (GammaRegressor-TheilSenRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TransformedTargetRegressor #####\n",
      "Error (GammaRegressor-TransformedTargetRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TweedieRegressor #####\n",
      "Error (GammaRegressor-TweedieRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GaussianProcessRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.561\n",
      "Train inference error (RMSE): ±0.7491230978518888\n",
      "Test MSE: 3.007\n",
      "Test inference error (RMSE): ±1.7340713011005318\n",
      "##### GaussianProcessRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.324\n",
      "Train inference error (RMSE): ±0.5688316883231569\n",
      "Test MSE: 2.480\n",
      "Test inference error (RMSE): ±1.574894194682812\n",
      "##### GaussianProcessRegressor - HuberRegressor #####\n",
      "Train MSE: 0.446\n",
      "Train inference error (RMSE): ±0.6681507610138016\n",
      "Test MSE: 4.308\n",
      "Test inference error (RMSE): ±2.0756325684444956\n",
      "##### GaussianProcessRegressor - IsotonicRegression #####\n",
      "Error (GaussianProcessRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### GaussianProcessRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.511\n",
      "Train inference error (RMSE): ±0.7146906955365246\n",
      "Test MSE: 3.995\n",
      "Test inference error (RMSE): ±1.9988428889119123\n",
      "##### GaussianProcessRegressor - KernelRidge #####\n",
      "Train MSE: 0.457\n",
      "Train inference error (RMSE): ±0.6759643024635817\n",
      "Test MSE: 4.225\n",
      "Test inference error (RMSE): ±2.05553409979583\n",
      "##### GaussianProcessRegressor - Lars #####\n",
      "Train MSE: 0.456\n",
      "Train inference error (RMSE): ±0.6753239212656035\n",
      "Test MSE: 4.226\n",
      "Test inference error (RMSE): ±2.0557174721653033\n",
      "##### GaussianProcessRegressor - LarsCV #####\n",
      "Train MSE: 0.459\n",
      "Train inference error (RMSE): ±0.6773726008353675\n",
      "Test MSE: 4.225\n",
      "Test inference error (RMSE): ±2.0555215455071085\n",
      "##### GaussianProcessRegressor - Lasso #####\n",
      "Train MSE: 0.403\n",
      "Train inference error (RMSE): ±0.6348275233927623\n",
      "Test MSE: 4.446\n",
      "Test inference error (RMSE): ±2.1084477270572335\n",
      "##### GaussianProcessRegressor - LassoCV #####\n",
      "Train MSE: 0.459\n",
      "Train inference error (RMSE): ±0.6772108014599765\n",
      "Test MSE: 4.225\n",
      "Test inference error (RMSE): ±2.055557215127583\n",
      "##### GaussianProcessRegressor - LassoLars #####\n",
      "Train MSE: 0.403\n",
      "Train inference error (RMSE): ±0.634827522305642\n",
      "Test MSE: 4.446\n",
      "Test inference error (RMSE): ±2.1084477242777875\n",
      "##### GaussianProcessRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.459\n",
      "Train inference error (RMSE): ±0.6773726008353675\n",
      "Test MSE: 4.225\n",
      "Test inference error (RMSE): ±2.0555215455071085\n",
      "##### GaussianProcessRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.457\n",
      "Train inference error (RMSE): ±0.6759375684503783\n",
      "Test MSE: 4.224\n",
      "Test inference error (RMSE): ±2.0552905356199536\n",
      "##### GaussianProcessRegressor - LinearRegression #####\n",
      "Train MSE: 0.456\n",
      "Train inference error (RMSE): ±0.6753239212689917\n",
      "Test MSE: 4.226\n",
      "Test inference error (RMSE): ±2.0557174721652145\n",
      "##### GaussianProcessRegressor - LinearSVR #####\n",
      "Train MSE: 0.443\n",
      "Train inference error (RMSE): ±0.6652249056845989\n",
      "Test MSE: 4.321\n",
      "Test inference error (RMSE): ±2.078739992924085\n",
      "##### GaussianProcessRegressor - MLPRegressor #####\n",
      "Train MSE: 0.842\n",
      "Train inference error (RMSE): ±0.9178458881324107\n",
      "Test MSE: 2.260\n",
      "Test inference error (RMSE): ±1.5034532381301036\n",
      "##### GaussianProcessRegressor - MultiTaskElasticNet #####\n",
      "Error (GaussianProcessRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### GaussianProcessRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GaussianProcessRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### GaussianProcessRegressor - MultiTaskLasso #####\n",
      "Error (GaussianProcessRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### GaussianProcessRegressor - MultiTaskLassoCV #####\n",
      "Error (GaussianProcessRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### GaussianProcessRegressor - NuSVR #####\n",
      "Train MSE: 0.797\n",
      "Train inference error (RMSE): ±0.8927007638367421\n",
      "Test MSE: 3.796\n",
      "Test inference error (RMSE): ±1.9483210946161025\n",
      "##### GaussianProcessRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.480\n",
      "Train inference error (RMSE): ±0.6930304066683107\n",
      "Test MSE: 4.471\n",
      "Test inference error (RMSE): ±2.114526071117709\n",
      "##### GaussianProcessRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.439\n",
      "Train inference error (RMSE): ±0.6624568329069911\n",
      "Test MSE: 4.300\n",
      "Test inference error (RMSE): ±2.073706537333549\n",
      "##### GaussianProcessRegressor - PLSCanonical #####\n",
      "Error (GaussianProcessRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### GaussianProcessRegressor - PLSRegression #####\n",
      "Train MSE: 0.456\n",
      "Train inference error (RMSE): ±0.6754687745918966\n",
      "Test MSE: 4.228\n",
      "Test inference error (RMSE): ±2.0561001199255453\n",
      "##### GaussianProcessRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.783\n",
      "Train inference error (RMSE): ±0.8848964313546774\n",
      "Test MSE: 4.381\n",
      "Test inference error (RMSE): ±2.0930133796708876\n",
      "##### GaussianProcessRegressor - PoissonRegressor #####\n",
      "Error (GaussianProcessRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### GaussianProcessRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.477\n",
      "Train inference error (RMSE): ±0.6904887207456504\n",
      "Test MSE: 4.431\n",
      "Test inference error (RMSE): ±2.1049426849236275\n",
      "##### GaussianProcessRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.421\n",
      "Train inference error (RMSE): ±0.6489182200463531\n",
      "Test MSE: 4.280\n",
      "Test inference error (RMSE): ±2.068801813594282\n",
      "##### GaussianProcessRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GaussianProcessRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### GaussianProcessRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.542\n",
      "Train inference error (RMSE): ±0.736352526018867\n",
      "Test MSE: 3.194\n",
      "Test inference error (RMSE): ±1.7870905170969253\n",
      "##### GaussianProcessRegressor - Ridge #####\n",
      "Train MSE: 0.456\n",
      "Train inference error (RMSE): ±0.6755300887278203\n",
      "Test MSE: 4.226\n",
      "Test inference error (RMSE): ±2.0556834192495796\n",
      "##### GaussianProcessRegressor - RidgeCV #####\n",
      "Train MSE: 0.459\n",
      "Train inference error (RMSE): ±0.6771397494732436\n",
      "Test MSE: 4.225\n",
      "Test inference error (RMSE): ±2.055498647699278\n",
      "##### GaussianProcessRegressor - SGDRegressor #####\n",
      "Train MSE: 0.463\n",
      "Train inference error (RMSE): ±0.68013026009219\n",
      "Test MSE: 4.236\n",
      "Test inference error (RMSE): ±2.058060355932262\n",
      "##### GaussianProcessRegressor - SVR #####\n",
      "Train MSE: 0.905\n",
      "Train inference error (RMSE): ±0.9510667215607463\n",
      "Test MSE: 3.832\n",
      "Test inference error (RMSE): ±1.9576686882354961\n",
      "##### GaussianProcessRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.431\n",
      "Train inference error (RMSE): ±0.6566061552572567\n",
      "Test MSE: 4.312\n",
      "Test inference error (RMSE): ±2.076569406710643\n",
      "##### GaussianProcessRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.456\n",
      "Train inference error (RMSE): ±0.6753239212689917\n",
      "Test MSE: 4.226\n",
      "Test inference error (RMSE): ±2.0557174721652145\n",
      "##### GaussianProcessRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.452\n",
      "Train inference error (RMSE): ±0.6724840269800002\n",
      "Test MSE: 4.245\n",
      "Test inference error (RMSE): ±2.06037480634364\n",
      "##### GradientBoostingRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.357\n",
      "Train inference error (RMSE): ±0.5978724411159945\n",
      "Test MSE: 2.482\n",
      "Test inference error (RMSE): ±1.575522272524492\n",
      "##### GradientBoostingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.805\n",
      "Train inference error (RMSE): ±0.8970011486810157\n",
      "Test MSE: 3.294\n",
      "Test inference error (RMSE): ±1.8148500454965002\n",
      "##### GradientBoostingRegressor - IsotonicRegression #####\n",
      "Error (GradientBoostingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### GradientBoostingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.855\n",
      "Train inference error (RMSE): ±0.9247336183061925\n",
      "Test MSE: 3.178\n",
      "Test inference error (RMSE): ±1.7828276307596345\n",
      "##### GradientBoostingRegressor - KernelRidge #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.8957547562409258\n",
      "Test MSE: 3.335\n",
      "Test inference error (RMSE): ±1.82616959598635\n",
      "##### GradientBoostingRegressor - Lars #####\n",
      "Train MSE: 0.803\n",
      "Train inference error (RMSE): ±0.895906060387611\n",
      "Test MSE: 3.322\n",
      "Test inference error (RMSE): ±1.8225333932770174\n",
      "##### GradientBoostingRegressor - LarsCV #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.8956557973047604\n",
      "Test MSE: 3.296\n",
      "Test inference error (RMSE): ±1.8153635402120472\n",
      "##### GradientBoostingRegressor - Lasso #####\n",
      "Train MSE: 0.821\n",
      "Train inference error (RMSE): ±0.9060235656913028\n",
      "Test MSE: 3.247\n",
      "Test inference error (RMSE): ±1.8019077689330563\n",
      "##### GradientBoostingRegressor - LassoCV #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.895798373146383\n",
      "Test MSE: 3.366\n",
      "Test inference error (RMSE): ±1.8347602688002043\n",
      "##### GradientBoostingRegressor - LassoLars #####\n",
      "Train MSE: 0.820\n",
      "Train inference error (RMSE): ±0.9056985626246484\n",
      "Test MSE: 3.245\n",
      "Test inference error (RMSE): ±1.801354496465372\n",
      "##### GradientBoostingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.8954976994637153\n",
      "Test MSE: 3.325\n",
      "Test inference error (RMSE): ±1.8233484699587046\n",
      "##### GradientBoostingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.801\n",
      "Train inference error (RMSE): ±0.894861213068227\n",
      "Test MSE: 3.337\n",
      "Test inference error (RMSE): ±1.8267015178858663\n",
      "##### GradientBoostingRegressor - LinearRegression #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.8955551387925752\n",
      "Test MSE: 3.359\n",
      "Test inference error (RMSE): ±1.832709326461419\n",
      "##### GradientBoostingRegressor - LinearSVR #####\n",
      "Train MSE: 0.806\n",
      "Train inference error (RMSE): ±0.8979575478371286\n",
      "Test MSE: 3.308\n",
      "Test inference error (RMSE): ±1.8187382565372374\n",
      "##### GradientBoostingRegressor - MLPRegressor #####\n",
      "Train MSE: 0.992\n",
      "Train inference error (RMSE): ±0.9959539377715364\n",
      "Test MSE: 2.303\n",
      "Test inference error (RMSE): ±1.5175328362583516\n",
      "##### GradientBoostingRegressor - MultiTaskElasticNet #####\n",
      "Error (GradientBoostingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### GradientBoostingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GradientBoostingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### GradientBoostingRegressor - MultiTaskLasso #####\n",
      "Error (GradientBoostingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### GradientBoostingRegressor - MultiTaskLassoCV #####\n",
      "Error (GradientBoostingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### GradientBoostingRegressor - NuSVR #####\n",
      "Train MSE: 0.999\n",
      "Train inference error (RMSE): ±0.9995740663401164\n",
      "Test MSE: 3.211\n",
      "Test inference error (RMSE): ±1.7918756016234993\n",
      "##### GradientBoostingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.845\n",
      "Train inference error (RMSE): ±0.9193636781989502\n",
      "Test MSE: 3.283\n",
      "Test inference error (RMSE): ±1.8117854451609727\n",
      "##### GradientBoostingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.808\n",
      "Train inference error (RMSE): ±0.8986669360511571\n",
      "Test MSE: 3.351\n",
      "Test inference error (RMSE): ±1.8306850534031118\n",
      "##### GradientBoostingRegressor - PLSCanonical #####\n",
      "Error (GradientBoostingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### GradientBoostingRegressor - PLSRegression #####\n",
      "Train MSE: 0.803\n",
      "Train inference error (RMSE): ±0.896119845543204\n",
      "Test MSE: 3.318\n",
      "Test inference error (RMSE): ±1.8214592447822069\n",
      "##### GradientBoostingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.824\n",
      "Train inference error (RMSE): ±0.9079909221253385\n",
      "Test MSE: 3.358\n",
      "Test inference error (RMSE): ±1.832465623601683\n",
      "##### GradientBoostingRegressor - PoissonRegressor #####\n",
      "Error (GradientBoostingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### GradientBoostingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.856\n",
      "Train inference error (RMSE): ±0.9250781458005788\n",
      "Test MSE: 3.299\n",
      "Test inference error (RMSE): ±1.8163567093860966\n",
      "##### GradientBoostingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.819\n",
      "Train inference error (RMSE): ±0.9047533225529868\n",
      "Test MSE: 3.244\n",
      "Test inference error (RMSE): ±1.8010500282238793\n",
      "##### GradientBoostingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GradientBoostingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### GradientBoostingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.746\n",
      "Train inference error (RMSE): ±0.8634343322480175\n",
      "Test MSE: 3.322\n",
      "Test inference error (RMSE): ±1.822757709242309\n",
      "##### GradientBoostingRegressor - Ridge #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.8953126129484501\n",
      "Test MSE: 3.303\n",
      "Test inference error (RMSE): ±1.8172892578957562\n",
      "##### GradientBoostingRegressor - RidgeCV #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.8953646593433148\n",
      "Test MSE: 3.282\n",
      "Test inference error (RMSE): ±1.811494730936494\n",
      "##### GradientBoostingRegressor - SGDRegressor #####\n",
      "Train MSE: 0.801\n",
      "Train inference error (RMSE): ±0.8951387645549723\n",
      "Test MSE: 3.299\n",
      "Test inference error (RMSE): ±1.816238906653189\n",
      "##### GradientBoostingRegressor - SVR #####\n",
      "Train MSE: 1.030\n",
      "Train inference error (RMSE): ±1.0149577014060582\n",
      "Test MSE: 3.191\n",
      "Test inference error (RMSE): ±1.7862712163777654\n",
      "##### GradientBoostingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.805\n",
      "Train inference error (RMSE): ±0.8972510103069024\n",
      "Test MSE: 3.327\n",
      "Test inference error (RMSE): ±1.8240165018647028\n",
      "##### GradientBoostingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.803\n",
      "Train inference error (RMSE): ±0.8961962551827045\n",
      "Test MSE: 3.324\n",
      "Test inference error (RMSE): ±1.8230882956116141\n",
      "##### GradientBoostingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.802\n",
      "Train inference error (RMSE): ±0.895539588534527\n",
      "Test MSE: 3.309\n",
      "Test inference error (RMSE): ±1.819071185397593\n",
      "##### HistGradientBoostingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.337\n",
      "Train inference error (RMSE): ±0.5805735242508041\n",
      "Test MSE: 2.465\n",
      "Test inference error (RMSE): ±1.5699071642951077\n",
      "##### HistGradientBoostingRegressor - IsotonicRegression #####\n",
      "Error (HistGradientBoostingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### HistGradientBoostingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.393\n",
      "Train inference error (RMSE): ±0.6265261835843046\n",
      "Test MSE: 2.425\n",
      "Test inference error (RMSE): ±1.5572630242881285\n",
      "##### HistGradientBoostingRegressor - KernelRidge #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812990789442902\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718215224985204\n",
      "##### HistGradientBoostingRegressor - Lars #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812674625996332\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718136511418292\n",
      "##### HistGradientBoostingRegressor - LarsCV #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5810741684505425\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718544090498325\n",
      "##### HistGradientBoostingRegressor - Lasso #####\n",
      "Train MSE: 0.347\n",
      "Train inference error (RMSE): ±0.5886552015755567\n",
      "Test MSE: 2.423\n",
      "Test inference error (RMSE): ±1.5567398432798052\n",
      "##### HistGradientBoostingRegressor - LassoCV #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5810759565992599\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718504448334938\n",
      "##### HistGradientBoostingRegressor - LassoLars #####\n",
      "Train MSE: 0.347\n",
      "Train inference error (RMSE): ±0.5886552013096903\n",
      "Test MSE: 2.423\n",
      "Test inference error (RMSE): ±1.5567398439569529\n",
      "##### HistGradientBoostingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5810741684505425\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718544090498325\n",
      "##### HistGradientBoostingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5811627843312133\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718477670910038\n",
      "##### HistGradientBoostingRegressor - LinearRegression #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812674625977867\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718136511428265\n",
      "##### HistGradientBoostingRegressor - LinearSVR #####\n",
      "Train MSE: 0.337\n",
      "Train inference error (RMSE): ±0.5806546960028001\n",
      "Test MSE: 2.464\n",
      "Test inference error (RMSE): ±1.5695632438879703\n",
      "##### HistGradientBoostingRegressor - MLPRegressor #####\n",
      "Train MSE: 0.582\n",
      "Train inference error (RMSE): ±0.7631913029573923\n",
      "Test MSE: 1.964\n",
      "Test inference error (RMSE): ±1.4014085185558822\n",
      "##### HistGradientBoostingRegressor - MultiTaskElasticNet #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### HistGradientBoostingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### HistGradientBoostingRegressor - MultiTaskLasso #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### HistGradientBoostingRegressor - MultiTaskLassoCV #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### HistGradientBoostingRegressor - NuSVR #####\n",
      "Train MSE: 0.450\n",
      "Train inference error (RMSE): ±0.6706302733303063\n",
      "Test MSE: 2.452\n",
      "Test inference error (RMSE): ±1.5659304834287096\n",
      "##### HistGradientBoostingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.342\n",
      "Train inference error (RMSE): ±0.5849413697150712\n",
      "Test MSE: 2.459\n",
      "Test inference error (RMSE): ±1.5681104450489696\n",
      "##### HistGradientBoostingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.336\n",
      "Train inference error (RMSE): ±0.579799536994605\n",
      "Test MSE: 2.466\n",
      "Test inference error (RMSE): ±1.5703876777291654\n",
      "##### HistGradientBoostingRegressor - PLSCanonical #####\n",
      "Error (HistGradientBoostingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### HistGradientBoostingRegressor - PLSRegression #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812815890231505\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5717840738301523\n",
      "##### HistGradientBoostingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.343\n",
      "Train inference error (RMSE): ±0.5859802271059766\n",
      "Test MSE: 2.467\n",
      "Test inference error (RMSE): ±1.5707044666663723\n",
      "##### HistGradientBoostingRegressor - PoissonRegressor #####\n",
      "Error (HistGradientBoostingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### HistGradientBoostingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.345\n",
      "Train inference error (RMSE): ±0.587341536033995\n",
      "Test MSE: 2.470\n",
      "Test inference error (RMSE): ±1.5715651894820837\n",
      "##### HistGradientBoostingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.340\n",
      "Train inference error (RMSE): ±0.5832486126783204\n",
      "Test MSE: 2.448\n",
      "Test inference error (RMSE): ±1.5646929127115465\n",
      "##### HistGradientBoostingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (HistGradientBoostingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### HistGradientBoostingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.342\n",
      "Train inference error (RMSE): ±0.5851027611435475\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5719734727607935\n",
      "##### HistGradientBoostingRegressor - Ridge #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812618519548544\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.571817110830208\n",
      "##### HistGradientBoostingRegressor - RidgeCV #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812178539749464\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718414914723764\n",
      "##### HistGradientBoostingRegressor - SGDRegressor #####\n",
      "Train MSE: 0.339\n",
      "Train inference error (RMSE): ±0.5820812856738277\n",
      "Test MSE: 2.470\n",
      "Test inference error (RMSE): ±1.5717820734941486\n",
      "##### HistGradientBoostingRegressor - SVR #####\n",
      "Train MSE: 0.471\n",
      "Train inference error (RMSE): ±0.6860947929839151\n",
      "Test MSE: 2.470\n",
      "Test inference error (RMSE): ±1.5717563451847116\n",
      "##### HistGradientBoostingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.337\n",
      "Train inference error (RMSE): ±0.5803835586817427\n",
      "Test MSE: 2.462\n",
      "Test inference error (RMSE): ±1.5691978165560445\n",
      "##### HistGradientBoostingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.338\n",
      "Train inference error (RMSE): ±0.5812674625977867\n",
      "Test MSE: 2.471\n",
      "Test inference error (RMSE): ±1.5718136511428265\n",
      "##### HistGradientBoostingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.337\n",
      "Train inference error (RMSE): ±0.5807948887295675\n",
      "Test MSE: 2.470\n",
      "Test inference error (RMSE): ±1.571551816244742\n",
      "##### HuberRegressor - IsotonicRegression #####\n",
      "Error (HuberRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### HuberRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 2.766\n",
      "Train inference error (RMSE): ±1.6632691125036303\n",
      "Test MSE: 4.804\n",
      "Test inference error (RMSE): ±2.1919040838908312\n",
      "##### HuberRegressor - KernelRidge #####\n",
      "Train MSE: 6.848\n",
      "Train inference error (RMSE): ±2.616920283486938\n",
      "Test MSE: 7.317\n",
      "Test inference error (RMSE): ±2.7050752259922386\n",
      "##### HuberRegressor - Lars #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6175358207759674\n",
      "Test MSE: 7.337\n",
      "Test inference error (RMSE): ±2.7087738457952715\n",
      "##### HuberRegressor - LarsCV #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.617505763975457\n",
      "Test MSE: 7.303\n",
      "Test inference error (RMSE): ±2.7023880022775697\n",
      "##### HuberRegressor - Lasso #####\n",
      "Train MSE: 6.935\n",
      "Train inference error (RMSE): ±2.6335023886194913\n",
      "Test MSE: 7.459\n",
      "Test inference error (RMSE): ±2.7310448091327744\n",
      "##### HuberRegressor - LassoCV #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6175182760140334\n",
      "Test MSE: 7.303\n",
      "Test inference error (RMSE): ±2.702448259693339\n",
      "##### HuberRegressor - LassoLars #####\n",
      "Train MSE: 6.935\n",
      "Train inference error (RMSE): ±2.633502386534605\n",
      "Test MSE: 7.459\n",
      "Test inference error (RMSE): ±2.7310448134236\n",
      "##### HuberRegressor - LassoLarsCV #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.617505763975457\n",
      "Test MSE: 7.303\n",
      "Test inference error (RMSE): ±2.7023880022775697\n",
      "##### HuberRegressor - LassoLarsIC #####\n",
      "Train MSE: 6.852\n",
      "Train inference error (RMSE): ±2.6175751265364413\n",
      "Test MSE: 7.305\n",
      "Test inference error (RMSE): ±2.702772999882611\n",
      "##### HuberRegressor - LinearRegression #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.617535820775971\n",
      "Test MSE: 7.337\n",
      "Test inference error (RMSE): ±2.7087738457952915\n",
      "##### HuberRegressor - LinearSVR #####\n",
      "Train MSE: 6.999\n",
      "Train inference error (RMSE): ±2.645493260347352\n",
      "Test MSE: 7.670\n",
      "Test inference error (RMSE): ±2.7694226920871383\n",
      "##### HuberRegressor - MLPRegressor #####\n",
      "Train MSE: 1.594\n",
      "Train inference error (RMSE): ±1.262577138663024\n",
      "Test MSE: 2.416\n",
      "Test inference error (RMSE): ±1.5544977799196524\n",
      "##### HuberRegressor - MultiTaskElasticNet #####\n",
      "Error (HuberRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### HuberRegressor - MultiTaskElasticNetCV #####\n",
      "Error (HuberRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### HuberRegressor - MultiTaskLasso #####\n",
      "Error (HuberRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### HuberRegressor - MultiTaskLassoCV #####\n",
      "Error (HuberRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### HuberRegressor - NuSVR #####\n",
      "Train MSE: 2.804\n",
      "Train inference error (RMSE): ±1.674508988720633\n",
      "Test MSE: 3.890\n",
      "Test inference error (RMSE): ±1.9722529173153591\n",
      "##### HuberRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.973\n",
      "Train inference error (RMSE): ±2.6407067752299436\n",
      "Test MSE: 7.636\n",
      "Test inference error (RMSE): ±2.763366072331417\n",
      "##### HuberRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.971\n",
      "Train inference error (RMSE): ±2.640341029892587\n",
      "Test MSE: 7.605\n",
      "Test inference error (RMSE): ±2.757645457265514\n",
      "##### HuberRegressor - PLSCanonical #####\n",
      "Error (HuberRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### HuberRegressor - PLSRegression #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.617518404784588\n",
      "Test MSE: 7.345\n",
      "Test inference error (RMSE): ±2.710087765568336\n",
      "##### HuberRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 7.026\n",
      "Train inference error (RMSE): ±2.6506834361270446\n",
      "Test MSE: 7.706\n",
      "Test inference error (RMSE): ±2.775969298015919\n",
      "##### HuberRegressor - PoissonRegressor #####\n",
      "Error (HuberRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### HuberRegressor - QuantileRegressor #####\n",
      "Train MSE: 6.997\n",
      "Train inference error (RMSE): ±2.6452299746737915\n",
      "Test MSE: 7.656\n",
      "Test inference error (RMSE): ±2.766916807155007\n",
      "##### HuberRegressor - RANSACRegressor #####\n",
      "Train MSE: 6.982\n",
      "Train inference error (RMSE): ±2.64234306294041\n",
      "Test MSE: 7.607\n",
      "Test inference error (RMSE): ±2.7580349528772636\n",
      "##### HuberRegressor - RadiusNeighborsRegressor #####\n",
      "Error (HuberRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### HuberRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.437\n",
      "Train inference error (RMSE): ±0.6610251306078593\n",
      "Test MSE: 3.606\n",
      "Test inference error (RMSE): ±1.8989797068580667\n",
      "##### HuberRegressor - Ridge #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.6174808377330523\n",
      "Test MSE: 7.335\n",
      "Test inference error (RMSE): ±2.7083446743054007\n",
      "##### HuberRegressor - RidgeCV #####\n",
      "Train MSE: 6.850\n",
      "Train inference error (RMSE): ±2.6172538707657758\n",
      "Test MSE: 7.323\n",
      "Test inference error (RMSE): ±2.7060362559702074\n",
      "##### HuberRegressor - SGDRegressor #####\n",
      "Train MSE: 6.885\n",
      "Train inference error (RMSE): ±2.6238946928689906\n",
      "Test MSE: 7.397\n",
      "Test inference error (RMSE): ±2.719720732550159\n",
      "##### HuberRegressor - SVR #####\n",
      "Train MSE: 2.768\n",
      "Train inference error (RMSE): ±1.6637773342978057\n",
      "Test MSE: 3.979\n",
      "Test inference error (RMSE): ±1.994618070279983\n",
      "##### HuberRegressor - TheilSenRegressor #####\n",
      "Train MSE: 7.012\n",
      "Train inference error (RMSE): ±2.6479254413763624\n",
      "Test MSE: 7.674\n",
      "Test inference error (RMSE): ±2.770267836644463\n",
      "##### HuberRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.617535820775971\n",
      "Test MSE: 7.337\n",
      "Test inference error (RMSE): ±2.7087738457952915\n",
      "##### HuberRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.885\n",
      "Train inference error (RMSE): ±2.6239690972634713\n",
      "Test MSE: 7.444\n",
      "Test inference error (RMSE): ±2.728353318163021\n",
      "##### IsotonicRegression - KNeighborsRegressor #####\n",
      "Error (IsotonicRegression-KNeighborsRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - KernelRidge #####\n",
      "Error (IsotonicRegression-KernelRidge): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Lars #####\n",
      "Error (IsotonicRegression-Lars): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LarsCV #####\n",
      "Error (IsotonicRegression-LarsCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Lasso #####\n",
      "Error (IsotonicRegression-Lasso): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoCV #####\n",
      "Error (IsotonicRegression-LassoCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLars #####\n",
      "Error (IsotonicRegression-LassoLars): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLarsCV #####\n",
      "Error (IsotonicRegression-LassoLarsCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLarsIC #####\n",
      "Error (IsotonicRegression-LassoLarsIC): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LinearRegression #####\n",
      "Error (IsotonicRegression-LinearRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LinearSVR #####\n",
      "Error (IsotonicRegression-LinearSVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MLPRegressor #####\n",
      "Error (IsotonicRegression-MLPRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskElasticNet #####\n",
      "Error (IsotonicRegression-MultiTaskElasticNet): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskElasticNetCV #####\n",
      "Error (IsotonicRegression-MultiTaskElasticNetCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskLasso #####\n",
      "Error (IsotonicRegression-MultiTaskLasso): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskLassoCV #####\n",
      "Error (IsotonicRegression-MultiTaskLassoCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - NuSVR #####\n",
      "Error (IsotonicRegression-NuSVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - OrthogonalMatchingPursuit #####\n",
      "Error (IsotonicRegression-OrthogonalMatchingPursuit): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - OrthogonalMatchingPursuitCV #####\n",
      "Error (IsotonicRegression-OrthogonalMatchingPursuitCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PLSCanonical #####\n",
      "Error (IsotonicRegression-PLSCanonical): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PLSRegression #####\n",
      "Error (IsotonicRegression-PLSRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PassiveAggressiveRegressor #####\n",
      "Error (IsotonicRegression-PassiveAggressiveRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PoissonRegressor #####\n",
      "Error (IsotonicRegression-PoissonRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - QuantileRegressor #####\n",
      "Error (IsotonicRegression-QuantileRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RANSACRegressor #####\n",
      "Error (IsotonicRegression-RANSACRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RadiusNeighborsRegressor #####\n",
      "Error (IsotonicRegression-RadiusNeighborsRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RandomForestRegressor #####\n",
      "Error (IsotonicRegression-RandomForestRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Ridge #####\n",
      "Error (IsotonicRegression-Ridge): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RidgeCV #####\n",
      "Error (IsotonicRegression-RidgeCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - SGDRegressor #####\n",
      "Error (IsotonicRegression-SGDRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - SVR #####\n",
      "Error (IsotonicRegression-SVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TheilSenRegressor #####\n",
      "Error (IsotonicRegression-TheilSenRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TransformedTargetRegressor #####\n",
      "Error (IsotonicRegression-TransformedTargetRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TweedieRegressor #####\n",
      "Error (IsotonicRegression-TweedieRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### KNeighborsRegressor - KernelRidge #####\n",
      "Train MSE: 2.760\n",
      "Train inference error (RMSE): ±1.6614684285366819\n",
      "Test MSE: 4.702\n",
      "Test inference error (RMSE): ±2.168492131261088\n",
      "##### KNeighborsRegressor - Lars #####\n",
      "Train MSE: 2.759\n",
      "Train inference error (RMSE): ±1.6609915136627522\n",
      "Test MSE: 4.703\n",
      "Test inference error (RMSE): ±2.168702034742408\n",
      "##### KNeighborsRegressor - LarsCV #####\n",
      "Train MSE: 2.761\n",
      "Train inference error (RMSE): ±1.6615443260630192\n",
      "Test MSE: 4.702\n",
      "Test inference error (RMSE): ±2.168420722213953\n",
      "##### KNeighborsRegressor - Lasso #####\n",
      "Train MSE: 2.677\n",
      "Train inference error (RMSE): ±1.6361666370806114\n",
      "Test MSE: 4.920\n",
      "Test inference error (RMSE): ±2.218088608659334\n",
      "##### KNeighborsRegressor - LassoCV #####\n",
      "Train MSE: 2.761\n",
      "Train inference error (RMSE): ±1.6615303014592213\n",
      "Test MSE: 4.702\n",
      "Test inference error (RMSE): ±2.1684505262846923\n",
      "##### KNeighborsRegressor - LassoLars #####\n",
      "Train MSE: 2.677\n",
      "Train inference error (RMSE): ±1.6361666374065102\n",
      "Test MSE: 4.920\n",
      "Test inference error (RMSE): ±2.2180886077272444\n",
      "##### KNeighborsRegressor - LassoLarsCV #####\n",
      "Train MSE: 2.761\n",
      "Train inference error (RMSE): ±1.6615443260630192\n",
      "Test MSE: 4.702\n",
      "Test inference error (RMSE): ±2.168420722213953\n",
      "##### KNeighborsRegressor - LassoLarsIC #####\n",
      "Train MSE: 2.760\n",
      "Train inference error (RMSE): ±1.661278205088302\n",
      "Test MSE: 4.701\n",
      "Test inference error (RMSE): ±2.1681169630893704\n",
      "##### KNeighborsRegressor - LinearRegression #####\n",
      "Train MSE: 2.759\n",
      "Train inference error (RMSE): ±1.6609915136629931\n",
      "Test MSE: 4.703\n",
      "Test inference error (RMSE): ±2.1687020347424526\n",
      "##### KNeighborsRegressor - LinearSVR #####\n",
      "Train MSE: 2.768\n",
      "Train inference error (RMSE): ±1.6636373812282415\n",
      "Test MSE: 4.819\n",
      "Test inference error (RMSE): ±2.19532044091363\n",
      "##### KNeighborsRegressor - MLPRegressor #####\n",
      "Train MSE: 1.448\n",
      "Train inference error (RMSE): ±1.203143325765565\n",
      "Test MSE: 2.219\n",
      "Test inference error (RMSE): ±1.489665965774654\n",
      "##### KNeighborsRegressor - MultiTaskElasticNet #####\n",
      "Error (KNeighborsRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### KNeighborsRegressor - MultiTaskElasticNetCV #####\n",
      "Error (KNeighborsRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### KNeighborsRegressor - MultiTaskLasso #####\n",
      "Error (KNeighborsRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### KNeighborsRegressor - MultiTaskLassoCV #####\n",
      "Error (KNeighborsRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### KNeighborsRegressor - NuSVR #####\n",
      "Train MSE: 2.519\n",
      "Train inference error (RMSE): ±1.587121515188368\n",
      "Test MSE: 3.894\n",
      "Test inference error (RMSE): ±1.9732170107489102\n",
      "##### KNeighborsRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 2.612\n",
      "Train inference error (RMSE): ±1.6161557892803586\n",
      "Test MSE: 4.953\n",
      "Test inference error (RMSE): ±2.225428156354091\n",
      "##### KNeighborsRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 2.756\n",
      "Train inference error (RMSE): ±1.6601453314232824\n",
      "Test MSE: 4.781\n",
      "Test inference error (RMSE): ±2.18657900807917\n",
      "##### KNeighborsRegressor - PLSCanonical #####\n",
      "Error (KNeighborsRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### KNeighborsRegressor - PLSRegression #####\n",
      "Train MSE: 2.759\n",
      "Train inference error (RMSE): ±1.6609765264590428\n",
      "Test MSE: 4.702\n",
      "Test inference error (RMSE): ±2.1684245798816626\n",
      "##### KNeighborsRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 2.600\n",
      "Train inference error (RMSE): ±1.6122982818568676\n",
      "Test MSE: 4.735\n",
      "Test inference error (RMSE): ±2.1759682094034436\n",
      "##### KNeighborsRegressor - PoissonRegressor #####\n",
      "Error (KNeighborsRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### KNeighborsRegressor - QuantileRegressor #####\n",
      "Train MSE: 2.596\n",
      "Train inference error (RMSE): ±1.6110739779257799\n",
      "Test MSE: 4.923\n",
      "Test inference error (RMSE): ±2.218747244144154\n",
      "##### KNeighborsRegressor - RANSACRegressor #####\n",
      "Train MSE: 2.799\n",
      "Train inference error (RMSE): ±1.6731029499911176\n",
      "Test MSE: 4.771\n",
      "Test inference error (RMSE): ±2.1843614990351754\n",
      "##### KNeighborsRegressor - RadiusNeighborsRegressor #####\n",
      "Error (KNeighborsRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### KNeighborsRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.740\n",
      "Train inference error (RMSE): ±0.8602852832479588\n",
      "Test MSE: 3.296\n",
      "Test inference error (RMSE): ±1.8155253538566332\n",
      "##### KNeighborsRegressor - Ridge #####\n",
      "Train MSE: 2.759\n",
      "Train inference error (RMSE): ±1.6610480031687063\n",
      "Test MSE: 4.703\n",
      "Test inference error (RMSE): ±2.16866506298757\n",
      "##### KNeighborsRegressor - RidgeCV #####\n",
      "Train MSE: 2.760\n",
      "Train inference error (RMSE): ±1.6613989110041378\n",
      "Test MSE: 4.702\n",
      "Test inference error (RMSE): ±2.168476568662181\n",
      "##### KNeighborsRegressor - SGDRegressor #####\n",
      "Train MSE: 2.762\n",
      "Train inference error (RMSE): ±1.661805142732684\n",
      "Test MSE: 4.707\n",
      "Test inference error (RMSE): ±2.169503617559949\n",
      "##### KNeighborsRegressor - SVR #####\n",
      "Train MSE: 2.551\n",
      "Train inference error (RMSE): ±1.5972561163225243\n",
      "Test MSE: 3.954\n",
      "Test inference error (RMSE): ±1.988591775081085\n",
      "##### KNeighborsRegressor - TheilSenRegressor #####\n",
      "Train MSE: 2.757\n",
      "Train inference error (RMSE): ±1.6604303966635963\n",
      "Test MSE: 4.801\n",
      "Test inference error (RMSE): ±2.1910564288011476\n",
      "##### KNeighborsRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 2.759\n",
      "Train inference error (RMSE): ±1.6609915136629931\n",
      "Test MSE: 4.703\n",
      "Test inference error (RMSE): ±2.1687020347424526\n",
      "##### KNeighborsRegressor - TweedieRegressor #####\n",
      "Train MSE: 2.751\n",
      "Train inference error (RMSE): ±1.6585094483575558\n",
      "Test MSE: 4.717\n",
      "Test inference error (RMSE): ±2.1717609510922284\n",
      "##### KernelRidge - Lars #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153576344323377\n",
      "Test MSE: 7.212\n",
      "Test inference error (RMSE): ±2.6854530697244794\n",
      "##### KernelRidge - LarsCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6148464433185974\n",
      "Test MSE: 7.226\n",
      "Test inference error (RMSE): ±2.688196602841543\n",
      "##### KernelRidge - Lasso #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147862600951512\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873670069443074\n",
      "##### KernelRidge - LassoCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614851332002232\n",
      "Test MSE: 7.227\n",
      "Test inference error (RMSE): ±2.688236629831398\n",
      "##### KernelRidge - LassoLars #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147862599812295\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687367008912373\n",
      "##### KernelRidge - LassoLarsCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6148464433185974\n",
      "Test MSE: 7.226\n",
      "Test inference error (RMSE): ±2.688196602841543\n",
      "##### KernelRidge - LassoLarsIC #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614864142964953\n",
      "Test MSE: 7.226\n",
      "Test inference error (RMSE): ±2.6882027427838597\n",
      "##### KernelRidge - LinearRegression #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153576344305125\n",
      "Test MSE: 7.212\n",
      "Test inference error (RMSE): ±2.685453069714275\n",
      "##### KernelRidge - LinearSVR #####\n",
      "Train MSE: 6.853\n",
      "Train inference error (RMSE): ±2.6178613910279696\n",
      "Test MSE: 7.349\n",
      "Test inference error (RMSE): ±2.7108279953539167\n",
      "##### KernelRidge - MLPRegressor #####\n",
      "Train MSE: 1.474\n",
      "Train inference error (RMSE): ±1.2141446046437054\n",
      "Test MSE: 2.241\n",
      "Test inference error (RMSE): ±1.4971365422354064\n",
      "##### KernelRidge - MultiTaskElasticNet #####\n",
      "Error (KernelRidge-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### KernelRidge - MultiTaskElasticNetCV #####\n",
      "Error (KernelRidge-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### KernelRidge - MultiTaskLasso #####\n",
      "Error (KernelRidge-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### KernelRidge - MultiTaskLassoCV #####\n",
      "Error (KernelRidge-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### KernelRidge - NuSVR #####\n",
      "Train MSE: 2.848\n",
      "Train inference error (RMSE): ±1.6874690578722786\n",
      "Test MSE: 4.009\n",
      "Test inference error (RMSE): ±2.002222841357939\n",
      "##### KernelRidge - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147236621750714\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.689959391504429\n",
      "##### KernelRidge - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615217822862344\n",
      "Test MSE: 7.253\n",
      "Test inference error (RMSE): ±2.6931662331118686\n",
      "##### KernelRidge - PLSCanonical #####\n",
      "Error (KernelRidge-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### KernelRidge - PLSRegression #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6150957294025017\n",
      "Test MSE: 7.225\n",
      "Test inference error (RMSE): ±2.6878593024524466\n",
      "##### KernelRidge - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147562901052135\n",
      "Test MSE: 7.233\n",
      "Test inference error (RMSE): ±2.689494352740814\n",
      "##### KernelRidge - PoissonRegressor #####\n",
      "Error (KernelRidge-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### KernelRidge - QuantileRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.61489506785298\n",
      "Test MSE: 7.227\n",
      "Test inference error (RMSE): ±2.6883569133891774\n",
      "##### KernelRidge - RANSACRegressor #####\n",
      "Train MSE: 6.851\n",
      "Train inference error (RMSE): ±2.61735582439956\n",
      "Test MSE: 7.255\n",
      "Test inference error (RMSE): ±2.693461075536572\n",
      "##### KernelRidge - RadiusNeighborsRegressor #####\n",
      "Error (KernelRidge-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### KernelRidge - RandomForestRegressor #####\n",
      "Train MSE: 0.503\n",
      "Train inference error (RMSE): ±0.7090293649609014\n",
      "Test MSE: 3.596\n",
      "Test inference error (RMSE): ±1.8961879777922095\n",
      "##### KernelRidge - Ridge #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152707974740688\n",
      "Test MSE: 7.214\n",
      "Test inference error (RMSE): ±2.6859352435336663\n",
      "##### KernelRidge - RidgeCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6151212318959076\n",
      "Test MSE: 7.249\n",
      "Test inference error (RMSE): ±2.6923866876082165\n",
      "##### KernelRidge - SGDRegressor #####\n",
      "Train MSE: 6.853\n",
      "Train inference error (RMSE): ±2.6179012463502933\n",
      "Test MSE: 7.227\n",
      "Test inference error (RMSE): ±2.688315084264773\n",
      "##### KernelRidge - SVR #####\n",
      "Train MSE: 2.843\n",
      "Train inference error (RMSE): ±1.6861636751796825\n",
      "Test MSE: 4.120\n",
      "Test inference error (RMSE): ±2.0297767677806524\n",
      "##### KernelRidge - TheilSenRegressor #####\n",
      "Train MSE: 6.846\n",
      "Train inference error (RMSE): ±2.616406370725511\n",
      "Test MSE: 7.304\n",
      "Test inference error (RMSE): ±2.702648818594802\n",
      "##### KernelRidge - TransformedTargetRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153576344305125\n",
      "Test MSE: 7.212\n",
      "Test inference error (RMSE): ±2.685453069714275\n",
      "##### KernelRidge - TweedieRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6146992623447627\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.6897209981819485\n",
      "##### Lars - LarsCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.61503146720525\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687366080311305\n",
      "##### Lars - Lasso #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614726649581237\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.689858256641157\n",
      "##### Lars - LassoCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150402384928766\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6874442825785727\n",
      "##### Lars - LassoLars #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614726649503863\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.689858258450899\n",
      "##### Lars - LassoLarsCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.61503146720525\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687366080311305\n",
      "##### Lars - LassoLarsIC #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6150663877003195\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6872938088565763\n",
      "##### Lars - LinearRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614676271606189\n",
      "Test MSE: 7.244\n",
      "Test inference error (RMSE): ±2.691387021494251\n",
      "##### Lars - LinearSVR #####\n",
      "Train MSE: 6.854\n",
      "Train inference error (RMSE): ±2.6180108839950624\n",
      "Test MSE: 7.358\n",
      "Test inference error (RMSE): ±2.7125747485188927\n",
      "##### Lars - MLPRegressor #####\n",
      "Train MSE: 1.509\n",
      "Train inference error (RMSE): ±1.2282551441627447\n",
      "Test MSE: 2.322\n",
      "Test inference error (RMSE): ±1.5239181208794097\n",
      "##### Lars - MultiTaskElasticNet #####\n",
      "Error (Lars-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### Lars - MultiTaskElasticNetCV #####\n",
      "Error (Lars-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### Lars - MultiTaskLasso #####\n",
      "Error (Lars-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### Lars - MultiTaskLassoCV #####\n",
      "Error (Lars-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### Lars - NuSVR #####\n",
      "Train MSE: 2.847\n",
      "Train inference error (RMSE): ±1.687429131839452\n",
      "Test MSE: 4.009\n",
      "Test inference error (RMSE): ±2.002231552049966\n",
      "##### Lars - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147183763118536\n",
      "Test MSE: 7.245\n",
      "Test inference error (RMSE): ±2.691615983525816\n",
      "##### Lars - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6155106606691714\n",
      "Test MSE: 7.267\n",
      "Test inference error (RMSE): ±2.6957278120109627\n",
      "##### Lars - PLSCanonical #####\n",
      "Error (Lars-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### Lars - PLSRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147538929347784\n",
      "Test MSE: 7.247\n",
      "Test inference error (RMSE): ±2.6920395017208985\n",
      "##### Lars - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6149688142407976\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687353816172385\n",
      "##### Lars - PoissonRegressor #####\n",
      "Error (Lars-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### Lars - QuantileRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6149036607572507\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.6900103086403178\n",
      "##### Lars - RANSACRegressor #####\n",
      "Train MSE: 6.844\n",
      "Train inference error (RMSE): ±2.6160485911006335\n",
      "Test MSE: 7.296\n",
      "Test inference error (RMSE): ±2.7011222856535437\n",
      "##### Lars - RadiusNeighborsRegressor #####\n",
      "Error (Lars-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### Lars - RandomForestRegressor #####\n",
      "Train MSE: 0.460\n",
      "Train inference error (RMSE): ±0.6782023584984992\n",
      "Test MSE: 3.577\n",
      "Test inference error (RMSE): ±1.8914150732467099\n",
      "##### Lars - Ridge #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.614656671598616\n",
      "Test MSE: 7.237\n",
      "Test inference error (RMSE): ±2.6901700254624004\n",
      "##### Lars - RidgeCV #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.615625137523405\n",
      "Test MSE: 7.203\n",
      "Test inference error (RMSE): ±2.6837803998474294\n",
      "##### Lars - SGDRegressor #####\n",
      "Train MSE: 6.847\n",
      "Train inference error (RMSE): ±2.616754995372211\n",
      "Test MSE: 7.249\n",
      "Test inference error (RMSE): ±2.692446874311748\n",
      "##### Lars - SVR #####\n",
      "Train MSE: 2.843\n",
      "Train inference error (RMSE): ±1.686213628258738\n",
      "Test MSE: 4.120\n",
      "Test inference error (RMSE): ±2.0298819828751884\n",
      "##### Lars - TheilSenRegressor #####\n",
      "Train MSE: 6.848\n",
      "Train inference error (RMSE): ±2.6168292318176882\n",
      "Test MSE: 7.312\n",
      "Test inference error (RMSE): ±2.7040319886804345\n",
      "##### Lars - TransformedTargetRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614676271606189\n",
      "Test MSE: 7.244\n",
      "Test inference error (RMSE): ±2.691387021494251\n",
      "##### Lars - TweedieRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614725586636764\n",
      "Test MSE: 7.252\n",
      "Test inference error (RMSE): ±2.69289485522735\n",
      "##### LarsCV - Lasso #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153414319044685\n",
      "Test MSE: 7.197\n",
      "Test inference error (RMSE): ±2.6826947695371643\n",
      "##### LarsCV - LassoCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615243693689553\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.686592339830657\n",
      "##### LarsCV - LassoLars #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615341431776503\n",
      "Test MSE: 7.197\n",
      "Test inference error (RMSE): ±2.682694771802174\n",
      "##### LarsCV - LassoLarsCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6152393004354195\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.6865393706801344\n",
      "##### LarsCV - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152597987878377\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.6864533911219066\n",
      "##### LarsCV - LinearRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150314672052075\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873660803110506\n",
      "##### LarsCV - LinearSVR #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.618169192072603\n",
      "Test MSE: 7.328\n",
      "Test inference error (RMSE): ±2.7069728054500666\n",
      "##### LarsCV - MLPRegressor #####\n",
      "Train MSE: 1.552\n",
      "Train inference error (RMSE): ±1.2457061703466017\n",
      "Test MSE: 2.332\n",
      "Test inference error (RMSE): ±1.527039290047782\n",
      "##### LarsCV - MultiTaskElasticNet #####\n",
      "Error (LarsCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LarsCV - MultiTaskElasticNetCV #####\n",
      "Error (LarsCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LarsCV - MultiTaskLasso #####\n",
      "Error (LarsCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LarsCV - MultiTaskLassoCV #####\n",
      "Error (LarsCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LarsCV - NuSVR #####\n",
      "Train MSE: 2.846\n",
      "Train inference error (RMSE): ±1.6869651598875814\n",
      "Test MSE: 4.007\n",
      "Test inference error (RMSE): ±2.0018683330306586\n",
      "##### LarsCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152643520870185\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.686689845606598\n",
      "##### LarsCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.615710094336384\n",
      "Test MSE: 7.234\n",
      "Test inference error (RMSE): ±2.689701594621297\n",
      "##### LarsCV - PLSCanonical #####\n",
      "Error (LarsCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LarsCV - PLSRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614973963007703\n",
      "Test MSE: 7.224\n",
      "Test inference error (RMSE): ±2.687787400694491\n",
      "##### LarsCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.932\n",
      "Train inference error (RMSE): ±2.632801437237207\n",
      "Test MSE: 7.249\n",
      "Test inference error (RMSE): ±2.692407994268047\n",
      "##### LarsCV - PoissonRegressor #####\n",
      "Error (LarsCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LarsCV - QuantileRegressor #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6154381751196287\n",
      "Test MSE: 7.210\n",
      "Test inference error (RMSE): ±2.685129317502702\n",
      "##### LarsCV - RANSACRegressor #####\n",
      "Train MSE: 6.858\n",
      "Train inference error (RMSE): ±2.61881799094973\n",
      "Test MSE: 7.284\n",
      "Test inference error (RMSE): ±2.6988484795755743\n",
      "##### LarsCV - RadiusNeighborsRegressor #####\n",
      "Error (LarsCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LarsCV - RandomForestRegressor #####\n",
      "Train MSE: 0.434\n",
      "Train inference error (RMSE): ±0.6587334114313479\n",
      "Test MSE: 3.621\n",
      "Test inference error (RMSE): ±1.9028944252042304\n",
      "##### LarsCV - Ridge #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150210133326817\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873933483516024\n",
      "##### LarsCV - RidgeCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6149852242554705\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873548178642603\n",
      "##### LarsCV - SGDRegressor #####\n",
      "Train MSE: 6.861\n",
      "Train inference error (RMSE): ±2.6192621911160825\n",
      "Test MSE: 7.308\n",
      "Test inference error (RMSE): ±2.70327854683573\n",
      "##### LarsCV - SVR #####\n",
      "Train MSE: 2.840\n",
      "Train inference error (RMSE): ±1.6853380118362031\n",
      "Test MSE: 4.118\n",
      "Test inference error (RMSE): ±2.0292115910308306\n",
      "##### LarsCV - TheilSenRegressor #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.615820241861988\n",
      "Test MSE: 7.251\n",
      "Test inference error (RMSE): ±2.692770775157455\n",
      "##### LarsCV - TransformedTargetRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150314672052075\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873660803110506\n",
      "##### LarsCV - TweedieRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152463966242534\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.686607214735796\n",
      "##### Lasso - LassoCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615346852185883\n",
      "Test MSE: 7.197\n",
      "Test inference error (RMSE): ±2.6827683366956414\n",
      "##### Lasso - LassoLars #####\n",
      "Train MSE: 8.157\n",
      "Train inference error (RMSE): ±2.8560817479250002\n",
      "Test MSE: 9.274\n",
      "Test inference error (RMSE): ±3.0452638886617103\n",
      "##### Lasso - LassoLarsCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153414319044614\n",
      "Test MSE: 7.197\n",
      "Test inference error (RMSE): ±2.682694769537129\n",
      "##### Lasso - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153855760771703\n",
      "Test MSE: 7.200\n",
      "Test inference error (RMSE): ±2.683342874179298\n",
      "##### Lasso - LinearRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147266495811903\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.6898582566409615\n",
      "##### Lasso - LinearSVR #####\n",
      "Train MSE: 6.951\n",
      "Train inference error (RMSE): ±2.636483523998914\n",
      "Test MSE: 7.551\n",
      "Test inference error (RMSE): ±2.7478772961866484\n",
      "##### Lasso - MLPRegressor #####\n",
      "Train MSE: 1.554\n",
      "Train inference error (RMSE): ±1.2466409010118404\n",
      "Test MSE: 2.329\n",
      "Test inference error (RMSE): ±1.5260957564415987\n",
      "##### Lasso - MultiTaskElasticNet #####\n",
      "Error (Lasso-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### Lasso - MultiTaskElasticNetCV #####\n",
      "Error (Lasso-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### Lasso - MultiTaskLasso #####\n",
      "Error (Lasso-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### Lasso - MultiTaskLassoCV #####\n",
      "Error (Lasso-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### Lasso - NuSVR #####\n",
      "Train MSE: 2.821\n",
      "Train inference error (RMSE): ±1.6796941782995296\n",
      "Test MSE: 3.747\n",
      "Test inference error (RMSE): ±1.9357039829207696\n",
      "##### Lasso - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 8.110\n",
      "Train inference error (RMSE): ±2.8478827275277485\n",
      "Test MSE: 9.218\n",
      "Test inference error (RMSE): ±3.0361624898782082\n",
      "##### Lasso - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 7.051\n",
      "Train inference error (RMSE): ±2.65536888037899\n",
      "Test MSE: 7.579\n",
      "Test inference error (RMSE): ±2.7529140419470446\n",
      "##### Lasso - PLSCanonical #####\n",
      "Error (Lasso-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### Lasso - PLSRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.615048049086101\n",
      "Test MSE: 7.245\n",
      "Test inference error (RMSE): ±2.691630201730701\n",
      "##### Lasso - PassiveAggressiveRegressor #####\n",
      "Train MSE: 8.638\n",
      "Train inference error (RMSE): ±2.939063587263168\n",
      "Test MSE: 9.695\n",
      "Test inference error (RMSE): ±3.1136114112978146\n",
      "##### Lasso - PoissonRegressor #####\n",
      "Error (Lasso-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### Lasso - QuantileRegressor #####\n",
      "Train MSE: 8.158\n",
      "Train inference error (RMSE): ±2.8561435547917324\n",
      "Test MSE: 9.274\n",
      "Test inference error (RMSE): ±3.0453095867456055\n",
      "##### Lasso - RANSACRegressor #####\n",
      "Train MSE: 7.284\n",
      "Train inference error (RMSE): ±2.6989478759220518\n",
      "Test MSE: 8.137\n",
      "Test inference error (RMSE): ±2.852462845977128\n",
      "##### Lasso - RadiusNeighborsRegressor #####\n",
      "Error (Lasso-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### Lasso - RandomForestRegressor #####\n",
      "Train MSE: 0.397\n",
      "Train inference error (RMSE): ±0.6304571243955222\n",
      "Test MSE: 3.464\n",
      "Test inference error (RMSE): ±1.8612567735811716\n",
      "##### Lasso - Ridge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614721545232825\n",
      "Test MSE: 7.233\n",
      "Test inference error (RMSE): ±2.6894513355058876\n",
      "##### Lasso - RidgeCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614733129433506\n",
      "Test MSE: 7.221\n",
      "Test inference error (RMSE): ±2.687141378408136\n",
      "##### Lasso - SGDRegressor #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.615633977939104\n",
      "Test MSE: 7.225\n",
      "Test inference error (RMSE): ±2.687898285345459\n",
      "##### Lasso - SVR #####\n",
      "Train MSE: 2.764\n",
      "Train inference error (RMSE): ±1.6624148949226407\n",
      "Test MSE: 3.805\n",
      "Test inference error (RMSE): ±1.9507172986192411\n",
      "##### Lasso - TheilSenRegressor #####\n",
      "Train MSE: 6.920\n",
      "Train inference error (RMSE): ±2.6306190949364456\n",
      "Test MSE: 7.280\n",
      "Test inference error (RMSE): ±2.698088426160158\n",
      "##### Lasso - TransformedTargetRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147266495811903\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.6898582566409615\n",
      "##### Lasso - TweedieRegressor #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.618252166580774\n",
      "Test MSE: 7.304\n",
      "Test inference error (RMSE): ±2.702569143855434\n",
      "##### LassoCV - LassoLars #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153468520591576\n",
      "Test MSE: 7.197\n",
      "Test inference error (RMSE): ±2.6827683389655506\n",
      "##### LassoCV - LassoLarsCV #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6152436936894716\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.6865923398301295\n",
      "##### LassoCV - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152644538151923\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.6865094849415923\n",
      "##### LassoCV - LinearRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150402384927975\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6874442825781126\n",
      "##### LassoCV - LinearSVR #####\n",
      "Train MSE: 6.854\n",
      "Train inference error (RMSE): ±2.6180786550480324\n",
      "Test MSE: 7.329\n",
      "Test inference error (RMSE): ±2.707147864980189\n",
      "##### LassoCV - MLPRegressor #####\n",
      "Train MSE: 1.519\n",
      "Train inference error (RMSE): ±1.232319131567339\n",
      "Test MSE: 2.280\n",
      "Test inference error (RMSE): ±1.5098958722925757\n",
      "##### LassoCV - MultiTaskElasticNet #####\n",
      "Error (LassoCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoCV - MultiTaskElasticNetCV #####\n",
      "Error (LassoCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoCV - MultiTaskLasso #####\n",
      "Error (LassoCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoCV - MultiTaskLassoCV #####\n",
      "Error (LassoCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoCV - NuSVR #####\n",
      "Train MSE: 2.846\n",
      "Train inference error (RMSE): ±1.6869525647850547\n",
      "Test MSE: 4.007\n",
      "Test inference error (RMSE): ±2.0018243266043583\n",
      "##### LassoCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152735583936884\n",
      "Test MSE: 7.219\n",
      "Test inference error (RMSE): ±2.686794779215703\n",
      "##### LassoCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.615720955849795\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.6897847323272503\n",
      "##### LassoCV - PLSCanonical #####\n",
      "Error (LassoCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoCV - PLSRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614981134768164\n",
      "Test MSE: 7.225\n",
      "Test inference error (RMSE): ±2.6878602252441866\n",
      "##### LassoCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6155215021089533\n",
      "Test MSE: 7.212\n",
      "Test inference error (RMSE): ±2.685425906809348\n",
      "##### LassoCV - PoissonRegressor #####\n",
      "Error (LassoCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoCV - QuantileRegressor #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.615446772423412\n",
      "Test MSE: 7.210\n",
      "Test inference error (RMSE): ±2.6852354602263016\n",
      "##### LassoCV - RANSACRegressor #####\n",
      "Train MSE: 6.871\n",
      "Train inference error (RMSE): ±2.6212073986581292\n",
      "Test MSE: 7.351\n",
      "Test inference error (RMSE): ±2.711350456128255\n",
      "##### LassoCV - RadiusNeighborsRegressor #####\n",
      "Error (LassoCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoCV - RandomForestRegressor #####\n",
      "Train MSE: 0.472\n",
      "Train inference error (RMSE): ±0.6869871130329397\n",
      "Test MSE: 3.563\n",
      "Test inference error (RMSE): ±1.8877065633896029\n",
      "##### LassoCV - Ridge #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.615029532933713\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687469639484789\n",
      "##### LassoCV - RidgeCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6149920752084075\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6874204614824944\n",
      "##### LassoCV - SGDRegressor #####\n",
      "Train MSE: 6.847\n",
      "Train inference error (RMSE): ±2.616662444659842\n",
      "Test MSE: 7.227\n",
      "Test inference error (RMSE): ±2.68825144866995\n",
      "##### LassoCV - SVR #####\n",
      "Train MSE: 2.840\n",
      "Train inference error (RMSE): ±1.6853165515704547\n",
      "Test MSE: 4.118\n",
      "Test inference error (RMSE): ±2.029162908510358\n",
      "##### LassoCV - TheilSenRegressor #####\n",
      "Train MSE: 6.856\n",
      "Train inference error (RMSE): ±2.6183771825732634\n",
      "Test MSE: 7.313\n",
      "Test inference error (RMSE): ±2.7041821281301823\n",
      "##### LassoCV - TransformedTargetRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150402384927975\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6874442825781126\n",
      "##### LassoCV - TweedieRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152555776564217\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.6867026211591534\n",
      "##### LassoLars - LassoLarsCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153414317764176\n",
      "Test MSE: 7.197\n",
      "Test inference error (RMSE): ±2.6826947718017293\n",
      "##### LassoLars - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153855759648623\n",
      "Test MSE: 7.200\n",
      "Test inference error (RMSE): ±2.683342876268075\n",
      "##### LassoLars - LinearRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614726649503759\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.6898582584504727\n",
      "##### LassoLars - LinearSVR #####\n",
      "Train MSE: 6.957\n",
      "Train inference error (RMSE): ±2.6375673965434276\n",
      "Test MSE: 7.547\n",
      "Test inference error (RMSE): ±2.7472494870211266\n",
      "##### LassoLars - MLPRegressor #####\n",
      "Train MSE: 1.529\n",
      "Train inference error (RMSE): ±1.2367176492547436\n",
      "Test MSE: 2.269\n",
      "Test inference error (RMSE): ±1.5061859250059595\n",
      "##### LassoLars - MultiTaskElasticNet #####\n",
      "Error (LassoLars-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLars - MultiTaskElasticNetCV #####\n",
      "Error (LassoLars-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLars - MultiTaskLasso #####\n",
      "Error (LassoLars-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLars - MultiTaskLassoCV #####\n",
      "Error (LassoLars-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLars - NuSVR #####\n",
      "Train MSE: 2.821\n",
      "Train inference error (RMSE): ±1.6796941762305673\n",
      "Test MSE: 3.747\n",
      "Test inference error (RMSE): ±1.9357039865336525\n",
      "##### LassoLars - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 8.110\n",
      "Train inference error (RMSE): ±2.8478827212580105\n",
      "Test MSE: 9.218\n",
      "Test inference error (RMSE): ±3.036162456804869\n",
      "##### LassoLars - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 7.051\n",
      "Train inference error (RMSE): ±2.655368880213089\n",
      "Test MSE: 7.579\n",
      "Test inference error (RMSE): ±2.752914043935046\n",
      "##### LassoLars - PLSCanonical #####\n",
      "Error (LassoLars-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLars - PLSRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150480490005337\n",
      "Test MSE: 7.245\n",
      "Test inference error (RMSE): ±2.691630203895279\n",
      "##### LassoLars - PassiveAggressiveRegressor #####\n",
      "Train MSE: 7.556\n",
      "Train inference error (RMSE): ±2.748799448938002\n",
      "Test MSE: 8.521\n",
      "Test inference error (RMSE): ±2.919070433725911\n",
      "##### LassoLars - PoissonRegressor #####\n",
      "Error (LassoLars-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLars - QuantileRegressor #####\n",
      "Train MSE: 8.158\n",
      "Train inference error (RMSE): ±2.8561435539681574\n",
      "Test MSE: 9.274\n",
      "Test inference error (RMSE): ±3.0453095614743697\n",
      "##### LassoLars - RANSACRegressor #####\n",
      "Train MSE: 8.213\n",
      "Train inference error (RMSE): ±2.8658088779652506\n",
      "Test MSE: 9.446\n",
      "Test inference error (RMSE): ±3.073461682226516\n",
      "##### LassoLars - RadiusNeighborsRegressor #####\n",
      "Error (LassoLars-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLars - RandomForestRegressor #####\n",
      "Train MSE: 0.393\n",
      "Train inference error (RMSE): ±0.6271318224938921\n",
      "Test MSE: 3.723\n",
      "Test inference error (RMSE): ±1.9294378563445314\n",
      "##### LassoLars - Ridge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147215451522587\n",
      "Test MSE: 7.233\n",
      "Test inference error (RMSE): ±2.689451337338896\n",
      "##### LassoLars - RidgeCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614733129337803\n",
      "Test MSE: 7.221\n",
      "Test inference error (RMSE): ±2.687141380385762\n",
      "##### LassoLars - SGDRegressor #####\n",
      "Train MSE: 6.859\n",
      "Train inference error (RMSE): ±2.6189486417571746\n",
      "Test MSE: 7.167\n",
      "Test inference error (RMSE): ±2.677127665536792\n",
      "##### LassoLars - SVR #####\n",
      "Train MSE: 2.764\n",
      "Train inference error (RMSE): ±1.662414896634807\n",
      "Test MSE: 3.805\n",
      "Test inference error (RMSE): ±1.9507173060030691\n",
      "##### LassoLars - TheilSenRegressor #####\n",
      "Train MSE: 6.914\n",
      "Train inference error (RMSE): ±2.6295402638219505\n",
      "Test MSE: 7.466\n",
      "Test inference error (RMSE): ±2.732319025689675\n",
      "##### LassoLars - TransformedTargetRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614726649503759\n",
      "Test MSE: 7.235\n",
      "Test inference error (RMSE): ±2.6898582584504727\n",
      "##### LassoLars - TweedieRegressor #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.618252167170843\n",
      "Test MSE: 7.304\n",
      "Test inference error (RMSE): ±2.702569149318659\n",
      "##### LassoLarsCV - LassoLarsIC #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152597987878377\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.6864533911219066\n",
      "##### LassoLarsCV - LinearRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150314672052075\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873660803110506\n",
      "##### LassoLarsCV - LinearSVR #####\n",
      "Train MSE: 6.854\n",
      "Train inference error (RMSE): ±2.618023000205831\n",
      "Test MSE: 7.324\n",
      "Test inference error (RMSE): ±2.706273577745622\n",
      "##### LassoLarsCV - MLPRegressor #####\n",
      "Train MSE: 1.516\n",
      "Train inference error (RMSE): ±1.2312672632911463\n",
      "Test MSE: 2.276\n",
      "Test inference error (RMSE): ±1.508662336225757\n",
      "##### LassoLarsCV - MultiTaskElasticNet #####\n",
      "Error (LassoLarsCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsCV - MultiTaskElasticNetCV #####\n",
      "Error (LassoLarsCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLarsCV - MultiTaskLasso #####\n",
      "Error (LassoLarsCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsCV - MultiTaskLassoCV #####\n",
      "Error (LassoLarsCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLarsCV - NuSVR #####\n",
      "Train MSE: 2.846\n",
      "Train inference error (RMSE): ±1.6869651598875814\n",
      "Test MSE: 4.007\n",
      "Test inference error (RMSE): ±2.0018683330306586\n",
      "##### LassoLarsCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152643520870185\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.686689845606598\n",
      "##### LassoLarsCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.615710094336384\n",
      "Test MSE: 7.234\n",
      "Test inference error (RMSE): ±2.689701594621297\n",
      "##### LassoLarsCV - PLSCanonical #####\n",
      "Error (LassoLarsCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLarsCV - PLSRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614973963007703\n",
      "Test MSE: 7.224\n",
      "Test inference error (RMSE): ±2.687787400694491\n",
      "##### LassoLarsCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615348384281601\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.6866699031954693\n",
      "##### LassoLarsCV - PoissonRegressor #####\n",
      "Error (LassoLarsCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLarsCV - QuantileRegressor #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6154381751196287\n",
      "Test MSE: 7.210\n",
      "Test inference error (RMSE): ±2.685129317502702\n",
      "##### LassoLarsCV - RANSACRegressor #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6152148399174804\n",
      "Test MSE: 7.217\n",
      "Test inference error (RMSE): ±2.6864315161086987\n",
      "##### LassoLarsCV - RadiusNeighborsRegressor #####\n",
      "Error (LassoLarsCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLarsCV - RandomForestRegressor #####\n",
      "Train MSE: 0.431\n",
      "Train inference error (RMSE): ±0.6567750073470515\n",
      "Test MSE: 3.585\n",
      "Test inference error (RMSE): ±1.8934182787417142\n",
      "##### LassoLarsCV - Ridge #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150210133326817\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873933483516024\n",
      "##### LassoLarsCV - RidgeCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6149852242554705\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873548178642603\n",
      "##### LassoLarsCV - SGDRegressor #####\n",
      "Train MSE: 6.944\n",
      "Train inference error (RMSE): ±2.6351028543268002\n",
      "Test MSE: 7.440\n",
      "Test inference error (RMSE): ±2.727601001820332\n",
      "##### LassoLarsCV - SVR #####\n",
      "Train MSE: 2.840\n",
      "Train inference error (RMSE): ±1.6853380118362031\n",
      "Test MSE: 4.118\n",
      "Test inference error (RMSE): ±2.0292115910308306\n",
      "##### LassoLarsCV - TheilSenRegressor #####\n",
      "Train MSE: 6.850\n",
      "Train inference error (RMSE): ±2.6171634950014826\n",
      "Test MSE: 7.276\n",
      "Test inference error (RMSE): ±2.697419621914559\n",
      "##### LassoLarsCV - TransformedTargetRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150314672052075\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.6873660803110506\n",
      "##### LassoLarsCV - TweedieRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6152463966242534\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.686607214735796\n",
      "##### LassoLarsIC - LinearRegression #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615066387700118\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687293808855594\n",
      "##### LassoLarsIC - LinearSVR #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.6182007552674107\n",
      "Test MSE: 7.332\n",
      "Test inference error (RMSE): ±2.707841017352104\n",
      "##### LassoLarsIC - MLPRegressor #####\n",
      "Train MSE: 1.670\n",
      "Train inference error (RMSE): ±1.2921010529658539\n",
      "Test MSE: 2.428\n",
      "Test inference error (RMSE): ±1.558122583837263\n",
      "##### LassoLarsIC - MultiTaskElasticNet #####\n",
      "Error (LassoLarsIC-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsIC - MultiTaskElasticNetCV #####\n",
      "Error (LassoLarsIC-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLarsIC - MultiTaskLasso #####\n",
      "Error (LassoLarsIC-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsIC - MultiTaskLassoCV #####\n",
      "Error (LassoLarsIC-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLarsIC - NuSVR #####\n",
      "Train MSE: 2.847\n",
      "Train inference error (RMSE): ±1.6873285228522237\n",
      "Test MSE: 4.008\n",
      "Test inference error (RMSE): ±2.002064286558778\n",
      "##### LassoLarsIC - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615323683844939\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.6865541053792072\n",
      "##### LassoLarsIC - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.6158100051334445\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.689980285655336\n",
      "##### LassoLarsIC - PLSCanonical #####\n",
      "Error (LassoLarsIC-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLarsIC - PLSRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.615018659359571\n",
      "Test MSE: 7.224\n",
      "Test inference error (RMSE): ±2.687718685692651\n",
      "##### LassoLarsIC - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.615812066097937\n",
      "Test MSE: 7.243\n",
      "Test inference error (RMSE): ±2.69120847365642\n",
      "##### LassoLarsIC - PoissonRegressor #####\n",
      "Error (LassoLarsIC-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLarsIC - QuantileRegressor #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.615492401561095\n",
      "Test MSE: 7.209\n",
      "Test inference error (RMSE): ±2.684952390795968\n",
      "##### LassoLarsIC - RANSACRegressor #####\n",
      "Train MSE: 6.881\n",
      "Train inference error (RMSE): ±2.6231564512399523\n",
      "Test MSE: 7.353\n",
      "Test inference error (RMSE): ±2.7116500615122225\n",
      "##### LassoLarsIC - RadiusNeighborsRegressor #####\n",
      "Error (LassoLarsIC-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLarsIC - RandomForestRegressor #####\n",
      "Train MSE: 0.455\n",
      "Train inference error (RMSE): ±0.6743227782827516\n",
      "Test MSE: 3.446\n",
      "Test inference error (RMSE): ±1.8564409545892453\n",
      "##### LassoLarsIC - Ridge #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615054794541783\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687324088387903\n",
      "##### LassoLarsIC - RidgeCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150099582992588\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687292242931419\n",
      "##### LassoLarsIC - SGDRegressor #####\n",
      "Train MSE: 6.887\n",
      "Train inference error (RMSE): ±2.624316635613938\n",
      "Test MSE: 7.230\n",
      "Test inference error (RMSE): ±2.6889395601558927\n",
      "##### LassoLarsIC - SVR #####\n",
      "Train MSE: 2.842\n",
      "Train inference error (RMSE): ±1.6857620758808645\n",
      "Test MSE: 4.118\n",
      "Test inference error (RMSE): ±2.0293894482373953\n",
      "##### LassoLarsIC - TheilSenRegressor #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.6157401801412163\n",
      "Test MSE: 7.247\n",
      "Test inference error (RMSE): ±2.6920493581757667\n",
      "##### LassoLarsIC - TransformedTargetRegressor #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615066387700118\n",
      "Test MSE: 7.222\n",
      "Test inference error (RMSE): ±2.687293808855594\n",
      "##### LassoLarsIC - TweedieRegressor #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.615299839677682\n",
      "Test MSE: 7.218\n",
      "Test inference error (RMSE): ±2.686549008319872\n",
      "##### LinearRegression - LinearSVR #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.6182700848945726\n",
      "Test MSE: 7.362\n",
      "Test inference error (RMSE): ±2.7132867410183974\n",
      "##### LinearRegression - MLPRegressor #####\n",
      "Train MSE: 1.464\n",
      "Train inference error (RMSE): ±1.2100245834690169\n",
      "Test MSE: 2.291\n",
      "Test inference error (RMSE): ±1.5135699556337783\n",
      "##### LinearRegression - MultiTaskElasticNet #####\n",
      "Error (LinearRegression-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LinearRegression - MultiTaskElasticNetCV #####\n",
      "Error (LinearRegression-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LinearRegression - MultiTaskLasso #####\n",
      "Error (LinearRegression-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LinearRegression - MultiTaskLassoCV #####\n",
      "Error (LinearRegression-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LinearRegression - NuSVR #####\n",
      "Train MSE: 2.847\n",
      "Train inference error (RMSE): ±1.687429131840164\n",
      "Test MSE: 4.009\n",
      "Test inference error (RMSE): ±2.002231552049394\n",
      "##### LinearRegression - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614718376311811\n",
      "Test MSE: 7.245\n",
      "Test inference error (RMSE): ±2.6916159835256073\n",
      "##### LinearRegression - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6155106606690754\n",
      "Test MSE: 7.267\n",
      "Test inference error (RMSE): ±2.695727812010484\n",
      "##### LinearRegression - PLSCanonical #####\n",
      "Error (LinearRegression-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LinearRegression - PLSRegression #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147538929347367\n",
      "Test MSE: 7.247\n",
      "Test inference error (RMSE): ±2.692039501720694\n",
      "##### LinearRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615128162264088\n",
      "Test MSE: 7.256\n",
      "Test inference error (RMSE): ±2.693624786470908\n",
      "##### LinearRegression - PoissonRegressor #####\n",
      "Error (LinearRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LinearRegression - QuantileRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614903660756855\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.690010308638352\n",
      "##### LinearRegression - RANSACRegressor #####\n",
      "Train MSE: 6.848\n",
      "Train inference error (RMSE): ±2.61679318550466\n",
      "Test MSE: 7.334\n",
      "Test inference error (RMSE): ±2.708194020928669\n",
      "##### LinearRegression - RadiusNeighborsRegressor #####\n",
      "Error (LinearRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LinearRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.491\n",
      "Train inference error (RMSE): ±0.7006293334318078\n",
      "Test MSE: 3.748\n",
      "Test inference error (RMSE): ±1.9360106765842133\n",
      "##### LinearRegression - Ridge #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.6146566715943043\n",
      "Test MSE: 7.237\n",
      "Test inference error (RMSE): ±2.690170025439101\n",
      "##### LinearRegression - RidgeCV #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6156251375235113\n",
      "Test MSE: 7.203\n",
      "Test inference error (RMSE): ±2.6837803998403147\n",
      "##### LinearRegression - SGDRegressor #####\n",
      "Train MSE: 6.852\n",
      "Train inference error (RMSE): ±2.6176910695450744\n",
      "Test MSE: 7.230\n",
      "Test inference error (RMSE): ±2.688857429942376\n",
      "##### LinearRegression - SVR #####\n",
      "Train MSE: 2.843\n",
      "Train inference error (RMSE): ±1.6862136282563338\n",
      "Test MSE: 4.120\n",
      "Test inference error (RMSE): ±2.029881982877083\n",
      "##### LinearRegression - TheilSenRegressor #####\n",
      "Train MSE: 6.848\n",
      "Train inference error (RMSE): ±2.6168113490385805\n",
      "Test MSE: 7.307\n",
      "Test inference error (RMSE): ±2.7032364041391013\n",
      "##### LinearRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614676271606088\n",
      "Test MSE: 7.244\n",
      "Test inference error (RMSE): ±2.69138702149376\n",
      "##### LinearRegression - TweedieRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147255866367587\n",
      "Test MSE: 7.252\n",
      "Test inference error (RMSE): ±2.6928948552273226\n",
      "##### LinearSVR - MLPRegressor #####\n",
      "Train MSE: 1.483\n",
      "Train inference error (RMSE): ±1.2177135312637224\n",
      "Test MSE: 2.262\n",
      "Test inference error (RMSE): ±1.50394446369309\n",
      "##### LinearSVR - MultiTaskElasticNet #####\n",
      "Error (LinearSVR-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LinearSVR - MultiTaskElasticNetCV #####\n",
      "Error (LinearSVR-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LinearSVR - MultiTaskLasso #####\n",
      "Error (LinearSVR-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LinearSVR - MultiTaskLassoCV #####\n",
      "Error (LinearSVR-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LinearSVR - NuSVR #####\n",
      "Train MSE: 2.802\n",
      "Train inference error (RMSE): ±1.6740599960598155\n",
      "Test MSE: 3.872\n",
      "Test inference error (RMSE): ±1.967679763029234\n",
      "##### LinearSVR - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 7.007\n",
      "Train inference error (RMSE): ±2.647099164464762\n",
      "Test MSE: 7.731\n",
      "Test inference error (RMSE): ±2.780545961485847\n",
      "##### LinearSVR - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 6.986\n",
      "Train inference error (RMSE): ±2.6431985899284918\n",
      "Test MSE: 7.661\n",
      "Test inference error (RMSE): ±2.767786073147678\n",
      "##### LinearSVR - PLSCanonical #####\n",
      "Error (LinearSVR-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LinearSVR - PLSRegression #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.6181750761391434\n",
      "Test MSE: 7.368\n",
      "Test inference error (RMSE): ±2.7144130686918566\n",
      "##### LinearSVR - PassiveAggressiveRegressor #####\n",
      "Train MSE: 7.091\n",
      "Train inference error (RMSE): ±2.662825679872403\n",
      "Test MSE: 7.891\n",
      "Test inference error (RMSE): ±2.8090591126781814\n",
      "##### LinearSVR - PoissonRegressor #####\n",
      "Error (LinearSVR-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LinearSVR - QuantileRegressor #####\n",
      "Train MSE: 7.023\n",
      "Train inference error (RMSE): ±2.650028889114371\n",
      "Test MSE: 7.748\n",
      "Test inference error (RMSE): ±2.7835369187912264\n",
      "##### LinearSVR - RANSACRegressor #####\n",
      "Train MSE: 7.007\n",
      "Train inference error (RMSE): ±2.6469994501117555\n",
      "Test MSE: 7.721\n",
      "Test inference error (RMSE): ±2.778738586996646\n",
      "##### LinearSVR - RadiusNeighborsRegressor #####\n",
      "Error (LinearSVR-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LinearSVR - RandomForestRegressor #####\n",
      "Train MSE: 0.459\n",
      "Train inference error (RMSE): ±0.6776756175829017\n",
      "Test MSE: 3.500\n",
      "Test inference error (RMSE): ±1.8709593762896974\n",
      "##### LinearSVR - Ridge #####\n",
      "Train MSE: 6.856\n",
      "Train inference error (RMSE): ±2.618386234880158\n",
      "Test MSE: 7.366\n",
      "Test inference error (RMSE): ±2.7140642906086567\n",
      "##### LinearSVR - RidgeCV #####\n",
      "Train MSE: 6.854\n",
      "Train inference error (RMSE): ±2.6179415662594376\n",
      "Test MSE: 7.348\n",
      "Test inference error (RMSE): ±2.7106914236347133\n",
      "##### LinearSVR - SGDRegressor #####\n",
      "Train MSE: 6.874\n",
      "Train inference error (RMSE): ±2.6219226034810017\n",
      "Test MSE: 7.406\n",
      "Test inference error (RMSE): ±2.721468284943947\n",
      "##### LinearSVR - SVR #####\n",
      "Train MSE: 2.763\n",
      "Train inference error (RMSE): ±1.6621509458956802\n",
      "Test MSE: 3.962\n",
      "Test inference error (RMSE): ±1.9904644924184631\n",
      "##### LinearSVR - TheilSenRegressor #####\n",
      "Train MSE: 7.051\n",
      "Train inference error (RMSE): ±2.6554229703259318\n",
      "Test MSE: 7.837\n",
      "Test inference error (RMSE): ±2.7994828161209977\n",
      "##### LinearSVR - TransformedTargetRegressor #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.6182887261462677\n",
      "Test MSE: 7.363\n",
      "Test inference error (RMSE): ±2.71347705071496\n",
      "##### LinearSVR - TweedieRegressor #####\n",
      "Train MSE: 6.887\n",
      "Train inference error (RMSE): ±2.624332872153875\n",
      "Test MSE: 7.465\n",
      "Test inference error (RMSE): ±2.7321801140920208\n",
      "##### MLPRegressor - MultiTaskElasticNet #####\n",
      "Error (MLPRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### MLPRegressor - MultiTaskElasticNetCV #####\n",
      "Error (MLPRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MLPRegressor - MultiTaskLasso #####\n",
      "Error (MLPRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### MLPRegressor - MultiTaskLassoCV #####\n",
      "Error (MLPRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### MLPRegressor - NuSVR #####\n",
      "Train MSE: 1.480\n",
      "Train inference error (RMSE): ±1.216485218981208\n",
      "Test MSE: 2.250\n",
      "Test inference error (RMSE): ±1.5000131147174118\n",
      "##### MLPRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 1.598\n",
      "Train inference error (RMSE): ±1.264190053951142\n",
      "Test MSE: 2.331\n",
      "Test inference error (RMSE): ±1.5266346535449762\n",
      "##### MLPRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.524\n",
      "Train inference error (RMSE): ±1.2345557038588495\n",
      "Test MSE: 2.285\n",
      "Test inference error (RMSE): ±1.5117825590089906\n",
      "##### MLPRegressor - PLSCanonical #####\n",
      "Error (MLPRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### MLPRegressor - PLSRegression #####\n",
      "Train MSE: 1.494\n",
      "Train inference error (RMSE): ±1.2222908531452008\n",
      "Test MSE: 2.307\n",
      "Test inference error (RMSE): ±1.5188461426873583\n",
      "##### MLPRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 1.509\n",
      "Train inference error (RMSE): ±1.2283576794748567\n",
      "Test MSE: 2.299\n",
      "Test inference error (RMSE): ±1.5162578381784222\n",
      "##### MLPRegressor - PoissonRegressor #####\n",
      "Error (MLPRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### MLPRegressor - QuantileRegressor #####\n",
      "Train MSE: 1.692\n",
      "Train inference error (RMSE): ±1.3006291807936052\n",
      "Test MSE: 2.484\n",
      "Test inference error (RMSE): ±1.5761763962951838\n",
      "##### MLPRegressor - RANSACRegressor #####\n",
      "Train MSE: 1.562\n",
      "Train inference error (RMSE): ±1.2498464110289913\n",
      "Test MSE: 2.233\n",
      "Test inference error (RMSE): ±1.4944578198134897\n",
      "##### MLPRegressor - RadiusNeighborsRegressor #####\n",
      "Error (MLPRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### MLPRegressor - RandomForestRegressor #####\n",
      "Train MSE: 1.012\n",
      "Train inference error (RMSE): ±1.0059466121573786\n",
      "Test MSE: 2.299\n",
      "Test inference error (RMSE): ±1.516312531651683\n",
      "##### MLPRegressor - Ridge #####\n",
      "Train MSE: 1.503\n",
      "Train inference error (RMSE): ±1.2261523827521714\n",
      "Test MSE: 2.323\n",
      "Test inference error (RMSE): ±1.5241161345107552\n",
      "##### MLPRegressor - RidgeCV #####\n",
      "Train MSE: 1.497\n",
      "Train inference error (RMSE): ±1.2233768494415405\n",
      "Test MSE: 2.238\n",
      "Test inference error (RMSE): ±1.4960749863246632\n",
      "##### MLPRegressor - SGDRegressor #####\n",
      "Train MSE: 1.536\n",
      "Train inference error (RMSE): ±1.2393604630445116\n",
      "Test MSE: 2.249\n",
      "Test inference error (RMSE): ±1.4995244164153763\n",
      "##### MLPRegressor - SVR #####\n",
      "Train MSE: 1.504\n",
      "Train inference error (RMSE): ±1.2263219282467996\n",
      "Test MSE: 2.278\n",
      "Test inference error (RMSE): ±1.5091606564069628\n",
      "##### MLPRegressor - TheilSenRegressor #####\n",
      "Train MSE: 1.549\n",
      "Train inference error (RMSE): ±1.244539449066217\n",
      "Test MSE: 2.432\n",
      "Test inference error (RMSE): ±1.5594800696385351\n",
      "##### MLPRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 1.601\n",
      "Train inference error (RMSE): ±1.265307474034681\n",
      "Test MSE: 2.427\n",
      "Test inference error (RMSE): ±1.557947826829912\n",
      "##### MLPRegressor - TweedieRegressor #####\n",
      "Train MSE: 1.471\n",
      "Train inference error (RMSE): ±1.2128714575424357\n",
      "Test MSE: 2.248\n",
      "Test inference error (RMSE): ±1.4994905707637034\n",
      "##### MultiTaskElasticNet - MultiTaskElasticNetCV #####\n",
      "Error (MultiTaskElasticNet-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - MultiTaskLasso #####\n",
      "Error (MultiTaskElasticNet-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - MultiTaskLassoCV #####\n",
      "Error (MultiTaskElasticNet-MultiTaskLassoCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - NuSVR #####\n",
      "Error (MultiTaskElasticNet-NuSVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskElasticNet-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskElasticNet-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PLSCanonical #####\n",
      "Error (MultiTaskElasticNet-PLSCanonical): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PLSRegression #####\n",
      "Error (MultiTaskElasticNet-PLSRegression): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskElasticNet-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PoissonRegressor #####\n",
      "Error (MultiTaskElasticNet-PoissonRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - QuantileRegressor #####\n",
      "Error (MultiTaskElasticNet-QuantileRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RANSACRegressor #####\n",
      "Error (MultiTaskElasticNet-RANSACRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskElasticNet-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RandomForestRegressor #####\n",
      "Error (MultiTaskElasticNet-RandomForestRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - Ridge #####\n",
      "Error (MultiTaskElasticNet-Ridge): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RidgeCV #####\n",
      "Error (MultiTaskElasticNet-RidgeCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - SGDRegressor #####\n",
      "Error (MultiTaskElasticNet-SGDRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - SVR #####\n",
      "Error (MultiTaskElasticNet-SVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TheilSenRegressor #####\n",
      "Error (MultiTaskElasticNet-TheilSenRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TransformedTargetRegressor #####\n",
      "Error (MultiTaskElasticNet-TransformedTargetRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TweedieRegressor #####\n",
      "Error (MultiTaskElasticNet-TweedieRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNetCV - MultiTaskLasso #####\n",
      "Error (MultiTaskElasticNetCV-MultiTaskLasso): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - MultiTaskLassoCV #####\n",
      "Error (MultiTaskElasticNetCV-MultiTaskLassoCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - NuSVR #####\n",
      "Error (MultiTaskElasticNetCV-NuSVR): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskElasticNetCV-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskElasticNetCV-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PLSCanonical #####\n",
      "Error (MultiTaskElasticNetCV-PLSCanonical): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PLSRegression #####\n",
      "Error (MultiTaskElasticNetCV-PLSRegression): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskElasticNetCV-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PoissonRegressor #####\n",
      "Error (MultiTaskElasticNetCV-PoissonRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - QuantileRegressor #####\n",
      "Error (MultiTaskElasticNetCV-QuantileRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RANSACRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RANSACRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RandomForestRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RandomForestRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - Ridge #####\n",
      "Error (MultiTaskElasticNetCV-Ridge): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RidgeCV #####\n",
      "Error (MultiTaskElasticNetCV-RidgeCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - SGDRegressor #####\n",
      "Error (MultiTaskElasticNetCV-SGDRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - SVR #####\n",
      "Error (MultiTaskElasticNetCV-SVR): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TheilSenRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TheilSenRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TransformedTargetRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TransformedTargetRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TweedieRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TweedieRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskLasso - MultiTaskLassoCV #####\n",
      "Error (MultiTaskLasso-MultiTaskLassoCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - NuSVR #####\n",
      "Error (MultiTaskLasso-NuSVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskLasso-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskLasso-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PLSCanonical #####\n",
      "Error (MultiTaskLasso-PLSCanonical): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PLSRegression #####\n",
      "Error (MultiTaskLasso-PLSRegression): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskLasso-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PoissonRegressor #####\n",
      "Error (MultiTaskLasso-PoissonRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - QuantileRegressor #####\n",
      "Error (MultiTaskLasso-QuantileRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RANSACRegressor #####\n",
      "Error (MultiTaskLasso-RANSACRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskLasso-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RandomForestRegressor #####\n",
      "Error (MultiTaskLasso-RandomForestRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - Ridge #####\n",
      "Error (MultiTaskLasso-Ridge): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RidgeCV #####\n",
      "Error (MultiTaskLasso-RidgeCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - SGDRegressor #####\n",
      "Error (MultiTaskLasso-SGDRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - SVR #####\n",
      "Error (MultiTaskLasso-SVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TheilSenRegressor #####\n",
      "Error (MultiTaskLasso-TheilSenRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TransformedTargetRegressor #####\n",
      "Error (MultiTaskLasso-TransformedTargetRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TweedieRegressor #####\n",
      "Error (MultiTaskLasso-TweedieRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLassoCV - NuSVR #####\n",
      "Error (MultiTaskLassoCV-NuSVR): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskLassoCV-OrthogonalMatchingPursuit): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskLassoCV-OrthogonalMatchingPursuitCV): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PLSCanonical #####\n",
      "Error (MultiTaskLassoCV-PLSCanonical): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PLSRegression #####\n",
      "Error (MultiTaskLassoCV-PLSRegression): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskLassoCV-PassiveAggressiveRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PoissonRegressor #####\n",
      "Error (MultiTaskLassoCV-PoissonRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - QuantileRegressor #####\n",
      "Error (MultiTaskLassoCV-QuantileRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RANSACRegressor #####\n",
      "Error (MultiTaskLassoCV-RANSACRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskLassoCV-RadiusNeighborsRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RandomForestRegressor #####\n",
      "Error (MultiTaskLassoCV-RandomForestRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - Ridge #####\n",
      "Error (MultiTaskLassoCV-Ridge): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RidgeCV #####\n",
      "Error (MultiTaskLassoCV-RidgeCV): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - SGDRegressor #####\n",
      "Error (MultiTaskLassoCV-SGDRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - SVR #####\n",
      "Error (MultiTaskLassoCV-SVR): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TheilSenRegressor #####\n",
      "Error (MultiTaskLassoCV-TheilSenRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TransformedTargetRegressor #####\n",
      "Error (MultiTaskLassoCV-TransformedTargetRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TweedieRegressor #####\n",
      "Error (MultiTaskLassoCV-TweedieRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### NuSVR - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 3.034\n",
      "Train inference error (RMSE): ±1.7417368026662343\n",
      "Test MSE: 4.074\n",
      "Test inference error (RMSE): ±2.0183066331208064\n",
      "##### NuSVR - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 2.834\n",
      "Train inference error (RMSE): ±1.683473874835773\n",
      "Test MSE: 3.962\n",
      "Test inference error (RMSE): ±1.9903840988851533\n",
      "##### NuSVR - PLSCanonical #####\n",
      "Error (NuSVR-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### NuSVR - PLSRegression #####\n",
      "Train MSE: 2.850\n",
      "Train inference error (RMSE): ±1.6880827374891745\n",
      "Test MSE: 4.008\n",
      "Test inference error (RMSE): ±2.0018924198953645\n",
      "##### NuSVR - PassiveAggressiveRegressor #####\n",
      "Train MSE: 3.037\n",
      "Train inference error (RMSE): ±1.7425714926264186\n",
      "Test MSE: 4.094\n",
      "Test inference error (RMSE): ±2.023379694963388\n",
      "##### NuSVR - PoissonRegressor #####\n",
      "Error (NuSVR-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### NuSVR - QuantileRegressor #####\n",
      "Train MSE: 3.062\n",
      "Train inference error (RMSE): ±1.7498848158408498\n",
      "Test MSE: 4.113\n",
      "Test inference error (RMSE): ±2.0279575603882063\n",
      "##### NuSVR - RANSACRegressor #####\n",
      "Train MSE: 2.822\n",
      "Train inference error (RMSE): ±1.6798614113304653\n",
      "Test MSE: 3.926\n",
      "Test inference error (RMSE): ±1.9815142205788299\n",
      "##### NuSVR - RadiusNeighborsRegressor #####\n",
      "Error (NuSVR-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### NuSVR - RandomForestRegressor #####\n",
      "Train MSE: 1.012\n",
      "Train inference error (RMSE): ±1.0058330173519745\n",
      "Test MSE: 3.379\n",
      "Test inference error (RMSE): ±1.8382765869743185\n",
      "##### NuSVR - Ridge #####\n",
      "Train MSE: 2.847\n",
      "Train inference error (RMSE): ±1.6874191736610322\n",
      "Test MSE: 4.009\n",
      "Test inference error (RMSE): ±2.0022345453258406\n",
      "##### NuSVR - RidgeCV #####\n",
      "Train MSE: 2.847\n",
      "Train inference error (RMSE): ±1.6873288775573485\n",
      "Test MSE: 4.009\n",
      "Test inference error (RMSE): ±2.002252931637333\n",
      "##### NuSVR - SGDRegressor #####\n",
      "Train MSE: 2.855\n",
      "Train inference error (RMSE): ±1.689647210695889\n",
      "Test MSE: 3.987\n",
      "Test inference error (RMSE): ±1.996844065509128\n",
      "##### NuSVR - SVR #####\n",
      "Train MSE: 3.093\n",
      "Train inference error (RMSE): ±1.7586043990711346\n",
      "Test MSE: 4.337\n",
      "Test inference error (RMSE): ±2.0825209410698746\n",
      "##### NuSVR - TheilSenRegressor #####\n",
      "Train MSE: 2.799\n",
      "Train inference error (RMSE): ±1.6728920748592024\n",
      "Test MSE: 3.902\n",
      "Test inference error (RMSE): ±1.9752728619128388\n",
      "##### NuSVR - TransformedTargetRegressor #####\n",
      "Train MSE: 2.847\n",
      "Train inference error (RMSE): ±1.687429131836579\n",
      "Test MSE: 4.009\n",
      "Test inference error (RMSE): ±2.002231552052216\n",
      "##### NuSVR - TweedieRegressor #####\n",
      "Train MSE: 2.843\n",
      "Train inference error (RMSE): ±1.6860657439488111\n",
      "Test MSE: 3.983\n",
      "Test inference error (RMSE): ±1.9956729084541829\n",
      "##### OrthogonalMatchingPursuit - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 7.049\n",
      "Train inference error (RMSE): ±2.6550342108021536\n",
      "Test MSE: 7.601\n",
      "Test inference error (RMSE): ±2.757030944481808\n",
      "##### OrthogonalMatchingPursuit - PLSCanonical #####\n",
      "Error (OrthogonalMatchingPursuit-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### OrthogonalMatchingPursuit - PLSRegression #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.615034281177878\n",
      "Test MSE: 7.253\n",
      "Test inference error (RMSE): ±2.6931083501159256\n",
      "##### OrthogonalMatchingPursuit - PassiveAggressiveRegressor #####\n",
      "Train MSE: 9.942\n",
      "Train inference error (RMSE): ±3.1531029233644463\n",
      "Test MSE: 11.160\n",
      "Test inference error (RMSE): ±3.340710020424287\n",
      "##### OrthogonalMatchingPursuit - PoissonRegressor #####\n",
      "Error (OrthogonalMatchingPursuit-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### OrthogonalMatchingPursuit - QuantileRegressor #####\n",
      "Train MSE: 17.801\n",
      "Train inference error (RMSE): ±4.219076385263823\n",
      "Test MSE: 19.895\n",
      "Test inference error (RMSE): ±4.460364121550596\n",
      "##### OrthogonalMatchingPursuit - RANSACRegressor #####\n",
      "Train MSE: 7.205\n",
      "Train inference error (RMSE): ±2.684240430655135\n",
      "Test MSE: 7.747\n",
      "Test inference error (RMSE): ±2.783403641289241\n",
      "##### OrthogonalMatchingPursuit - RadiusNeighborsRegressor #####\n",
      "Error (OrthogonalMatchingPursuit-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### OrthogonalMatchingPursuit - RandomForestRegressor #####\n",
      "Train MSE: 0.453\n",
      "Train inference error (RMSE): ±0.6729345301745847\n",
      "Test MSE: 3.527\n",
      "Test inference error (RMSE): ±1.8779522885291495\n",
      "##### OrthogonalMatchingPursuit - Ridge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147091679171246\n",
      "Test MSE: 7.243\n",
      "Test inference error (RMSE): ±2.6913021844609815\n",
      "##### OrthogonalMatchingPursuit - RidgeCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6146990155186454\n",
      "Test MSE: 7.233\n",
      "Test inference error (RMSE): ±2.6894995397771133\n",
      "##### OrthogonalMatchingPursuit - SGDRegressor #####\n",
      "Train MSE: 6.846\n",
      "Train inference error (RMSE): ±2.6165054984707616\n",
      "Test MSE: 7.220\n",
      "Test inference error (RMSE): ±2.6869247557438327\n",
      "##### OrthogonalMatchingPursuit - SVR #####\n",
      "Train MSE: 3.004\n",
      "Train inference error (RMSE): ±1.7331866988233595\n",
      "Test MSE: 4.136\n",
      "Test inference error (RMSE): ±2.033612461706463\n",
      "##### OrthogonalMatchingPursuit - TheilSenRegressor #####\n",
      "Train MSE: 7.029\n",
      "Train inference error (RMSE): ±2.6513134937507656\n",
      "Test MSE: 7.659\n",
      "Test inference error (RMSE): ±2.76744187863454\n",
      "##### OrthogonalMatchingPursuit - TransformedTargetRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614718376311825\n",
      "Test MSE: 7.245\n",
      "Test inference error (RMSE): ±2.6916159835256774\n",
      "##### OrthogonalMatchingPursuit - TweedieRegressor #####\n",
      "Train MSE: 6.858\n",
      "Train inference error (RMSE): ±2.6188043501406444\n",
      "Test MSE: 7.333\n",
      "Test inference error (RMSE): ±2.707952275238163\n",
      "##### OrthogonalMatchingPursuitCV - PLSCanonical #####\n",
      "Error (OrthogonalMatchingPursuitCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### OrthogonalMatchingPursuitCV - PLSRegression #####\n",
      "Train MSE: 6.842\n",
      "Train inference error (RMSE): ±2.615785132734448\n",
      "Test MSE: 7.274\n",
      "Test inference error (RMSE): ±2.6970702208001023\n",
      "##### OrthogonalMatchingPursuitCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 7.021\n",
      "Train inference error (RMSE): ±2.6496883708776306\n",
      "Test MSE: 7.613\n",
      "Test inference error (RMSE): ±2.7591896553509097\n",
      "##### OrthogonalMatchingPursuitCV - PoissonRegressor #####\n",
      "Error (OrthogonalMatchingPursuitCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### OrthogonalMatchingPursuitCV - QuantileRegressor #####\n",
      "Train MSE: 7.050\n",
      "Train inference error (RMSE): ±2.655151320918499\n",
      "Test MSE: 7.594\n",
      "Test inference error (RMSE): ±2.7557700745716507\n",
      "##### OrthogonalMatchingPursuitCV - RANSACRegressor #####\n",
      "Train MSE: 7.048\n",
      "Train inference error (RMSE): ±2.6548445870348556\n",
      "Test MSE: 7.602\n",
      "Test inference error (RMSE): ±2.757257785371245\n",
      "##### OrthogonalMatchingPursuitCV - RadiusNeighborsRegressor #####\n",
      "Error (OrthogonalMatchingPursuitCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### OrthogonalMatchingPursuitCV - RandomForestRegressor #####\n",
      "Train MSE: 0.467\n",
      "Train inference error (RMSE): ±0.6834365543927643\n",
      "Test MSE: 3.675\n",
      "Test inference error (RMSE): ±1.917132562529285\n",
      "##### OrthogonalMatchingPursuitCV - Ridge #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.615475469565001\n",
      "Test MSE: 7.265\n",
      "Test inference error (RMSE): ±2.6953582093506\n",
      "##### OrthogonalMatchingPursuitCV - RidgeCV #####\n",
      "Train MSE: 6.840\n",
      "Train inference error (RMSE): ±2.6153462432602046\n",
      "Test MSE: 7.254\n",
      "Test inference error (RMSE): ±2.693324145898269\n",
      "##### OrthogonalMatchingPursuitCV - SGDRegressor #####\n",
      "Train MSE: 6.849\n",
      "Train inference error (RMSE): ±2.617084475305425\n",
      "Test MSE: 7.268\n",
      "Test inference error (RMSE): ±2.6959996582903134\n",
      "##### OrthogonalMatchingPursuitCV - SVR #####\n",
      "Train MSE: 2.808\n",
      "Train inference error (RMSE): ±1.6756143543490873\n",
      "Test MSE: 4.057\n",
      "Test inference error (RMSE): ±2.0141324952829054\n",
      "##### OrthogonalMatchingPursuitCV - TheilSenRegressor #####\n",
      "Train MSE: 6.974\n",
      "Train inference error (RMSE): ±2.6409241728131336\n",
      "Test MSE: 7.568\n",
      "Test inference error (RMSE): ±2.751051140393582\n",
      "##### OrthogonalMatchingPursuitCV - TransformedTargetRegressor #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6155106606690857\n",
      "Test MSE: 7.267\n",
      "Test inference error (RMSE): ±2.695727812010534\n",
      "##### OrthogonalMatchingPursuitCV - TweedieRegressor #####\n",
      "Train MSE: 6.864\n",
      "Train inference error (RMSE): ±2.6199101407847065\n",
      "Test MSE: 7.359\n",
      "Test inference error (RMSE): ±2.712679754294234\n",
      "##### PLSCanonical - PLSRegression #####\n",
      "Error (PLSCanonical-PLSRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - PassiveAggressiveRegressor #####\n",
      "Error (PLSCanonical-PassiveAggressiveRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - PoissonRegressor #####\n",
      "Error (PLSCanonical-PoissonRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - QuantileRegressor #####\n",
      "Error (PLSCanonical-QuantileRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RANSACRegressor #####\n",
      "Error (PLSCanonical-RANSACRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RadiusNeighborsRegressor #####\n",
      "Error (PLSCanonical-RadiusNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RandomForestRegressor #####\n",
      "Error (PLSCanonical-RandomForestRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - Ridge #####\n",
      "Error (PLSCanonical-Ridge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RidgeCV #####\n",
      "Error (PLSCanonical-RidgeCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - SGDRegressor #####\n",
      "Error (PLSCanonical-SGDRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - SVR #####\n",
      "Error (PLSCanonical-SVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TheilSenRegressor #####\n",
      "Error (PLSCanonical-TheilSenRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TransformedTargetRegressor #####\n",
      "Error (PLSCanonical-TransformedTargetRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TweedieRegressor #####\n",
      "Error (PLSCanonical-TweedieRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614984648383093\n",
      "Test MSE: 7.251\n",
      "Test inference error (RMSE): ±2.6928429873883144\n",
      "##### PLSRegression - PoissonRegressor #####\n",
      "Error (PLSRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PLSRegression - QuantileRegressor #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.615226536963691\n",
      "Test MSE: 7.244\n",
      "Test inference error (RMSE): ±2.6914448944720095\n",
      "##### PLSRegression - RANSACRegressor #####\n",
      "Train MSE: 7.071\n",
      "Train inference error (RMSE): ±2.6591786711162846\n",
      "Test MSE: 7.774\n",
      "Test inference error (RMSE): ±2.788157795268694\n",
      "##### PLSRegression - RadiusNeighborsRegressor #####\n",
      "Error (PLSRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### PLSRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.502\n",
      "Train inference error (RMSE): ±0.7085608050745191\n",
      "Test MSE: 3.706\n",
      "Test inference error (RMSE): ±1.9250402612745523\n",
      "##### PLSRegression - Ridge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147378633162304\n",
      "Test MSE: 7.246\n",
      "Test inference error (RMSE): ±2.6918236922033496\n",
      "##### PLSRegression - RidgeCV #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614677177044317\n",
      "Test MSE: 7.238\n",
      "Test inference error (RMSE): ±2.6903296838510538\n",
      "##### PLSRegression - SGDRegressor #####\n",
      "Train MSE: 6.844\n",
      "Train inference error (RMSE): ±2.616127583456619\n",
      "Test MSE: 7.272\n",
      "Test inference error (RMSE): ±2.6966100429750495\n",
      "##### PLSRegression - SVR #####\n",
      "Train MSE: 2.845\n",
      "Train inference error (RMSE): ±1.6868106902681508\n",
      "Test MSE: 4.119\n",
      "Test inference error (RMSE): ±2.029530520380595\n",
      "##### PLSRegression - TheilSenRegressor #####\n",
      "Train MSE: 6.849\n",
      "Train inference error (RMSE): ±2.6169845535402665\n",
      "Test MSE: 7.321\n",
      "Test inference error (RMSE): ±2.705741851164517\n",
      "##### PLSRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147538929346235\n",
      "Test MSE: 7.247\n",
      "Test inference error (RMSE): ±2.692039501720141\n",
      "##### PLSRegression - TweedieRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6150518806915417\n",
      "Test MSE: 7.258\n",
      "Test inference error (RMSE): ±2.694075909455083\n",
      "##### PassiveAggressiveRegressor - PoissonRegressor #####\n",
      "Error (PassiveAggressiveRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PassiveAggressiveRegressor - QuantileRegressor #####\n",
      "Train MSE: 12.961\n",
      "Train inference error (RMSE): ±3.6000813033989596\n",
      "Test MSE: 13.407\n",
      "Test inference error (RMSE): ±3.661531651677975\n",
      "##### PassiveAggressiveRegressor - RANSACRegressor #####\n",
      "Train MSE: 8.134\n",
      "Train inference error (RMSE): ±2.8519540601778015\n",
      "Test MSE: 9.297\n",
      "Test inference error (RMSE): ±3.0491526951776846\n",
      "##### PassiveAggressiveRegressor - RadiusNeighborsRegressor #####\n",
      "Error (PassiveAggressiveRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### PassiveAggressiveRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.393\n",
      "Train inference error (RMSE): ±0.6271862732739939\n",
      "Test MSE: 3.735\n",
      "Test inference error (RMSE): ±1.9326357895237707\n",
      "##### PassiveAggressiveRegressor - Ridge #####\n",
      "Train MSE: 6.898\n",
      "Train inference error (RMSE): ±2.626439160376729\n",
      "Test MSE: 7.410\n",
      "Test inference error (RMSE): ±2.7221772152039407\n",
      "##### PassiveAggressiveRegressor - RidgeCV #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.6158658059044657\n",
      "Test MSE: 7.278\n",
      "Test inference error (RMSE): ±2.6978159745900503\n",
      "##### PassiveAggressiveRegressor - SGDRegressor #####\n",
      "Train MSE: 6.878\n",
      "Train inference error (RMSE): ±2.622533326778039\n",
      "Test MSE: 7.290\n",
      "Test inference error (RMSE): ±2.699908395257817\n",
      "##### PassiveAggressiveRegressor - SVR #####\n",
      "Train MSE: 2.948\n",
      "Train inference error (RMSE): ±1.7171172660337413\n",
      "Test MSE: 4.232\n",
      "Test inference error (RMSE): ±2.0573001646787015\n",
      "##### PassiveAggressiveRegressor - TheilSenRegressor #####\n",
      "Train MSE: 7.045\n",
      "Train inference error (RMSE): ±2.654327398201287\n",
      "Test MSE: 7.748\n",
      "Test inference error (RMSE): ±2.7834376154725167\n",
      "##### PassiveAggressiveRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 6.918\n",
      "Train inference error (RMSE): ±2.6303025604649486\n",
      "Test MSE: 7.323\n",
      "Test inference error (RMSE): ±2.706079652666912\n",
      "##### PassiveAggressiveRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.964\n",
      "Train inference error (RMSE): ±2.6389589682812806\n",
      "Test MSE: 7.644\n",
      "Test inference error (RMSE): ±2.7647633062029247\n",
      "##### PoissonRegressor - QuantileRegressor #####\n",
      "Error (PoissonRegressor-QuantileRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RANSACRegressor #####\n",
      "Error (PoissonRegressor-RANSACRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RadiusNeighborsRegressor #####\n",
      "Error (PoissonRegressor-RadiusNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RandomForestRegressor #####\n",
      "Error (PoissonRegressor-RandomForestRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - Ridge #####\n",
      "Error (PoissonRegressor-Ridge): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RidgeCV #####\n",
      "Error (PoissonRegressor-RidgeCV): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - SGDRegressor #####\n",
      "Error (PoissonRegressor-SGDRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - SVR #####\n",
      "Error (PoissonRegressor-SVR): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TheilSenRegressor #####\n",
      "Error (PoissonRegressor-TheilSenRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TransformedTargetRegressor #####\n",
      "Error (PoissonRegressor-TransformedTargetRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TweedieRegressor #####\n",
      "Error (PoissonRegressor-TweedieRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### QuantileRegressor - RANSACRegressor #####\n",
      "Train MSE: 7.979\n",
      "Train inference error (RMSE): ±2.824661519218542\n",
      "Test MSE: 8.978\n",
      "Test inference error (RMSE): ±2.996340099745674\n",
      "##### QuantileRegressor - RadiusNeighborsRegressor #####\n",
      "Error (QuantileRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### QuantileRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.452\n",
      "Train inference error (RMSE): ±0.6723889018618167\n",
      "Test MSE: 3.568\n",
      "Test inference error (RMSE): ±1.8888536739640933\n",
      "##### QuantileRegressor - Ridge #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614894340728762\n",
      "Test MSE: 7.234\n",
      "Test inference error (RMSE): ±2.6896966265964237\n",
      "##### QuantileRegressor - RidgeCV #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614884634831997\n",
      "Test MSE: 7.225\n",
      "Test inference error (RMSE): ±2.6878934298903796\n",
      "##### QuantileRegressor - SGDRegressor #####\n",
      "Train MSE: 6.839\n",
      "Train inference error (RMSE): ±2.6151423391692994\n",
      "Test MSE: 7.254\n",
      "Test inference error (RMSE): ±2.693394005513395\n",
      "##### QuantileRegressor - SVR #####\n",
      "Train MSE: 3.039\n",
      "Train inference error (RMSE): ±1.7431944170295952\n",
      "Test MSE: 4.184\n",
      "Test inference error (RMSE): ±2.0454486336333817\n",
      "##### QuantileRegressor - TheilSenRegressor #####\n",
      "Train MSE: 7.079\n",
      "Train inference error (RMSE): ±2.660648610782532\n",
      "Test MSE: 7.778\n",
      "Test inference error (RMSE): ±2.788975575890061\n",
      "##### QuantileRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.6149036607567577\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.69001030863787\n",
      "##### QuantileRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.859\n",
      "Train inference error (RMSE): ±2.619010813642538\n",
      "Test MSE: 7.322\n",
      "Test inference error (RMSE): ±2.705889578004756\n",
      "##### RANSACRegressor - RadiusNeighborsRegressor #####\n",
      "Error (RANSACRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RANSACRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.432\n",
      "Train inference error (RMSE): ±0.657482102205506\n",
      "Test MSE: 3.536\n",
      "Test inference error (RMSE): ±1.880322731817595\n",
      "##### RANSACRegressor - Ridge #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.614671893388847\n",
      "Test MSE: 7.241\n",
      "Test inference error (RMSE): ±2.6909972183978423\n",
      "##### RANSACRegressor - RidgeCV #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.6159634387963298\n",
      "Test MSE: 7.267\n",
      "Test inference error (RMSE): ±2.695818117105333\n",
      "##### RANSACRegressor - SGDRegressor #####\n",
      "Train MSE: 6.932\n",
      "Train inference error (RMSE): ±2.6329036933531733\n",
      "Test MSE: 7.460\n",
      "Test inference error (RMSE): ±2.7313316817692126\n",
      "##### RANSACRegressor - SVR #####\n",
      "Train MSE: 2.839\n",
      "Train inference error (RMSE): ±1.684819725339866\n",
      "Test MSE: 3.968\n",
      "Test inference error (RMSE): ±1.991859819639633\n",
      "##### RANSACRegressor - TheilSenRegressor #####\n",
      "Train MSE: 6.976\n",
      "Train inference error (RMSE): ±2.641211153438211\n",
      "Test MSE: 7.603\n",
      "Test inference error (RMSE): ±2.7572890023896988\n",
      "##### RANSACRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 6.838\n",
      "Train inference error (RMSE): ±2.614903550819801\n",
      "Test MSE: 7.237\n",
      "Test inference error (RMSE): ±2.6902514830854636\n",
      "##### RANSACRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.886\n",
      "Train inference error (RMSE): ±2.624176361836519\n",
      "Test MSE: 7.423\n",
      "Test inference error (RMSE): ±2.724473555002864\n",
      "##### RadiusNeighborsRegressor - RandomForestRegressor #####\n",
      "Error (RadiusNeighborsRegressor-RandomForestRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - Ridge #####\n",
      "Error (RadiusNeighborsRegressor-Ridge): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - RidgeCV #####\n",
      "Error (RadiusNeighborsRegressor-RidgeCV): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - SGDRegressor #####\n",
      "Error (RadiusNeighborsRegressor-SGDRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - SVR #####\n",
      "Error (RadiusNeighborsRegressor-SVR): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TheilSenRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TheilSenRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TransformedTargetRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TransformedTargetRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TweedieRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TweedieRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RandomForestRegressor - Ridge #####\n",
      "Train MSE: 0.511\n",
      "Train inference error (RMSE): ±0.714748880719407\n",
      "Test MSE: 3.471\n",
      "Test inference error (RMSE): ±1.8630010060969306\n",
      "##### RandomForestRegressor - RidgeCV #####\n",
      "Train MSE: 0.515\n",
      "Train inference error (RMSE): ±0.717490144289022\n",
      "Test MSE: 3.560\n",
      "Test inference error (RMSE): ±1.8868446389037214\n",
      "##### RandomForestRegressor - SGDRegressor #####\n",
      "Train MSE: 0.471\n",
      "Train inference error (RMSE): ±0.6863140890495144\n",
      "Test MSE: 3.605\n",
      "Test inference error (RMSE): ±1.8987575252720141\n",
      "##### RandomForestRegressor - SVR #####\n",
      "Train MSE: 1.104\n",
      "Train inference error (RMSE): ±1.0507858512447295\n",
      "Test MSE: 3.385\n",
      "Test inference error (RMSE): ±1.8398538251618104\n",
      "##### RandomForestRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.450\n",
      "Train inference error (RMSE): ±0.6708360730720574\n",
      "Test MSE: 3.834\n",
      "Test inference error (RMSE): ±1.9580949163043648\n",
      "##### RandomForestRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.473\n",
      "Train inference error (RMSE): ±0.6880278587383444\n",
      "Test MSE: 3.486\n",
      "Test inference error (RMSE): ±1.8670561823711205\n",
      "##### RandomForestRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.466\n",
      "Train inference error (RMSE): ±0.6825266260277124\n",
      "Test MSE: 3.559\n",
      "Test inference error (RMSE): ±1.8864958096923496\n",
      "##### Ridge - RidgeCV #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.6155314725087004\n",
      "Test MSE: 7.204\n",
      "Test inference error (RMSE): ±2.684046123030252\n",
      "##### Ridge - SGDRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147607883063824\n",
      "Test MSE: 7.213\n",
      "Test inference error (RMSE): ±2.6856404528058464\n",
      "##### Ridge - SVR #####\n",
      "Train MSE: 2.843\n",
      "Train inference error (RMSE): ±1.6861893113430713\n",
      "Test MSE: 4.120\n",
      "Test inference error (RMSE): ±2.0298711835827343\n",
      "##### Ridge - TheilSenRegressor #####\n",
      "Train MSE: 6.843\n",
      "Train inference error (RMSE): ±2.6159740117598114\n",
      "Test MSE: 7.295\n",
      "Test inference error (RMSE): ±2.7008445416050595\n",
      "##### Ridge - TransformedTargetRegressor #####\n",
      "Train MSE: 6.836\n",
      "Train inference error (RMSE): ±2.614656671600237\n",
      "Test MSE: 7.237\n",
      "Test inference error (RMSE): ±2.6901700254711653\n",
      "##### Ridge - TweedieRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147153084678756\n",
      "Test MSE: 7.249\n",
      "Test inference error (RMSE): ±2.6924781735873604\n",
      "##### RidgeCV - SGDRegressor #####\n",
      "Train MSE: 6.867\n",
      "Train inference error (RMSE): ±2.6205138093912437\n",
      "Test MSE: 7.316\n",
      "Test inference error (RMSE): ±2.7048661761045345\n",
      "##### RidgeCV - SVR #####\n",
      "Train MSE: 2.843\n",
      "Train inference error (RMSE): ±1.6860067436165096\n",
      "Test MSE: 4.120\n",
      "Test inference error (RMSE): ±2.0298058632372245\n",
      "##### RidgeCV - TheilSenRegressor #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.618176956543852\n",
      "Test MSE: 7.324\n",
      "Test inference error (RMSE): ±2.706363838423237\n",
      "##### RidgeCV - TransformedTargetRegressor #####\n",
      "Train MSE: 6.841\n",
      "Train inference error (RMSE): ±2.615625137523226\n",
      "Test MSE: 7.203\n",
      "Test inference error (RMSE): ±2.6837803998594087\n",
      "##### RidgeCV - TweedieRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6146937031531317\n",
      "Test MSE: 7.236\n",
      "Test inference error (RMSE): ±2.690043309971752\n",
      "##### SGDRegressor - SVR #####\n",
      "Train MSE: 2.835\n",
      "Train inference error (RMSE): ±1.6836721523371396\n",
      "Test MSE: 4.103\n",
      "Test inference error (RMSE): ±2.0256482079299722\n",
      "##### SGDRegressor - TheilSenRegressor #####\n",
      "Train MSE: 6.855\n",
      "Train inference error (RMSE): ±2.618161279508819\n",
      "Test MSE: 7.328\n",
      "Test inference error (RMSE): ±2.7069756927191495\n",
      "##### SGDRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 6.850\n",
      "Train inference error (RMSE): ±2.6171637661557683\n",
      "Test MSE: 7.163\n",
      "Test inference error (RMSE): ±2.6763833541820783\n",
      "##### SGDRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.884\n",
      "Train inference error (RMSE): ±2.623661671330977\n",
      "Test MSE: 7.338\n",
      "Test inference error (RMSE): ±2.7088630454698728\n",
      "##### SVR - TheilSenRegressor #####\n",
      "Train MSE: 2.764\n",
      "Train inference error (RMSE): ±1.6624787089211663\n",
      "Test MSE: 3.968\n",
      "Test inference error (RMSE): ±1.9920627721206072\n",
      "##### SVR - TransformedTargetRegressor #####\n",
      "Train MSE: 2.843\n",
      "Train inference error (RMSE): ±1.686213628258621\n",
      "Test MSE: 4.120\n",
      "Test inference error (RMSE): ±2.0298819828752683\n",
      "##### SVR - TweedieRegressor #####\n",
      "Train MSE: 2.830\n",
      "Train inference error (RMSE): ±1.6822907388080235\n",
      "Test MSE: 4.090\n",
      "Test inference error (RMSE): ±2.0224418167191685\n",
      "##### TheilSenRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 6.852\n",
      "Train inference error (RMSE): ±2.617650778854931\n",
      "Test MSE: 7.335\n",
      "Test inference error (RMSE): ±2.708269056241487\n",
      "##### TheilSenRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.873\n",
      "Train inference error (RMSE): ±2.6217037431335477\n",
      "Test MSE: 7.386\n",
      "Test inference error (RMSE): ±2.717753375925352\n",
      "##### TransformedTargetRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.837\n",
      "Train inference error (RMSE): ±2.6147255866367587\n",
      "Test MSE: 7.252\n",
      "Test inference error (RMSE): ±2.6928948552273226\n",
      "########## Best Estimator ##########\n",
      "['HistGradientBoostingRegressor-MLPRegressor', 1.9639458358809923, 1.4014085185558822]\n",
      "Total time: 635.9362871646881\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimators_stacked_trained, best_stacked_estimator_name = run_sklearn_estimators_with_stacking(\n",
    "    all_estimators,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    model_type\n",
    ")\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b0d684-33bf-419b-b59d-4c171e29b1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;HistGradientBoostingRegressor&#x27;,\n",
       "                               HistGradientBoostingRegressor()),\n",
       "                              (&#x27;MLPRegressor&#x27;, MLPRegressor())],\n",
       "                  final_estimator=RidgeCV())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingRegressor.html\">?<span>Documentation for StackingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingRegressor(estimators=[(&#x27;HistGradientBoostingRegressor&#x27;,\n",
       "                               HistGradientBoostingRegressor()),\n",
       "                              (&#x27;MLPRegressor&#x27;, MLPRegressor())],\n",
       "                  final_estimator=RidgeCV())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>HistGradientBoostingRegressor</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;HistGradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html\">?<span>Documentation for HistGradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingRegressor()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>MLPRegressor</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RidgeCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.RidgeCV.html\">?<span>Documentation for RidgeCV</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RidgeCV()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('HistGradientBoostingRegressor',\n",
       "                               HistGradientBoostingRegressor()),\n",
       "                              ('MLPRegressor', MLPRegressor())],\n",
       "                  final_estimator=RidgeCV())"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_stacked_trained[best_stacked_estimator_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a42d4-3bad-4a1c-a8c9-dee86bc52bb5",
   "metadata": {},
   "source": [
    "### Save Estimator stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32120e1f-2db5-41c8-b53f-2dc4588c3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(estimators_trained[best_estimator_name], open('results/estimator_sklearn_stacked.sav', 'wb'))\n",
    "\n",
    "# Scaler\n",
    "pickle.dump(scaler, open('results/scaler.pkl','wb'))\n",
    "\n",
    "# Save columns names and informations\n",
    "data_to_save = {\n",
    "    'col_names_order': col_names_order,\n",
    "    'num_col_names': num_col_names,\n",
    "    'cat_col_names': cat_col_names,\n",
    "    'date_col_names': date_col_names,\n",
    "    'target_cols': target_cols,\n",
    "    'category_mappings': category_mappings,\n",
    "    'window_size': window_size\n",
    "}\n",
    "with open('results/columns_metadata_sklearn_stacked.json', 'w') as json_file:\n",
    "    json.dump(data_to_save, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538ba71-15e3-42db-a526-cb376135a073",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c843071-fc93-45c4-bca3-a1fd36a7fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43724cc0-8d03-4e8e-a4d4-4a0eefb8a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "loaded_estimator = pickle.load(open('results/estimator_sklearn_stacked.sav', 'rb'))\n",
    "# Scaler\n",
    "loaded_scaler = pickle.load(open('results/scaler.pkl','rb'))\n",
    "# columns_metadata\n",
    "columns_metadata = json.load(open('results/columns_metadata_sklearn_stacked.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1ef45e9-aa23-4ce3-819f-d6e4081582c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inference_data(new_input, columns_metadata, scaler=None):\n",
    "    \"\"\"\n",
    "    Preprocess the input data for inference based on metadata and scaler for numeric normalization.\n",
    "\n",
    "    Args:\n",
    "        new_input (list of list): Data to preprocess (each inner list is a row).\n",
    "        columns_metadata (dict): Metadata defining column names, types, mappings, and order.\n",
    "        scaler (StandardScaler): Trained scaler for numerical columns.\n",
    "    \n",
    "    Returns:\n",
    "        list: Preprocessed data ready for inference.\n",
    "    \"\"\"\n",
    "    # Exclude target columns from col_names_order for inference\n",
    "    target_cols = columns_metadata['target_cols']\n",
    "    col_names_order = [col for col in columns_metadata['col_names_order'] if col not in target_cols]\n",
    "    # Transform the new_input into a DataFrame with the correct column order\n",
    "    df_input = pd.DataFrame(new_input, columns=col_names_order)\n",
    "\n",
    "    # Convert categorical columns based on category_mappings\n",
    "    category_mappings = columns_metadata['category_mappings']\n",
    "    for col in columns_metadata['cat_col_names']:\n",
    "        if col in df_input.columns and col in category_mappings:\n",
    "            # Replace string categories with mapped integer IDs\n",
    "            df_input[col] = df_input[col].map(category_mappings[col])\n",
    "            if df_input[col].isnull().any():\n",
    "                raise ValueError(f'Invalid value found in column \"{col}\" that is not in the category mappings.')\n",
    "\n",
    "    # Normalize numeric columns using the trained scaler\n",
    "    num_col_names = columns_metadata['num_col_names']\n",
    "    if num_col_names and scaler:\n",
    "        df_input[num_col_names] = scaler.transform(df_input[num_col_names])\n",
    "\n",
    "    # Ensure date columns are in the correct datetime format\n",
    "    for col in columns_metadata['date_col_names']:\n",
    "        if col in df_input.columns:\n",
    "            df_input[col] = pd.to_datetime(df_input[col], errors='coerce')\n",
    "            if df_input[col].isnull().any():\n",
    "                raise ValueError(f'Invalid date value found in column \"{col}\".')\n",
    "\n",
    "    # Drop target columns if they exist in the input (not used in inference)\n",
    "    target_cols = columns_metadata['target_cols']\n",
    "    df_input = df_input.drop(columns=target_cols, errors='ignore')\n",
    "\n",
    "    # Convert DataFrame to list of rows for model inference\n",
    "    processed_data = df_input.values.tolist()\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "297367d2-2bb1-41be-a3bc-f05b8811222e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5491044432223594,\n",
       "  0.0,\n",
       "  0.41440031594083443,\n",
       "  0.007242552557203476,\n",
       "  0.24344510566718364,\n",
       "  0.8252178660760494,\n",
       "  1.1,\n",
       "  0.007550748107512281]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = [\n",
    "    [66.770774, 'A', 129.519443, 157.649826, 6.255495, 0.828523, 1.10, 0.656228]  # target 2.432088\n",
    "]\n",
    "new_input_preprocessed = preprocess_inference_data(new_input, columns_metadata, loaded_scaler)\n",
    "new_input_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f13e453-b591-4a78-9832-a1032a5b5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = columns_metadata['target_cols'][0]\n",
    "clss_to_cat = {}\n",
    "if target in columns_metadata['category_mappings']:\n",
    "    for key, value in columns_metadata['category_mappings'][target].items():\n",
    "        clss_to_cat[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1adcc30-d10d-42f6-b7a6-4332800409c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.55359761]\n",
      "Total time: 0.0005085468292236328\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "result = loaded_estimator.predict(new_input_preprocessed)\n",
    "if clss_to_cat:\n",
    "    result = clss_to_cat[result[0]]\n",
    "print(result)\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
