{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3489c1bc-d70b-4089-a6fc-9428e959dfc3",
   "metadata": {},
   "source": [
    "# Sklearn\n",
    "Notebook pensando para facilitar e agiliar o treinamento de Machine Learning, sendo necessário, em grande parte das vezes, somente alterar o caminho do dataset e o tipo (classificador ou regressão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7227abb5-2f27-4fc4-be31-afe3a4a093ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0be3e-6a93-41aa-9ec8-0ceb6ffece8c",
   "metadata": {},
   "source": [
    "## Preparar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a81160e-461d-440f-a3ac-7869034ff805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_cols, max_unique_values=10, window_size=1, no_columns_lags=[]):\n",
    "    \"\"\"\n",
    "    Preprocess dataset, converting string columns to number and identifying numeric, categorical, and date columns.\n",
    "    Adds a window of historical rows to the data.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame with data to analyze.\n",
    "        target_cols (list): All target columns to not add in numeric, categorical, or date feature lists.\n",
    "        max_unique_values (int): Maximum number of unique values to consider a numeric column as categorical.\n",
    "        window_size (int): Number of previous rows to include for each row.\n",
    "        no_columns_lags (list): Columns names to not do lags, keeping only the current one.\n",
    "\n",
    "    Returns:\n",
    "        df_copy (DataFrame): Processed DataFrame with transformations applied.\n",
    "        num_col_names (list): List of numeric feature column names.\n",
    "        cat_col_names (list): List of categorical feature column names.\n",
    "        date_col_names (list): List of date feature column names.\n",
    "        mappings (dict): Mapping of original categorical values (or target columns) to transformed numeric values.\n",
    "    \"\"\"\n",
    "    # Create a copy so as not to alter the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Remove lines with null values\n",
    "    df_copy = df_copy.dropna()\n",
    "    \n",
    "    # Identify categorical and numeric columns\n",
    "    cat_col_names = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_col_names = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    date_col_names = []\n",
    "\n",
    "    # Identify columns that are dates\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['object', 'string']:  # Only check object/string columns\n",
    "            try:\n",
    "                # Attempt to convert the column to datetime\n",
    "                df_copy[col] = pd.to_datetime(df[col], errors='raise').astype(int) // 10**9\n",
    "                date_col_names.append(col)\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "    # Identify numeric columns that are categorical\n",
    "    potential_categorical = []\n",
    "    for col in num_col_names:\n",
    "        if df_copy[col].nunique() <= max_unique_values:\n",
    "            potential_categorical.append(col)\n",
    "\n",
    "    cat_col_names += potential_categorical\n",
    "\n",
    "    # Remove target columns from the lists\n",
    "    num_col_names = [col for col in num_col_names if col not in potential_categorical + date_col_names]\n",
    "    cat_col_names = [col for col in cat_col_names if col not in num_col_names + date_col_names]\n",
    "    date_col_names = [col for col in date_col_names if col not in num_col_names + cat_col_names]\n",
    "    \n",
    "    mappings = {}\n",
    "    label_encoders = {}\n",
    "\n",
    "    # Convert string columns to category and create a mapping (old value -> new value)\n",
    "    for col in cat_col_names:\n",
    "        if df_copy[col].dtype not in ['int64', 'float64']:\n",
    "            le = LabelEncoder()\n",
    "            df_copy[col] = le.fit_transform(df_copy[col])\n",
    "            mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            label_encoders[col] = le\n",
    "            # Convert values to int (otherwise will raise error if save as json)\n",
    "            for key, value in mappings[col].items():\n",
    "                mappings[col][key] = int(value)\n",
    "        #else:\n",
    "        #    mappings[col] = {int(val): int(val) for val in df_copy[col].unique()}\n",
    "\n",
    "    # Remove target column as input\n",
    "    for col in target_cols:\n",
    "        if col in num_col_names:\n",
    "            num_col_names.remove(col)\n",
    "        if col in cat_col_names:\n",
    "            cat_col_names.remove(col)\n",
    "        if col in date_col_names:\n",
    "            date_col_names.remove(col)\n",
    "    \n",
    "    # Add historical data based on window_size\n",
    "    if window_size > 1:\n",
    "        historical_features = []\n",
    "        for i in range(window_size - 1, 0, -1):  # Create features lag, oldest to newest\n",
    "            shifted = df_copy.drop(columns=no_columns_lags, errors='ignore').shift(i).add_suffix(f'_lag_{i}')\n",
    "            historical_features.append(shifted)\n",
    "        \n",
    "        # Concatenate the lags to the left and keep the current values\n",
    "        df_copy = pd.concat(historical_features + [df_copy], axis=1)\n",
    "\n",
    "        # Remove NaNs columns created by shifts\n",
    "        df_copy = df_copy.dropna()\n",
    "    \n",
    "        # Add lags\n",
    "        num_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in num_col_names if col not in no_columns_lags]\n",
    "        cat_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in cat_col_names if col not in no_columns_lags]\n",
    "        date_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in date_col_names if col not in no_columns_lags]\n",
    "\n",
    "        mappings_lags = {}\n",
    "        for col, value in mappings.items():\n",
    "            for i in range(window_size - 1, 0, -1):\n",
    "                mappings_lags[f'{col}_lag_{i}'] = value\n",
    "    \n",
    "        # Update main columns + lags columns\n",
    "        num_col_names = num_col_lags + num_col_names\n",
    "        cat_col_names = cat_col_lags + cat_col_names\n",
    "        date_col_names = date_col_lags + date_col_names\n",
    "\n",
    "        mappings = {**mappings_lags, **mappings}\n",
    "    \n",
    "    return df_copy, num_col_names, cat_col_names, date_col_names, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dda78a0-630b-4947-8e10-a24019cf98d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>atmospheric_pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>21.945101</td>\n",
       "      <td>985.302886</td>\n",
       "      <td>79.747740</td>\n",
       "      <td>3.849785</td>\n",
       "      <td>11.598255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-04</td>\n",
       "      <td>24.256379</td>\n",
       "      <td>992.558017</td>\n",
       "      <td>70.013222</td>\n",
       "      <td>3.537094</td>\n",
       "      <td>11.729554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>25.437674</td>\n",
       "      <td>1002.415965</td>\n",
       "      <td>85.906186</td>\n",
       "      <td>16.613512</td>\n",
       "      <td>10.067073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>26.343396</td>\n",
       "      <td>980.012419</td>\n",
       "      <td>73.849816</td>\n",
       "      <td>12.854979</td>\n",
       "      <td>11.774130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>15.172844</td>\n",
       "      <td>998.832892</td>\n",
       "      <td>82.972967</td>\n",
       "      <td>15.764626</td>\n",
       "      <td>7.019475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2027-09-23</td>\n",
       "      <td>28.037259</td>\n",
       "      <td>1011.984036</td>\n",
       "      <td>58.526246</td>\n",
       "      <td>19.503921</td>\n",
       "      <td>15.119683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2027-09-24</td>\n",
       "      <td>20.568564</td>\n",
       "      <td>1028.322144</td>\n",
       "      <td>41.765820</td>\n",
       "      <td>19.950369</td>\n",
       "      <td>13.642110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2027-09-25</td>\n",
       "      <td>12.500191</td>\n",
       "      <td>992.043538</td>\n",
       "      <td>41.860743</td>\n",
       "      <td>2.304613</td>\n",
       "      <td>9.617098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2027-09-26</td>\n",
       "      <td>24.722567</td>\n",
       "      <td>994.324767</td>\n",
       "      <td>34.068356</td>\n",
       "      <td>4.585596</td>\n",
       "      <td>12.473074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2027-09-27</td>\n",
       "      <td>19.672376</td>\n",
       "      <td>1002.718003</td>\n",
       "      <td>43.659637</td>\n",
       "      <td>18.101452</td>\n",
       "      <td>11.759212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  temperature  atmospheric_pressure   humidity  wind_speed  \\\n",
       "0    2025-01-03    21.945101            985.302886  79.747740    3.849785   \n",
       "1    2025-01-04    24.256379            992.558017  70.013222    3.537094   \n",
       "2    2025-01-05    25.437674           1002.415965  85.906186   16.613512   \n",
       "3    2025-01-06    26.343396            980.012419  73.849816   12.854979   \n",
       "4    2025-01-07    15.172844            998.832892  82.972967   15.764626   \n",
       "..          ...          ...                   ...        ...         ...   \n",
       "993  2027-09-23    28.037259           1011.984036  58.526246   19.503921   \n",
       "994  2027-09-24    20.568564           1028.322144  41.765820   19.950369   \n",
       "995  2027-09-25    12.500191            992.043538  41.860743    2.304613   \n",
       "996  2027-09-26    24.722567            994.324767  34.068356    4.585596   \n",
       "997  2027-09-27    19.672376           1002.718003  43.659637   18.101452   \n",
       "\n",
       "        target  \n",
       "0    11.598255  \n",
       "1    11.729554  \n",
       "2    10.067073  \n",
       "3    11.774130  \n",
       "4     7.019475  \n",
       "..         ...  \n",
       "993  15.119683  \n",
       "994  13.642110  \n",
       "995   9.617098  \n",
       "996  12.473074  \n",
       "997  11.759212  \n",
       "\n",
       "[998 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/time_series_temperature.csv')\n",
    "train_percentage = 0.7\n",
    "model_type = 'regressor'  # classifier or regressor\n",
    "\n",
    "# Temporal data\n",
    "window_size = 3  # Greater than 1 for temporal data\n",
    "no_columns_lags = ['date', 'target']  # Only for temporal data. Otherwise, keep the list empty\n",
    "\n",
    "test_part = 2  # Which part of the dataset will be used to test. 0 == random; 1 == begin; 2 == end\n",
    "target_cols = ['target']  # Target column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502d6196-e3f8-4683-8d12-73fcf834d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "df, num_col_names, cat_col_names, date_col_names, category_mappings = preprocess_data(df, target_cols, max_unique_values=10, window_size=window_size, no_columns_lags=no_columns_lags)\n",
    "col_names_order = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6911e8e8-d77e-497e-a8bc-134fdcd791fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_names_order: ['temperature_lag_2', 'atmospheric_pressure_lag_2', 'humidity_lag_2', 'wind_speed_lag_2', 'temperature_lag_1', 'atmospheric_pressure_lag_1', 'humidity_lag_1', 'wind_speed_lag_1', 'date', 'temperature', 'atmospheric_pressure', 'humidity', 'wind_speed', 'target']\n",
      "num_col_names: ['temperature_lag_2', 'atmospheric_pressure_lag_2', 'humidity_lag_2', 'wind_speed_lag_2', 'temperature_lag_1', 'atmospheric_pressure_lag_1', 'humidity_lag_1', 'wind_speed_lag_1', 'temperature', 'atmospheric_pressure', 'humidity', 'wind_speed']\n",
      "cat_col_names: []\n",
      "date_col_names: ['date']\n",
      "target_cols: ['target']\n",
      "category_mappings: {}\n"
     ]
    }
   ],
   "source": [
    "print(f'''col_names_order: {col_names_order}\n",
    "num_col_names: {num_col_names}\n",
    "cat_col_names: {cat_col_names}\n",
    "date_col_names: {date_col_names}\n",
    "target_cols: {target_cols}\n",
    "category_mappings: {category_mappings}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed57e737-f6d9-4fe3-b38c-038d44e280bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 996 entries, 2 to 997\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   temperature_lag_2           996 non-null    float64\n",
      " 1   atmospheric_pressure_lag_2  996 non-null    float64\n",
      " 2   humidity_lag_2              996 non-null    float64\n",
      " 3   wind_speed_lag_2            996 non-null    float64\n",
      " 4   temperature_lag_1           996 non-null    float64\n",
      " 5   atmospheric_pressure_lag_1  996 non-null    float64\n",
      " 6   humidity_lag_1              996 non-null    float64\n",
      " 7   wind_speed_lag_1            996 non-null    float64\n",
      " 8   date                        996 non-null    int64  \n",
      " 9   temperature                 996 non-null    float64\n",
      " 10  atmospheric_pressure        996 non-null    float64\n",
      " 11  humidity                    996 non-null    float64\n",
      " 12  wind_speed                  996 non-null    float64\n",
      " 13  target                      996 non-null    float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 116.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eacf642-fe7f-465c-8f74-fea497c7453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'classifier':\n",
    "    print(df[target_cols].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fffec-dfee-49f8-815d-3fc5c94a51c1",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8adfa6d0-8dee-468c-8c3b-b00ab8a204a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Get random dates for the dataset for testing\n",
    "if test_part == 0:\n",
    "    train, test = train_test_split(df, random_state=42, test_size=1 - train_percentage)\n",
    "# Get first part of the dataset for testing\n",
    "elif test_part == 1:\n",
    "    train = df.iloc[int((len(df) * (1 - train_percentage))):]\n",
    "    train = shuffle(train, random_state=42)\n",
    "    test = df.iloc[:int((len(df) * (1 - train_percentage)))]\n",
    "# Get last part of the dataset for testing\n",
    "elif test_part == 2:\n",
    "    train = df.iloc[:int((len(df) * train_percentage))]\n",
    "    train = shuffle(train, random_state=42)\n",
    "    test = df.iloc[int((len(df) * train_percentage)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e972c845-197d-4055-bfb0-641a680b9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[target_cols]\n",
    "x_train = train.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4b2e59-7601-42ad-bf06-f2a4982a7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[target_cols]\n",
    "x_test = test.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee0910a-7f2d-4009-9b66-67bdd31fc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d7ec3c7-e375-40d3-8a2c-663157d552e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skelarn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeca4cce-663a-43b1-8539-37ccc4f433ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_lag_2</th>\n",
       "      <th>atmospheric_pressure_lag_2</th>\n",
       "      <th>humidity_lag_2</th>\n",
       "      <th>wind_speed_lag_2</th>\n",
       "      <th>temperature_lag_1</th>\n",
       "      <th>atmospheric_pressure_lag_1</th>\n",
       "      <th>humidity_lag_1</th>\n",
       "      <th>wind_speed_lag_1</th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>atmospheric_pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>16.815960</td>\n",
       "      <td>987.314012</td>\n",
       "      <td>56.183267</td>\n",
       "      <td>4.112322</td>\n",
       "      <td>29.406987</td>\n",
       "      <td>988.982827</td>\n",
       "      <td>75.354354</td>\n",
       "      <td>14.699909</td>\n",
       "      <td>1749686400</td>\n",
       "      <td>19.244755</td>\n",
       "      <td>1004.082068</td>\n",
       "      <td>60.661015</td>\n",
       "      <td>7.701151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>12.531782</td>\n",
       "      <td>987.224511</td>\n",
       "      <td>47.465223</td>\n",
       "      <td>1.971596</td>\n",
       "      <td>22.673901</td>\n",
       "      <td>1014.340370</td>\n",
       "      <td>74.716544</td>\n",
       "      <td>12.090821</td>\n",
       "      <td>1778976000</td>\n",
       "      <td>26.268309</td>\n",
       "      <td>1025.575855</td>\n",
       "      <td>37.749788</td>\n",
       "      <td>18.680172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>14.956122</td>\n",
       "      <td>1005.502825</td>\n",
       "      <td>38.963410</td>\n",
       "      <td>15.416997</td>\n",
       "      <td>17.342810</td>\n",
       "      <td>1021.543733</td>\n",
       "      <td>71.788275</td>\n",
       "      <td>13.622730</td>\n",
       "      <td>1770163200</td>\n",
       "      <td>20.678386</td>\n",
       "      <td>990.823301</td>\n",
       "      <td>82.890835</td>\n",
       "      <td>9.655311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>23.637781</td>\n",
       "      <td>1014.067251</td>\n",
       "      <td>69.913660</td>\n",
       "      <td>12.585429</td>\n",
       "      <td>22.844511</td>\n",
       "      <td>990.164820</td>\n",
       "      <td>31.005195</td>\n",
       "      <td>12.180545</td>\n",
       "      <td>1749427200</td>\n",
       "      <td>14.838741</td>\n",
       "      <td>987.648141</td>\n",
       "      <td>69.474221</td>\n",
       "      <td>6.909956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>11.852715</td>\n",
       "      <td>992.086614</td>\n",
       "      <td>49.789486</td>\n",
       "      <td>3.100768</td>\n",
       "      <td>23.017990</td>\n",
       "      <td>1023.680505</td>\n",
       "      <td>75.718884</td>\n",
       "      <td>4.223303</td>\n",
       "      <td>1763769600</td>\n",
       "      <td>27.396513</td>\n",
       "      <td>1014.242435</td>\n",
       "      <td>75.199077</td>\n",
       "      <td>15.603616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>27.431543</td>\n",
       "      <td>1027.322362</td>\n",
       "      <td>35.631393</td>\n",
       "      <td>19.932392</td>\n",
       "      <td>18.313506</td>\n",
       "      <td>991.924819</td>\n",
       "      <td>59.354113</td>\n",
       "      <td>9.420553</td>\n",
       "      <td>1742169600</td>\n",
       "      <td>18.855997</td>\n",
       "      <td>999.930881</td>\n",
       "      <td>30.625643</td>\n",
       "      <td>16.642565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>17.782608</td>\n",
       "      <td>1019.292864</td>\n",
       "      <td>32.054411</td>\n",
       "      <td>13.719904</td>\n",
       "      <td>24.116506</td>\n",
       "      <td>1023.728692</td>\n",
       "      <td>68.637319</td>\n",
       "      <td>12.067479</td>\n",
       "      <td>1745193600</td>\n",
       "      <td>16.389962</td>\n",
       "      <td>1022.596846</td>\n",
       "      <td>35.346800</td>\n",
       "      <td>1.987379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>29.796732</td>\n",
       "      <td>985.224935</td>\n",
       "      <td>38.906449</td>\n",
       "      <td>4.814267</td>\n",
       "      <td>21.589198</td>\n",
       "      <td>1026.235062</td>\n",
       "      <td>83.407687</td>\n",
       "      <td>0.968470</td>\n",
       "      <td>1759363200</td>\n",
       "      <td>18.659585</td>\n",
       "      <td>1014.436805</td>\n",
       "      <td>57.465416</td>\n",
       "      <td>5.236754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>21.070562</td>\n",
       "      <td>981.662322</td>\n",
       "      <td>61.782293</td>\n",
       "      <td>4.390508</td>\n",
       "      <td>10.635643</td>\n",
       "      <td>1012.181943</td>\n",
       "      <td>56.914436</td>\n",
       "      <td>16.635742</td>\n",
       "      <td>1773619200</td>\n",
       "      <td>21.504835</td>\n",
       "      <td>986.156433</td>\n",
       "      <td>65.939294</td>\n",
       "      <td>14.548845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>22.168361</td>\n",
       "      <td>1012.689969</td>\n",
       "      <td>72.350462</td>\n",
       "      <td>8.154663</td>\n",
       "      <td>27.816370</td>\n",
       "      <td>1026.526161</td>\n",
       "      <td>45.191316</td>\n",
       "      <td>8.752761</td>\n",
       "      <td>1744848000</td>\n",
       "      <td>18.265178</td>\n",
       "      <td>1003.927363</td>\n",
       "      <td>54.053717</td>\n",
       "      <td>19.644860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     temperature_lag_2  atmospheric_pressure_lag_2  humidity_lag_2  \\\n",
       "160          16.815960                  987.314012       56.183267   \n",
       "499          12.531782                  987.224511       47.465223   \n",
       "397          14.956122                 1005.502825       38.963410   \n",
       "157          23.637781                 1014.067251       69.913660   \n",
       "323          11.852715                  992.086614       49.789486   \n",
       "..                 ...                         ...             ...   \n",
       "73           27.431543                 1027.322362       35.631393   \n",
       "108          17.782608                 1019.292864       32.054411   \n",
       "272          29.796732                  985.224935       38.906449   \n",
       "437          21.070562                  981.662322       61.782293   \n",
       "104          22.168361                 1012.689969       72.350462   \n",
       "\n",
       "     wind_speed_lag_2  temperature_lag_1  atmospheric_pressure_lag_1  \\\n",
       "160          4.112322          29.406987                  988.982827   \n",
       "499          1.971596          22.673901                 1014.340370   \n",
       "397         15.416997          17.342810                 1021.543733   \n",
       "157         12.585429          22.844511                  990.164820   \n",
       "323          3.100768          23.017990                 1023.680505   \n",
       "..                ...                ...                         ...   \n",
       "73          19.932392          18.313506                  991.924819   \n",
       "108         13.719904          24.116506                 1023.728692   \n",
       "272          4.814267          21.589198                 1026.235062   \n",
       "437          4.390508          10.635643                 1012.181943   \n",
       "104          8.154663          27.816370                 1026.526161   \n",
       "\n",
       "     humidity_lag_1  wind_speed_lag_1        date  temperature  \\\n",
       "160       75.354354         14.699909  1749686400    19.244755   \n",
       "499       74.716544         12.090821  1778976000    26.268309   \n",
       "397       71.788275         13.622730  1770163200    20.678386   \n",
       "157       31.005195         12.180545  1749427200    14.838741   \n",
       "323       75.718884          4.223303  1763769600    27.396513   \n",
       "..              ...               ...         ...          ...   \n",
       "73        59.354113          9.420553  1742169600    18.855997   \n",
       "108       68.637319         12.067479  1745193600    16.389962   \n",
       "272       83.407687          0.968470  1759363200    18.659585   \n",
       "437       56.914436         16.635742  1773619200    21.504835   \n",
       "104       45.191316          8.752761  1744848000    18.265178   \n",
       "\n",
       "     atmospheric_pressure   humidity  wind_speed  \n",
       "160           1004.082068  60.661015    7.701151  \n",
       "499           1025.575855  37.749788   18.680172  \n",
       "397            990.823301  82.890835    9.655311  \n",
       "157            987.648141  69.474221    6.909956  \n",
       "323           1014.242435  75.199077   15.603616  \n",
       "..                    ...        ...         ...  \n",
       "73             999.930881  30.625643   16.642565  \n",
       "108           1022.596846  35.346800    1.987379  \n",
       "272           1014.436805  57.465416    5.236754  \n",
       "437            986.156433  65.939294   14.548845  \n",
       "104           1003.927363  54.053717   19.644860  \n",
       "\n",
       "[697 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bddd440-aac8-4616-94fa-22e859de77ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.5379701205759683,\n",
       "  -1.2394277874954696,\n",
       "  -0.257625514885446,\n",
       "  -0.9489956759628737,\n",
       "  1.6641968133011944,\n",
       "  -1.1237660948513866,\n",
       "  0.8790885403109037,\n",
       "  0.8705002235273208,\n",
       "  1749686400.0,\n",
       "  -0.10994692313901493,\n",
       "  -0.07747603098447292,\n",
       "  0.010698581245868269,\n",
       "  -0.33665828065395037],\n",
       " [-1.2868970894345035,\n",
       "  -1.2456342763494475,\n",
       "  -0.7731577561001289,\n",
       "  -1.3179365094154658,\n",
       "  0.4873551539662368,\n",
       "  0.634719736996811,\n",
       "  0.8413458149078842,\n",
       "  0.4214994415209878,\n",
       "  1778976000.0,\n",
       "  1.1177743388171146,\n",
       "  1.4137658459792668,\n",
       "  -1.3453561115658916,\n",
       "  1.553437469000768],\n",
       " [-0.8630926371697056,\n",
       "  0.0218808343994275,\n",
       "  -1.2759034032817689,\n",
       "  0.9992950658183793,\n",
       "  -0.44443904422825975,\n",
       "  1.134256027039112,\n",
       "  0.6680639225947633,\n",
       "  0.6851274216993911,\n",
       "  1770163200.0,\n",
       "  0.14065269448733514,\n",
       "  -0.9973711640471795,\n",
       "  1.326422604578634,\n",
       "  -0.00023930656423791293],\n",
       " [0.6545680169850145,\n",
       "  0.6157834775198672,\n",
       "  0.5543066510403347,\n",
       "  0.5112918868481178,\n",
       "  0.5171752479598154,\n",
       "  -1.0417976632364583,\n",
       "  -1.745296866906565,\n",
       "  0.43693999019300656,\n",
       "  1749427200.0,\n",
       "  -0.8801206236755378,\n",
       "  -1.2176641743142858,\n",
       "  0.5323288457973172,\n",
       "  -0.4728665000305205],\n",
       " [-1.4056063217896813,\n",
       "  -0.9084702921512445,\n",
       "  -0.6357149043294179,\n",
       "  -1.123330746322007,\n",
       "  0.5474966405941643,\n",
       "  1.2824360964127437,\n",
       "  0.9006598060424039,\n",
       "  -0.9324308521853375,\n",
       "  1763769600.0,\n",
       "  1.3149850948273278,\n",
       "  0.6274515844132751,\n",
       "  0.871167845057968,\n",
       "  1.0237923994024216],\n",
       " [-0.09265994719952053,\n",
       "  -1.4143572064585461,\n",
       "  -0.5688475569631466,\n",
       "  -0.7152869702846468,\n",
       "  -0.4667836360572836,\n",
       "  -0.38843681381822226,\n",
       "  1.1126341847131165,\n",
       "  -1.5720851435872014,\n",
       "  1754352000.0,\n",
       "  -1.3907771201926964,\n",
       "  -0.32310987064440044,\n",
       "  -0.7489985215336715,\n",
       "  0.9989529118186804],\n",
       " [0.1782135034703562,\n",
       "  -0.8783498008201608,\n",
       "  1.6214839900851825,\n",
       "  0.2850436000454522,\n",
       "  0.45496953925086525,\n",
       "  -1.3864129302821866,\n",
       "  1.3377647073081729,\n",
       "  -1.3643041104137041,\n",
       "  1756252800.0,\n",
       "  -0.8402756963489948,\n",
       "  -0.8847633618833797,\n",
       "  0.7733961844857925,\n",
       "  -1.3669527213663037],\n",
       " [1.4631099345510357,\n",
       "  1.5478272448854664,\n",
       "  0.9228731025640359,\n",
       "  -1.1814885903905403,\n",
       "  -0.6273898415418129,\n",
       "  1.3318500371946322,\n",
       "  -1.472798064698622,\n",
       "  -1.2031604929806834,\n",
       "  1761004800.0,\n",
       "  0.2542842889924509,\n",
       "  -0.44691030494905243,\n",
       "  0.7420074692294,\n",
       "  0.9777141655594997],\n",
       " [1.4413735019419545,\n",
       "  -0.7860701694497211,\n",
       "  1.3169140304504274,\n",
       "  0.6999002380922524,\n",
       "  0.7392919964558896,\n",
       "  -1.4365903035487197,\n",
       "  -0.20142098940402975,\n",
       "  -0.43124075304384246,\n",
       "  1761955200.0,\n",
       "  0.03601558099978479,\n",
       "  0.7192409062757962,\n",
       "  1.3194179046210575,\n",
       "  0.12490376323457433],\n",
       " [-0.3341829459072852,\n",
       "  1.2897994598604898,\n",
       "  0.6688162211029787,\n",
       "  -0.6727705493641649,\n",
       "  -0.11568094504177412,\n",
       "  -1.4671693320304604,\n",
       "  -1.6602814967339046,\n",
       "  1.0829280905661114,\n",
       "  1766793600.0,\n",
       "  -0.9535148654808542,\n",
       "  1.3172312885395694,\n",
       "  -0.14339408288349276,\n",
       "  -1.3382332226844758],\n",
       " [-1.4930445819898124,\n",
       "  0.8067426164066445,\n",
       "  0.9585108477211458,\n",
       "  -1.443880377486155,\n",
       "  -0.4045960160798951,\n",
       "  0.8906900229407377,\n",
       "  -1.1716236837329066,\n",
       "  0.4939738090648125,\n",
       "  1771372800.0,\n",
       "  -1.2313503274098068,\n",
       "  -0.7763652443530128,\n",
       "  0.4601835702400895,\n",
       "  -0.008381345506689019],\n",
       " [0.07508186215643815,\n",
       "  -1.3514331043999102,\n",
       "  -0.43340539575911047,\n",
       "  1.0314250319915634,\n",
       "  -0.7196662516022351,\n",
       "  1.7032860516687442,\n",
       "  0.4923373307388249,\n",
       "  -1.0757536177027018,\n",
       "  1764374400.0,\n",
       "  1.4547613711471445,\n",
       "  -0.9211488781021353,\n",
       "  1.6527010465137262,\n",
       "  1.0528092742783324],\n",
       " [1.4057163468832294,\n",
       "  -0.5523332520598541,\n",
       "  -0.5152327812273717,\n",
       "  -1.3737252737226742,\n",
       "  0.18604672385793505,\n",
       "  -0.4100305576393487,\n",
       "  0.6477783540669758,\n",
       "  -0.22559623203637721,\n",
       "  1753228800.0,\n",
       "  -0.7707527728113415,\n",
       "  1.7125694077470166,\n",
       "  1.2763193059739442,\n",
       "  -1.482658854431223],\n",
       " [0.45298733369838234,\n",
       "  -0.4525242690853284,\n",
       "  0.19550194955868572,\n",
       "  -0.9579778756484241,\n",
       "  -0.37764822291283734,\n",
       "  -0.04795750052954421,\n",
       "  1.1159711195866833,\n",
       "  -0.7824644378411865,\n",
       "  1742774400.0,\n",
       "  -0.7434552337714571,\n",
       "  1.338038533679582,\n",
       "  1.5428401968519847,\n",
       "  0.3644269035678797],\n",
       " [-1.5791009339845985,\n",
       "  1.3065015190144404,\n",
       "  -1.1309223785455849,\n",
       "  0.8668629819796856,\n",
       "  0.12323696208398466,\n",
       "  1.0492760916705575,\n",
       "  -1.5071306198464514,\n",
       "  0.5355750776290907,\n",
       "  1768608000.0,\n",
       "  -0.4721948359094325,\n",
       "  0.7025143195571637,\n",
       "  -0.615250956008886,\n",
       "  1.6096496336169925],\n",
       " [1.2899498603793298,\n",
       "  -1.3270788739248327,\n",
       "  -0.6668318678919243,\n",
       "  -1.4434534915303896,\n",
       "  1.4785926228533404,\n",
       "  1.6955488976984212,\n",
       "  1.6174331950042413,\n",
       "  0.3154451917447612,\n",
       "  1770508800.0,\n",
       "  -1.0161785625276847,\n",
       "  0.6157354051866751,\n",
       "  1.1658902673557539,\n",
       "  -1.4216118765633952],\n",
       " [1.2522104024257192,\n",
       "  -0.03549883105672232,\n",
       "  -0.1903044852776737,\n",
       "  -0.43212280176366247,\n",
       "  1.4908839321175058,\n",
       "  -1.1376533244920235,\n",
       "  1.2288140818566222,\n",
       "  1.2059134180633868,\n",
       "  1774483200.0,\n",
       "  0.36903957347588595,\n",
       "  -1.2175313311441323,\n",
       "  -0.43540523440676904,\n",
       "  -1.254511223519234],\n",
       " [1.3940444476147902,\n",
       "  -0.3395734205970099,\n",
       "  0.1927266370755451,\n",
       "  1.557695017390277,\n",
       "  -1.1188004974976513,\n",
       "  -0.7450143260294082,\n",
       "  -0.8620237583049699,\n",
       "  -1.150377870375878,\n",
       "  1776470400.0,\n",
       "  -0.6460997039561105,\n",
       "  1.719261127589382,\n",
       "  1.7009330836620655,\n",
       "  1.395139575509459],\n",
       " [-1.3274163843989606,\n",
       "  0.41836962067779876,\n",
       "  1.1107746118017054,\n",
       "  -0.6505689265974511,\n",
       "  -0.039889351972558856,\n",
       "  -1.5892406074851948,\n",
       "  0.333918288329778,\n",
       "  1.4018382790113286,\n",
       "  1789948800.0,\n",
       "  0.7671123827783594,\n",
       "  -0.7035899917649915,\n",
       "  0.743328360115865,\n",
       "  0.9587087448220102],\n",
       " [-1.6670739683057458,\n",
       "  -0.04216012168195335,\n",
       "  -0.30324164444364143,\n",
       "  -1.1062625896191909,\n",
       "  0.02772799008638718,\n",
       "  -0.9206505882253669,\n",
       "  -0.6319742269435931,\n",
       "  0.9095359571999784,\n",
       "  1782172800.0,\n",
       "  -0.31864689364374976,\n",
       "  0.24022674836553234,\n",
       "  1.407616994112634,\n",
       "  1.751895892695698],\n",
       " [0.0583843603103871,\n",
       "  -1.4400614148569815,\n",
       "  1.2279735785499117,\n",
       "  -0.9836412404202389,\n",
       "  -1.4554486907824153,\n",
       "  -1.317090479021719,\n",
       "  -0.7177492207389125,\n",
       "  -1.5874033608287932,\n",
       "  1767139200.0,\n",
       "  -0.18339741607537605,\n",
       "  0.4725438587036866,\n",
       "  -0.2607500946468637,\n",
       "  -0.5054255059834872],\n",
       " [-0.5876877305373407,\n",
       "  -0.3254973489195022,\n",
       "  -0.1674982163247049,\n",
       "  -1.3222839176877195,\n",
       "  1.146103273303783,\n",
       "  1.2116701628304973,\n",
       "  -0.839686896856089,\n",
       "  -0.5464578385424071,\n",
       "  1765238400.0,\n",
       "  1.320745355781691,\n",
       "  0.6583953961903675,\n",
       "  -1.1238404736020862,\n",
       "  1.749713293063034],\n",
       " [1.5391429027120818,\n",
       "  -0.7893330598035018,\n",
       "  0.23355065510281162,\n",
       "  -1.5374962871079774,\n",
       "  1.7384363100673115,\n",
       "  1.2591317612377084,\n",
       "  0.22524109535742434,\n",
       "  -0.39415500596184283,\n",
       "  1784160000.0,\n",
       "  0.21678773029184745,\n",
       "  1.047670728886329,\n",
       "  1.4354401118534235,\n",
       "  -0.5656063387139738],\n",
       " [-0.6288497074863136,\n",
       "  1.3318296514577983,\n",
       "  -1.4741967384298817,\n",
       "  -1.2009959445574037,\n",
       "  0.2521906549569011,\n",
       "  -0.44593053180625025,\n",
       "  0.7407653248495814,\n",
       "  0.9799592785595955,\n",
       "  1761091200.0,\n",
       "  1.0900784534276529,\n",
       "  0.7463309819117324,\n",
       "  -0.3601103472772618,\n",
       "  -0.5966736365386215],\n",
       " [0.7184644621612775,\n",
       "  0.7170779594814236,\n",
       "  -1.4961884598437225,\n",
       "  -0.08989182061225263,\n",
       "  1.6850796542699498,\n",
       "  0.763536218274123,\n",
       "  0.3253217534531353,\n",
       "  -0.4425108265245026,\n",
       "  1760572800.0,\n",
       "  -1.2473984329939791,\n",
       "  -0.5995913955617163,\n",
       "  -0.6879189154261309,\n",
       "  -1.184411338541541],\n",
       " [-1.2956774757090337,\n",
       "  0.733933913233403,\n",
       "  -0.07596508265888956,\n",
       "  -1.2166535830672267,\n",
       "  -0.5058731307179403,\n",
       "  1.325181808800662,\n",
       "  -0.4653507262768066,\n",
       "  1.6442809161980672,\n",
       "  1764633600.0,\n",
       "  -0.14146628310000897,\n",
       "  1.4280531229283377,\n",
       "  -0.890310611608672,\n",
       "  -0.5432295220697145],\n",
       " [-0.7139318062650577,\n",
       "  0.7169367119637755,\n",
       "  0.7054462652684258,\n",
       "  -0.3591181864031487,\n",
       "  -0.3381518381146993,\n",
       "  -0.4499404189469097,\n",
       "  0.12507509410737686,\n",
       "  -0.3155270121026459,\n",
       "  1793232000.0,\n",
       "  0.8540364754170002,\n",
       "  -0.22555640442147445,\n",
       "  1.0610400386002645,\n",
       "  -1.4884512739466467],\n",
       " [-0.687809441084182,\n",
       "  1.4935746236677236,\n",
       "  -0.5060966306069412,\n",
       "  -0.581899580931783,\n",
       "  0.6743882509400484,\n",
       "  -0.5696552750086135,\n",
       "  -0.5495584217752564,\n",
       "  -1.5104004995101712,\n",
       "  1740700800.0,\n",
       "  1.6837232737257772,\n",
       "  -0.44653511596885737,\n",
       "  -0.3632495960009627,\n",
       "  -0.292588890231933],\n",
       " [-0.6813110876924066,\n",
       "  0.9621128195750579,\n",
       "  -0.5969756539723579,\n",
       "  -0.21989170003053563,\n",
       "  -0.7677814991857275,\n",
       "  0.8408365299774534,\n",
       "  0.7594505767613328,\n",
       "  0.18669987243627462,\n",
       "  1757462400.0,\n",
       "  -1.5406597127997648,\n",
       "  1.3277746022032062,\n",
       "  -1.4778066882782563,\n",
       "  1.3588689729337038],\n",
       " [1.5929032219689165,\n",
       "  1.389912230115729,\n",
       "  0.27286122585930017,\n",
       "  -0.07518563574282568,\n",
       "  -1.0866618573843583,\n",
       "  0.30896269703492213,\n",
       "  -0.6814857893253585,\n",
       "  -0.8576936917298976,\n",
       "  1755302400.0,\n",
       "  1.3885163209451385,\n",
       "  -1.4760516331504494,\n",
       "  0.31761115959955416,\n",
       "  0.4117209977036848],\n",
       " [-0.11655098827570433,\n",
       "  0.062429772522849133,\n",
       "  -0.03741182212509659,\n",
       "  0.311710929665467,\n",
       "  1.5006665784797928,\n",
       "  -1.0649897132170267,\n",
       "  0.3907062312383989,\n",
       "  1.6343475603540343,\n",
       "  1747526400.0,\n",
       "  1.1675728716770433,\n",
       "  1.062516715303381,\n",
       "  1.7369429756049528,\n",
       "  1.3614965463928317],\n",
       " [-1.3785149331969309,\n",
       "  -1.5113600778673761,\n",
       "  1.3154008340267658,\n",
       "  -1.5786311698630182,\n",
       "  1.4925880235682063,\n",
       "  -0.9698803105480568,\n",
       "  -1.3977021887583183,\n",
       "  1.309553636581252,\n",
       "  1779753600.0,\n",
       "  1.5983136818902741,\n",
       "  1.496191801757987,\n",
       "  0.9539649484700524,\n",
       "  -0.2692892142937704],\n",
       " [0.912834249052942,\n",
       "  1.3231513099717493,\n",
       "  -0.7753580633593311,\n",
       "  1.0874440422214442,\n",
       "  -0.18576593569551997,\n",
       "  -0.0891578260042879,\n",
       "  1.6921399441154812,\n",
       "  -0.5125137797696095,\n",
       "  1747785600.0,\n",
       "  1.087838074594945,\n",
       "  -1.4481346064119787,\n",
       "  -1.1471964060556221,\n",
       "  -1.5573177984421593],\n",
       " [-0.027799027873695745,\n",
       "  -0.2949889838294457,\n",
       "  -0.39469098200381647,\n",
       "  0.9055291998865839,\n",
       "  -0.6624361686223396,\n",
       "  -0.16642214264435923,\n",
       "  -1.3727216923143637,\n",
       "  0.151518596615435,\n",
       "  1745452800.0,\n",
       "  -1.0932364680647315,\n",
       "  -0.38514614726447277,\n",
       "  -0.4234157185821748,\n",
       "  0.2984948331767738],\n",
       " [1.3670683278547644,\n",
       "  0.1956707033514947,\n",
       "  -0.5119205256930472,\n",
       "  -0.20648391362616397,\n",
       "  -1.3979216431807602,\n",
       "  1.055794943035004,\n",
       "  0.7994040164266046,\n",
       "  -1.579167775816866,\n",
       "  1751673600.0,\n",
       "  -0.5425253992278963,\n",
       "  0.05977453039363933,\n",
       "  0.33000005451240644,\n",
       "  -0.7276409769950953],\n",
       " [-1.5970717155361673,\n",
       "  -1.5987255208572781,\n",
       "  0.5359630700253757,\n",
       "  -0.7533587158661407,\n",
       "  0.1398484478373489,\n",
       "  0.6274053333562478,\n",
       "  1.4798018315577324,\n",
       "  -0.1321248184633272,\n",
       "  1773273600.0,\n",
       "  0.4726086373830462,\n",
       "  0.5537337920367572,\n",
       "  -1.3410477306567077,\n",
       "  0.26208599395026444],\n",
       " [0.290353915723419,\n",
       "  -0.21911833891458332,\n",
       "  -0.27269926058773847,\n",
       "  -1.2933819196500314,\n",
       "  1.468681521188763,\n",
       "  -0.414527765444601,\n",
       "  1.5409453075471977,\n",
       "  0.15543285325667375,\n",
       "  1785628800.0,\n",
       "  1.0369477111867198,\n",
       "  0.8961352621447765,\n",
       "  -0.23139917397022072,\n",
       "  0.9047657446343643],\n",
       " [-0.4070929262893692,\n",
       "  0.8984580566742378,\n",
       "  1.161506241145019,\n",
       "  -0.6291032812922094,\n",
       "  -1.5806426198365306,\n",
       "  -0.6645943958868894,\n",
       "  -1.6353644011896231,\n",
       "  -0.9002774319739573,\n",
       "  1780790400.0,\n",
       "  -1.572019352614134,\n",
       "  -0.13511036725365577,\n",
       "  1.2329909061000492,\n",
       "  -0.9547992017688268],\n",
       " [-0.9056504867984393,\n",
       "  0.4143186349966355,\n",
       "  -1.467519468709073,\n",
       "  0.0475595384800173,\n",
       "  -1.1847276642657742,\n",
       "  -1.0754886912251913,\n",
       "  -1.1223077765111287,\n",
       "  -1.2464183606987598,\n",
       "  1780531200.0,\n",
       "  1.6916365713548618,\n",
       "  1.2964095403629403,\n",
       "  0.48814375630698476,\n",
       "  0.4942690605519595],\n",
       " [-0.09925205377532416,\n",
       "  0.3524334393282926,\n",
       "  0.06318426934651193,\n",
       "  -0.4251952559719515,\n",
       "  -0.11517141543436787,\n",
       "  0.062407177140475154,\n",
       "  -0.035002248485465674,\n",
       "  0.30732863510860714,\n",
       "  1747440000.0,\n",
       "  1.502872170861128,\n",
       "  -1.0662595481902397,\n",
       "  0.39187854672005185,\n",
       "  1.6323460529225051],\n",
       " [0.994176476321582,\n",
       "  1.5101097597160826,\n",
       "  0.26014327900068696,\n",
       "  -0.06524194692210937,\n",
       "  1.2918665848143687,\n",
       "  1.368782836159101,\n",
       "  -0.49021292403256445,\n",
       "  0.3009363792284959,\n",
       "  1751241600.0,\n",
       "  -0.06132027190752132,\n",
       "  0.044722226809971385,\n",
       "  1.2566989077802084,\n",
       "  0.3155487868862617],\n",
       " [-0.27618071529919,\n",
       "  -0.9196900439731932,\n",
       "  -0.07012086978652139,\n",
       "  -0.03415496282991476,\n",
       "  -0.17995689147673125,\n",
       "  -0.3645443227459794,\n",
       "  -1.7677570887957352,\n",
       "  1.2048142305406084,\n",
       "  1742256000.0,\n",
       "  -0.5406166103350896,\n",
       "  1.0150111293770376,\n",
       "  0.4563910381805176,\n",
       "  0.34183304560320016],\n",
       " [-1.2615333235188966,\n",
       "  0.295859516279814,\n",
       "  0.43971143037324845,\n",
       "  0.25063109922138926,\n",
       "  -1.2011446691022676,\n",
       "  -1.5337575084008714,\n",
       "  1.4323108241975413,\n",
       "  1.746708195324488,\n",
       "  1780185600.0,\n",
       "  -1.21372826805992,\n",
       "  -1.3723947658937186,\n",
       "  -1.0985229183299676,\n",
       "  -1.0127386561786944],\n",
       " [1.4675502261538378,\n",
       "  -0.41448902187764414,\n",
       "  1.5374277008878385,\n",
       "  0.15959212980125875,\n",
       "  1.034783897307742,\n",
       "  0.896486042421651,\n",
       "  -0.23244718439253959,\n",
       "  0.9070380036410916,\n",
       "  1785715200.0,\n",
       "  0.605852949646835,\n",
       "  1.2955871192719999,\n",
       "  1.699225075304073,\n",
       "  -0.9532395810777727],\n",
       " [-1.6193753193790503,\n",
       "  0.7011342322105396,\n",
       "  -0.2241395270076925,\n",
       "  1.711521307561412,\n",
       "  0.9774207331086561,\n",
       "  -0.8211846600503152,\n",
       "  0.3313627695558932,\n",
       "  0.649546176247448,\n",
       "  1791936000.0,\n",
       "  -1.5248099667893054,\n",
       "  -0.7139093900049982,\n",
       "  1.473042380676803,\n",
       "  -0.04552086741043893],\n",
       " [-1.560616670458226,\n",
       "  0.19055462802655687,\n",
       "  -1.6772102574865788,\n",
       "  0.3060576486521165,\n",
       "  -0.5544426436032991,\n",
       "  -0.6307921730266344,\n",
       "  1.1325577073374364,\n",
       "  -1.2466083013949072,\n",
       "  1787270400.0,\n",
       "  -1.2376383074201296,\n",
       "  -0.6766288959827151,\n",
       "  -0.9792918731899031,\n",
       "  -1.4168862038417056],\n",
       " [0.8506610821154278,\n",
       "  -0.2246479830023162,\n",
       "  1.0565549951337556,\n",
       "  -1.4835381169946844,\n",
       "  -1.658973064163767,\n",
       "  -1.068980333702812,\n",
       "  1.1902956702445169,\n",
       "  0.9126019842754721,\n",
       "  1793404800.0,\n",
       "  0.3917797761335762,\n",
       "  -1.7402802408044526,\n",
       "  1.7428056819908353,\n",
       "  -1.3608700684348085],\n",
       " [0.374847555807198,\n",
       "  -0.3574252428809558,\n",
       "  -0.8353482976864174,\n",
       "  0.6359086350482238,\n",
       "  -1.6720625091513246,\n",
       "  1.1578067991255292,\n",
       "  1.2284958625526867,\n",
       "  0.010966553251972454,\n",
       "  1766448000.0,\n",
       "  1.0509671820541,\n",
       "  -0.06943413401013078,\n",
       "  1.4025895148243361,\n",
       "  0.024811038026660095],\n",
       " [-1.473981106691746,\n",
       "  -0.8733615308224497,\n",
       "  -0.16021657897863453,\n",
       "  -1.026067058540532,\n",
       "  -1.4334722599552507,\n",
       "  -1.032708336000319,\n",
       "  0.3709808394889618,\n",
       "  1.1636195643167193,\n",
       "  1742601600.0,\n",
       "  0.4563893986062388,\n",
       "  -0.4535471819157795,\n",
       "  0.19920928774104182,\n",
       "  -0.9634661842411215],\n",
       " [0.6311453939881287,\n",
       "  1.6275468713262224,\n",
       "  1.6992216204891843,\n",
       "  0.6628633736147334,\n",
       "  0.8245061348974952,\n",
       "  -0.5195422446038611,\n",
       "  -1.2621173448345535,\n",
       "  0.18900097023396162,\n",
       "  1748822400.0,\n",
       "  0.9484087798351831,\n",
       "  -1.1355688090142706,\n",
       "  -0.1683210190975301,\n",
       "  0.06079776754129231],\n",
       " [0.9863307291698618,\n",
       "  1.1496903698417282,\n",
       "  -0.06114974462916505,\n",
       "  0.9832742952977074,\n",
       "  0.06421180357412161,\n",
       "  0.4104224916308462,\n",
       "  1.679974316501822,\n",
       "  -0.6574935766395803,\n",
       "  1765929600.0,\n",
       "  -0.29234662582729426,\n",
       "  -0.4845483920146245,\n",
       "  -1.063002896837727,\n",
       "  1.2423224001633046],\n",
       " [-1.5912183606118786,\n",
       "  0.1327479899076722,\n",
       "  -0.7373383539489267,\n",
       "  1.5663989100543914,\n",
       "  -0.5708165294596864,\n",
       "  -1.492415470515382,\n",
       "  -1.0001063094587117,\n",
       "  1.1637403597544544,\n",
       "  1743811200.0,\n",
       "  1.5827541877189482,\n",
       "  0.7193439252168808,\n",
       "  0.3761399617210196,\n",
       "  1.3483705315731436],\n",
       " [-0.1898921922884724,\n",
       "  -1.2960949695894384,\n",
       "  -0.6384811798824043,\n",
       "  0.8865840496189022,\n",
       "  0.2815659868014463,\n",
       "  -1.093910817542659,\n",
       "  1.1131375153435672,\n",
       "  0.7540614823949361,\n",
       "  1782604800.0,\n",
       "  -1.5554320978917573,\n",
       "  -0.8826151067050004,\n",
       "  -1.1552801427505397,\n",
       "  0.7001106166482812],\n",
       " [0.42767891286138865,\n",
       "  0.6772265579662666,\n",
       "  1.2604806442062464,\n",
       "  -0.05861808290963989,\n",
       "  -0.878113729707002,\n",
       "  -1.3368228152656245,\n",
       "  -1.408493890436558,\n",
       "  1.2768284198278177,\n",
       "  1736899200.0,\n",
       "  1.5097972087071105,\n",
       "  -1.3744598604156395,\n",
       "  -1.5953146267970058,\n",
       "  -0.45075422051138464],\n",
       " [0.27677177100859285,\n",
       "  0.11033151352037421,\n",
       "  -0.15825164390447877,\n",
       "  -1.5211212805630014,\n",
       "  -1.315076026375857,\n",
       "  -0.5436047769003852,\n",
       "  1.0523414996195368,\n",
       "  -1.4245874095115596,\n",
       "  1741478400.0,\n",
       "  1.3358728175225538,\n",
       "  -1.1365493588448734,\n",
       "  -0.2510043840660585,\n",
       "  -0.4927835448040135],\n",
       " [0.8188963115434482,\n",
       "  0.5337744376493918,\n",
       "  -1.0090661675916306,\n",
       "  1.147680142365494,\n",
       "  -1.4706938630893742,\n",
       "  -1.3094703753935464,\n",
       "  0.13089257595178885,\n",
       "  0.8167704735262644,\n",
       "  1781740800.0,\n",
       "  -1.5727032856507492,\n",
       "  0.5938583082490381,\n",
       "  -1.043701579649635,\n",
       "  0.26278113844347495],\n",
       " [0.4858193545969337,\n",
       "  -1.3648890893474914,\n",
       "  -1.7711854655853558,\n",
       "  0.7782909270249702,\n",
       "  -0.47364816309256536,\n",
       "  1.347317784883385,\n",
       "  0.8452884951778903,\n",
       "  0.04059355645150163,\n",
       "  1781222400.0,\n",
       "  -1.1660277272739492,\n",
       "  0.059648768358894766,\n",
       "  1.1458264972157433,\n",
       "  0.47150072044126756],\n",
       " [-0.9194136670268778,\n",
       "  -0.15387773421630496,\n",
       "  -1.7007174927782458,\n",
       "  0.32532558945626516,\n",
       "  -0.06056507119147535,\n",
       "  1.4463655067355734,\n",
       "  1.333084802252784,\n",
       "  -0.8336197545170223,\n",
       "  1751068800.0,\n",
       "  0.9975422441799232,\n",
       "  1.5100729290430654,\n",
       "  0.26390900139495665,\n",
       "  -0.07170722921592777],\n",
       " [1.6817237439312394,\n",
       "  0.7978551269791927,\n",
       "  -1.4709633666917008,\n",
       "  1.3436708503556765,\n",
       "  0.8081000025361702,\n",
       "  1.64888790944729,\n",
       "  0.2574951073076016,\n",
       "  0.9929175966266117,\n",
       "  1758153600.0,\n",
       "  -0.3108578105778712,\n",
       "  -1.5951668208757868,\n",
       "  -0.9222781235991503,\n",
       "  -0.10877195250699398],\n",
       " [-0.8871346749169904,\n",
       "  -0.6620210509290329,\n",
       "  1.6121433739897193,\n",
       "  0.6049751014517676,\n",
       "  0.9654845894343765,\n",
       "  -0.14663953578721584,\n",
       "  1.7360256628453474,\n",
       "  -1.1634222268533225,\n",
       "  1785110400.0,\n",
       "  -0.5870815211352134,\n",
       "  -1.4335909847336692,\n",
       "  -0.8324198569464719,\n",
       "  1.4294548128977689],\n",
       " [-1.5628550621312747,\n",
       "  -1.7221497135543538,\n",
       "  -1.2209782972492482,\n",
       "  0.5807525756656851,\n",
       "  -0.21407795590301318,\n",
       "  -1.0123020432923853,\n",
       "  1.6071541174856103,\n",
       "  1.2675418474597695,\n",
       "  1738713600.0,\n",
       "  1.3600989253002957,\n",
       "  0.7725137579288813,\n",
       "  0.43786960143059706,\n",
       "  -0.38340862233358164],\n",
       " [1.5504018707143832,\n",
       "  -0.9516434446935945,\n",
       "  -0.9742180208990149,\n",
       "  -0.7758123371577758,\n",
       "  -0.2616559002282241,\n",
       "  -1.2689443612965208,\n",
       "  0.32232708830446904,\n",
       "  -0.8398843743418529,\n",
       "  1767916800.0,\n",
       "  1.6935355931739318,\n",
       "  1.0129185376467382,\n",
       "  -0.815293647290419,\n",
       "  -0.4772233517005931],\n",
       " [0.5047498830792794,\n",
       "  -1.190141766991483,\n",
       "  -0.42704306989219365,\n",
       "  -0.1018840057211662,\n",
       "  -0.5523017534756398,\n",
       "  -1.1197061404518893,\n",
       "  0.4665335428825658,\n",
       "  1.3868315909940117,\n",
       "  1777680000.0,\n",
       "  -0.9805690417552549,\n",
       "  1.5966309266166971,\n",
       "  -1.5931709510757686,\n",
       "  -0.5759874877147829],\n",
       " [-1.4350584838273108,\n",
       "  -1.032648661918385,\n",
       "  0.3682858231864676,\n",
       "  1.1692590912906529,\n",
       "  0.4542776422149655,\n",
       "  -0.452564300502963,\n",
       "  0.1980753977683943,\n",
       "  -0.9604987074944191,\n",
       "  1742688000.0,\n",
       "  -0.37561107031801766,\n",
       "  -0.04875080234719262,\n",
       "  1.117288109064687,\n",
       "  -0.7853656387380764],\n",
       " [1.4914604760112398,\n",
       "  -0.9698227637133873,\n",
       "  -1.3991536616514972,\n",
       "  1.3154074284039048,\n",
       "  1.596099531462005,\n",
       "  1.4962615556186194,\n",
       "  0.9526805317834295,\n",
       "  -0.2665800588704168,\n",
       "  1779840000.0,\n",
       "  -1.5495173840751901,\n",
       "  0.09391001502636168,\n",
       "  1.504291269055975,\n",
       "  -1.3292085488794119],\n",
       " [0.07701487940634154,\n",
       "  0.36108679745899414,\n",
       "  -1.5571838353865757,\n",
       "  0.9485184722038745,\n",
       "  0.6436976792704607,\n",
       "  1.5059265963602988,\n",
       "  -1.289766765263715,\n",
       "  -1.4118884964699452,\n",
       "  1768435200.0,\n",
       "  -1.5755625788176395,\n",
       "  1.3063623898739984,\n",
       "  -1.1284130701644086,\n",
       "  0.8593776421605456],\n",
       " [-0.15834967160060961,\n",
       "  0.15577661848458765,\n",
       "  -0.5576999883617968,\n",
       "  0.40220856803298793,\n",
       "  -0.09128411882553077,\n",
       "  -1.414429804963058,\n",
       "  -0.5668118933844833,\n",
       "  -0.7181636059061103,\n",
       "  1754265600.0,\n",
       "  -0.4647544767711201,\n",
       "  -0.3893896481261319,\n",
       "  1.1139505085478338,\n",
       "  -1.5752802922920317],\n",
       " [0.6731324459924762,\n",
       "  -0.5696112790949849,\n",
       "  -0.5516062160978487,\n",
       "  -1.5086870502202057,\n",
       "  1.6815014647924444,\n",
       "  -0.44555551853952147,\n",
       "  -0.36427131048169775,\n",
       "  -0.289871064392558,\n",
       "  1740787200.0,\n",
       "  -1.4933203457867124,\n",
       "  -1.2157757239996254,\n",
       "  0.5955919310473374,\n",
       "  0.11484128669409947],\n",
       " [1.1642185083787187,\n",
       "  1.0627782977979723,\n",
       "  1.7318480057867105,\n",
       "  1.369531986619157,\n",
       "  0.9140524852913213,\n",
       "  1.3231714018651408,\n",
       "  -0.7734676974168169,\n",
       "  1.0819244624837094,\n",
       "  1747699200.0,\n",
       "  -0.18371157586181194,\n",
       "  -0.08997043234431411,\n",
       "  1.6935718662860175,\n",
       "  -0.515314487602406],\n",
       " [0.6879145516398634,\n",
       "  0.21913387212403798,\n",
       "  0.8022232119639554,\n",
       "  0.20404608807227093,\n",
       "  0.7514480560035204,\n",
       "  1.3973115306483095,\n",
       "  0.31559302162836234,\n",
       "  1.1740342363713445,\n",
       "  1793836800.0,\n",
       "  1.1200622594889733,\n",
       "  -0.49004266383934886,\n",
       "  0.8757113642586934,\n",
       "  1.7758545140461648],\n",
       " [1.3174012663076387,\n",
       "  0.6588599185611557,\n",
       "  -1.126353908237176,\n",
       "  1.7581740472710068,\n",
       "  1.486347858440822,\n",
       "  1.6777587765692616,\n",
       "  0.6782635012383995,\n",
       "  1.2219511437420245,\n",
       "  1765411200.0,\n",
       "  -1.5847850186130654,\n",
       "  1.324092141633245,\n",
       "  -0.25702309690129366,\n",
       "  0.5308004833085301],\n",
       " [0.9692114754626356,\n",
       "  -0.19217842617665845,\n",
       "  1.5000076248305385,\n",
       "  1.2055070943366912,\n",
       "  1.128727327170697,\n",
       "  -1.7458427588548087,\n",
       "  0.7900566894145532,\n",
       "  0.5530042237306548,\n",
       "  1736208000.0,\n",
       "  -0.8217192552576884,\n",
       "  -0.4416646111073341,\n",
       "  1.3312837972856317,\n",
       "  1.0515109670444507],\n",
       " [0.22173239933167507,\n",
       "  -1.1936105567842477,\n",
       "  -0.7239361098069851,\n",
       "  -0.5475032923036323,\n",
       "  0.0955983441781787,\n",
       "  -1.4393092151431277,\n",
       "  0.06675675074053508,\n",
       "  0.416257052409848,\n",
       "  1755648000.0,\n",
       "  1.7545189501413465,\n",
       "  -0.9400407739708913,\n",
       "  1.5562075461258706,\n",
       "  0.8756454462810167],\n",
       " [-1.4882689610390603,\n",
       "  1.6803992622749193,\n",
       "  0.999304366094454,\n",
       "  -1.176313536751073,\n",
       "  -1.098503957747228,\n",
       "  -1.2536576649296467,\n",
       "  -0.7204495781768344,\n",
       "  0.16506452952633613,\n",
       "  1743033600.0,\n",
       "  -0.7802951199003165,\n",
       "  -1.0144010126614065,\n",
       "  -0.9064152092105422,\n",
       "  0.18637139344777456],\n",
       " [0.13850885078592348,\n",
       "  0.627408798887355,\n",
       "  1.476327214266946,\n",
       "  -0.1283877428487449,\n",
       "  0.47049542664549127,\n",
       "  0.554244930299435,\n",
       "  -1.3418744353510983,\n",
       "  0.2645974108243274,\n",
       "  1773360000.0,\n",
       "  0.9653296905950101,\n",
       "  -1.5954658217487987,\n",
       "  1.0366306230642033,\n",
       "  1.5262585879863275],\n",
       " [-1.2624605686931365,\n",
       "  -0.6974299979950291,\n",
       "  0.59591378734134,\n",
       "  -0.6655465777837347,\n",
       "  -0.6939492768457972,\n",
       "  0.3277234766550948,\n",
       "  -1.3845437622129158,\n",
       "  -0.45840868128795353,\n",
       "  1795824000.0,\n",
       "  0.06085171074275878,\n",
       "  -1.5001843137916295,\n",
       "  1.3743788849567407,\n",
       "  -1.171701369203791],\n",
       " [-0.2678092626360842,\n",
       "  1.6034799972369649,\n",
       "  1.1933045047303623,\n",
       "  -0.787976852807469,\n",
       "  -0.2835745682253512,\n",
       "  -0.44608752438759197,\n",
       "  -0.7672390917610034,\n",
       "  -1.5677338445465998,\n",
       "  1791158400.0,\n",
       "  0.6776957309092306,\n",
       "  -1.5212709152353376,\n",
       "  -1.7750206325614373,\n",
       "  -1.1738438907727438],\n",
       " [-0.3362489963272591,\n",
       "  -0.6250019424198142,\n",
       "  -1.3162013194228723,\n",
       "  -0.06151907101638588,\n",
       "  1.557786657434301,\n",
       "  -0.24893870327276052,\n",
       "  -1.5365327906839121,\n",
       "  -1.526649825489564,\n",
       "  1788048000.0,\n",
       "  1.3438940980429768,\n",
       "  -0.5241409969638563,\n",
       "  1.6638596138635033,\n",
       "  -1.4581111711474144],\n",
       " [-1.1442522933709538,\n",
       "  0.43257008276204806,\n",
       "  -0.8805961546624825,\n",
       "  1.0412465176206516,\n",
       "  -1.2680900648406805,\n",
       "  -0.5780301307710615,\n",
       "  -1.3605934698885889,\n",
       "  -0.06287150436806484,\n",
       "  1746403200.0,\n",
       "  0.13593495450033377,\n",
       "  0.3698581495802242,\n",
       "  0.0945550117780703,\n",
       "  1.3944210412399014],\n",
       " [-1.3602518964422678,\n",
       "  0.024728127229576433,\n",
       "  0.9474320429213099,\n",
       "  1.5573051821899713,\n",
       "  0.6207936104161865,\n",
       "  1.0901584041044936,\n",
       "  1.4661764018981631,\n",
       "  0.3594285670859819,\n",
       "  1762905600.0,\n",
       "  1.4418139712220086,\n",
       "  0.487217166003878,\n",
       "  -0.4424699530055837,\n",
       "  0.036131442788695095],\n",
       " [0.07690086236251743,\n",
       "  0.9524033478004792,\n",
       "  0.6440791333900632,\n",
       "  1.009866508087312,\n",
       "  1.4673139531237325,\n",
       "  -0.619763845377324,\n",
       "  -0.9485518430236476,\n",
       "  -1.4444320411415916,\n",
       "  1753660800.0,\n",
       "  -0.7645243261565472,\n",
       "  -0.3926440461527501,\n",
       "  0.8190488463543497,\n",
       "  -1.391914017327024],\n",
       " [-0.6622562583104705,\n",
       "  1.3350054551915513,\n",
       "  -0.8376582388391707,\n",
       "  -1.3377968058200658,\n",
       "  -0.795605960993173,\n",
       "  -0.4046840364275601,\n",
       "  -1.7930121421297505,\n",
       "  -0.5641477242098553,\n",
       "  1757116800.0,\n",
       "  0.2758403057956007,\n",
       "  -0.47097142300703465,\n",
       "  -1.6386485648875626,\n",
       "  -1.4159978942736027],\n",
       " [1.1806235769019127,\n",
       "  -0.7551995627848755,\n",
       "  -1.4402994666441022,\n",
       "  1.2063899937157117,\n",
       "  0.6150182690651896,\n",
       "  0.36953876153632326,\n",
       "  0.5442459810070206,\n",
       "  -0.6264631296716385,\n",
       "  1795132800.0,\n",
       "  -1.0638551022539406,\n",
       "  0.6256424732677025,\n",
       "  -1.1733429986793447,\n",
       "  -1.5659671370748998],\n",
       " [0.29645053888680956,\n",
       "  1.4595639011241086,\n",
       "  1.3522615449676965,\n",
       "  -1.4908191063622447,\n",
       "  -0.21428662193518963,\n",
       "  0.641407331286982,\n",
       "  -0.1794989921372583,\n",
       "  -0.7580248670671017,\n",
       "  1759449600.0,\n",
       "  1.2529505142318957,\n",
       "  1.0272416604508905,\n",
       "  -1.4337305903139712,\n",
       "  1.28474556930229],\n",
       " [-1.593247445032421,\n",
       "  1.473505275787285,\n",
       "  1.1780577760967659,\n",
       "  1.144682311579485,\n",
       "  -0.09787519221371649,\n",
       "  0.35242066329629074,\n",
       "  0.06566462085866721,\n",
       "  -0.4284971886478302,\n",
       "  1747353600.0,\n",
       "  -0.11311072496539408,\n",
       "  0.06166558698687915,\n",
       "  -0.03391485224922444,\n",
       "  0.30483312555513187],\n",
       " [-1.2863020294778844,\n",
       "  -0.753571259189015,\n",
       "  0.8727666455164468,\n",
       "  -0.7367443135187359,\n",
       "  -0.05403376923203778,\n",
       "  0.3668707510556036,\n",
       "  -0.26725197669719236,\n",
       "  0.9317949714817483,\n",
       "  1794614400.0,\n",
       "  0.10026698891189514,\n",
       "  0.7789125132622673,\n",
       "  1.0937819551238486,\n",
       "  0.862395365318826],\n",
       " [1.155711326600839,\n",
       "  0.8046295856912702,\n",
       "  0.8169748136082993,\n",
       "  -1.593383224545947,\n",
       "  0.04542675071608337,\n",
       "  -1.180726612192295,\n",
       "  -0.5774565722094833,\n",
       "  1.407943133708765,\n",
       "  1741219200.0,\n",
       "  0.6285443390337674,\n",
       "  1.5597915143349683,\n",
       "  0.8240894085414112,\n",
       "  1.4611615910051585],\n",
       " [0.8934052270385001,\n",
       "  1.3397565797874795,\n",
       "  1.1149953363846559,\n",
       "  1.0217868746963863,\n",
       "  -1.3586773970832957,\n",
       "  0.024704255292085683,\n",
       "  0.950534537652774,\n",
       "  1.551096749413858,\n",
       "  1762819200.0,\n",
       "  0.6229202992959406,\n",
       "  1.089898369529188,\n",
       "  1.467563249435683,\n",
       "  0.3569524524909812],\n",
       " [1.0284590024161198,\n",
       "  1.4085665431387597,\n",
       "  1.5312126783898956,\n",
       "  -1.461527670912702,\n",
       "  -1.5612488085705563,\n",
       "  -1.72223273372871,\n",
       "  -1.2194014628927743,\n",
       "  0.5759758450945804,\n",
       "  1738627200.0,\n",
       "  -0.21202613497845715,\n",
       "  -1.013547191317343,\n",
       "  1.6085690868994793,\n",
       "  1.2654037912593685],\n",
       " [-1.519278020212034,\n",
       "  -1.3951097586887793,\n",
       "  -1.0372003645107546,\n",
       "  0.4947998902013964,\n",
       "  -0.5395735820680612,\n",
       "  -0.8484788080731785,\n",
       "  -0.9583634212143968,\n",
       "  1.3669464691807294,\n",
       "  1741996800.0,\n",
       "  1.3211084092081886,\n",
       "  1.5349386904123279,\n",
       "  -1.4707382460438914,\n",
       "  1.7690136493559494],\n",
       " [-1.050516569387085,\n",
       "  1.174644593274606,\n",
       "  1.0398074060362956,\n",
       "  0.32299444905704255,\n",
       "  0.16876918956771014,\n",
       "  0.961725547933734,\n",
       "  -1.4424194573531024,\n",
       "  -1.5133139832569675,\n",
       "  1772064000.0,\n",
       "  0.41762342785359713,\n",
       "  -0.013465129895329773,\n",
       "  -0.006081675306591692,\n",
       "  1.422906888391837],\n",
       " [0.3379081825932534,\n",
       "  -0.8010134093098542,\n",
       "  -0.34924778029544223,\n",
       "  -0.7716872505175796,\n",
       "  1.536344107776157,\n",
       "  0.8566270792989356,\n",
       "  0.10452703620700125,\n",
       "  -1.3801340334014238,\n",
       "  1790553600.0,\n",
       "  -0.36137515453406294,\n",
       "  1.6990820354591494,\n",
       "  0.2643206925974235,\n",
       "  0.7468829746675137],\n",
       " [-1.4197365583619264,\n",
       "  -0.6018581924749984,\n",
       "  0.02680430684408838,\n",
       "  -0.8694912109175323,\n",
       "  0.3082583196951164,\n",
       "  -0.3603041915675161,\n",
       "  1.7297652733385442,\n",
       "  0.6048557153779913,\n",
       "  1739836800.0,\n",
       "  -0.7109016206447731,\n",
       "  0.5926599216610277,\n",
       "  0.48478611084605794,\n",
       "  0.4431246741894738],\n",
       " [0.892378875716935,\n",
       "  -1.7456568436983113,\n",
       "  -0.3196132097024131,\n",
       "  1.2594227241039133,\n",
       "  -1.3258470313834343,\n",
       "  0.4183590772053849,\n",
       "  1.1139920318682288,\n",
       "  -0.6535404439131847,\n",
       "  1789862400.0,\n",
       "  -0.037821910508124376,\n",
       "  -1.590756081613035,\n",
       "  0.33507927589693076,\n",
       "  1.3997502166134985],\n",
       " [-0.5410196823227272,\n",
       "  -0.8484253716814554,\n",
       "  -0.9601237888162999,\n",
       "  1.3728845269078667,\n",
       "  1.3189191152151158,\n",
       "  1.534990297817518,\n",
       "  -1.4715390855634567,\n",
       "  1.7709642992167176,\n",
       "  1742083200.0,\n",
       "  -0.2727297457724213,\n",
       "  -0.9209476739380771,\n",
       "  -0.06665344280505815,\n",
       "  -0.04065426544814037],\n",
       " [-0.11209741932167731,\n",
       "  1.6812380767590398,\n",
       "  -0.9117825180485194,\n",
       "  0.9246371350057618,\n",
       "  -0.9041472375841862,\n",
       "  0.41430795436027407,\n",
       "  -1.466116096952888,\n",
       "  0.04356451044284075,\n",
       "  1780444800.0,\n",
       "  -1.1827628873391343,\n",
       "  -1.0767634455225497,\n",
       "  -1.1214372732177569,\n",
       "  -1.2494922752005702],\n",
       " [0.6671558000021541,\n",
       "  -0.3874782569036906,\n",
       "  0.18301359584614882,\n",
       "  0.5458126897548595,\n",
       "  -1.5653573681807231,\n",
       "  -1.5069756393689417,\n",
       "  -1.6818488822316795,\n",
       "  0.7903685201858288,\n",
       "  1792368000.0,\n",
       "  0.5168791871092644,\n",
       "  -1.2459623044389558,\n",
       "  0.10651854148694254,\n",
       "  1.152142199048696],\n",
       " [-0.7692633723077839,\n",
       "  0.8408327691008244,\n",
       "  0.7564824312583044,\n",
       "  0.1909050561705273,\n",
       "  -1.5425923978431486,\n",
       "  1.3279232314345746,\n",
       "  -1.4786061180841386,\n",
       "  1.3609722483066464,\n",
       "  1757548800.0,\n",
       "  1.2886830295856122,\n",
       "  0.036648864100085964,\n",
       "  0.9404991237080955,\n",
       "  -1.446253238929789],\n",
       " [-0.7448959139012754,\n",
       "  0.9092228352120758,\n",
       "  0.07925660373097294,\n",
       "  -0.7280532727899651,\n",
       "  1.2670072601244102,\n",
       "  1.4176075767258978,\n",
       "  0.04333811265402483,\n",
       "  0.4774700461689232,\n",
       "  1754092800.0,\n",
       "  -0.15490660489171126,\n",
       "  0.15505933301144387,\n",
       "  -0.5546729440709324,\n",
       "  0.39523172700719583],\n",
       " [0.712218142962629,\n",
       "  0.785146722947137,\n",
       "  1.2641765616251148,\n",
       "  -0.2387930618909075,\n",
       "  -0.9446666763828572,\n",
       "  0.2567458103034553,\n",
       "  -0.1212001224548797,\n",
       "  1.6196192805128409,\n",
       "  1750291200.0,\n",
       "  -0.7820375443102864,\n",
       "  0.5593133658564488,\n",
       "  -0.08082309615987783,\n",
       "  1.5552921510053237],\n",
       " [-0.4458702316120256,\n",
       "  1.1342423314905272,\n",
       "  0.6651600301374606,\n",
       "  0.6900644119390281,\n",
       "  0.1385692495666521,\n",
       "  -0.9961335917932911,\n",
       "  1.3250639058031364,\n",
       "  0.0023697283837607573,\n",
       "  1770249600.0,\n",
       "  0.2414195755939022,\n",
       "  -0.8674028093311053,\n",
       "  -0.39466827235352236,\n",
       "  1.1092219824206342],\n",
       " [0.24490183989253936,\n",
       "  0.27427326693019494,\n",
       "  -1.2196654478410942,\n",
       "  -1.5471635076480135,\n",
       "  0.7134678219688677,\n",
       "  0.7851485983276134,\n",
       "  1.267501912959054,\n",
       "  -0.24236827470602426,\n",
       "  1750204800.0,\n",
       "  -0.9426803717434398,\n",
       "  0.25609527803470694,\n",
       "  -0.1201299207514284,\n",
       "  1.6176122902646348],\n",
       " [-0.6488900863907733,\n",
       "  -0.5468842034093295,\n",
       "  -0.10878717723352845,\n",
       "  1.0530051720135551,\n",
       "  -0.2130930251294651,\n",
       "  0.3441946752836264,\n",
       "  0.4660776969236599,\n",
       "  0.15223890423583097,\n",
       "  1783900800.0,\n",
       "  -0.6119716152016438,\n",
       "  1.2086363563653864,\n",
       "  0.8264595137343299,\n",
       "  1.7004447629773174],\n",
       " [1.311640618992049,\n",
       "  0.6279316460120973,\n",
       "  0.8668541398827467,\n",
       "  1.0314578651322648,\n",
       "  -1.1224601681807187,\n",
       "  -0.7835673189915142,\n",
       "  -0.008640674253317424,\n",
       "  -1.6144568695457708,\n",
       "  1763942400.0,\n",
       "  0.8375572445024972,\n",
       "  0.35758624277072315,\n",
       "  -1.014427538464643,\n",
       "  0.8053574189087062],\n",
       " [1.3325297427012606,\n",
       "  -1.135183458969016,\n",
       "  -0.25430545506519653,\n",
       "  -0.4867795760570636,\n",
       "  -0.21412878860219609,\n",
       "  -0.19070419382018322,\n",
       "  0.48285635591603443,\n",
       "  1.3718615497936648,\n",
       "  1741651200.0,\n",
       "  1.7188106159870795,\n",
       "  1.4427786354916299,\n",
       "  1.3500472941469313,\n",
       "  -0.4447194223506056],\n",
       " [1.6763799387527136,\n",
       "  -1.041688094552104,\n",
       "  -1.5436481774609674,\n",
       "  -0.7990869701640284,\n",
       "  0.21143273296720919,\n",
       "  -0.058460689943780765,\n",
       "  0.44111499484173466,\n",
       "  -0.3787094217825741,\n",
       "  1769731200.0,\n",
       "  -0.538584428365696,\n",
       "  -1.597311580424588,\n",
       "  -1.7150894278520668,\n",
       "  0.43158190873747865],\n",
       " [1.2710851273975854,\n",
       "  -0.3313160463220335,\n",
       "  0.6489596327109892,\n",
       "  0.10779319166554975,\n",
       "  0.7914626914363192,\n",
       "  -1.3969381402125087,\n",
       "  -1.5422874342431276,\n",
       "  -1.0963240036822144,\n",
       "  1740268800.0,\n",
       "  -0.24731440293935414,\n",
       "  0.9695750369218307,\n",
       "  -0.1010734054190464,\n",
       "  0.8167980388273897],\n",
       " [0.07953233792875046,\n",
       "  -0.9678964983150058,\n",
       "  0.4024265062184905,\n",
       "  0.7034063308757944,\n",
       "  1.1011003607264656,\n",
       "  1.1639729888202015,\n",
       "  -1.1365791792106041,\n",
       "  -0.2758765446400478,\n",
       "  1746230400.0,\n",
       "  -1.1407431030955215,\n",
       "  0.43199186605690326,\n",
       "  -0.8778607510040451,\n",
       "  1.0335703395897318],\n",
       " [-0.1340285917369902,\n",
       "  -0.6721901737202765,\n",
       "  0.2865728027989423,\n",
       "  0.6716466141426832,\n",
       "  1.0389130786710659,\n",
       "  0.4292134673983576,\n",
       "  -1.5612088784977818,\n",
       "  -1.499877054891967,\n",
       "  1752624000.0,\n",
       "  0.667818422844111,\n",
       "  1.1345495376811756,\n",
       "  -0.4699460994616844,\n",
       "  1.5004602015036317],\n",
       " [0.9694240218681494,\n",
       "  1.3223529520268045,\n",
       "  0.07022241735801034,\n",
       "  -0.11301094186996886,\n",
       "  0.009043266449672802,\n",
       "  -1.5459780377329748,\n",
       "  1.2604736882469072,\n",
       "  1.574837051973255,\n",
       "  1739404800.0,\n",
       "  -0.0824961846663261,\n",
       "  1.122364573274585,\n",
       "  -1.285748979388364,\n",
       "  -0.9825162939726737],\n",
       " [-1.4635984678812963,\n",
       "  1.0030949998063898,\n",
       "  -0.796305930118108,\n",
       "  0.6923500000437434,\n",
       "  1.4604986580981298,\n",
       "  0.011560559559598792,\n",
       "  1.1689557042855265,\n",
       "  -1.2753803026613346,\n",
       "  1758412800.0,\n",
       "  1.2495726082866774,\n",
       "  -1.0736307602572595,\n",
       "  -0.03300930601072335,\n",
       "  1.121164490022847],\n",
       " [0.9619617621259247,\n",
       "  -1.5938694652111376,\n",
       "  1.032167606348801,\n",
       "  1.534474534593523,\n",
       "  0.2071156017372773,\n",
       "  -1.631425892387726,\n",
       "  0.0759545053146558,\n",
       "  -0.9036563295489436,\n",
       "  1773532800.0,\n",
       "  -1.6148244665304323,\n",
       "  0.4844943739622409,\n",
       "  -0.2110514602955448,\n",
       "  1.2014782041275167],\n",
       " [-0.1334057648658978,\n",
       "  1.054822224044416,\n",
       "  -1.03598767293937,\n",
       "  -0.7795299409800248,\n",
       "  -0.1348908508695499,\n",
       "  0.23256113426194167,\n",
       "  0.5355107284735321,\n",
       "  -1.0732407781314504,\n",
       "  1736553600.0,\n",
       "  1.2214539275876177,\n",
       "  -1.0289098540536235,\n",
       "  -1.7513090390504926,\n",
       "  1.6431230327365764],\n",
       " [-0.7635872930096511,\n",
       "  -0.5281426252034301,\n",
       "  -1.6923399662130587,\n",
       "  -1.0039961230817442,\n",
       "  0.39899435981590997,\n",
       "  0.520268359166176,\n",
       "  0.7013316352322129,\n",
       "  -0.2558786488880277,\n",
       "  1744761600.0,\n",
       "  1.3883764080029286,\n",
       "  1.4796981614237195,\n",
       "  -0.9049118077784596,\n",
       "  -0.1556181216740788],\n",
       " [-1.5589691028356343,\n",
       "  -0.881376726421043,\n",
       "  -1.1577652066216433,\n",
       "  0.7074214701956497,\n",
       "  -0.836643572498054,\n",
       "  0.19573812991475842,\n",
       "  -0.19552744231085809,\n",
       "  1.1969519520499399,\n",
       "  1782777600.0,\n",
       "  -0.7586404399280261,\n",
       "  0.08733235556101301,\n",
       "  0.6547499923426544,\n",
       "  1.3130269857425005],\n",
       " [0.6185034861206663,\n",
       "  0.4254513093446201,\n",
       "  -0.08721116068243825,\n",
       "  -1.149085019890016,\n",
       "  1.4425088996816862,\n",
       "  -0.7861214945316632,\n",
       "  1.320276487061432,\n",
       "  0.6949488277651592,\n",
       "  1761868800.0,\n",
       "  0.741429311798701,\n",
       "  -1.4380342529695493,\n",
       "  -0.20036678995520119,\n",
       "  -0.4340112058087602],\n",
       " [-0.7785576652136108,\n",
       "  0.01455771995267438,\n",
       "  0.6899925483453782,\n",
       "  1.5193559179213922,\n",
       "  -1.1045189137486133,\n",
       "  -0.7106195181726913,\n",
       "  -0.44605737803789286,\n",
       "  -0.9491769074111658,\n",
       "  1779494400.0,\n",
       "  0.718612111595538,\n",
       "  -1.1778977291711041,\n",
       "  0.0043728285851778,\n",
       "  1.5598339806141077],\n",
       " [1.1144166353537557,\n",
       "  1.41385103972196,\n",
       "  -1.3476696532614512,\n",
       "  1.5616831916498266,\n",
       "  -0.924851594519403,\n",
       "  1.0477201997293342,\n",
       "  -1.1201043155620904,\n",
       "  -1.5422353510644622,\n",
       "  1779148800.0,\n",
       "  0.9447549096801791,\n",
       "  1.6018442744260042,\n",
       "  -0.5541306288980647,\n",
       "  -1.6097803637778592],\n",
       " [0.7936560360125386,\n",
       "  0.217398205728982,\n",
       "  -1.3955013008139758,\n",
       "  0.5225473018951354,\n",
       "  0.2611354741015096,\n",
       "  0.8239291797889022,\n",
       "  1.1184331046225817,\n",
       "  0.4506860715895683,\n",
       "  1763510400.0,\n",
       "  1.6892486992986449,\n",
       "  -1.6243046578527325,\n",
       "  -0.1560985406241407,\n",
       "  0.9943420055270539],\n",
       " [0.13344846974824176,\n",
       "  1.5225462316258278,\n",
       "  -0.5265743048260461,\n",
       "  -1.5974387156790326,\n",
       "  -0.06565563266016033,\n",
       "  1.435202817132756,\n",
       "  -1.574203181461426,\n",
       "  0.6434693804029303,\n",
       "  1748563200.0,\n",
       "  0.8467342514419601,\n",
       "  -0.1329181479534338,\n",
       "  0.22264752099630428,\n",
       "  -0.005071459452378868],\n",
       " [0.9642744154659847,\n",
       "  -0.14660986244806956,\n",
       "  1.7323708971324758,\n",
       "  -1.1611993334976496,\n",
       "  -0.5890997116031378,\n",
       "  -1.4321491162429958,\n",
       "  -0.8333480012013051,\n",
       "  1.4315318214419652,\n",
       "  1785196800.0,\n",
       "  -1.7198761064329453,\n",
       "  0.6818420540133163,\n",
       "  1.0757328743438628,\n",
       "  -1.2424497882359993],\n",
       " [-1.6736861333793975,\n",
       "  1.1577923061889135,\n",
       "  1.2251979359840288,\n",
       "  0.01491371997576497,\n",
       "  1.0488021110775725,\n",
       "  -0.06863114550099672,\n",
       "  1.4012156254973667,\n",
       "  0.02741075108925315,\n",
       "  1766534400.0,\n",
       "  0.6509353419939082,\n",
       "  0.3309029363488631,\n",
       "  0.5012509868965457,\n",
       "  -1.340463701697559],\n",
       " [0.2239424137680497,\n",
       "  1.4068468332863262,\n",
       "  -0.25019201451847867,\n",
       "  -0.8715082120379621,\n",
       "  -0.743417859915942,\n",
       "  0.9092289117353604,\n",
       "  0.08174826349196365,\n",
       "  -0.7309111920173249,\n",
       "  1754006400.0,\n",
       "  1.2691918988691813,\n",
       "  1.4175009693336937,\n",
       "  0.044441136026369996,\n",
       "  0.4750378742336957],\n",
       " [-0.6954195763540533,\n",
       "  0.32773708889072306,\n",
       "  -1.3860044866646533,\n",
       "  -0.4551506655764003,\n",
       "  0.058775421414614976,\n",
       "  -1.4987112574321881,\n",
       "  1.373010621892195,\n",
       "  -1.1686564027233808,\n",
       "  1795910400.0,\n",
       "  -0.6408804347940885,\n",
       "  -0.260639987094972,\n",
       "  -1.3107853109557552,\n",
       "  1.3048365534590467],\n",
       " [-1.4570383595829233,\n",
       "  -1.3170211762568609,\n",
       "  -0.7196787617870523,\n",
       "  -1.5858029694846205,\n",
       "  -0.18545180407915562,\n",
       "  0.4730930209099317,\n",
       "  -0.2617922513898112,\n",
       "  -0.50262847809821,\n",
       "  1767225600.0,\n",
       "  0.9317471304321123,\n",
       "  -1.185742739586053,\n",
       "  -1.800730720976649,\n",
       "  0.6582374550055686],\n",
       " [-1.576746294311077,\n",
       "  -0.6498573482343161,\n",
       "  1.4360385851614623,\n",
       "  -0.7525884370078264,\n",
       "  0.995411504243691,\n",
       "  -0.34558614970479345,\n",
       "  -1.0412776856492523,\n",
       "  -1.4763273454702217,\n",
       "  1743465600.0,\n",
       "  0.3857823717867028,\n",
       "  -1.2524377707523597,\n",
       "  0.6454779372633842,\n",
       "  -0.5819638843305878],\n",
       " [1.718650803168103,\n",
       "  -0.5298966720699944,\n",
       "  -0.8318277781378404,\n",
       "  0.2976068226830802,\n",
       "  0.5033630991236693,\n",
       "  0.6025753328801484,\n",
       "  1.0412115984983277,\n",
       "  -0.18543016467234694,\n",
       "  1776902400.0,\n",
       "  -0.6660816990444999,\n",
       "  1.5357818426587213,\n",
       "  0.9239816751338118,\n",
       "  0.46596120515107614],\n",
       " [-0.7649815360388298,\n",
       "  -1.4602707963819468,\n",
       "  1.367536970635866,\n",
       "  1.352440776727455,\n",
       "  1.354925249426645,\n",
       "  -0.7789044213130673,\n",
       "  0.9481714291413346,\n",
       "  0.2982985912828275,\n",
       "  1772496000.0,\n",
       "  -0.1859935055783398,\n",
       "  -0.25589778066375324,\n",
       "  0.9111146116844482,\n",
       "  0.5597226031951258],\n",
       " [-0.34104640823636934,\n",
       "  1.2656195008523252,\n",
       "  -0.2879663991271916,\n",
       "  -1.3004398226690568,\n",
       "  -1.0118578730313639,\n",
       "  -0.026607729980495255,\n",
       "  -0.0655519399454267,\n",
       "  1.7672913085543833,\n",
       "  1769558400.0,\n",
       "  1.6796999518630285,\n",
       "  -1.043007019745315,\n",
       "  -1.5415116440631353,\n",
       "  -0.8047491624674745],\n",
       " [-0.0859343945503369,\n",
       "  1.1225961016336656,\n",
       "  -1.2881163098140442,\n",
       "  -0.9770488558810307,\n",
       "  0.0678473065164293,\n",
       "  0.3747493315058535,\n",
       "  -0.7293769935911192,\n",
       "  -0.8494710395538583,\n",
       "  1739577600.0,\n",
       "  -1.426312368083231,\n",
       "  -1.637738713003429,\n",
       "  1.0509892725166585,\n",
       "  -0.2913509836383427],\n",
       " [-0.6124397571826197,\n",
       "  1.20727075458298,\n",
       "  -1.4897677551311603,\n",
       "  -1.315216498297103,\n",
       "  -0.026433365218048566,\n",
       "  -0.2950236811967252,\n",
       "  -0.39253278452069007,\n",
       "  0.9002763214808149,\n",
       "  1745366400.0,\n",
       "  -0.6604245546756431,\n",
       "  -0.16727095138600234,\n",
       "  -1.3719011409523805,\n",
       "  0.14896508450587564],\n",
       " [-0.9558840902825251,\n",
       "  1.5908336035703514,\n",
       "  0.5127093505961432,\n",
       "  -1.3361041374724358,\n",
       "  0.5257180870898346,\n",
       "  0.4490014877506173,\n",
       "  1.3633368648148312,\n",
       "  1.691998120162284,\n",
       "  1776211200.0,\n",
       "  -1.3074098466076658,\n",
       "  -1.435619229755288,\n",
       "  -1.665001291550046,\n",
       "  0.878783558177897],\n",
       " [1.6804035304739955,\n",
       "  -0.4455157244270091,\n",
       "  -0.36644937832554875,\n",
       "  -0.28636559661976063,\n",
       "  -1.4952572756552287,\n",
       "  -1.2144358656331418,\n",
       "  0.5943789874420001,\n",
       "  0.1174074971572344,\n",
       "  1740873600.0,\n",
       "  0.9115586362131952,\n",
       "  -0.5006796868848429,\n",
       "  1.6578125557223216,\n",
       "  1.4504902879518344],\n",
       " [1.7013186032687602,\n",
       "  1.1045395835724525,\n",
       "  -1.2832729145857265,\n",
       "  -0.21411699997976477,\n",
       "  -0.26315132181389733,\n",
       "  1.1704525759111475,\n",
       "  -0.7913921848296575,\n",
       "  0.6129691048509308,\n",
       "  1777420800.0,\n",
       "  -1.449555149079512,\n",
       "  -0.03217668496300572,\n",
       "  -1.3781218365746604,\n",
       "  -0.8326013109445174],\n",
       " [-1.2172423537104171,\n",
       "  -1.3709104302030588,\n",
       "  -1.1010591992100973,\n",
       "  -1.007304328439232,\n",
       "  -0.11071854449276616,\n",
       "  1.68127029325577,\n",
       "  -0.9099881382673157,\n",
       "  0.9193562428783966,\n",
       "  1780358400.0,\n",
       "  -0.9021572993229627,\n",
       "  0.41373124825432395,\n",
       "  -1.4653141756693393,\n",
       "  0.040970810852434314],\n",
       " [-1.0464426046032755,\n",
       "  -1.0490613671116935,\n",
       "  -0.19701655015249495,\n",
       "  0.7982329584416442,\n",
       "  1.7671351155304194,\n",
       "  -0.546886144441515,\n",
       "  -1.6485659753912008,\n",
       "  1.4298487329469167,\n",
       "  1738108800.0,\n",
       "  -1.037612623659465,\n",
       "  -1.470753530803818,\n",
       "  -0.44330403974137317,\n",
       "  -1.5261971148345235],\n",
       " [-1.5033591268440014,\n",
       "  0.6391802391232242,\n",
       "  0.8047047333147263,\n",
       "  -0.4761804112647964,\n",
       "  0.21680078003284314,\n",
       "  -0.5452765153516281,\n",
       "  0.6538340421164787,\n",
       "  0.7081876934074861,\n",
       "  1754870400.0,\n",
       "  -0.622159092260625,\n",
       "  -1.0968597001155154,\n",
       "  -0.6261387402864435,\n",
       "  -1.5050356906220401],\n",
       " [-1.5731107242686804,\n",
       "  1.5430759537239926,\n",
       "  1.576826063904538,\n",
       "  -0.5924693889991738,\n",
       "  -1.5954600991643024,\n",
       "  -1.598804361962432,\n",
       "  0.5387760614760927,\n",
       "  -0.7561795353423874,\n",
       "  1773187200.0,\n",
       "  0.1419320074714354,\n",
       "  0.6269284745955328,\n",
       "  1.4811913970613257,\n",
       "  -0.1347839209652007],\n",
       " [0.48849645455243973,\n",
       "  -1.332373459189612,\n",
       "  -0.43546325821860143,\n",
       "  0.25253927867592396,\n",
       "  0.7397879143830781,\n",
       "  0.6625439511223167,\n",
       "  -1.6047016661684648,\n",
       "  0.2704261805824867,\n",
       "  1760313600.0,\n",
       "  1.0297585674921268,\n",
       "  0.6348441912098948,\n",
       "  -1.6789450643355335,\n",
       "  -0.8506644927896406],\n",
       " [-0.6639015282746267,\n",
       "  -0.16639179950067878,\n",
       "  -1.3741907287456205,\n",
       "  0.1556721261292268,\n",
       "  -1.0952092726440115,\n",
       "  -0.3841953003290201,\n",
       "  -0.42442543367132396,\n",
       "  0.30099270137385986,\n",
       "  1745539200.0,\n",
       "  0.546887453355031,\n",
       "  1.5755468867977507,\n",
       "  0.8631842627474648,\n",
       "  -0.2782744662381157],\n",
       " [-1.1000376734644168,\n",
       "  -1.2535905098891407,\n",
       "  -0.7223772206305732,\n",
       "  0.16923794759131325,\n",
       "  -0.7822959852962815,\n",
       "  -1.0131554647635423,\n",
       "  -0.907328596004378,\n",
       "  0.18891098569590695,\n",
       "  1743120000.0,\n",
       "  -1.416113888935972,\n",
       "  0.9780925386568762,\n",
       "  1.1026196222037143,\n",
       "  0.45864782409991345],\n",
       " [-0.2507636677685225,\n",
       "  0.9698832924618965,\n",
       "  -0.10450977225699705,\n",
       "  0.8242367302193665,\n",
       "  1.4770621564605058,\n",
       "  0.30167010114352605,\n",
       "  1.262848920842313,\n",
       "  -0.5229739415117981,\n",
       "  1740441600.0,\n",
       "  -0.2572850471502125,\n",
       "  0.2375042963430685,\n",
       "  0.400610557263437,\n",
       "  1.0862328203270846],\n",
       " [-0.625633499258702,\n",
       "  -1.0955137314188557,\n",
       "  -0.6291012947371651,\n",
       "  -1.5001407028612577,\n",
       "  0.22774311436307398,\n",
       "  0.031109414455106527,\n",
       "  -1.15329716151631,\n",
       "  -0.6055646852442056,\n",
       "  1755043200.0,\n",
       "  -1.7222650892444837,\n",
       "  -0.7569365604364157,\n",
       "  1.3787201214872118,\n",
       "  0.5980896473909267],\n",
       " [1.7373473006042996,\n",
       "  1.259113837614756,\n",
       "  0.2226485472164919,\n",
       "  -0.39080265104759504,\n",
       "  0.21469745849674993,\n",
       "  1.0479505400688922,\n",
       "  1.4340596708797684,\n",
       "  -0.5627869159740353,\n",
       "  1784246400.0,\n",
       "  -1.1669179863581782,\n",
       "  -0.3405976416168681,\n",
       "  -0.9852120877735546,\n",
       "  1.6247086945710292],\n",
       " [0.7138718616022086,\n",
       "  0.011005511878669223,\n",
       "  -0.7235907194412218,\n",
       "  -0.3109930779379873,\n",
       "  1.0381100552980491,\n",
       "  -0.3847135145756775,\n",
       "  -1.1989580737133978,\n",
       "  -0.40239675650832074,\n",
       "  1775001600.0,\n",
       "  0.33262800297972,\n",
       "  -0.6926544613141584,\n",
       "  1.6591574609456896,\n",
       "  -1.1405335397117835],\n",
       " [0.03258532012216233,\n",
       "  0.7196748735144993,\n",
       "  1.3146997042017334,\n",
       "  0.1315844442837324,\n",
       "  -0.3516898207581541,\n",
       "  1.1024005425128167,\n",
       "  1.4332214792354026,\n",
       "  0.4085294438599543,\n",
       "  1762128000.0,\n",
       "  -1.5448864224231202,\n",
       "  -0.4308120275587952,\n",
       "  0.07460120921079105,\n",
       "  0.16550702803131262],\n",
       " [-1.1705390343260043,\n",
       "  0.17844927081634177,\n",
       "  -0.4393469443958394,\n",
       "  0.9352227109807304,\n",
       "  -1.1246628626840056,\n",
       "  0.6225932331111739,\n",
       "  1.537013080068332,\n",
       "  1.3815397561204827,\n",
       "  1783641600.0,\n",
       "  -0.5708192287513837,\n",
       "  -1.7233764986459732,\n",
       "  0.2031347123675416,\n",
       "  -1.6052148814980565],\n",
       " [1.636596639562641,\n",
       "  -0.2022854213526845,\n",
       "  -0.4171132948299337,\n",
       "  0.7566936087633703,\n",
       "  -0.7387071849744579,\n",
       "  1.0829148877749053,\n",
       "  1.6396766612829556,\n",
       "  0.6542878336410867,\n",
       "  1754611200.0,\n",
       "  0.07118763102767285,\n",
       "  -0.17641045276638204,\n",
       "  0.7074502933402992,\n",
       "  -0.263008425338087],\n",
       " [0.4536793391930123,\n",
       "  -1.3863412803801431,\n",
       "  1.3343899549038116,\n",
       "  -1.3623761579565041,\n",
       "  -0.8422711834081876,\n",
       "  -0.8835785276049883,\n",
       "  0.7721477800135899,\n",
       "  -1.3638350967744033,\n",
       "  1756339200.0,\n",
       "  -1.4350884773666073,\n",
       "  -0.38413290678829765,\n",
       "  -0.36147862865530217,\n",
       "  0.6175701361121942],\n",
       " [-0.16192007995386973,\n",
       "  -0.12044872404192525,\n",
       "  -0.2505491171212699,\n",
       "  -0.6972232601799231,\n",
       "  1.5186874461417588,\n",
       "  -0.9564525827095958,\n",
       "  -0.11619032810211938,\n",
       "  -0.5481059085884743,\n",
       "  1737590400.0,\n",
       "  0.10906766448769231,\n",
       "  -1.62200479390784,\n",
       "  1.6281611703928673,\n",
       "  -0.5432076413365926],\n",
       " [-1.544195726907139,\n",
       "  1.327902978652529,\n",
       "  -1.4800007082309496,\n",
       "  1.3669015345007762,\n",
       "  1.286496643110638,\n",
       "  0.03740217041626812,\n",
       "  0.9392173926142516,\n",
       "  -1.4431061045507219,\n",
       "  1757635200.0,\n",
       "  -0.29413619854083073,\n",
       "  -1.390139934872775,\n",
       "  -1.181964146256449,\n",
       "  1.4766945295214964],\n",
       " [1.459366080353648,\n",
       "  0.011584876519682433,\n",
       "  1.1656996398087303,\n",
       "  -1.2733217895617845,\n",
       "  1.247389728763945,\n",
       "  -1.072357473100504,\n",
       "  -0.03409688284700076,\n",
       "  1.1233562214224944,\n",
       "  1758499200.0,\n",
       "  -1.0400885436402718,\n",
       "  0.944331755009556,\n",
       "  1.585398052993666,\n",
       "  0.8568205036004737],\n",
       " [0.8572669382137075,\n",
       "  0.4839204870515326,\n",
       "  -0.33401270212392303,\n",
       "  -1.368340325402527,\n",
       "  -1.5715028633275274,\n",
       "  1.543103492134031,\n",
       "  1.5803713906499808,\n",
       "  -0.5955260847635988,\n",
       "  1773100800.0,\n",
       "  -1.5935321550857013,\n",
       "  -1.600324317212938,\n",
       "  0.5399779135510974,\n",
       "  -0.7590709513015026],\n",
       " [-0.4755225892614417,\n",
       "  -0.7574414646455174,\n",
       "  0.2735313300153539,\n",
       "  -1.5314772746944376,\n",
       "  -1.2858756444849258,\n",
       "  -1.0037598196062474,\n",
       "  0.9853805589935897,\n",
       "  -1.161927254145934,\n",
       "  1758844800.0,\n",
       "  -1.6359285435016295,\n",
       "  0.8576304970950714,\n",
       "  -0.2655789502086155,\n",
       "  -1.330140591283385],\n",
       " [0.04407235253552731,\n",
       "  -1.180661926469921,\n",
       "  -0.5794847516205565,\n",
       "  1.4139413839871469,\n",
       "  0.626417145857764,\n",
       "  1.5598314823369033,\n",
       "  0.8228308939304778,\n",
       "  1.4632268006317382,\n",
       "  1741305600.0,\n",
       "  0.28018565452938987,\n",
       "  0.10959139515709894,\n",
       "  -0.15486381686065032,\n",
       "  -1.5259933080373327],\n",
       " [-0.4682183260807934,\n",
       "  -0.38839895364534116,\n",
       "  1.1094177193353947,\n",
       "  -1.5704622615700214,\n",
       "  -1.392723244904504,\n",
       "  -0.3221880773586368,\n",
       "  -0.7499433031456635,\n",
       "  1.0011901213283443,\n",
       "  1754438400.0,\n",
       "  1.6399193209016152,\n",
       "  -0.20318260719622674,\n",
       "  -0.41395927228261553,\n",
       "  0.749328833802032],\n",
       " [-0.27555635250932786,\n",
       "  -0.32408398528808025,\n",
       "  1.722223707779302,\n",
       "  0.02314836180683771,\n",
       "  0.8854855216388251,\n",
       "  1.3607491771433493,\n",
       "  1.2001517633164864,\n",
       "  -0.24891273511625103,\n",
       "  1783296000.0,\n",
       "  0.8157677536482233,\n",
       "  0.15738878389625036,\n",
       "  0.6677552816761898,\n",
       "  -0.8318348421773901],\n",
       " [1.7240066459798509,\n",
       "  0.08283606219972808,\n",
       "  0.3312521034338525,\n",
       "  -0.42402138474870565,\n",
       "  1.029659116668435,\n",
       "  1.408589527140761,\n",
       "  1.534725912254411,\n",
       "  -1.46331025952695,\n",
       "  1738540800.0,\n",
       "  -1.5593177965597431,\n",
       "  -1.7238105216719766,\n",
       "  -1.2185503276011562,\n",
       "  0.5735803433776653],\n",
       " [-1.3995022942948039,\n",
       "  1.0557839040417563,\n",
       "  0.7964077800583496,\n",
       "  -1.5775552927359981,\n",
       "  -0.5445475849530035,\n",
       "  0.060517006191874174,\n",
       "  0.32884007993335607,\n",
       "  -0.724761256947696,\n",
       "  1751760000.0,\n",
       "  -0.9769873102130744,\n",
       "  -0.901699898586953,\n",
       "  0.13213776592384296,\n",
       "  -0.5238242328074754],\n",
       " [-0.9274939447020737,\n",
       "  0.13021589402684058,\n",
       "  -1.4651747743412051,\n",
       "  -1.1480987397384634,\n",
       "  1.3154198053411819,\n",
       "  0.5018023067476416,\n",
       "  -0.6166833902278639,\n",
       "  -1.4520620250871779,\n",
       "  1762473600.0,\n",
       "  -0.3332869799672811,\n",
       "  -1.0717860715098688,\n",
       "  -0.5035389652358786,\n",
       "  0.48168738277908885],\n",
       " [-0.3648320698242466,\n",
       "  1.69902395036593,\n",
       "  0.26055459869816483,\n",
       "  0.7542450700481901,\n",
       "  -1.5863190427806775,\n",
       "  0.5831880239959858,\n",
       "  -0.5180126291777916,\n",
       "  1.6719665120875817,\n",
       "  1790726400.0,\n",
       "  1.4699293420540456,\n",
       "  -0.6511541250472687,\n",
       "  1.250100491808765,\n",
       "  0.31880464450963075],\n",
       " [-0.721140582390121,\n",
       "  1.7032530897568665,\n",
       "  0.4895569898968506,\n",
       "  -1.0734020066254877,\n",
       "  1.4525600927637494,\n",
       "  -0.919947003277477,\n",
       "  1.65127727552445,\n",
       "  1.05502644243338,\n",
       "  1764460800.0,\n",
       "  -1.2921581294882796,\n",
       "  0.733507110134546,\n",
       "  -0.07250293418524406,\n",
       "  -1.2218588075416141],\n",
       " [-1.6183654551320927,\n",
       "  0.4850462251876388,\n",
       "  -0.21438858431310057,\n",
       "  1.2093383349709543,\n",
       "  0.28301994562956023,\n",
       "  -1.3197698622144103,\n",
       "  0.32194732008989957,\n",
       "  0.8445035898771344,\n",
       "  1773705600.0,\n",
       "  0.15149264405779225,\n",
       "  1.1802759940620464,\n",
       "  -1.5599798048896858,\n",
       "  -0.9493047398198988],\n",
       " [1.7317323964483897,\n",
       "  0.3981690576602463,\n",
       "  0.12726375027615452,\n",
       "  -1.569284579341885,\n",
       "  -1.033614654921554,\n",
       "  -0.2040060708064552,\n",
       "  -1.760159439605106,\n",
       "  1.366095833166223,\n",
       "  1761609600.0,\n",
       "  -0.9788207172927408,\n",
       "  -1.3039396496263793,\n",
       "  -0.2670339210215921,\n",
       "  0.630128579165379],\n",
       " [0.9511656728079978,\n",
       "  1.3062537239369783,\n",
       "  1.713936719958066,\n",
       "  0.9538883656752537,\n",
       "  -0.6533834638142706,\n",
       "  -0.7258357889421606,\n",
       "  -1.0992788954248325,\n",
       "  -0.3714137787399994,\n",
       "  1786579200.0,\n",
       "  -0.06984200859948872,\n",
       "  -0.8160488716575037,\n",
       "  -1.6505958556891418,\n",
       "  -1.3252527071173426],\n",
       " [-1.5883239923619215,\n",
       "  1.3242223673245077,\n",
       "  -0.2603187366892907,\n",
       "  0.5379258477765078,\n",
       "  -0.7901383646268522,\n",
       "  -0.8295597453588592,\n",
       "  -0.8176824007269601,\n",
       "  -1.2150265070913493,\n",
       "  1765584000.0,\n",
       "  -0.27756498024475157,\n",
       "  -0.749008268133461,\n",
       "  1.0924963332536106,\n",
       "  -0.4348691940073938],\n",
       " [-1.5658343151669205,\n",
       "  -0.8112620692879203,\n",
       "  0.6214188033488729,\n",
       "  -0.5013839877060577,\n",
       "  0.7406994299785838,\n",
       "  0.01646458011324973,\n",
       "  -0.4353212151003045,\n",
       "  1.694636995643024,\n",
       "  1787702400.0,\n",
       "  -0.9758291531256073,\n",
       "  -1.0795125126217242,\n",
       "  -0.03529414849561295,\n",
       "  0.6796335590713845],\n",
       " [-1.1396417676003747,\n",
       "  -1.7352554278720613,\n",
       "  -1.2708466101127913,\n",
       "  -1.3544885776154498,\n",
       "  -1.4914492698971744,\n",
       "  0.8067452230111319,\n",
       "  0.9616211373303469,\n",
       "  -1.4456888384074786,\n",
       "  1771286400.0,\n",
       "  -0.4025612800557827,\n",
       "  0.8903365269234781,\n",
       "  -1.1707630178513495,\n",
       "  0.49154778089568774],\n",
       " [1.087315319691125,\n",
       "  0.16727239096573523,\n",
       "  1.3399563323754042,\n",
       "  -1.1674798615085653,\n",
       "  0.4351651269400914,\n",
       "  0.5505517556844796,\n",
       "  -1.5204425323190847,\n",
       "  -0.1567575149037408,\n",
       "  1764201600.0,\n",
       "  0.07850927283074173,\n",
       "  -1.3529076541380352,\n",
       "  -0.4302660882784745,\n",
       "  1.0237596021929671],\n",
       " [-0.18684239376449507,\n",
       "  0.47310171118655936,\n",
       "  -0.26404237123873675,\n",
       "  -0.49943538723886516,\n",
       "  0.9295927496760793,\n",
       "  -1.1844169466641092,\n",
       "  -1.801465747564331,\n",
       "  0.6606014536072072,\n",
       "  1767312000.0,\n",
       "  -1.4969362667998787,\n",
       "  0.07731951141011836,\n",
       "  0.3186607663407758,\n",
       "  0.7691253255525667],\n",
       " [1.3347549668235672,\n",
       "  0.886670344726978,\n",
       "  0.6604683954094298,\n",
       "  -1.470226593732231,\n",
       "  0.4060306886189969,\n",
       "  1.4689260809022764,\n",
       "  -0.44488534653325973,\n",
       "  -1.348425265388371,\n",
       "  1789171200.0,\n",
       "  1.1751289458088399,\n",
       "  0.9113887212189544,\n",
       "  -0.37377516359391055,\n",
       "  0.8607364760090191],\n",
       " [1.033584586393455,\n",
       "  0.8964803973496764,\n",
       "  -0.23471793646559888,\n",
       "  0.9123008097545073,\n",
       "  0.6037277911617462,\n",
       "  1.2957508229711538,\n",
       "  1.6977920256706749,\n",
       "  -0.950275909916356,\n",
       "  1785801600.0,\n",
       "  1.3955522531897622,\n",
       "  0.8865697607418623,\n",
       "  1.623285591581729,\n",
       "  -0.039403161705109574],\n",
       " [1.301665815395466,\n",
       "  -0.2754263805814534,\n",
       "  -0.82648665690056,\n",
       "  0.34488607552568235,\n",
       "  1.3488850377973318,\n",
       "  1.348718126988214,\n",
       "  1.5734713271794567,\n",
       "  0.5532797864483848,\n",
       "  1755993600.0,\n",
       "  0.5678778988839334,\n",
       "  0.49511357157035596,\n",
       "  -1.4193889557197334,\n",
       "  -1.5953797129440321],\n",
       " [1.6876734703953837,\n",
       "  -1.2235538017935674,\n",
       "  -0.47820517096506593,\n",
       "  -1.5757174257298168,\n",
       "  -1.0793267807637366,\n",
       "  -1.1159060868960502,\n",
       "  -0.08761490944675239,\n",
       "  -1.5572002118691675,\n",
       "  1765065600.0,\n",
       "  -0.5842158685264737,\n",
       "  -0.3264564398770768,\n",
       "  -0.16411874080842576,\n",
       "  -1.3273735446425672],\n",
       " [-1.5669642657811398,\n",
       "  -1.506899907424032,\n",
       "  -1.683100574416668,\n",
       "  0.7954600286109474,\n",
       "  0.5147620067212056,\n",
       "  -1.2446083086938098,\n",
       "  0.10540313754119819,\n",
       "  1.154322402836313,\n",
       "  1792454400.0,\n",
       "  -0.5125717360067805,\n",
       "  -0.8686799080679866,\n",
       "  -0.41102149995426457,\n",
       "  -0.3515508367914683],\n",
       " [-1.3593803787537613,\n",
       "  1.0859547202973412,\n",
       "  -0.3462912250116762,\n",
       "  0.7200212821976915,\n",
       "  0.24622476186177158,\n",
       "  0.2742578444415935,\n",
       "  -1.2180876897838413,\n",
       "  -1.548820547453664,\n",
       "  1750118400.0,\n",
       "  0.7156028215026176,\n",
       "  0.7847456505943843,\n",
       "  1.2688491294145379,\n",
       "  -0.24506841694009643],\n",
       " [-1.2509147770224074,\n",
       "  -0.5984951428869292,\n",
       "  -0.6908257202199576,\n",
       "  -1.1791650881910682,\n",
       "  0.9011083778784046,\n",
       "  0.8359357597098506,\n",
       "  -0.6656213893127712,\n",
       "  -1.1448508727930984,\n",
       "  1760745600.0,\n",
       "  -1.5108185238687335,\n",
       "  0.9169962129125292,\n",
       "  -1.391295886680461,\n",
       "  -1.5745763454918107],\n",
       " [0.3879143583409866,\n",
       "  0.06874298804285454,\n",
       "  0.1000089423547001,\n",
       "  0.8276625531864774,\n",
       "  1.6206844700247514,\n",
       "  -0.4642062578499061,\n",
       "  -0.860171563830931,\n",
       "  0.7027410492788669,\n",
       "  1788739200.0,\n",
       "  -0.34990453599488675,\n",
       "  1.5751177268503214,\n",
       "  -0.6473752683398504,\n",
       "  0.06982740300529569],\n",
       " [0.2817027915111815,\n",
       "  -1.3197004687303144,\n",
       "  0.3192867787661949,\n",
       "  0.8496745810600341,\n",
       "  0.1494082271407925,\n",
       "  1.1804937017927062,\n",
       "  -1.5607628462802647,\n",
       "  -0.9463425329153574,\n",
       "  1773792000.0,\n",
       "  0.9104872835856266,\n",
       "  -0.9398329820668703,\n",
       "  -1.7041779021837247,\n",
       "  1.5642043614719159],\n",
       " [0.9103086555879369,\n",
       "  0.24146017197246245,\n",
       "  0.07548176006663546,\n",
       "  -0.9365119536590257,\n",
       "  -0.4839500947216188,\n",
       "  0.4438585308811323,\n",
       "  1.2146687885527971,\n",
       "  -1.2044135229592687,\n",
       "  1778803200.0,\n",
       "  -1.283378332106043,\n",
       "  -1.2470556698011293,\n",
       "  -0.7703253138089241,\n",
       "  -1.323030893996184],\n",
       " [1.2307873484515617,\n",
       "  -1.224268620351139,\n",
       "  -0.8517526695994033,\n",
       "  -1.2814932654439433,\n",
       "  -1.4091616314773965,\n",
       "  1.1490198358631112,\n",
       "  1.4584563793186904,\n",
       "  -1.1304360636153064,\n",
       "  1759968000.0,\n",
       "  0.31611461386369616,\n",
       "  -0.10834041506752146,\n",
       "  -1.1226271238102603,\n",
       "  -0.9406806607839271],\n",
       " [0.9071156766408959,\n",
       "  -0.9385658683605642,\n",
       "  -1.706167647585923,\n",
       "  1.5724618798766863,\n",
       "  1.2907658032397158,\n",
       "  0.7256319756742402,\n",
       "  0.4533965931243232,\n",
       "  1.4634568139875852,\n",
       "  1773964800.0,\n",
       "  -0.3241114425194022,\n",
       "  0.280765801176608,\n",
       "  1.2621367294202452,\n",
       "  0.7900383958691943],\n",
       " [-0.28462892156892994,\n",
       "  -0.08737008815312959,\n",
       "  -0.3835541469716021,\n",
       "  1.7279411884675917,\n",
       "  1.1629075648840337,\n",
       "  1.593054298259478,\n",
       "  1.7252756446753705,\n",
       "  -1.0255243459756846,\n",
       "  1745020800.0,\n",
       "  -0.36553092434246715,\n",
       "  0.9778510275150002,\n",
       "  -1.6824503313585748,\n",
       "  0.6995014465494575],\n",
       " [-0.10999106670150116,\n",
       "  -1.108023395087307,\n",
       "  -1.7089061729369037,\n",
       "  1.5207816629244455,\n",
       "  -0.8384221339080729,\n",
       "  1.6964873525012245,\n",
       "  -0.14378538799354088,\n",
       "  1.2468030074787542,\n",
       "  1745884800.0,\n",
       "  -1.1684417161994218,\n",
       "  -0.5744676096663694,\n",
       "  -0.3201339670916902,\n",
       "  -1.1202833210495082],\n",
       " [-0.041257123929390044,\n",
       "  -1.5891620901920724,\n",
       "  0.3312493303376143,\n",
       "  1.4078275659561457,\n",
       "  0.7649727644866059,\n",
       "  -0.7024900069958742,\n",
       "  0.7420859523006393,\n",
       "  0.9609609302339667,\n",
       "  1790035200.0,\n",
       "  0.6340679209929372,\n",
       "  -0.48847775236036745,\n",
       "  -1.3263957199783207,\n",
       "  0.47794061830556],\n",
       " [1.1568924287481166,\n",
       "  -0.06820963999019418,\n",
       "  -1.669225692401129,\n",
       "  -0.13067245359715704,\n",
       "  0.455922550683352,\n",
       "  -0.3504563582107515,\n",
       "  1.5717036221225962,\n",
       "  0.07800257571653872,\n",
       "  1783036800.0,\n",
       "  -0.3762866987656374,\n",
       "  -0.9325418647873268,\n",
       "  0.6410365810675008,\n",
       "  -0.7678129569097442],\n",
       " [-0.6523488888936682,\n",
       "  -1.5181805136639845,\n",
       "  1.6202464773923964,\n",
       "  0.3669050363834517,\n",
       "  1.41125375182741,\n",
       "  -0.46072085705060817,\n",
       "  1.380485520107655,\n",
       "  1.6588094332638925,\n",
       "  1795478400.0,\n",
       "  0.17689421650787318,\n",
       "  -0.44619055849508016,\n",
       "  -0.7149782034746499,\n",
       "  -1.5259421804469588],\n",
       " [1.5794276721108085,\n",
       "  0.7197778407219828,\n",
       "  0.37227296351267136,\n",
       "  1.3563915914882796,\n",
       "  -1.200416617820918,\n",
       "  0.048930102731775574,\n",
       "  0.458125655889728,\n",
       "  -0.666203147332618,\n",
       "  1743984000.0,\n",
       "  0.6901569268214036,\n",
       "  1.1158743355621525,\n",
       "  1.0229556870004202,\n",
       "  -0.5537326475989431],\n",
       " [-0.13627351484268294,\n",
       "  0.2325779685283609,\n",
       "  0.5327000328459046,\n",
       "  -1.0708854776266596,\n",
       "  1.2192735694100165,\n",
       "  -1.0276575111832342,\n",
       "  -1.7520539221835,\n",
       "  1.645120529773339,\n",
       "  1736640000.0,\n",
       "  0.844603151861018,\n",
       "  -1.0252711207041283,\n",
       "  0.3453094412494624,\n",
       "  -1.0178462083168909],\n",
       " [-0.7937758470476364,\n",
       "  0.7274541879378943,\n",
       "  0.8246536835717027,\n",
       "  -0.16061681262398128,\n",
       "  -1.5896076616423283,\n",
       "  0.1327277754580004,\n",
       "  -0.735421237919936,\n",
       "  1.5601771451647306,\n",
       "  1743724800.0,\n",
       "  -0.5687966994288438,\n",
       "  -1.4938855769670734,\n",
       "  -0.9992114297273207,\n",
       "  1.1615636619384655],\n",
       " [0.287927991841135,\n",
       "  -0.27477821856257306,\n",
       "  -1.4263469868100267,\n",
       "  -0.637179320644311,\n",
       "  0.30728085357355905,\n",
       "  1.5633574891064081,\n",
       "  0.8165147701090552,\n",
       "  1.480215609576909,\n",
       "  1781568000.0,\n",
       "  0.822273835278467,\n",
       "  0.5332470688390376,\n",
       "  -1.0064467983731429,\n",
       "  1.1398874877271647],\n",
       " [0.4859224182225201,\n",
       "  -0.40334711853254945,\n",
       "  1.0591254861338777,\n",
       "  -0.5129657086526033,\n",
       "  -0.05030044210601266,\n",
       "  -0.5817922631707171,\n",
       "  -0.17470867669461612,\n",
       "  -1.0107687662190492,\n",
       "  1788998400.0,\n",
       "  1.3380978924011602,\n",
       "  0.8863202806776206,\n",
       "  0.6645956924593032,\n",
       "  -1.4751543182710136],\n",
       " [-0.0043729897733146995,\n",
       "  -1.3472198351801283,\n",
       "  -0.7289630381969819,\n",
       "  1.3067477945962478,\n",
       "  0.20863558441090002,\n",
       "  -0.8599116202162818,\n",
       "  0.05382394499390745,\n",
       "  -0.8304910385653003,\n",
       "  1788480000.0,\n",
       "  0.10086545423931445,\n",
       "  0.52152840116378,\n",
       "  -0.44240429698324746,\n",
       "  0.2368367042400747],\n",
       " [1.3333115797505855,\n",
       "  1.455258994875773,\n",
       "  -0.7734438930954631,\n",
       "  0.7442193731481426,\n",
       "  1.1817998422445608,\n",
       "  -0.7552498426065754,\n",
       "  -1.4388769433104744,\n",
       "  1.2006960299459306,\n",
       "  1795046400.0,\n",
       "  0.6171444400353454,\n",
       "  0.36894107870568116,\n",
       "  0.5454489242076691,\n",
       "  -0.6293062568095218],\n",
       " [0.9283769494610599,\n",
       "  -1.184352135993452,\n",
       "  -1.8026333383234836,\n",
       "  0.6655024340736541,\n",
       "  -1.4988728724360836,\n",
       "  0.07805377031075673,\n",
       "  0.3175030532429916,\n",
       "  0.7714480598906197,\n",
       "  1767398400.0,\n",
       "  0.3477076774662476,\n",
       "  1.3508404729949706,\n",
       "  -0.47088265103261473,\n",
       "  1.3149078993928665],\n",
       " [-0.7975915721336677,\n",
       "  0.14035240825126566,\n",
       "  -1.1731312157849465,\n",
       "  0.12373978068979297,\n",
       "  -0.6224296664531519,\n",
       "  0.6932255476088494,\n",
       "  -1.186380750223558,\n",
       "  1.5313650735392572,\n",
       "  1790985600.0,\n",
       "  -0.2643588545748142,\n",
       "  1.6034900783793467,\n",
       "  1.1979130606991093,\n",
       "  -0.7936512035691158],\n",
       " [-0.06076072608566158,\n",
       "  -1.0989578136149392,\n",
       "  1.1485003321729172,\n",
       "  0.3042414744431376,\n",
       "  0.3357246476900596,\n",
       "  1.514280565882287,\n",
       "  -1.7332796542910895,\n",
       "  -0.638452131979663,\n",
       "  1748131200.0,\n",
       "  1.4473038211030178,\n",
       "  0.7527519781194566,\n",
       "  -1.7321670440211334,\n",
       "  -0.5777789684617664],\n",
       " [-1.5240489926604315,\n",
       "  -1.610703545430089,\n",
       "  0.738537205994702,\n",
       "  1.011422823056798,\n",
       "  1.725097746337331,\n",
       "  0.08281415776209401,\n",
       "  0.33392106337712435,\n",
       "  -0.4273250384112547,\n",
       "  1738454400.0,\n",
       "  1.0318224709775068,\n",
       "  1.4084786943173737,\n",
       "  1.5361264338740082,\n",
       "  -1.4664649151969653],\n",
       " [-1.4298407125067678,\n",
       "  -1.636121128050161,\n",
       "  1.0465132987356824,\n",
       "  -0.2851263338276376,\n",
       "  -1.4181527359109434,\n",
       "  -0.60190328024979,\n",
       "  0.02925906197063096,\n",
       "  -0.8721417711080761,\n",
       "  1739750400.0,\n",
       "  0.3103569816554167,\n",
       "  -0.36124384426024364,\n",
       "  1.731204700914113,\n",
       "  0.6024709646134024],\n",
       " [0.06649642288339461,\n",
       "  0.37476135152812834,\n",
       "  -0.7312983592680566,\n",
       "  -0.846787193504903,\n",
       "  -1.428255306421353,\n",
       "  -1.636201235348165,\n",
       "  1.049685505524454,\n",
       "  -0.28863361845623997,\n",
       "  1739664000.0,\n",
       "  -1.4162088916145557,\n",
       "  -0.6029561348398371,\n",
       "  0.030359276889733847,\n",
       "  -0.875076355698357],\n",
       " [-0.18134661980378686,\n",
       "  -0.36450727153113754,\n",
       "  -1.7689483797769057,\n",
       "  1.2105142407779055,\n",
       "  -0.5426389672174295,\n",
       "  1.0153062361352676,\n",
       "  0.455205856477576,\n",
       "  0.3443147865231362,\n",
       "  1742342400.0,\n",
       "  1.0827683478541938,\n",
       "  1.3638702158222589,\n",
       "  1.5745351910019614,\n",
       "  -0.7316489041261764],\n",
       " [-0.7855226749257997,\n",
       "  0.5598276448077941,\n",
       "  -0.08427773662348048,\n",
       "  1.5635399055661812,\n",
       "  1.1061620246096715,\n",
       "  -0.8784638643864102,\n",
       "  0.8980497800774999,\n",
       "  1.2815921337687073,\n",
       "  1750464000.0,\n",
       "  0.01743966217257253,\n",
       "  0.10690124274466117,\n",
       "  -1.5648876463637515,\n",
       "  0.2446650707682729],\n",
       " [1.2658443515210855,\n",
       "  1.4175842873884803,\n",
       "  0.04087345868726773,\n",
       "  0.48210214752645714,\n",
       "  -0.15696354760880862,\n",
       "  0.15575718377047948,\n",
       "  -0.5556564815242367,\n",
       "  0.3976935968875518,\n",
       "  1754179200.0,\n",
       "  -0.08922128623898529,\n",
       "  -1.4158633710231756,\n",
       "  -0.5658305811843806,\n",
       "  -0.7210408698818196],\n",
       " [0.20730677012786358,\n",
       "  -0.8598577967294974,\n",
       "  0.05135191854294081,\n",
       "  -0.8277793255009359,\n",
       "  0.09878557695985733,\n",
       "  0.5220546222811276,\n",
       "  -0.44341022503447364,\n",
       "  0.23935751703220168,\n",
       "  1788566400.0,\n",
       "  0.3913207876324247,\n",
       "  0.06798197444270598,\n",
       "  0.10363003101191506,\n",
       "  0.8202201127139093],\n",
       " [-0.21552387356525182,\n",
       "  -0.1906730285286385,\n",
       "  0.4800826810529645,\n",
       "  1.3778068239918266,\n",
       "  1.7165856608428514,\n",
       "  1.4428734045128433,\n",
       "  1.3486838837182795,\n",
       "  -0.44194498477952526,\n",
       "  1741737600.0,\n",
       "  0.7860094516270747,\n",
       "  -0.17282027655653953,\n",
       "  0.7754223555024348,\n",
       "  -0.3476178828454603],\n",
       " [-0.8796128980232881,\n",
       "  -1.3367528443983074,\n",
       "  -1.4099377757918443,\n",
       "  1.2826341634907217,\n",
       "  1.5075909953716615,\n",
       "  -1.3730456849952994,\n",
       "  -1.5960906210928658,\n",
       "  -0.4479775372347933,\n",
       "  1736985600.0,\n",
       "  0.6006235054438843,\n",
       "  -0.9302566963242414,\n",
       "  -0.6873665932524237,\n",
       "  0.7892318031183547],\n",
       " [-0.7205619897811503,\n",
       "  -0.4919417402537479,\n",
       "  1.1917007705181124,\n",
       "  -1.009589485991739,\n",
       "  0.19964879037090644,\n",
       "  -0.735408161162862,\n",
       "  0.9430663758637311,\n",
       "  1.2358873937385353,\n",
       "  1786060800.0,\n",
       "  0.16242083504199498,\n",
       "  1.139905009987384,\n",
       "  0.015032067197484827,\n",
       "  -0.6937235197742513],\n",
       " [-1.5990628579410733,\n",
       "  -1.4591431062579494,\n",
       "  0.8414714673008098,\n",
       "  0.22547486779130324,\n",
       "  -0.01671882882948671,\n",
       "  0.264577897745306,\n",
       "  0.7402186264740833,\n",
       "  1.215174166889093,\n",
       "  1792972800.0,\n",
       "  1.2810018087079305,\n",
       "  0.7050316967628741,\n",
       "  1.4510803074057952,\n",
       "  1.111719624227477],\n",
       " [-0.06475706144761223,\n",
       "  0.045494920888436007,\n",
       "  1.2520373041987336,\n",
       "  0.3224383306256206,\n",
       "  0.4030330341843059,\n",
       "  -1.7434372416368276,\n",
       "  -1.2188934314744568,\n",
       "  -1.3034448114290433,\n",
       "  1751414400.0,\n",
       "  0.3742127440703653,\n",
       "  1.3806105209490636,\n",
       "  0.6177649745668753,\n",
       "  -0.18979172108469683],\n",
       " [0.020445463157903458,\n",
       "  -0.0717914302638467,\n",
       "  0.19877417847470902,\n",
       "  0.4044143255287549,\n",
       "  0.031794259196021774,\n",
       "  0.03095378162607012,\n",
       "  0.7595998291300836,\n",
       "  -0.6251584807151221,\n",
       "  1782000000.0,\n",
       "  -1.6635297128696735,\n",
       "  -0.0429768561022338,\n",
       "  -0.29998477273427016,\n",
       "  -1.111588621483501],\n",
       " [-0.11706059775472635,\n",
       "  -1.467094947857628,\n",
       "  -1.661548352732682,\n",
       "  1.088449143861158,\n",
       "  -0.9555001986131684,\n",
       "  1.3173848555550607,\n",
       "  -0.14445964483654358,\n",
       "  -1.3351262853657442,\n",
       "  1766880000.0,\n",
       "  -1.6187100172018114,\n",
       "  -1.300037223237493,\n",
       "  -0.8454965271218462,\n",
       "  -0.100764432668663],\n",
       " [0.513481179467052,\n",
       "  -1.2445414600487086,\n",
       "  0.10289484627402333,\n",
       "  1.1599482794346543,\n",
       "  -0.514596607616184,\n",
       "  -0.8675026062054396,\n",
       "  -0.4120336869175571,\n",
       "  -0.34881106967670983,\n",
       "  1792540800.0,\n",
       "  0.26140065194703194,\n",
       "  0.03374782067503271,\n",
       "  -1.5079553391785663,\n",
       "  1.1468160398854617],\n",
       " [0.2508686681747791,\n",
       "  -0.44589072499644333,\n",
       "  0.7378103167609428,\n",
       "  0.9853291499093635,\n",
       "  1.0879098754226588,\n",
       "  0.7467519205107522,\n",
       "  -0.3611326878424628,\n",
       "  -0.5938426528483283,\n",
       "  1761177600.0,\n",
       "  -0.011198486669329922,\n",
       "  1.441525250296547,\n",
       "  -0.7064405005839722,\n",
       "  -0.08740058636838681],\n",
       " [-0.6443560974993147,\n",
       "  -0.25971394755574045,\n",
       "  -1.3131300489091475,\n",
       "  1.3128099193740461,\n",
       "  -1.3600512785023893,\n",
       "  0.8054182475293307,\n",
       "  -0.4079252141426824,\n",
       "  1.304331136334289,\n",
       "  1796083200.0,\n",
       "  -0.5868400096446185,\n",
       "  -1.3631478627909481,\n",
       "  -0.5577670760635647,\n",
       "  1.7372631542270291],\n",
       " [1.290707573049229,\n",
       "  1.368761199942167,\n",
       "  -0.49230244358314385,\n",
       "  0.30530928848062283,\n",
       "  -0.06338560632149572,\n",
       "  0.045471752102133965,\n",
       "  1.2553541145366747,\n",
       "  0.3180403088631744,\n",
       "  1751328000.0,\n",
       "  0.405140195163335,\n",
       "  -1.7450249650088245,\n",
       "  -1.2180421948420228,\n",
       "  -1.3065399548576853],\n",
       " [-0.7621240012163831,\n",
       "  0.08808365187142013,\n",
       "  0.6506315799293518,\n",
       "  1.3210093247515147,\n",
       "  1.1580724134979299,\n",
       "  -0.06823665874478965,\n",
       "  -1.6679642380612076,\n",
       "  -0.13440617964777887,\n",
       "  1782950400.0,\n",
       "  0.4580344545834619,\n",
       "  -0.35139139667489666,\n",
       "  1.573111519961763,\n",
       "  0.07542169619749471],\n",
       " [-0.6856713041012317,\n",
       "  1.4037508952689992,\n",
       "  -1.5232743050958806,\n",
       "  -0.3668242679442138,\n",
       "  0.49582249784089494,\n",
       "  -0.7854981944506033,\n",
       "  0.03539320695953889,\n",
       "  -0.8518352628153066,\n",
       "  1774310400.0,\n",
       "  1.2555588641900262,\n",
       "  -0.03631221865852585,\n",
       "  -0.18694560844107833,\n",
       "  -0.43818658464977095],\n",
       " [-0.7837801336452163,\n",
       "  -1.0130964527076955,\n",
       "  -0.90912484568324,\n",
       "  0.19311941585397774,\n",
       "  -1.4180577417510571,\n",
       "  0.9784049356178752,\n",
       "  1.101305558174622,\n",
       "  0.46108609519950916,\n",
       "  1743206400.0,\n",
       "  0.4512080827535706,\n",
       "  1.1484705288510675,\n",
       "  -0.1513071923168068,\n",
       "  -0.1348677489496725],\n",
       " [0.6743085098056106,\n",
       "  -1.5197118175712627,\n",
       "  -1.7769464503703076,\n",
       "  -1.1685860631698084,\n",
       "  -1.0144356390717801,\n",
       "  -0.6971995168783414,\n",
       "  0.434827853013317,\n",
       "  1.2408294602433343,\n",
       "  1791331200.0,\n",
       "  -0.40967260921286436,\n",
       "  -0.619731641637881,\n",
       "  1.594298644882192,\n",
       "  -1.0041636252299404],\n",
       " [1.0476049975966988,\n",
       "  -0.06860411338976832,\n",
       "  1.3977962613848198,\n",
       "  0.031382061685050616,\n",
       "  0.6488061410620326,\n",
       "  0.33151843370550627,\n",
       "  0.500056858429743,\n",
       "  -1.3373559343595165,\n",
       "  1766620800.0,\n",
       "  -0.33072808622517047,\n",
       "  1.2896519391389978,\n",
       "  0.6729510579300891,\n",
       "  -0.6785709771941202],\n",
       " [0.8546579798771318,\n",
       "  1.0141739382538841,\n",
       "  -0.1024774970158972,\n",
       "  -1.4170827845284153,\n",
       "  0.8355620560971804,\n",
       "  -1.2119570005787046,\n",
       "  -0.6060228718118258,\n",
       "  -1.1719665989171173,\n",
       "  1778630400.0,\n",
       "  0.9136800483825566,\n",
       "  0.2407859363099507,\n",
       "  0.0790806957108986,\n",
       "  -0.9420237536791197],\n",
       " [0.7502043306113927,\n",
       "  1.3972889284995818,\n",
       "  0.3129369479485749,\n",
       "  1.1796890544839245,\n",
       "  1.1178909928968357,\n",
       "  -0.48904269037967185,\n",
       "  0.874442554284946,\n",
       "  1.7778026182430806,\n",
       "  1793923200.0,\n",
       "  0.517141042110271,\n",
       "  -0.2688456444443617,\n",
       "  1.521439112786646,\n",
       "  -1.4972126573223212],\n",
       " [-0.37906894046179646,\n",
       "  -0.047931168391845094,\n",
       "  1.11275230804331,\n",
       "  -0.7796822106591869,\n",
       "  -0.7454594025253753,\n",
       "  1.3381823559707888,\n",
       "  1.5414383362551105,\n",
       "  0.3669002367250381,\n",
       "  1742860800.0,\n",
       "  -1.4847366978875538,\n",
       "  1.680447989804607,\n",
       "  1.0037377006483081,\n",
       "  -1.1815629077228569],\n",
       " [1.2650209538500778,\n",
       "  1.4031143222615636,\n",
       "  -1.2532950665270322,\n",
       "  -1.457261262308396,\n",
       "  -1.044917288896143,\n",
       "  -1.04912159691799,\n",
       "  -0.1947192719602254,\n",
       "  0.7931373846853531,\n",
       "  1738022400.0,\n",
       "  1.76936460374831,\n",
       "  -0.5479132206058546,\n",
       "  -1.647800448745627,\n",
       "  1.4277710978485152],\n",
       " [-0.7967500419351775,\n",
       "  0.9579713860609428,\n",
       "  -1.775259407485226,\n",
       "  -0.06521290262636903,\n",
       "  0.42558503815632065,\n",
       "  -1.0064325407506762,\n",
       "  0.39864063158657986,\n",
       "  0.04122510990023709,\n",
       "  1737331200.0,\n",
       "  -1.4400504789621487,\n",
       "  1.1814364828755621,\n",
       "  -0.36134001346068995,\n",
       "  0.05726321222297825],\n",
       " [-0.21521266430305058,\n",
       "  -1.2494426471727011,\n",
       "  1.2159708811659802,\n",
       "  -1.490087326909413,\n",
       "  0.31521595258098206,\n",
       "  0.469702538844784,\n",
       "  0.9009747812154205,\n",
       "  0.6313359567401379,\n",
       "  1768867200.0,\n",
       "  0.07037530741465942,\n",
       "  -0.5922281484193778,\n",
       "  -0.48934031824965407,\n",
       "  1.1974505035583458],\n",
       " [1.0867188923025786,\n",
       "  0.7467513451747586,\n",
       "  -0.36331296242060984,\n",
       "  -0.5907834854179033,\n",
       "  -0.01326831540224219,\n",
       "  1.4416206063196948,\n",
       "  -0.7073937698687042,\n",
       "  -0.08475911643893738,\n",
       "  1761264000.0,\n",
       "  -1.637671994092355,\n",
       "  -0.11249377299694506,\n",
       "  1.511494284057627,\n",
       "  -0.026415076260880473],\n",
       " [-0.7593980882871779,\n",
       "  -1.4025025297687612,\n",
       "  -0.4650617884327803,\n",
       "  -0.09081278655991652,\n",
       "  -1.6934365132662528,\n",
       "  -0.04066114811062337,\n",
       "  -0.912847521638952,\n",
       "  0.8179285316888252,\n",
       "  1759795200.0,\n",
       "  1.2341372470400576,\n",
       "  -1.22567927910045,\n",
       "  -0.8489912144324531,\n",
       "  -1.2866275320208913],\n",
       " [-0.5355382704393917,\n",
       "  -0.044935059979355776,\n",
       "  0.20613031497648768,\n",
       "  0.7337244267270103,\n",
       "  0.6684125416755761,\n",
       "  -0.3875160859023318,\n",
       "  0.1855782574410479,\n",
       "  0.5410871837786894,\n",
       "  1792281600.0,\n",
       "  -1.5634267246091635,\n",
       "  -1.5084525680265797,\n",
       "  -1.6810899947757592,\n",
       "  0.7880528292646829],\n",
       " [1.178088041002273,\n",
       "  1.0458303230367352,\n",
       "  0.9015571352934973,\n",
       "  -0.9137113182730119,\n",
       "  -1.385573734921302,\n",
       "  1.5144188106976069,\n",
       "  -1.0404888077939975,\n",
       "  0.012416580942897349,\n",
       "  1763164800.0,\n",
       "  0.2806871005612161,\n",
       "  1.531259122342694,\n",
       "  -0.6153668051006933,\n",
       "  1.129940563339102],\n",
       " [-0.38835678715790306,\n",
       "  0.6359249992808793,\n",
       "  -1.5227415111520843,\n",
       "  -0.6498141303830269,\n",
       "  0.13481287736994013,\n",
       "  -0.04626841286563985,\n",
       "  0.37674630326340725,\n",
       "  -0.8619372754956012,\n",
       "  1792800000.0,\n",
       "  -1.5955231639465488,\n",
       "  -1.4606717725096225,\n",
       "  0.8457622467820864,\n",
       "  0.21869143690134413],\n",
       " [-0.18715657462274723,\n",
       "  -0.08913009889549055,\n",
       "  1.6885160340140548,\n",
       "  -0.5093352028111948,\n",
       "  1.085669697480182,\n",
       "  -1.4466859266600165,\n",
       "  -1.148061772007437,\n",
       "  -1.5541293340489424,\n",
       "  1747872000.0,\n",
       "  1.6041332207292724,\n",
       "  0.1869444486852602,\n",
       "  0.19911382343177728,\n",
       "  1.0256160936603362],\n",
       " [-0.5537498489423636,\n",
       "  -1.1196435207761664,\n",
       "  0.46377134442665596,\n",
       "  1.3927988446625148,\n",
       "  -0.9825519489943931,\n",
       "  1.5966536414977568,\n",
       "  -1.5939473729013298,\n",
       "  -0.5731642018790291,\n",
       "  1777766400.0,\n",
       "  -0.4495864031457724,\n",
       "  -1.549606594660665,\n",
       "  0.5325486549166919,\n",
       "  1.3858824150099895],\n",
       " [-1.4530850524791858,\n",
       "  -0.03136537412542245,\n",
       "  -1.3804058108900201,\n",
       "  -0.8269696322865228,\n",
       "  0.5060320787984621,\n",
       "  -1.1902067736955766,\n",
       "  -0.4249076348436605,\n",
       "  -0.10565993787930078,\n",
       "  1777593600.0,\n",
       "  -0.5502802631134662,\n",
       "  -1.1210016129530056,\n",
       "  0.4677209842035973,\n",
       "  1.3847379421380062],\n",
       " [1.3567574754103704,\n",
       "  0.7729209728399843,\n",
       "  0.4339468991678935,\n",
       "  -0.3772848270099391,\n",
       "  0.6727351365408272,\n",
       "  1.478714265532248,\n",
       "  -0.33657678797375085,\n",
       "  -0.7511796186816166,\n",
       "  1738886400.0,\n",
       "  1.705774100916426,\n",
       "  -0.8412776439730615,\n",
       "  0.6179929885813086,\n",
       "  -1.1571348221300255],\n",
       " [-1.5879292262408278,\n",
       "  0.5831929866479989,\n",
       "  -0.5200826030327532,\n",
       "  1.678352409529843,\n",
       "  1.4677267035894288,\n",
       "  -0.6500786977368797,\n",
       "  1.2487570145379696,\n",
       "  0.3212949548971559,\n",
       "  1790812800.0,\n",
       "  -0.794105632068509,\n",
       "  0.13962737322406318,\n",
       "  -1.1706600305321044,\n",
       "  0.11706768451974506],\n",
       " [0.8068651576535196,\n",
       "  1.6488567893615464,\n",
       "  0.25487988169233144,\n",
       "  0.9983064937735578,\n",
       "  -0.3129007694663047,\n",
       "  -1.5936492810521892,\n",
       "  -0.9231883467302259,\n",
       "  -0.10612252973580288,\n",
       "  1758240000.0,\n",
       "  -1.460067859356687,\n",
       "  1.0028034307557814,\n",
       "  -0.7934943953161047,\n",
       "  0.685055640097116],\n",
       " [0.8412271258328232,\n",
       "  -1.023961102047112,\n",
       "  0.3414702641169577,\n",
       "  -1.012417476197285,\n",
       "  0.4289731879927007,\n",
       "  0.6772247792346283,\n",
       "  1.263803395149175,\n",
       "  -0.062457446281492156,\n",
       "  1736812800.0,\n",
       "  -0.8761214568645327,\n",
       "  -1.3382200183637505,\n",
       "  -1.4076804748217255,\n",
       "  1.2746938206892329],\n",
       " [1.618208034238876,\n",
       "  1.398972660989347,\n",
       "  1.2173278158639895,\n",
       "  1.3723447025423507,\n",
       "  1.266183991505363,\n",
       "  1.4031371216546333,\n",
       "  -1.2517409697555169,\n",
       "  -1.4590501058100565,\n",
       "  1737936000.0,\n",
       "  -1.0429399743321683,\n",
       "  -1.0503839968429927,\n",
       "  -0.19366373566983647,\n",
       "  0.7908227245143435],\n",
       " [0.06694735116631353,\n",
       "  -0.5911355933878301,\n",
       "  -0.49242631788445135,\n",
       "  1.205306221822005,\n",
       "  0.11411222817399308,\n",
       "  1.2823276687645724,\n",
       "  0.3957351631246367,\n",
       "  1.0746680507905548,\n",
       "  1769040000.0,\n",
       "  1.2078626593923896,\n",
       "  0.9029833086061749,\n",
       "  -0.6859140979528673,\n",
       "  -0.41047782036974634],\n",
       " [0.22641729529222723,\n",
       "  0.031133069525089336,\n",
       "  -1.1549204731482434,\n",
       "  -0.6025227284586904,\n",
       "  -1.7241814901016856,\n",
       "  -0.7558115916965841,\n",
       "  1.377350992616547,\n",
       "  0.6004760285577213,\n",
       "  1755129600.0,\n",
       "  1.5962288337845338,\n",
       "  1.3898150088464176,\n",
       "  0.27663843513527403,\n",
       "  -0.08164003607014382],\n",
       " [-0.8381362401352523,\n",
       "  0.19575621094382387,\n",
       "  -0.19782415228660885,\n",
       "  1.2026404186505437,\n",
       "  -0.7606432470552729,\n",
       "  0.0880619251140277,\n",
       "  0.6535252503911301,\n",
       "  1.315147320112369,\n",
       "  1782864000.0,\n",
       "  1.1602472833997486,\n",
       "  -0.06903946241610204,\n",
       "  -1.667202580931762,\n",
       "  -0.13706613141957957],\n",
       " [-0.629572858740697,\n",
       "  1.0514026304241686,\n",
       "  -1.5820741270612806,\n",
       "  0.7864393636698798,\n",
       "  1.3344639141461025,\n",
       "  1.4552835598562095,\n",
       "  -0.7715521803720059,\n",
       "  0.739202987516125,\n",
       "  1794960000.0,\n",
       "  1.1839768399276385,\n",
       "  -0.7563745481373726,\n",
       "  -1.4380695884297974,\n",
       "  1.1985330894164017],\n",
       " [-0.9124003510344515,\n",
       "  1.5092477468259966,\n",
       "  1.167649236114052,\n",
       "  -0.2705126381185812,\n",
       "  -0.11785199902157883,\n",
       "  -0.8516136170557703,\n",
       "  0.8278952363044224,\n",
       "  -0.3019998884847475,\n",
       "  1764892800.0,\n",
       "  1.6909927260590962,\n",
       "  -1.2249641013980685,\n",
       "  -0.4751063267544754,\n",
       "  -1.5805297054150265],\n",
       " [-1.4196415493111743,\n",
       "  0.9783965169151808,\n",
       "  1.0980970578413112,\n",
       "  0.46569414114132407,\n",
       "  0.44909679096039273,\n",
       "  1.148703132137921,\n",
       "  -0.15237117609771225,\n",
       "  -0.1322086152532235,\n",
       "  1743292800.0,\n",
       "  -1.5732080970675983,\n",
       "  -0.6509794067157468,\n",
       "  1.4408663791643415,\n",
       "  -0.7583015154048781],\n",
       " [-0.11923199205938526,\n",
       "  -0.8515600745248874,\n",
       "  0.8248789680434333,\n",
       "  -0.2985122286208156,\n",
       "  1.6887702652887002,\n",
       "  -1.223619939809137,\n",
       "  -0.4761057327889246,\n",
       "  -1.5773326032669053,\n",
       "  1764979200.0,\n",
       "  -1.0773525519058746,\n",
       "  -1.1171997788719388,\n",
       "  -0.0865380082503817,\n",
       "  -1.5603898194413781],\n",
       " [0.5044222125223915,\n",
       "  1.4463395100654204,\n",
       "  0.4817162006924269,\n",
       "  0.2795991222335221,\n",
       "  -0.679842999422034,\n",
       "  0.9621206869215184,\n",
       "  -0.5949597808928617,\n",
       "  -0.22349462371475703,\n",
       "  1757376000.0,\n",
       "  -0.7657793321884866,\n",
       "  0.8404596749731122,\n",
       "  0.760696448427706,\n",
       "  0.18415945706902817],\n",
       " [0.19831856735764047,\n",
       "  -0.7353585531458587,\n",
       "  0.9399691319223883,\n",
       "  1.2416330265402447,\n",
       "  0.16033543821624965,\n",
       "  1.1401416247913374,\n",
       "  0.013934909101443271,\n",
       "  -0.6908564212957217,\n",
       "  1786147200.0,\n",
       "  1.1799702452599636,\n",
       "  0.020364472677178766,\n",
       "  1.1480913687244108,\n",
       "  0.6121891163719608],\n",
       " [0.6048550853557896,\n",
       "  0.3843712957529862,\n",
       "  1.1842214628000034,\n",
       "  1.2286521795166505,\n",
       "  0.013903813704523335,\n",
       "  -1.606675698467915,\n",
       "  1.1391189638199273,\n",
       "  -0.6258480449557052,\n",
       "  1789430400.0,\n",
       "  -0.13543907145015316,\n",
       "  -1.1397067562372505,\n",
       "  0.834888167705121,\n",
       "  0.12008701507561666],\n",
       " [0.9988111896452392,\n",
       "  -0.6818555352430451,\n",
       "  -0.6736757638465303,\n",
       "  1.0068982821614776,\n",
       "  0.07825011529709214,\n",
       "  0.9524108863900439,\n",
       "  0.646968193650599,\n",
       "  1.0044606630587338,\n",
       "  1753574400.0,\n",
       "  1.4695165545745321,\n",
       "  -0.6208250685827936,\n",
       "  -0.9476466793383402,\n",
       "  -1.4475796691198664],\n",
       " [-0.6908404012580142,\n",
       "  -0.6916020155458473,\n",
       "  1.4216494803179631,\n",
       "  0.8487236757722206,\n",
       "  -0.06427028456274268,\n",
       "  -0.4710186042224165,\n",
       "  1.633663366311212,\n",
       "  0.414975318788186,\n",
       "  1752969600.0,\n",
       "  -1.6736087224105831,\n",
       "  0.2048442334236818,\n",
       "  0.44204494976320596,\n",
       "  -1.1542771197046213],\n",
       " [0.13347249096467964,\n",
       "  -0.04624213791750044,\n",
       "  0.37404723332079554,\n",
       "  -0.8592717327538634,\n",
       "  -1.597450929495419,\n",
       "  -1.4592172211861902,\n",
       "  0.8444994097906892,\n",
       "  0.22121900201985817,\n",
       "  1792886400.0,\n",
       "  -0.014649309524868688,\n",
       "  0.26393103522201583,\n",
       "  0.7414606617998997,\n",
       "  1.213016616056904],\n",
       " [0.43387182242984135,\n",
       "  0.5505578233435654,\n",
       "  -1.5218077077000163,\n",
       "  -0.15305660576415953,\n",
       "  0.07643140018477891,\n",
       "  -1.3515035723320339,\n",
       "  -0.4312744371458203,\n",
       "  1.0259875804873029,\n",
       "  1764288000.0,\n",
       "  -0.7176597698213247,\n",
       "  1.7033132996878468,\n",
       "  0.49352991933386636,\n",
       "  -1.0787639997683296],\n",
       " [0.23800309189406493,\n",
       "  -0.8661720682920967,\n",
       "  -0.39783970285775844,\n",
       "  1.1169810412177925,\n",
       "  1.2911089909015525,\n",
       "  -1.3271485172373068,\n",
       "  -0.664865144576912,\n",
       "  -1.445262578299783,\n",
       "  1770422400.0,\n",
       "  1.480796235730297,\n",
       "  1.695572520453397,\n",
       "  1.6188502148623647,\n",
       "  0.3129527036977052],\n",
       " [-1.2019663089175776,\n",
       "  0.04895315442436245,\n",
       "  0.4553693689353643,\n",
       "  -0.6632502217836354,\n",
       "  0.6880242089694776,\n",
       "  1.116122204729433,\n",
       "  1.021657510961326,\n",
       "  -0.5509176433685989,\n",
       "  1744070400.0,\n",
       "  0.4415986266041528,\n",
       "  1.1321495385862257,\n",
       "  1.1757525430406501,\n",
       "  0.2219095442810564],\n",
       " [1.107363388762308,\n",
       "  -0.46611078375802006,\n",
       "  -0.44860403079296185,\n",
       "  1.1610391149371793,\n",
       "  1.4206533432407116,\n",
       "  -0.4523518367726872,\n",
       "  -0.6594041076418486,\n",
       "  -1.2568295249229742,\n",
       "  1785456000.0,\n",
       "  0.29376688830247605,\n",
       "  -0.2200239820860949,\n",
       "  -0.26941480292017633,\n",
       "  -1.2985031757698808],\n",
       " [-1.6412145151590962,\n",
       "  -0.11164212887544128,\n",
       "  1.5066027563172486,\n",
       "  -0.01990017378432673,\n",
       "  1.7162603105661025,\n",
       "  1.1611527792362677,\n",
       "  0.2234888843090871,\n",
       "  1.2256636690633302,\n",
       "  1761436800.0,\n",
       "  1.7350486971211487,\n",
       "  0.39757355691918217,\n",
       "  0.13090945554467817,\n",
       "  -1.5741038988711766],\n",
       " [-1.287438731761993,\n",
       "  -1.003701125670544,\n",
       "  0.982253564371819,\n",
       "  -1.1597021658258089,\n",
       "  -1.6378526859819744,\n",
       "  0.857999310432859,\n",
       "  -0.26662014389583816,\n",
       "  -1.3270366654434886,\n",
       "  1758931200.0,\n",
       "  0.013135692956444586,\n",
       "  -1.5962861589960824,\n",
       "  -0.41084455913092566,\n",
       "  0.9070171979370768],\n",
       " [0.11482045788832906,\n",
       "  0.5368955342276165,\n",
       "  -0.8393516010692453,\n",
       "  -1.285345077853515,\n",
       "  1.4045268302701084,\n",
       "  1.5096346901215907,\n",
       "  0.6156226945319163,\n",
       "  0.055753528736279874,\n",
       "  1771027200.0,\n",
       "  -1.3986587857209298,\n",
       "  -0.8956834943305969,\n",
       "  1.2722093213124308,\n",
       "  -1.0693191554679118],\n",
       " [-0.9804855168040055,\n",
       "  -0.9004519343856952,\n",
       "  0.12849095224340493,\n",
       "  -0.5178542709361204,\n",
       "  0.25083630398071344,\n",
       "  0.07797196598883117,\n",
       "  -0.42755277652676354,\n",
       "  -1.2773478252038484,\n",
       "  1751932800.0,\n",
       "  0.6427927079946462,\n",
       "  1.435453136953691,\n",
       "  0.5886752896745692,\n",
       "  -0.21335085358155242],\n",
       " [0.38837337762813223,\n",
       "  -1.738611161995323,\n",
       "  1.7377054217397194,\n",
       "  -1.3558171388662215,\n",
       "  -0.636835343099001,\n",
       "  -1.6618718623487185,\n",
       "  0.6654632847657777,\n",
       "  0.13256233303719625,\n",
       "  1793577600.0,\n",
       "  0.9581420757094514,\n",
       "  0.5570166088840488,\n",
       "  -0.3528040085298816,\n",
       "  -1.3459786265779694],\n",
       " [-1.5293841156737,\n",
       "  0.7724654749748663,\n",
       "  0.6118713177659657,\n",
       "  -1.2340682169515051,\n",
       "  -0.6281128794559592,\n",
       "  1.0514135210701172,\n",
       "  -1.580751354211945,\n",
       "  0.7813610802423705,\n",
       "  1794873600.0,\n",
       "  1.3366546021347991,\n",
       "  1.4551946056463787,\n",
       "  -0.7706117092439146,\n",
       "  0.7368682494802556],\n",
       " [0.24703784921039473,\n",
       "  0.21558919631824344,\n",
       "  0.3689520773611348,\n",
       "  0.5853543562887621,\n",
       "  -0.4101474222610981,\n",
       "  0.7422839089582731,\n",
       "  1.073542334861633,\n",
       "  1.007478662520429,\n",
       "  1749254400.0,\n",
       "  0.657956562065021,\n",
       "  0.6152973123418652,\n",
       "  0.5583380625347304,\n",
       "  0.5041956694980576],\n",
       " [1.0794082964142921,\n",
       "  1.363980465934235,\n",
       "  1.5695867759360849,\n",
       "  -0.7259066262463062,\n",
       "  -1.4723887824371242,\n",
       "  -0.8734158115375783,\n",
       "  -0.15789340888907016,\n",
       "  -1.028488066339535,\n",
       "  1742515200.0,\n",
       "  -1.4315297894527328,\n",
       "  -1.0339630454481463,\n",
       "  0.3721492201996092,\n",
       "  1.1614428215328694],\n",
       " [-0.5073139482383684,\n",
       "  1.325161648838401,\n",
       "  -0.46745772619083525,\n",
       "  1.6506261648053926,\n",
       "  -0.1435244309835319,\n",
       "  1.4281547883963852,\n",
       "  -0.8912272102660063,\n",
       "  -0.5404184263258276,\n",
       "  1764720000.0,\n",
       "  -0.9089067108518951,\n",
       "  1.5092104830536253,\n",
       "  1.1722346201794283,\n",
       "  -0.27675328056039317],\n",
       " [0.7826294955106321,\n",
       "  -0.17193833793537744,\n",
       "  0.7711950498587768,\n",
       "  -0.3414548766890848,\n",
       "  -1.5176785965257449,\n",
       "  -1.3951817054862437,\n",
       "  -1.0354942268095295,\n",
       "  0.4901491729638117,\n",
       "  1741910400.0,\n",
       "  -0.5375509502941961,\n",
       "  -0.8496471962843762,\n",
       "  -0.9574602147177665,\n",
       "  1.364845417798517],\n",
       " [-1.1227907406343034,\n",
       "  -0.6022321135211437,\n",
       "  -1.1411563023215514,\n",
       "  -0.35151499154073496,\n",
       "  1.5057516223341716,\n",
       "  0.8735417313686099,\n",
       "  -1.5938283101248916,\n",
       "  0.2634748216431955,\n",
       "  1787529600.0,\n",
       "  -1.5622968497796748,\n",
       "  -0.8124652220096531,\n",
       "  0.6255108307086318,\n",
       "  -0.5073719739819965],\n",
       " [0.2671523462861596,\n",
       "  -0.31341714841465806,\n",
       "  -1.3576890827654184,\n",
       "  -1.5464715391799213,\n",
       "  1.47656858890338,\n",
       "  -0.7484691478284725,\n",
       "  -0.7297895417415841,\n",
       "  -0.8633040650359396,\n",
       "  1752278400.0,\n",
       "  -1.6648811206760832,\n",
       "  0.49078710848413176,\n",
       "  0.5552644108067645,\n",
       "  0.3615654477504611],\n",
       " [-0.8437647332048717,\n",
       "  -0.8835239027980345,\n",
       "  0.7691707072335034,\n",
       "  -1.3619064556970961,\n",
       "  -1.4370306287687897,\n",
       "  -0.3831825343870281,\n",
       "  -0.36250069633364673,\n",
       "  0.6199492680819629,\n",
       "  1756425600.0,\n",
       "  -1.3134886606455325,\n",
       "  0.7424066317314073,\n",
       "  0.7790477818328753,\n",
       "  -0.2275347076501177],\n",
       " [0.38237557101398023,\n",
       "  -1.2510136745407663,\n",
       "  0.6413678918365496,\n",
       "  -0.5760576178224364,\n",
       "  -0.7922901320602984,\n",
       "  0.7274541098837077,\n",
       "  0.8276697933259806,\n",
       "  -0.1643066379112854,\n",
       "  1743638400.0,\n",
       "  -1.5876791927404514,\n",
       "  0.13201913420828315,\n",
       "  -0.7344735594832869,\n",
       "  1.5581480267159116],\n",
       " [-0.808886924840254,\n",
       "  0.7385046772181125,\n",
       "  0.20058205073127605,\n",
       "  -0.9289122203214186,\n",
       "  -0.7477288661524142,\n",
       "  -0.003200449274382074,\n",
       "  -1.0423174303725846,\n",
       "  1.4800410753637174,\n",
       "  1786838400.0,\n",
       "  -1.7212141401976209,\n",
       "  1.1197644235458826,\n",
       "  -1.1403937131679467,\n",
       "  -1.5380920841448418],\n",
       " [1.0369213348436461,\n",
       "  1.4696907572310278,\n",
       "  0.4001572908048851,\n",
       "  -0.8153514966751473,\n",
       "  0.08088117842946346,\n",
       "  -0.9679539799274832,\n",
       "  0.40514554338378556,\n",
       "  0.6984497803435186,\n",
       "  1746144000.0,\n",
       "  1.1032701216016192,\n",
       "  1.1637475402654196,\n",
       "  -1.1357115227403658,\n",
       "  -0.27858916081562535],\n",
       " [1.1515471944442002,\n",
       "  -1.588133350030139,\n",
       "  -0.6916157764078323,\n",
       "  -1.0892575132562063,\n",
       "  -0.4877705768318664,\n",
       "  0.09839744137990135,\n",
       "  -0.20262695384505627,\n",
       "  0.7554743157698182,\n",
       "  1746835200.0,\n",
       "  0.5632037013322632,\n",
       "  -1.510369418311815,\n",
       "  -0.6758327929904185,\n",
       "  -0.2629373908494304],\n",
       " [-0.5905535753556115,\n",
       "  -1.4320759177935363,\n",
       "  -0.8351962658990346,\n",
       "  1.4375647053499734,\n",
       "  -1.7217927215053963,\n",
       "  0.6822931949201158,\n",
       "  1.0744241725452452,\n",
       "  -1.2393784944269386,\n",
       "  1785283200.0,\n",
       "  1.1107215652803175,\n",
       "  -0.46714052283294866,\n",
       "  -0.4454784507578514,\n",
       "  1.1532318407854456],\n",
       " [-1.317009437581013,\n",
       "  0.74282896570744,\n",
       "  0.7748172046498674,\n",
       "  -0.2212401434045839,\n",
       "  1.2528886414245015,\n",
       "  -0.22066556278443,\n",
       "  -1.7682417000032031,\n",
       "  -1.2334922441673735,\n",
       "  1756598400.0,\n",
       "  0.29333125634305607,\n",
       "  1.2443725244037946,\n",
       "  -1.2690538237724382,\n",
       "  -0.007633920089350232],\n",
       " [0.3586667495643417,\n",
       "  -1.3788899118478775,\n",
       "  1.1358344818166823,\n",
       "  -0.9942422429824518,\n",
       "  0.7639483400278713,\n",
       "  -0.8758350778994999,\n",
       "  0.5630242183045249,\n",
       "  -1.0505212636147447,\n",
       "  1736035200.0,\n",
       "  0.9725789177002298,\n",
       "  -0.19307053398351015,\n",
       "  1.5048931958315113,\n",
       "  1.1976511562463645],\n",
       " [1.4101134546684402,\n",
       "  -0.4606805494662076,\n",
       "  1.377080731125598,\n",
       "  1.6651760130823803,\n",
       "  0.17480752188333423,\n",
       "  -0.44521112243345823,\n",
       "  -0.7159297700197695,\n",
       "  -1.522765391738059,\n",
       "  1795564800.0,\n",
       "  -1.3439242054369949,\n",
       "  -0.3483253872466015,\n",
       "  0.05585069678793326,\n",
       "  -0.8071685603056096],\n",
       " [-1.4722859216559085,\n",
       "  -1.3094013306320949,\n",
       "  0.12836636331451182,\n",
       "  0.8219007461032402,\n",
       "  -1.574633097411874,\n",
       "  0.594350654867512,\n",
       "  -1.0445875863689764,\n",
       "  0.265292296636174,\n",
       "  1781827200.0,\n",
       "  0.02387653824437572,\n",
       "  -0.07262305228123656,\n",
       "  0.20248447214248153,\n",
       "  0.39743507061214123],\n",
       " [-1.6605946365481277,\n",
       "  -1.068919431514355,\n",
       "  1.187024601850343,\n",
       "  0.9178729595946833,\n",
       "  0.38967381315625393,\n",
       "  -1.7386947395444587,\n",
       "  1.7413639407425758,\n",
       "  -1.3577547073564251,\n",
       "  1793491200.0,\n",
       "  -0.634821433372288,\n",
       "  -1.6634213680447243,\n",
       "  0.6666904080860534,\n",
       "  0.1300017641824363],\n",
       " [-0.2070275247513592,\n",
       "  -1.499123884663629,\n",
       "  1.110112387871322,\n",
       "  1.357760232700261,\n",
       "  -0.0030109987046213664,\n",
       "  -1.347290160453481,\n",
       "  -0.7270400294238302,\n",
       "  1.3009066984714348,\n",
       "  1788393600.0,\n",
       "  0.21072531260128544,\n",
       "  -0.8610853653020991,\n",
       "  0.05492906005343346,\n",
       "  -0.8334101180637808],\n",
       " [-1.4107440445224717,\n",
       "  1.1490056404377325,\n",
       "  1.4549967698026305,\n",
       "  -1.1281647389703098,\n",
       "  0.3140154356281805,\n",
       "  -0.10751920545418628,\n",
       "  -1.1234973898025964,\n",
       "  -0.9377216631237221,\n",
       "  1760054400.0,\n",
       "  -1.1442657023898233,\n",
       "  -1.5634409229834818,\n",
       "  -0.7636436871165587,\n",
       "  1.5890021499092948],\n",
       " [-1.1719527643195269,\n",
       "  -0.5733839735444789,\n",
       "  -0.3233726564202314,\n",
       "  -1.1149668147332932,\n",
       "  1.0381201227859296,\n",
       "  1.4697158108622894,\n",
       "  0.4028747313848961,\n",
       "  -0.8180814299048303,\n",
       "  1746057600.0,\n",
       "  0.0829594501138074,\n",
       "  -0.96917834854908,\n",
       "  0.4063207391827214,\n",
       "  0.6960998713327397],\n",
       " [0.0942518106755109,\n",
       "  -1.4392357742652186,\n",
       "  0.06427563136274474,\n",
       "  0.4207992789859555,\n",
       "  1.7522907931031382,\n",
       "  -0.9388300514436557,\n",
       "  1.5548030195759397,\n",
       "  0.8779285417089054,\n",
       "  1755734400.0,\n",
       "  0.28416943010004303,\n",
       "  -1.0907883213334522,\n",
       "  -1.5767769222097308,\n",
       "  0.4164711328199411],\n",
       " [-0.3567783989727321,\n",
       "  0.6932691453002405,\n",
       "  0.9083481195153796,\n",
       "  -1.63777887726016,\n",
       "  -0.78542828477328,\n",
       "  0.4406613477862415,\n",
       "  -0.5645917188706956,\n",
       "  -0.9541374789446725,\n",
       "  1772323200.0,\n",
       "  -0.7614977830982854,\n",
       "  -1.4618000292166373,\n",
       "  1.3723028938076003,\n",
       "  1.3444240404224654],\n",
       " [0.25981488946981757,\n",
       "  0.8239259913656358,\n",
       "  1.1152125620820674,\n",
       "  0.45527884790002926,\n",
       "  1.6870263949115951,\n",
       "  -1.6227734718118836,\n",
       "  -0.15716156882968085,\n",
       "  0.9965809308749934,\n",
       "  1763596800.0,\n",
       "  -1.4020796027440587,\n",
       "  -0.9097222849994169,\n",
       "  -0.6327583233075734,\n",
       "  -1.1286380994934486],\n",
       " [0.21310119054963422,\n",
       "  1.5887385164916568,\n",
       "  1.0429282241625335,\n",
       "  0.56636593346756,\n",
       "  -0.757917761361194,\n",
       "  -1.4025747268810245,\n",
       "  -0.4629531027735628,\n",
       "  -0.09460494998790733,\n",
       "  1759708800.0,\n",
       "  -1.6915173553220433,\n",
       "  -0.04145103120288735,\n",
       "  -0.9119352357463729,\n",
       "  0.8156231003833518],\n",
       " [0.030437724046172506,\n",
       "  0.030977441965508837,\n",
       "  0.7566315786892023,\n",
       "  -0.6221452921367656,\n",
       "  -1.6654513804090798,\n",
       "  -0.04218625841546919,\n",
       "  -0.30101910460425063,\n",
       "  -1.108566024521547,\n",
       "  1782086400.0,\n",
       "  0.029801495204609993,\n",
       "  -0.921852792716629,\n",
       "  -0.6310059131601501,\n",
       "  0.9072646280928442],\n",
       " [-0.9124410059906354,\n",
       "  1.3445680998223712,\n",
       "  -0.2896079775418675,\n",
       "  1.7334903348880877,\n",
       "  0.13478885991837208,\n",
       "  1.5225730749117785,\n",
       "  -0.5245088984332518,\n",
       "  -1.599022048112736,\n",
       "  1748476800.0,\n",
       "  -0.06359050181310218,\n",
       "  1.4351044540373692,\n",
       "  -1.5734228211147445,\n",
       "  0.6410990041375257],\n",
       " [0.31390384536676746,\n",
       "  0.46971134391721575,\n",
       "  0.8979071314547628,\n",
       "  0.6361939687129244,\n",
       "  0.06829816412489642,\n",
       "  -0.5911803181018421,\n",
       "  -0.49033688548993715,\n",
       "  1.1996138469462574,\n",
       "  1768953600.0,\n",
       "  0.1161934798864561,\n",
       "  1.282157675610717,\n",
       "  0.396908481764839,\n",
       "  1.0724581945102833],\n",
       " [-1.6840692470657503,\n",
       "  -0.7258371238536176,\n",
       "  0.4441488960941707,\n",
       "  -1.0639781345510397,\n",
       "  -0.18850112460508545,\n",
       "  -1.296163563805479,\n",
       "  -0.636494509456599,\n",
       "  0.8813589462794547,\n",
       "  1782518400.0,\n",
       "  0.2836622550996986,\n",
       "  -1.0951942035764333,\n",
       "  1.1144539395813993,\n",
       "  0.7517322756501881],\n",
       " [-0.07342455959294979,\n",
       "  -0.37928644582070054,\n",
       "  -0.0974357976231216,\n",
       "  -0.217903552994376,\n",
       "  -0.14089760008589483,\n",
       "  1.6445988708902348,\n",
       "  -0.7894038595736269,\n",
       "  -1.3755864227896202,\n",
       "  1790380800.0,\n",
       "  0.3413179657521183,\n",
       "  -0.8022114128185428,\n",
       "  -0.3460324614440967,\n",
       "  -0.7773794279539763],\n",
       " [-0.2520884770091631,\n",
       "  -0.572861920494686,\n",
       "  0.6221456399428376,\n",
       "  -1.654965665629621,\n",
       "  -0.33483498999201766,\n",
       "  -0.6250478138281099,\n",
       "  -1.3146914825294824,\n",
       "  -0.06535418131365581,\n",
       "  1787961600.0,\n",
       "  1.5599973721166995,\n",
       "  -0.2498261753689484,\n",
       "  -1.5357449159434342,\n",
       "  -1.5298280602355019],\n",
       " [1.4201317045176671,\n",
       "  -0.12507371917352952,\n",
       "  -0.19565165967799933,\n",
       "  -0.1679750072715238,\n",
       "  -0.8139786819042975,\n",
       "  -1.2752204143636785,\n",
       "  -0.4506179734535896,\n",
       "  -1.444363940986182,\n",
       "  1759190400.0,\n",
       "  1.734544722498729,\n",
       "  -1.3857865133019451,\n",
       "  -1.2768963787746133,\n",
       "  -0.8336503732195262],\n",
       " [-0.8655396069828167,\n",
       "  -1.43799196031714,\n",
       "  -1.5424755728283503,\n",
       "  -1.0086383780536685,\n",
       "  -0.9543729679041285,\n",
       "  1.5908627590257947,\n",
       "  0.5155059810852622,\n",
       "  -1.3380706067585355,\n",
       "  1776124800.0,\n",
       "  0.5278362499755221,\n",
       "  0.448441037392261,\n",
       "  1.3647031981829052,\n",
       "  1.6900180739912802],\n",
       " [-0.7143819799204243,\n",
       "  0.5931574547848542,\n",
       "  0.48082107171239674,\n",
       "  0.45015398471905116,\n",
       "  -1.6033065990610094,\n",
       "  1.6797679304984705,\n",
       "  -0.0798932846949299,\n",
       "  -1.634007971415299,\n",
       "  1740009600.0,\n",
       "  -0.9538870519409256,\n",
       "  -0.4095623560144824,\n",
       "  1.1951340280852567,\n",
       "  -1.482873734515826],\n",
       " [1.2462237450028575,\n",
       "  -1.0722964565680022,\n",
       "  -0.03650709304018862,\n",
       "  1.1289366325303365,\n",
       "  -1.0420661138862597,\n",
       "  0.9446599632673439,\n",
       "  1.5839877047569206,\n",
       "  0.8591106042796394,\n",
       "  1758585600.0,\n",
       "  -1.154595742547231,\n",
       "  -1.132304497457606,\n",
       "  1.0787416201252247,\n",
       "  0.44151668962416435],\n",
       " [1.5314708885798922,\n",
       "  -0.03163728732923366,\n",
       "  -1.0490499098253974,\n",
       "  0.6646466579215363,\n",
       "  -0.6893708194485627,\n",
       "  -0.6916501419927088,\n",
       "  1.4250856271907966,\n",
       "  0.8435540786905585,\n",
       "  1752883200.0,\n",
       "  -0.0622050294831876,\n",
       "  -0.4720101324484563,\n",
       "  1.6350836237226518,\n",
       "  0.4125198822805027],\n",
       " [-1.3616259932249581,\n",
       "  0.8054156858539165,\n",
       "  -0.41007258936195257,\n",
       "  1.3101772603230497,\n",
       "  -0.588858221768389,\n",
       "  -1.361738985154972,\n",
       "  -0.5587499964303791,\n",
       "  1.739225619273656,\n",
       "  1796169600.0,\n",
       "  -0.67741208559489,\n",
       "  -0.33974693556121877,\n",
       "  -0.1985508345293595,\n",
       "  0.7655899758210497],\n",
       " [0.15899905261515124,\n",
       "  1.140127729966687,\n",
       "  0.011490928234052544,\n",
       "  -0.6879396924342854,\n",
       "  1.1777936068401127,\n",
       "  0.02112540551496372,\n",
       "  1.1467682359159261,\n",
       "  0.6145702507592692,\n",
       "  1786233600.0,\n",
       "  1.1034637209664835,\n",
       "  -1.2293658104844056,\n",
       "  -0.5392779396462338,\n",
       "  0.3284493323700137],\n",
       " [0.7382551075813673,\n",
       "  1.2857589643261123,\n",
       "  0.47883158736969333,\n",
       "  0.4220264395544795,\n",
       "  -0.6109824631864437,\n",
       "  1.207286922830208,\n",
       "  -1.4883800369292761,\n",
       "  -1.3172135904896034,\n",
       "  1745280000.0,\n",
       "  -0.024364717074342533,\n",
       "  -0.29593274653222273,\n",
       "  -0.39151670756695744,\n",
       "  0.8980015453394248],\n",
       " [1.1766167134976577,\n",
       "  0.02114939862606042,\n",
       "  1.1435277712270058,\n",
       "  0.6194036468120042,\n",
       "  1.1012939427316673,\n",
       "  -1.2280195874288484,\n",
       "  -0.5402645474434233,\n",
       "  0.3309360537180875,\n",
       "  1786320000.0,\n",
       "  1.542866325296409,\n",
       "  0.661958237934884,\n",
       "  1.6307403787646044,\n",
       "  0.6043993736392668],\n",
       " [-1.5822519134856359,\n",
       "  -0.6645471855003606,\n",
       "  -1.6366487761499378,\n",
       "  -0.8976681814174524,\n",
       "  -1.5739492257021486,\n",
       "  -0.13427662038219706,\n",
       "  1.2316508411252434,\n",
       "  -0.9518349502319464,\n",
       "  1780876800.0,\n",
       "  0.5246892966588295,\n",
       "  -0.21622139355284614,\n",
       "  0.07721426480570313,\n",
       "  -1.4155358828024944],\n",
       " [0.6137531575408983,\n",
       "  0.3695509579794013,\n",
       "  0.5414291437103981,\n",
       "  -0.6234518566186077,\n",
       "  -1.0658305414007676,\n",
       "  0.6261199343055706,\n",
       "  -1.1742031500155243,\n",
       "  -1.5627754540375929,\n",
       "  1795219200.0,\n",
       "  1.0125945592647032,\n",
       "  0.7572695030146276,\n",
       "  0.3143622398770997,\n",
       "  -0.7544913827876907],\n",
       " [0.07591554260189219,\n",
       "  0.652710308633002,\n",
       "  -0.24638734344341467,\n",
       "  -0.06990637202983302,\n",
       "  -0.7621063095053189,\n",
       "  -0.5281852170132882,\n",
       "  -1.6910947747229301,\n",
       "  -1.0064494885916906,\n",
       "  1744675200.0,\n",
       "  0.40110115862271534,\n",
       "  0.5197413010904821,\n",
       "  0.7025659134798646,\n",
       "  -0.25858382055565743],\n",
       " [1.159970958744332,\n",
       "  -1.2336183015447308,\n",
       "  0.3991164395725679,\n",
       "  1.6812468284961697,\n",
       "  -0.9650269860871292,\n",
       "  0.7533407955446566,\n",
       "  1.1534474484433903,\n",
       "  1.6803447048417284,\n",
       "  1766275200.0,\n",
       "  0.37825486147685805,\n",
       "  -0.3584003753042839,\n",
       "  -0.8325720260493489,\n",
       "  0.6286760422238569],\n",
       " [-0.04399917203718014,\n",
       "  -1.3195688399242336,\n",
       "  -0.027428069066408753,\n",
       "  -0.988222137607091,\n",
       "  0.893600317946936,\n",
       "  -1.7457406598100076,\n",
       "  -0.3174021886461277,\n",
       "  1.2536510102195688,\n",
       "  1789776000.0,\n",
       "  -1.3238949094792924,\n",
       "  0.41778426926384776,\n",
       "  1.1153086265628451,\n",
       "  -0.6563936509756548],\n",
       " [-0.144908448318636,\n",
       "  1.4281311419487925,\n",
       "  -0.8930347806687041,\n",
       "  -0.5372808198192077,\n",
       "  -0.9108960439070607,\n",
       "  1.509274139833221,\n",
       "  1.1709066722970125,\n",
       "  -0.2740413475636555,\n",
       "  1764806400.0,\n",
       "  -0.11579154893665931,\n",
       "  -0.852783474090077,\n",
       "  0.8291547611374994,\n",
       "  -0.304722229455538],\n",
       " [0.4017346927887994,\n",
       "  -1.7433535035148497,\n",
       "  -1.2204706230227578,\n",
       "  -1.301427503495855,\n",
       "  0.37210835629321815,\n",
       "  1.3807344053640458,\n",
       "  0.6165476088212964,\n",
       "  -0.187112148748276,\n",
       "  1751500800.0,\n",
       "  1.370409086205462,\n",
       "  0.1949734617809314,\n",
       "  -0.5088521332759481,\n",
       "  -0.21279462648626268],\n",
       " [-1.5484227200309686,\n",
       "  -0.4298005317687038,\n",
       "  0.07100631579908685,\n",
       "  0.1722321923140424,\n",
       "  -0.06511568290399326,\n",
       "  -1.521637018818521,\n",
       "  0.8125088890526101,\n",
       "  1.6106862343296136,\n",
       "  1762300800.0,\n",
       "  -0.92399929220631,\n",
       "  0.1294857661317531,\n",
       "  -1.4629673635676004,\n",
       "  -1.1533789878305432],\n",
       " [0.9735280773800086,\n",
       "  0.5299550698614484,\n",
       "  -1.0363092112023307,\n",
       "  -1.472882538173633,\n",
       "  1.1611504609929848,\n",
       "  -1.2336847803382307,\n",
       "  0.40183314782555946,\n",
       "  1.6748566876101978,\n",
       "  1766188800.0,\n",
       "  -0.9630425072791526,\n",
       "  0.7529229441806057,\n",
       "  1.154771913604212,\n",
       "  1.6783603205171485],\n",
       " [0.8232738617678529,\n",
       "  -0.5194999454299609,\n",
       "  -1.2636641460801685,\n",
       "  0.1932095325100713,\n",
       "  0.9462529050628038,\n",
       "  -1.1342665142111983,\n",
       "  -0.16938160968038393,\n",
       "  0.0633840890049219,\n",
       "  1748908800.0,\n",
       "  0.1347271493505902,\n",
       "  0.5122553999653742,\n",
       "  -0.1562160298472705,\n",
       "  0.9318689388166872],\n",
       " [-1.5489472190305187,\n",
       "  -0.8497269164865828,\n",
       "  0.11418608806362382,\n",
       "  -1.623221464774326,\n",
       "  1.1527280169580625,\n",
       "  -1.588211832490736,\n",
       "  -0.6896664906720732,\n",
       "  -1.091585878925387,\n",
       "  1746748800.0,\n",
       "  -0.48574329957092094,\n",
       "  0.09767271456059669,\n",
       "  -0.2015729949589489,\n",
       "  0.7531456349728708],\n",
       " [1.6023289069955813,\n",
       "  1.4209223158236928,\n",
       "  -1.487543572651084,\n",
       "  -0.8072484699066745,\n",
       "  -1.1689942688582917,\n",
       "  0.17843060378465486,\n",
       "  -0.43722016616536385,\n",
       "  0.9299262995742569,\n",
       "  1783555200.0,\n",
       "  -1.122692699385311,\n",
       "  0.6221141196280559,\n",
       "  1.538414057926351,\n",
       "  1.379444137301874],\n",
       " [1.5566693301278531,\n",
       "  -0.24890556626238422,\n",
       "  -1.5378866531645534,\n",
       "  -1.524960233954808,\n",
       "  1.341702760903349,\n",
       "  -0.5231250541217541,\n",
       "  1.6624336174355014,\n",
       "  -1.454959624123049,\n",
       "  1788134400.0,\n",
       "  -0.21169282895359795,\n",
       "  -0.9880206556959685,\n",
       "  -1.051958355462273,\n",
       "  -1.622579048937446],\n",
       " [0.24951410489650103,\n",
       "  0.07799403437462579,\n",
       "  -0.4296863518025425,\n",
       "  -1.2752922008808079,\n",
       "  0.6406642371962646,\n",
       "  1.435551336749282,\n",
       "  0.5874637255081042,\n",
       "  -0.21066251427856975,\n",
       "  1752019200.0,\n",
       "  -0.9695995849965087,\n",
       "  1.025933761608116,\n",
       "  -0.7856704922379432,\n",
       "  0.9032052247346429],\n",
       " [-0.28498053920277777,\n",
       "  -0.44604771226229034,\n",
       "  -0.7691338369740759,\n",
       "  -1.5661045738196675,\n",
       "  0.6755641304274963,\n",
       "  -1.5197879833197725,\n",
       "  -1.7757607867093703,\n",
       "  -1.170798127004277,\n",
       "  1791244800.0,\n",
       "  -1.0124555910349153,\n",
       "  -0.698297022774205,\n",
       "  0.43600896976392717,\n",
       "  1.2386814599677467],\n",
       " [1.083550229786225,\n",
       "  0.24983139763872966,\n",
       "  -0.9447890044046372,\n",
       "  -1.0735877807296537,\n",
       "  -1.3272050444007568,\n",
       "  -0.9373304699435082,\n",
       "  0.4971452305066313,\n",
       "  0.9754506132017964,\n",
       "  1769990400.0,\n",
       "  -0.859602304009391,\n",
       "  0.02109627594430925,\n",
       "  -1.273525042128082,\n",
       "  0.9916647977411376],\n",
       " [1.0092298010187672,\n",
       "  0.7576843732189771,\n",
       "  0.31055098911182316,\n",
       "  -0.7487741301691816,\n",
       "  -0.650885339898388,\n",
       "  -1.5182566275634617,\n",
       "  1.6238223540771641,\n",
       "  0.36244182296593475,\n",
       "  1795392000.0,\n",
       "  1.413451326022751,\n",
       "  -0.46170756023974774,\n",
       "  1.381855274245896,\n",
       "  1.6568170321208229],\n",
       " [-0.28101627408792457,\n",
       "  -0.7478369819472324,\n",
       "  1.0879829040204676,\n",
       "  -0.4288017767272647,\n",
       "  -1.6525569940398301,\n",
       "  0.11309081166862156,\n",
       "  0.5198164517847345,\n",
       "  -0.38631912035637755,\n",
       "  1765756800.0,\n",
       "  0.9896970232351247,\n",
       "  1.1494724543998074,\n",
       "  -0.05767421490481562,\n",
       "  0.9756615596967185],\n",
       " [-0.4131327639854203,\n",
       "  -0.6186252750224231,\n",
       "  1.5893323955228646,\n",
       "  -0.9987199030463,\n",
       "  -0.22286144379850764,\n",
       "  -1.621927621503962,\n",
       "  -0.17549668053896156,\n",
       "  0.19297761199396346,\n",
       "  1791504000.0,\n",
       "  1.0235422962053728,\n",
       "  0.5848158993687073,\n",
       "  -0.20359990555871174,\n",
       "  -0.054840166783931624],\n",
       " [1.4439682203561706,\n",
       "  0.753169116914696,\n",
       "  -1.7341315323720092,\n",
       "  -0.5718681171353497,\n",
       "  -0.5714255964438821,\n",
       "  0.4504311535427395,\n",
       "  -1.0914320822529175,\n",
       "  -0.720820691899504,\n",
       "  1748304000.0,\n",
       "  -0.9089473630813891,\n",
       "  1.3444480963954235,\n",
       "  -0.2863387918701377,\n",
       "  1.7250565935257594],\n",
       " [0.3344157553285098,\n",
       "  1.5142540033662162,\n",
       "  -1.7344951860128357,\n",
       "  -0.6354584615448964,\n",
       "  1.4451032114230264,\n",
       "  0.7531699095525949,\n",
       "  -1.7329157447891193,\n",
       "  -0.5749550159693855,\n",
       "  1748217600.0,\n",
       "  -0.5694058210317396,\n",
       "  0.4498713730581028,\n",
       "  -1.0905554199545393,\n",
       "  -0.7236989450141728],\n",
       " [0.6024609097918951,\n",
       "  1.2957316594906962,\n",
       "  1.6941641416470397,\n",
       "  -0.9477400686476638,\n",
       "  1.3933562839680194,\n",
       "  0.8869250208608873,\n",
       "  1.6218676871423858,\n",
       "  -0.03677955286698574,\n",
       "  1785888000.0,\n",
       "  -0.7170812160180191,\n",
       "  -0.4929844575227443,\n",
       "  1.1963078779900709,\n",
       "  -1.015021312948204],\n",
       " [1.6859293266568434,\n",
       "  -1.6226938191545126,\n",
       "  -0.15948525346869696,\n",
       "  1.0019752066408347,\n",
       "  -1.404024713985154,\n",
       "  -0.9085257616279926,\n",
       "  -0.6337262875944113,\n",
       "  -1.1256091579768457,\n",
       "  1763683200.0,\n",
       "  0.5496167564937449,\n",
       "  1.2822661540629519,\n",
       "  0.9019338457668894,\n",
       "  -0.9353878802641141],\n",
       " [1.5175639898152566,\n",
       "  -0.9563954905143504,\n",
       "  -0.11854281921214503,\n",
       "  -0.544979589077403,\n",
       "  0.10698705173265952,\n",
       "  -1.6204746849696965,\n",
       "  1.6267422935794233,\n",
       "  -0.5403965537350962,\n",
       "  1737676800.0,\n",
       "  0.8190349804743877,\n",
       "  1.4184358423214687,\n",
       "  -0.2690245991912127,\n",
       "  0.5995381208243709],\n",
       " [-0.9997200946882651,\n",
       "  1.0456103121220528,\n",
       "  0.45712868373694976,\n",
       "  -0.5401943162241493,\n",
       "  0.5860107779810665,\n",
       "  -1.252277450052434,\n",
       "  -0.2742121805181153,\n",
       "  -0.5920817045545078,\n",
       "  1750896000.0,\n",
       "  -0.9159195564677787,\n",
       "  -0.15475059868567995,\n",
       "  -1.6987228247824684,\n",
       "  0.3184328860188868],\n",
       " [1.020178272263161,\n",
       "  0.5853173715693346,\n",
       "  -0.20694375376600918,\n",
       "  -0.04835640564409954,\n",
       "  -1.5492580070434234,\n",
       "  1.6288399052236857,\n",
       "  1.4893911757025942,\n",
       "  0.6382128744695009,\n",
       "  1791676800.0,\n",
       "  -0.2839697204593321,\n",
       "  -0.09130385314318952,\n",
       "  -0.480082941728472,\n",
       "  -0.5071396757828809],\n",
       " [0.6195294042089539,\n",
       "  1.0901462016244414,\n",
       "  1.4627113645111702,\n",
       "  0.3638873563494596,\n",
       "  1.4396138538057341,\n",
       "  0.48775945621274824,\n",
       "  -0.4434758679625254,\n",
       "  0.03872694323395054,\n",
       "  1762992000.0,\n",
       "  1.1814414740840196,\n",
       "  1.045560225406224,\n",
       "  0.9059021843017676,\n",
       "  -0.9192480703762742],\n",
       " [0.9762124301975448,\n",
       "  -0.8211321477907975,\n",
       "  0.32869560832350947,\n",
       "  0.6544309250190323,\n",
       "  -1.5267440730473028,\n",
       "  -0.712804572318791,\n",
       "  1.4716544403940888,\n",
       "  -0.04289498201474826,\n",
       "  1792022400.0,\n",
       "  1.368803829296322,\n",
       "  1.3619359823139456,\n",
       "  -1.5702315628110688,\n",
       "  -1.2775912896893766],\n",
       " [1.5064657996144377,\n",
       "  -1.3729744876848466,\n",
       "  -1.5974026090565385,\n",
       "  -0.4447042061999037,\n",
       "  0.5984988158724627,\n",
       "  -0.9290505560056741,\n",
       "  -0.688323666592882,\n",
       "  0.7915470553126353,\n",
       "  1737072000.0,\n",
       "  1.70451506246584,\n",
       "  1.4143942279272594,\n",
       "  -0.4037499326237367,\n",
       "  -0.7887931172852831],\n",
       " [-0.0664874092292905,\n",
       "  -1.521560790464897,\n",
       "  0.8095034387790233,\n",
       "  1.6169821582020323,\n",
       "  -0.9259872719402825,\n",
       "  0.13019559384191962,\n",
       "  -1.4637697528938975,\n",
       "  -1.1503408395852632,\n",
       "  1762387200.0,\n",
       "  1.3176087855300893,\n",
       "  0.5012665963538402,\n",
       "  -0.6157120262671812,\n",
       "  -1.455212493438101],\n",
       " [1.766050604765678,\n",
       "  -0.5468429194508998,\n",
       "  -1.6498410684562697,\n",
       "  1.4358791456931448,\n",
       "  -1.0395904159161813,\n",
       "  -1.4692942578579788,\n",
       "  -0.4443097883499958,\n",
       "  -1.523020231257901,\n",
       "  1738195200.0,\n",
       "  0.8572662246802699,\n",
       "  0.6265385831427827,\n",
       "  -1.5353509308924833,\n",
       "  0.6108717708857317],\n",
       " [1.6883173588761473,\n",
       "  1.2965536675818108,\n",
       "  0.48417568727607907,\n",
       "  0.5013544027256875,\n",
       "  -0.4056678165123979,\n",
       "  0.8984637687085719,\n",
       "  1.1647593552106041,\n",
       "  -0.6321062689163626,\n",
       "  1780704000.0,\n",
       "  -1.5787133469854295,\n",
       "  -0.6656766245663583,\n",
       "  -1.6345962411275852,\n",
       "  -0.9032224904737701],\n",
       " [0.014008155341887128,\n",
       "  0.10764271203690681,\n",
       "  -1.5670030855496473,\n",
       "  0.25147695728188185,\n",
       "  1.7165973199450064,\n",
       "  1.3097677615997874,\n",
       "  0.7219240096992618,\n",
       "  0.9845780728735648,\n",
       "  1750636800.0,\n",
       "  -1.1408906421029938,\n",
       "  -0.35302252699685815,\n",
       "  1.5373080230734706,\n",
       "  0.27973105093179407],\n",
       " [-1.4336455072507464,\n",
       "  -1.4142547907449738,\n",
       "  0.884935518126757,\n",
       "  0.8521099842084391,\n",
       "  -0.9269147186364994,\n",
       "  -1.114836063071897,\n",
       "  -0.7221493318876695,\n",
       "  0.686746137106122,\n",
       "  1777248000.0,\n",
       "  1.7046369437661757,\n",
       "  1.1042989831143335,\n",
       "  -1.2809012095932508,\n",
       "  -0.22041935950223485],\n",
       " [-1.5190317216444045,\n",
       "  0.029698555673759095,\n",
       "  -0.4506638804494966,\n",
       "  -0.6782493355937748,\n",
       "  -0.8186328177441763,\n",
       "  1.466974469989993,\n",
       "  -1.3776824306940398,\n",
       "  -1.3858277442225948,\n",
       "  1778198400.0,\n",
       "  0.7151151928105143,\n",
       "  -1.5785580725787716,\n",
       "  -1.5279325044555006,\n",
       "  -0.7463495816821996],\n",
       " [-0.7970921957552418,\n",
       "  -0.4046456261520838,\n",
       "  -1.79418567653463,\n",
       "  -0.5610449577809666,\n",
       "  0.27374473887569556,\n",
       "  -0.4699803812431406,\n",
       "  -1.6394159167635725,\n",
       "  -1.412862018695977,\n",
       "  1757203200.0,\n",
       "  0.5078208277410423,\n",
       "  1.4462706394377134,\n",
       "  0.48568204830884226,\n",
       "  0.27275645997235753],\n",
       " [-0.9823190468568174,\n",
       "  -1.3024896904265486,\n",
       "  -0.2703205271671839,\n",
       "  0.6373627633282839,\n",
       "  0.6197678531210922,\n",
       "  0.4254410056539408,\n",
       "  -0.08483662509632063,\n",
       "  -1.151325673773272,\n",
       "  1761782400.0,\n",
       "  1.4447092767141385,\n",
       "  -0.7872606650573013,\n",
       "  1.3216342308548084,\n",
       "  0.6925976154737943],\n",
       " [1.6262435179067278,\n",
       "  0.6962869375564018,\n",
       "  0.26694278710876185,\n",
       "  0.9462657416923134,\n",
       "  -1.6824439954816308,\n",
       "  -0.7258864094807309,\n",
       "  0.4468972884953286,\n",
       "  -1.066343561758935,\n",
       "  1782432000.0,\n",
       "  -0.18644701005221942,\n",
       "  -1.2975417159028997,\n",
       "  -0.6355270973676216,\n",
       "  0.8790771278696285],\n",
       " [-0.21568173163950308,\n",
       "  0.6414103227348822,\n",
       "  -0.18180697155657619,\n",
       "  -0.7552067569630851,\n",
       "  1.2507673318191808,\n",
       "  1.0275310392450212,\n",
       "  -1.4345388105543433,\n",
       "  1.2868764279235196,\n",
       "  1759536000.0,\n",
       "  0.216519344396699,\n",
       "  1.588741191102345,\n",
       "  1.047400959895106,\n",
       "  0.5592094453325677],\n",
       " [-0.41157323424132525,\n",
       "  0.742283484901351,\n",
       "  1.0703533545739272,\n",
       "  1.0128889386677176,\n",
       "  0.6558267315545662,\n",
       "  0.615779618362345,\n",
       "  0.5571325487543044,\n",
       "  0.5066169910585469,\n",
       "  1749340800.0,\n",
       "  0.519292644757732,\n",
       "  -1.0430566315128023,\n",
       "  -1.744550635893347,\n",
       "  0.4344927303541525],\n",
       " [-0.489208556675724,\n",
       "  0.09841881819475545,\n",
       "  -0.2049186722250057,\n",
       "  0.7605145914614541,\n",
       "  0.5610823671188654,\n",
       "  -1.5088915919294952,\n",
       "  -0.676792166605182,\n",
       "  -0.26023059910494956,\n",
       "  1746921600.0,\n",
       "  0.3367469846776272,\n",
       "  0.07867916167198999,\n",
       "  -0.30759980644061896,\n",
       "  0.07770201003421469],\n",
       " [-0.649575716736316,\n",
       "  1.7191929090479503,\n",
       "  1.6958706087196649,\n",
       "  1.4032118736271326,\n",
       "  0.73328003491043,\n",
       "  -0.6051478087755106,\n",
       "  0.7607465332552206,\n",
       "  -1.2796728990836665,\n",
       "  1776643200.0,\n",
       "  0.09536886600020904,\n",
       "  -0.3796527716205718,\n",
       "  0.5750426815424832,\n",
       "  1.3308623952435863],\n",
       " [1.4852193327030703,\n",
       "  1.6777266789663565,\n",
       "  0.6753524375590082,\n",
       "  1.227676314917118,\n",
       "  -1.5867137470296726,\n",
       "  1.3242424954832595,\n",
       "  -0.25806599694800536,\n",
       "  0.5332119045251467,\n",
       "  1765497600.0,\n",
       "  -0.7881382025042145,\n",
       "  -0.8307192689927672,\n",
       "  -0.8167511315379652,\n",
       "  -1.218088735518456],\n",
       " [0.8998881125787909,\n",
       "  0.8359321647647476,\n",
       "  -0.6675875809196469,\n",
       "  -1.14260071240988,\n",
       "  -1.5127538847110718,\n",
       "  0.9173372233129894,\n",
       "  -1.392112569999454,\n",
       "  -1.571381458743912,\n",
       "  1760832000.0,\n",
       "  1.466444251481019,\n",
       "  1.5478093645305437,\n",
       "  0.9272374042077487,\n",
       "  -1.1867322979952017],\n",
       " [-1.2239171772747623,\n",
       "  0.2950450680643869,\n",
       "  -0.674132679707367,\n",
       "  -0.9830946987135775,\n",
       "  -0.10861252200339434,\n",
       "  -1.1080856213125374,\n",
       "  -1.7076726371766406,\n",
       "  1.5146267764731463,\n",
       "  1745798400.0,\n",
       "  -0.8364263016814589,\n",
       "  1.6965114149717007,\n",
       "  -0.14271969154144892,\n",
       "  1.244657230943125],\n",
       " [-0.8107726585692441,\n",
       "  0.330053974101497,\n",
       "  -1.2255570846516455,\n",
       "  0.9523595312614628,\n",
       "  -0.5935367384525162,\n",
       "  0.3843190108676117,\n",
       "  -0.5312230933044527,\n",
       "  0.781344549932701,\n",
       "  1767744000.0,\n",
       "  1.5537303330558692,\n",
       "  -0.9529171289395402,\n",
       "  -0.971567176746474,\n",
       "  -0.7815000002680066],\n",
       " [0.5847411193703069,\n",
       "  -1.2522103417435944,\n",
       "  -0.2764535680386558,\n",
       "  -0.5890199516461754,\n",
       "  -0.9179082606952856,\n",
       "  -0.153907653641234,\n",
       "  -1.6994781955877727,\n",
       "  0.320923334747425,\n",
       "  1750982400.0,\n",
       "  -0.05849948384315,\n",
       "  1.4462723739481695,\n",
       "  1.3344451010163167,\n",
       "  -0.8365399987255833],\n",
       " [0.6475463259756546,\n",
       "  0.3315319174505135,\n",
       "  0.49727109006478704,\n",
       "  -1.335388415769638,\n",
       "  -0.3327692633862429,\n",
       "  1.289818422480223,\n",
       "  0.6717226860003662,\n",
       "  -0.6757095173711796,\n",
       "  1766707200.0,\n",
       "  -0.1136203002653851,\n",
       "  -1.468627609336636,\n",
       "  -1.6595183070707482,\n",
       "  1.0807213092059478],\n",
       " [-1.4968531846740676,\n",
       "  -1.2143700385742915,\n",
       "  0.5915269021282114,\n",
       "  0.12151094371608877,\n",
       "  0.9094060657185379,\n",
       "  -0.4996747317538256,\n",
       "  1.6563877653055343,\n",
       "  1.4525594686481065,\n",
       "  1740960000.0,\n",
       "  0.23008290662291966,\n",
       "  -0.06956832945255166,\n",
       "  -1.7821517556007074,\n",
       "  -0.3371331127334884],\n",
       " [0.7117304815635319,\n",
       "  -1.5769702067006255,\n",
       "  -1.5300812914989774,\n",
       "  -0.7406234092479544,\n",
       "  0.09450520407279257,\n",
       "  1.4712699839320087,\n",
       "  0.6165047158849123,\n",
       "  1.4813990871987115,\n",
       "  1778371200.0,\n",
       "  0.9707895909744559,\n",
       "  -0.05771693442971308,\n",
       "  -0.666426824474512,\n",
       "  1.0669131223549173],\n",
       " [-1.7258132842715275,\n",
       "  -0.7557612928550407,\n",
       "  1.3739484074895283,\n",
       "  0.6052887310442385,\n",
       "  1.5940148703003707,\n",
       "  1.3899345824938698,\n",
       "  0.27548910287351286,\n",
       "  -0.07900070979143575,\n",
       "  1755216000.0,\n",
       "  -1.0846882863069383,\n",
       "  0.3083366311277083,\n",
       "  -0.6805273519825242,\n",
       "  -0.8606228978122047],\n",
       " [-1.1477751289385414,\n",
       "  -1.561860648569389,\n",
       "  -0.7664821588240732,\n",
       "  1.5972868357307901,\n",
       "  0.4897811976881287,\n",
       "  -1.3324432817735703,\n",
       "  -0.43333374748588693,\n",
       "  0.2482437343695163,\n",
       "  1760227200.0,\n",
       "  0.741925274197833,\n",
       "  0.6620835566546668,\n",
       "  -1.6039273895819877,\n",
       "  0.2679169335528578],\n",
       " [-1.443579744849732,\n",
       "  1.1816383467614904,\n",
       "  -0.3645415189686628,\n",
       "  0.06386978912202347,\n",
       "  -0.1605333963683093,\n",
       "  -0.12047751158060224,\n",
       "  -0.2482895036249681,\n",
       "  -0.7001263786077554,\n",
       "  1737504000.0,\n",
       "  1.5208946545626947,\n",
       "  -0.9576715623208533,\n",
       "  -0.11511912705762518,\n",
       "  -0.5509198661095958],\n",
       " [-0.7557877463728917,\n",
       "  0.016483184640487834,\n",
       "  0.0530447158358932,\n",
       "  0.06478660276050105,\n",
       "  0.1161637676458445,\n",
       "  0.5368890039716083,\n",
       "  -0.8375062600018347,\n",
       "  -1.2873859638756873,\n",
       "  1770940800.0,\n",
       "  1.40672380122193,\n",
       "  1.509571202278794,\n",
       "  0.6168398757779437,\n",
       "  0.05316436668545697],\n",
       " [0.546220944676957,\n",
       "  1.282417383745684,\n",
       "  0.897592377737651,\n",
       "  -0.9298688102594869,\n",
       "  1.31279634989945,\n",
       "  0.6279281981842804,\n",
       "  0.8698999412331251,\n",
       "  1.026020365492062,\n",
       "  1763856000.0,\n",
       "  -1.1204898073531586,\n",
       "  -0.7847052927513912,\n",
       "  -0.00754801947725779,\n",
       "  -1.6176677917427014],\n",
       " [-1.3806238921661165,\n",
       "  1.647000178250173,\n",
       "  -1.7389881141459025,\n",
       "  -1.0819865313520043,\n",
       "  1.6828214713312803,\n",
       "  0.797857432658614,\n",
       "  -1.4695624180095026,\n",
       "  1.337775622154421,\n",
       "  1758067200.0,\n",
       "  0.8102434883067747,\n",
       "  1.648889669071781,\n",
       "  0.2586408501728669,\n",
       "  0.9906773075491445],\n",
       " [-0.26455409133322033,\n",
       "  1.1704376548106055,\n",
       "  -0.7932699482437188,\n",
       "  0.6178001500524869,\n",
       "  -1.451496003284551,\n",
       "  -0.03139114535525483,\n",
       "  -1.3789411472955735,\n",
       "  -0.8296825324242232,\n",
       "  1777507200.0,\n",
       "  0.5081484763213725,\n",
       "  -1.1915352794564167,\n",
       "  -0.4238980159427755,\n",
       "  -0.10830918844393599],\n",
       " [-0.6382966896787002,\n",
       "  -1.6617908858880968,\n",
       "  0.6625612207910129,\n",
       "  0.13668803038756763,\n",
       "  0.9559853281721503,\n",
       "  0.5575262096945152,\n",
       "  -0.3538278062542932,\n",
       "  -1.3428688069927983,\n",
       "  1793664000.0,\n",
       "  0.691300860198986,\n",
       "  0.21844841910485202,\n",
       "  0.8064785423219449,\n",
       "  0.1972861079627262],\n",
       " [-1.6684254667558922,\n",
       "  0.4913357996516352,\n",
       "  0.5512357729372228,\n",
       "  0.368505405413027,\n",
       "  0.4266008345242222,\n",
       "  0.624178759633158,\n",
       "  0.4487948256972943,\n",
       "  -0.15268201911116255,\n",
       "  1752451200.0,\n",
       "  -0.13058715622016603,\n",
       "  -0.673323452837044,\n",
       "  0.29036239640581757,\n",
       "  0.6643749111351335],\n",
       " [-1.1862748960312148,\n",
       "  -1.07542756867511,\n",
       "  -1.1239528764707987,\n",
       "  -1.2443173247941037,\n",
       "  1.6894140528521624,\n",
       "  1.2965728588949699,\n",
       "  0.48695224191577313,\n",
       "  0.49669407606207594,\n",
       "  1780617600.0,\n",
       "  -0.4036331766030773,\n",
       "  0.8981139151006235,\n",
       "  1.1660860768418335,\n",
       "  -0.6349514967950176],\n",
       " [0.17347340486229396,\n",
       "  -0.4451713399815968,\n",
       "  -0.7178605903055763,\n",
       "  -1.5210700969593844,\n",
       "  -1.3458745313547467,\n",
       "  -0.3473917846965493,\n",
       "  0.05474539791931996,\n",
       "  -0.8042592459739673,\n",
       "  1795651200.0,\n",
       "  -1.2589434502992618,\n",
       "  -0.6985759583045249,\n",
       "  0.5999827785062636,\n",
       "  -0.6713549112328374],\n",
       " [-0.5380016889475003,\n",
       "  0.12270247204518869,\n",
       "  -0.9654093412353019,\n",
       "  0.717440844548474,\n",
       "  1.7054836307576267,\n",
       "  -0.8798048934611976,\n",
       "  0.11452176604879613,\n",
       "  0.9668543332675215,\n",
       "  1772755200.0,\n",
       "  1.6867730956147255,\n",
       "  -0.5678628859790332,\n",
       "  1.437428836223119,\n",
       "  0.4944142952914815],\n",
       " [0.6867705415345935,\n",
       "  1.1161091231604159,\n",
       "  1.0185050103761863,\n",
       "  -0.5477954521321515,\n",
       "  0.4394881964714395,\n",
       "  1.1323897855351357,\n",
       "  1.174423893551879,\n",
       "  0.2244359118580313,\n",
       "  1744156800.0,\n",
       "  -0.44014086712772843,\n",
       "  1.7022622525362383,\n",
       "  -0.5216166243735366,\n",
       "  -1.2009223188705764],\n",
       " [0.3708051672814884,\n",
       "  1.3807123644878418,\n",
       "  0.6136799369707628,\n",
       "  -0.18345580720643054,\n",
       "  1.368215371520564,\n",
       "  0.19565261942719342,\n",
       "  -0.5098448091252124,\n",
       "  -0.21010649416986346,\n",
       "  1751587200.0,\n",
       "  -1.395975984640595,\n",
       "  1.0555188073683706,\n",
       "  0.8006578579035633,\n",
       "  -1.582365561134697],\n",
       " [0.738046365533438,\n",
       "  -1.436516954728411,\n",
       "  -0.20371355568555824,\n",
       "  -0.427942848552754,\n",
       "  0.033941518677078175,\n",
       "  0.7196745320573882,\n",
       "  1.3180606028466315,\n",
       "  0.12746622918821293,\n",
       "  1762041600.0,\n",
       "  -0.34965034031727044,\n",
       "  1.1021462440241108,\n",
       "  1.434601753008719,\n",
       "  0.4060716077814497],\n",
       " [1.7043894557778265,\n",
       "  -0.8797503964229083,\n",
       "  0.11200706356479975,\n",
       "  0.9722049635375545,\n",
       "  1.6845510132100427,\n",
       "  -0.5668264667235098,\n",
       "  1.4360479986229,\n",
       "  0.4968392567559702,\n",
       "  1772841600.0,\n",
       "  -0.25554552134869357,\n",
       "  -1.1073960196255834,\n",
       "  1.239492853264394,\n",
       "  1.0680018251657561],\n",
       " [-1.5762414490347276,\n",
       "  0.5943552395723302,\n",
       "  -1.0462873306197256,\n",
       "  0.26961287216084523,\n",
       "  0.021803564405039836,\n",
       "  -0.07181857029571444,\n",
       "  0.20134992897467263,\n",
       "  0.399896120570978,\n",
       "  1781913600.0,\n",
       "  0.03386812896105471,\n",
       "  0.03019745390012319,\n",
       "  0.76084573056894,\n",
       "  -0.6280011221784301],\n",
       " [0.329217636954089,\n",
       "  -0.6915114746361176,\n",
       "  1.6541326838024253,\n",
       "  -1.1352392186856217,\n",
       "  -0.08211647438039492,\n",
       "  -1.045360113479136,\n",
       "  -0.24696033573614037,\n",
       "  -0.1633502186984013,\n",
       "  1775174400.0,\n",
       "  -0.9516506548838697,\n",
       "  1.129262918455606,\n",
       "  1.0587463636927386,\n",
       "  1.593546356447589],\n",
       " [-0.12863768795392014,\n",
       "  1.6702872594837366,\n",
       "  -1.6255237957635669,\n",
       "  1.3178105268565583,\n",
       "  1.4840335689732522,\n",
       "  1.400869616453186,\n",
       "  1.3112538058970296,\n",
       "  0.13198668470535901,\n",
       "  1778025600.0,\n",
       "  -1.5154973952633228,\n",
       "  0.028917925060177926,\n",
       "  -0.4475401608757953,\n",
       "  -0.6840437676640791],\n",
       " [-0.2589953382683017,\n",
       "  -1.1060447598460834,\n",
       "  1.2348467762111883,\n",
       "  1.0757157248878446,\n",
       "  0.8584938835736491,\n",
       "  0.4839121630921726,\n",
       "  -0.3318118123304344,\n",
       "  -1.3702595339255792,\n",
       "  1773014400.0,\n",
       "  -1.5695727708594833,\n",
       "  1.5430556861876747,\n",
       "  1.5817810175135805,\n",
       "  -0.5983576951359404],\n",
       " [0.8331206741348124,\n",
       "  -1.4245241453260626,\n",
       "  1.0311072333645335,\n",
       "  -0.6075681912328669,\n",
       "  -0.13202355035815694,\n",
       "  1.0548332304757555,\n",
       "  -1.0342806820068893,\n",
       "  -0.7823123914012375,\n",
       "  1736467200.0,\n",
       "  -0.1328319287609662,\n",
       "  0.2318992701987363,\n",
       "  0.5367119291882096,\n",
       "  -1.0762502247559502],\n",
       " [0.3069451218330324,\n",
       "  -0.36026728391611396,\n",
       "  1.7261149092431398,\n",
       "  0.6096748482540634,\n",
       "  -0.7129087084152284,\n",
       "  0.5931528295237608,\n",
       "  0.48359526609584963,\n",
       "  0.4455687218572949,\n",
       "  1739923200.0,\n",
       "  -1.6013793586252518,\n",
       "  1.6797841590391787,\n",
       "  -0.07881484320848159,\n",
       "  -1.6372261717946475],\n",
       " [-0.8060149330468426,\n",
       "  0.08296765278147925,\n",
       "  0.8521212925573723,\n",
       "  -0.6940200171349208,\n",
       "  -0.504396457548966,\n",
       "  1.6084326545319492,\n",
       "  1.174007584725402,\n",
       "  0.3513058203967595,\n",
       "  1794355200.0,\n",
       "  1.1532346163542444,\n",
       "  0.747583348519112,\n",
       "  0.1088704987878428,\n",
       "  -0.11386890420019827],\n",
       " [-1.7234241412224,\n",
       "  0.6822948020440467,\n",
       "  1.0712345722462528,\n",
       "  -1.2372671223762521,\n",
       "  1.1085511362493057,\n",
       "  -0.4661512752068997,\n",
       "  -0.446483765706997,\n",
       "  1.1554116390890037,\n",
       "  1785369600.0,\n",
       "  1.422851760353954,\n",
       "  -0.45333461863505625,\n",
       "  -0.6584412655012823,\n",
       "  -1.259907315132298],\n",
       " [-1.1443998422743928,\n",
       "  -0.35205009519786756,\n",
       "  1.5323932013380515,\n",
       "  0.2865813542622241,\n",
       "  -0.9982021018479834,\n",
       "  1.045621006643575,\n",
       "  0.4598862085183198,\n",
       "  -0.5433276513180472,\n",
       "  1750809600.0,\n",
       "  0.5881343476750136,\n",
       "  -1.2536350391942166,\n",
       "  -0.2731725012710596,\n",
       "  -0.5949120327061518],\n",
       " [0.4242902319135716,\n",
       "  -1.0063737563213004,\n",
       "  0.39592616795993724,\n",
       "  0.04521670315830019,\n",
       "  -1.441992185431701,\n",
       "  1.1816536471107497,\n",
       "  -0.3623621087841266,\n",
       "  0.05985084898666359,\n",
       "  1737417600.0,\n",
       "  -0.15847677378102326,\n",
       "  -0.12130479284283129,\n",
       "  -0.24724465338821955,\n",
       "  -0.7029969279629044],\n",
       " [-0.9573837091152267,\n",
       "  -0.4085615312914901,\n",
       "  1.1905279798807622,\n",
       "  -1.4779544670456455,\n",
       "  1.2722472146087371,\n",
       "  -0.3313519737018798,\n",
       "  0.6518521268162574,\n",
       "  0.1037098563999604,\n",
       "  1740182400.0,\n",
       "  0.793604685239162,\n",
       "  -1.3983635105064594,\n",
       "  -1.541500707424319,\n",
       "  -1.0993420433736152],\n",
       " [-1.7194968944053186,\n",
       "  -0.2855961119359221,\n",
       "  1.3302506815270732,\n",
       "  0.8913013504876678,\n",
       "  1.4924536459027113,\n",
       "  0.18934990534899476,\n",
       "  -1.136213466655256,\n",
       "  1.240670537668049,\n",
       "  1794182400.0,\n",
       "  -0.8025284280347474,\n",
       "  0.08221378605022646,\n",
       "  0.856421690987702,\n",
       "  -0.6997971904161268],\n",
       " [-0.623888754862465,\n",
       "  0.6932267845824026,\n",
       "  -1.1879808011140036,\n",
       "  1.5375445356680046,\n",
       "  -0.26640598293042766,\n",
       "  1.6035095808917192,\n",
       "  1.1965799915682254,\n",
       "  -0.7907469193978383,\n",
       "  1791072000.0,\n",
       "  -0.28152897948005207,\n",
       "  -0.4470673710896868,\n",
       "  -0.7662977602689596,\n",
       "  -1.5709273734169888],\n",
       " [1.127542742414473,\n",
       "  -1.7457589392862172,\n",
       "  0.7870670250587588,\n",
       "  0.5577472266677669,\n",
       "  -0.8237164062353594,\n",
       "  -0.44068729469726253,\n",
       "  1.3299241290051642,\n",
       "  1.0537286183334211,\n",
       "  1736294400.0,\n",
       "  0.8364972438551391,\n",
       "  -1.4260354180447679,\n",
       "  1.0355692923483797,\n",
       "  -0.6134399738577795],\n",
       " [0.10967758561047596,\n",
       "  0.6489019121451568,\n",
       "  1.3020062097804703,\n",
       "  -0.7389087010691712,\n",
       "  -1.4641097770787506,\n",
       "  1.1070626837947841,\n",
       "  0.9194761191281546,\n",
       "  0.0026637600941731275,\n",
       "  1774742400.0,\n",
       "  0.9351225320197636,\n",
       "  -0.08380915974929729,\n",
       "  -0.7912694859113674,\n",
       "  1.2329194937332484],\n",
       " [-1.2348655950346132,\n",
       "  -0.7751802201601398,\n",
       "  0.4562407321311815,\n",
       "  -0.001846686031250477,\n",
       "  1.3592834482821028,\n",
       "  -1.3956384630132832,\n",
       "  1.0580494602451875,\n",
       "  1.0006916062072488,\n",
       "  1771545600.0,\n",
       "  0.8999464360399965,\n",
       "  -1.002280916691516,\n",
       "  -1.7828211600508663,\n",
       "  0.6321175768320151],\n",
       " [0.2772732506741911,\n",
       "  1.5312853138258393,\n",
       "  -0.6183390800109207,\n",
       "  1.1377223205443532,\n",
       "  0.08804467491369146,\n",
       "  1.0119061924698107,\n",
       "  1.6934832273374858,\n",
       "  -1.1941730110763435,\n",
       "  1763337600.0,\n",
       "  0.7970352525892251,\n",
       "  0.2167118806625176,\n",
       "  -1.393230960783218,\n",
       "  0.5154387670790226],\n",
       " [-1.0159561766098169,\n",
       "  -0.6971512025393337,\n",
       "  0.43208794651195465,\n",
       "  1.2465823491375763,\n",
       "  -0.41170670757849853,\n",
       "  -0.6186709305205821,\n",
       "  1.5928865215320966,\n",
       "  -1.0011810039058922,\n",
       "  1791417600.0,\n",
       "  -0.2208104105421449,\n",
       "  -1.6234584112193933,\n",
       "  -0.1744373097748985,\n",
       "  0.19043953360669788],\n",
       " [1.026394960497379,\n",
       "  0.6353205404217749,\n",
       "  -1.6809575795348286,\n",
       "  -0.8450526033959105,\n",
       "  0.7197131621755082,\n",
       "  0.7170775300943595,\n",
       "  -1.4948052591515448,\n",
       "  -0.09368533424807578,\n",
       "  1760486400.0,\n",
       "  1.6873017840810562,\n",
       "  0.763123144002582,\n",
       "  0.3264810262053627,\n",
       "  -0.44528547473841357],\n",
       " [-0.9263580892574066,\n",
       "  1.0477094341327988,\n",
       "  -1.1217509647531927,\n",
       "  -1.5405686426729481,\n",
       "  0.942599362542934,\n",
       "  1.601864547723055,\n",
       "  -0.5551142745094461,\n",
       "  -1.606572376698223,\n",
       "  1779235200.0,\n",
       "  -1.304261713947008,\n",
       "  0.17748727772609382,\n",
       "  1.4286752801713731,\n",
       "  0.6422089212131655],\n",
       " [1.6839822808527143,\n",
       "  0.763535074651107,\n",
       "  0.3226588395989647,\n",
       "  -0.43922946909848204,\n",
       "  -1.249357414182189,\n",
       "  -0.598540116790877,\n",
       "  -0.6888758786127392,\n",
       "  -1.1813616423506372,\n",
       "  1760659200.0,\n",
       "  0.9032602042694818,\n",
       "  0.8355566084365307,\n",
       "  -0.6646597873797487,\n",
       "  -1.1478869773182827],\n",
       " [1.3581350044873788,\n",
       "  -1.3955665007508062,\n",
       "  1.0548713728432122,\n",
       "  1.0060919173917866,\n",
       "  0.8977949067878028,\n",
       "  -1.0010410450373226,\n",
       "  -1.7835597584797351,\n",
       "  0.6344912953203508,\n",
       "  1771632000.0,\n",
       "  -0.7281283366886526,\n",
       "  0.9445188711582799,\n",
       "  -0.03263229396390659,\n",
       "  1.7360863817330332],\n",
       " [1.385176777111192,\n",
       "  -1.4745152435076392,\n",
       "  0.3137969770497788,\n",
       "  0.41871590368271383,\n",
       "  1.3020677938070626,\n",
       "  -1.641108393945592,\n",
       "  0.4900610646560777,\n",
       "  1.432803657837708,\n",
       "  1755475200.0,\n",
       "  0.22514997429164132,\n",
       "  -1.1950058120660652,\n",
       "  -0.7210592104006077,\n",
       "  -0.5534408074981952],\n",
       " [-1.0411148966061807,\n",
       "  -1.4692198017388676,\n",
       "  -0.4464315819377731,\n",
       "  -1.5213253106423696,\n",
       "  0.8551185224761608,\n",
       "  0.6270156245026203,\n",
       "  -1.5361388842084236,\n",
       "  0.6132533954915924,\n",
       "  1738281600.0,\n",
       "  -1.5205143297756762,\n",
       "  -1.612308359879871,\n",
       "  0.74273501499135,\n",
       "  1.0037792828578749],\n",
       " [1.1001050576389955,\n",
       "  -1.2279533004488907,\n",
       "  -0.5423188761964296,\n",
       "  0.3353530094058164,\n",
       "  1.540657146720272,\n",
       "  0.6624186910934545,\n",
       "  1.6293209875598398,\n",
       "  0.6067834067926512,\n",
       "  1786406400.0,\n",
       "  0.9545343253606942,\n",
       "  1.3061144702973677,\n",
       "  1.7190155122577377,\n",
       "  0.9463077888342075],\n",
       " [-1.1581058619685494,\n",
       "  -1.1309407292476708,\n",
       "  1.0742406029730749,\n",
       "  0.4485442385133082,\n",
       "  -0.47408675443327963,\n",
       "  -0.7574918203766708,\n",
       "  0.2761596785046094,\n",
       "  -1.5331573117397224,\n",
       "  1758758400.0,\n",
       "  -1.2839199381060884,\n",
       "  -1.005000965149516,\n",
       "  0.9866714985985191,\n",
       "  -1.1649697156027814],\n",
       " [0.7902252385621,\n",
       "  -1.3968661339452306,\n",
       "  -1.5436372506912368,\n",
       "  -1.0940025946720817,\n",
       "  -0.24936305963641453,\n",
       "  0.9698914229119125,\n",
       "  -0.1021474077096043,\n",
       "  0.8191030329076785,\n",
       "  1740355200.0,\n",
       "  1.479265632091335,\n",
       "  0.3010406182710588,\n",
       "  1.2641952091307573,\n",
       "  -0.5257785432921473],\n",
       " [-1.50046934821994,\n",
       "  0.07807583592679983,\n",
       "  0.31484563663901255,\n",
       "  0.7765117887197883,\n",
       "  0.3456056663447248,\n",
       "  1.3509782997126119,\n",
       "  -0.47188289942712874,\n",
       "  1.3170275338257962,\n",
       "  1767484800.0,\n",
       "  0.9317420214580191,\n",
       "  0.9218767118604013,\n",
       "  -0.6574788904371596,\n",
       "  -0.05727643074401476],\n",
       " [1.7512039554078314,\n",
       "  -0.9387735559165559,\n",
       "  1.551275669697368,\n",
       "  0.8831486084239037,\n",
       "  0.282073116324436,\n",
       "  -1.0895069987207315,\n",
       "  -1.5775566136222887,\n",
       "  0.4189250989644282,\n",
       "  1755820800.0,\n",
       "  1.3050109602314908,\n",
       "  -0.2763603144859253,\n",
       "  -0.823702381407166,\n",
       "  0.337971965892075],\n",
       " [-1.4639641531133263,\n",
       "  -1.679867258336287,\n",
       "  -0.1072556873665322,\n",
       "  0.9614698666126591,\n",
       "  -0.6373950086359161,\n",
       "  -0.018628135434295458,\n",
       "  -0.5201157930118125,\n",
       "  0.8525249079930164,\n",
       "  1739232000.0,\n",
       "  0.9727914498504548,\n",
       "  1.322221787089079,\n",
       "  0.07381660275066391,\n",
       "  -0.11942394772873931],\n",
       " [-0.8836123330726606,\n",
       "  -1.2162575405552338,\n",
       "  0.5283209046946118,\n",
       "  -0.4668407110048528,\n",
       "  -0.5365244982822394,\n",
       "  -1.2394944629946825,\n",
       "  -0.2553708802344607,\n",
       "  -0.9515296764134167,\n",
       "  1749600000.0,\n",
       "  1.6664170704223387,\n",
       "  -1.1250634696549644,\n",
       "  0.8803582770541338,\n",
       "  0.8682143627998012],\n",
       " [-1.4386174104350635,\n",
       "  -0.38314485211487626,\n",
       "  -0.3646800090786581,\n",
       "  0.6247905617717269,\n",
       "  -1.3154417156569245,\n",
       "  0.7428294082340153,\n",
       "  0.7777982502192392,\n",
       "  -0.22484109016576082,\n",
       "  1756512000.0,\n",
       "  1.2550720140678087,\n",
       "  -0.2215397874252408,\n",
       "  -1.767500045966967,\n",
       "  -1.236561346734046],\n",
       " [0.9547736651414257,\n",
       "  0.5575320412107634,\n",
       "  -0.35601321682187975,\n",
       "  -1.340909382570392,\n",
       "  0.6891680397728716,\n",
       "  0.21911658264857095,\n",
       "  0.8052235399812205,\n",
       "  0.19982163856142401,\n",
       "  1793750400.0,\n",
       "  0.7535864614533115,\n",
       "  1.3971954134895883,\n",
       "  0.3167503537178952,\n",
       "  1.1718613706008487],\n",
       " [-1.061689679091039,\n",
       "  -0.044647641614940746,\n",
       "  0.3303883596442382,\n",
       "  0.1755495223287848,\n",
       "  0.07836411447090814,\n",
       "  0.36107431442451304,\n",
       "  -1.5558435501084222,\n",
       "  0.9432025681755665,\n",
       "  1768348800.0,\n",
       "  0.6458264220958395,\n",
       "  1.5058613710802813,\n",
       "  -1.2889296662637497,\n",
       "  -1.4150240096397435],\n",
       " [-0.2630584353318495,\n",
       "  -1.2688766886751615,\n",
       "  0.3196662799695177,\n",
       "  -0.837186452859111,\n",
       "  1.6913129043897932,\n",
       "  1.0132146244352085,\n",
       "  -0.8162252071566831,\n",
       "  -0.47443681857116493,\n",
       "  1768003200.0,\n",
       "  1.0799472755133752,\n",
       "  -1.1644771033511943,\n",
       "  -1.5329892196220296,\n",
       "  1.4172018143732432],\n",
       " [-0.06193608418293478,\n",
       "  1.4463412437048477,\n",
       "  1.3297133402430241,\n",
       "  -0.8309126351286904,\n",
       "  0.9953819637093383,\n",
       "  1.510136181910547,\n",
       "  0.26276220786186144,\n",
       "  -0.06907159919324983,\n",
       "  1751155200.0,\n",
       "  1.2940534528443164,\n",
       "  1.3686533518044943,\n",
       "  -0.48921633206476495,\n",
       "  0.2984384900646709],\n",
       " [-0.749207595912087,\n",
       "  -0.003175632532307228,\n",
       "  -1.044018770747389,\n",
       "  1.4861451820354827,\n",
       "  -1.7231306352912947,\n",
       "  1.1200104708557,\n",
       "  -1.1412604358330132,\n",
       "  -1.5349107741404544,\n",
       "  1786924800.0,\n",
       "  -1.27492753826085,\n",
       "  1.6520729442902833,\n",
       "  0.023203632417842717,\n",
       "  -1.3164703773570263],\n",
       " [-0.9284215367807475,\n",
       "  -1.1147736082884925,\n",
       "  -0.7240757792615151,\n",
       "  0.6916855039930104,\n",
       "  1.7024132595464205,\n",
       "  1.1045522734037923,\n",
       "  -1.2817399097699462,\n",
       "  -0.2177283898241712,\n",
       "  1777334400.0,\n",
       "  -0.26110390159324437,\n",
       "  1.1702301633841772,\n",
       "  -0.7904556713352234,\n",
       "  0.6105873744137387],\n",
       " [-1.2026944743250378,\n",
       "  -1.5336808696686284,\n",
       "  1.4288695973607033,\n",
       "  1.7532038307820275,\n",
       "  -1.2156902683836053,\n",
       "  -1.3709815576257622,\n",
       "  -1.0993979916089964,\n",
       "  -1.00975284386238,\n",
       "  1780272000.0,\n",
       "  -0.10865745470807052,\n",
       "  1.6812872257325544,\n",
       "  -0.9090752819922101,\n",
       "  0.9170885695156313],\n",
       " [0.6644305392342454,\n",
       "  1.1347749470481336,\n",
       "  -0.4730496001968061,\n",
       "  1.5086478844808595,\n",
       "  1.532592165263902,\n",
       "  -0.03166306776588417,\n",
       "  -1.0473521092831564,\n",
       "  0.6597469320896026,\n",
       "  1752796800.0,\n",
       "  -0.6873616208940208,\n",
       "  -0.6927450477141702,\n",
       "  1.426464278045028,\n",
       "  0.8412581868681732],\n",
       " [-1.2784457287644566,\n",
       "  1.6520384660168248,\n",
       "  0.01965511953621903,\n",
       "  -1.3113688053494972,\n",
       "  0.6627766959429153,\n",
       "  0.23207339236488064,\n",
       "  0.10391243786171549,\n",
       "  -0.6130426742270325,\n",
       "  1787097600.0,\n",
       "  -1.55707955501353,\n",
       "  0.18985481599684528,\n",
       "  -1.6751943576965511,\n",
       "  0.29918603126138943],\n",
       " [0.7394540196792089,\n",
       "  0.01648873103175824,\n",
       "  -0.4374493284643477,\n",
       "  1.7010561785795777,\n",
       "  -0.977812485380956,\n",
       "  -1.0782364708448973,\n",
       "  -0.03638126964821803,\n",
       "  0.6819895956256548,\n",
       "  1787788800.0,\n",
       "  -0.24863912332627833,\n",
       "  -0.573945294322542,\n",
       "  0.6262383237832427,\n",
       "  -1.6596912192811282],\n",
       " [-0.18943865739643181,\n",
       "  -0.25497412254500246,\n",
       "  0.9067648590469389,\n",
       "  0.566879653524345,\n",
       "  -0.5365560617060282,\n",
       "  0.12268191746030188,\n",
       "  -0.9636526924673002,\n",
       "  0.712463718325716,\n",
       "  1772668800.0,\n",
       "  1.707707590316037,\n",
       "  -0.880987959593247,\n",
       "  0.1156389889553762,\n",
       "  0.9646043417606772],\n",
       " [0.4945387017127943,\n",
       "  -0.7854468904725138,\n",
       "  0.03293413897679149,\n",
       "  -0.8491548879909365,\n",
       "  1.2533754478918548,\n",
       "  -0.0355247422429294,\n",
       "  -0.1880024845791404,\n",
       "  -0.4354145781176809,\n",
       "  1774396800.0,\n",
       "  1.493088647230098,\n",
       "  -1.1389572061940851,\n",
       "  1.2301535809619,\n",
       "  1.2037524197825717],\n",
       " [0.3656316497040249,\n",
       "  -1.2161247640956823,\n",
       "  -0.4385399043862529,\n",
       "  -1.2493417716619963,\n",
       "  0.1110217014156329,\n",
       "  0.6488991743579847,\n",
       "  1.3053581774766914,\n",
       "  -0.7417507053929202,\n",
       "  1774656000.0,\n",
       "  -1.462170054026681,\n",
       "  1.1068105697648092,\n",
       "  0.9207539122829446,\n",
       "  5.483460376100728e-05],\n",
       " [0.5137430520316065,\n",
       "  -0.26791548422401823,\n",
       "  1.5165386109572774,\n",
       "  -1.492309098974438,\n",
       "  -1.7178660902097325,\n",
       "  -0.28563049126618795,\n",
       "  1.333622521601948,\n",
       "  0.8860693312176187,\n",
       "  1794096000.0,\n",
       "  1.4946585017809806,\n",
       "  0.18866779454924276,\n",
       "  -1.1353457372336069,\n",
       "  1.2385224782312179],\n",
       " [1.392213181280861,\n",
       "  0.8869196995084124,\n",
       "  1.6182931847644584,\n",
       "  -0.03290248843010791,\n",
       "  -0.7190877496766768,\n",
       "  -0.49198310632333514,\n",
       "  1.1949751289930939,\n",
       "  -1.0120346511958767,\n",
       "  1785974400.0,\n",
       "  0.2017377126614137,\n",
       "  -0.7365235698209034,\n",
       "  0.9443488747429698,\n",
       "  1.2337375537067137],\n",
       " [1.5046261382449366,\n",
       "  0.8735368631509544,\n",
       "  -1.5951418886968582,\n",
       "  0.26779272869573834,\n",
       "  -1.5642275946648212,\n",
       "  -0.8113142473524947,\n",
       "  0.6242919201475152,\n",
       "  -0.5045742217653009,\n",
       "  1787616000.0,\n",
       "  0.7428368715344251,\n",
       "  0.015701463433292907,\n",
       "  -0.43431367347393846,\n",
       "  1.6926579318318513],\n",
       " [1.7154932261683615,\n",
       "  1.442849259718603,\n",
       "  1.345301454149812,\n",
       "  -0.43866279656742435,\n",
       "  0.7838681388734423,\n",
       "  -0.17196886888152552,\n",
       "  0.774173546935396,\n",
       "  -0.34487957928525914,\n",
       "  1741824000.0,\n",
       "  -1.5157436773119377,\n",
       "  -1.3966062527980192,\n",
       "  -1.0346064061699378,\n",
       "  0.48772172101819544],\n",
       " [-1.1262006789558516,\n",
       "  0.6225968615715951,\n",
       "  1.5334982381189222,\n",
       "  1.3874992401558837,\n",
       "  -0.5728388774261195,\n",
       "  -1.7217989139701115,\n",
       "  0.2020000395173342,\n",
       "  -1.6020085933532382,\n",
       "  1783728000.0,\n",
       "  -0.6454141195951537,\n",
       "  -0.5479545253064981,\n",
       "  -0.10535467375854922,\n",
       "  1.0453161257920174],\n",
       " [1.1049739026160619,\n",
       "  -0.8784094127530244,\n",
       "  0.8949841868559898,\n",
       "  1.2874048716614783,\n",
       "  0.01536726551487319,\n",
       "  0.10762164753757074,\n",
       "  -1.5656697089458387,\n",
       "  0.24718297042140397,\n",
       "  1750550400.0,\n",
       "  1.7188222761347762,\n",
       "  1.3096106255746094,\n",
       "  0.7231623956614277,\n",
       "  0.9823346792869216],\n",
       " [1.4897561174346734,\n",
       "  -1.137590097155979,\n",
       "  1.2255159315511432,\n",
       "  1.211615042161276,\n",
       "  0.36693564956646535,\n",
       "  -1.2161906505684874,\n",
       "  -0.4364125583347608,\n",
       "  -1.2514354413360862,\n",
       "  1774569600.0,\n",
       "  0.11310267598197164,\n",
       "  0.6484323865937928,\n",
       "  1.3067129454035933,\n",
       "  -0.7446367500099417],\n",
       " [-0.875825147985701,\n",
       "  1.5187724053112468,\n",
       "  -1.7310314832731024,\n",
       "  -0.31059561181318507,\n",
       "  -1.3578060159886494,\n",
       "  1.0859667808563476,\n",
       "  -0.34409897419923563,\n",
       "  0.715040372852296,\n",
       "  1750032000.0,\n",
       "  0.24831786089980212,\n",
       "  0.2736155174831432,\n",
       "  -1.217236292424103,\n",
       "  -1.5520070355737525],\n",
       " [-0.3779924954153557,\n",
       "  0.042608661185358804,\n",
       "  0.6355360239026986,\n",
       "  0.22014128405006095,\n",
       "  0.8946265084074069,\n",
       "  1.3397772339253562,\n",
       "  1.1182157260884893,\n",
       "  1.0163635534816358,\n",
       "  1762732800.0,\n",
       "  -1.3567282192755246,\n",
       "  0.023944999333908187,\n",
       "  0.9518185262619427,\n",
       "  1.5490642506554715],\n",
       " [1.0377144150290525,\n",
       "  0.4292236433600677,\n",
       "  -1.5625453914670189,\n",
       "  -1.4981481547601652,\n",
       "  0.6656877080405799,\n",
       "  1.134788660630762,\n",
       "  -0.470946534639866,\n",
       "  1.5025107870941092,\n",
       "  1752710400.0,\n",
       "  1.53480062060464,\n",
       "  -0.03244873478360576,\n",
       "  -1.0464666540238186,\n",
       "  0.6573826153798835],\n",
       " [-1.1499051115687702,\n",
       "  -1.6459894748383561,\n",
       "  0.7772180919875118,\n",
       "  -0.9385636250460905,\n",
       "  -0.07205174600096823,\n",
       "  -0.3793239974495274,\n",
       "  -0.09506845593528977,\n",
       "  -0.22150939145705023,\n",
       "  1790294400.0,\n",
       "  -0.13883921663864462,\n",
       "  1.6445986208742716,\n",
       "  -0.788466949453125,\n",
       "  -1.3787084219837789],\n",
       " [0.3442983228881143,\n",
       "  1.350957266326201,\n",
       "  -0.4739853066353193,\n",
       "  1.32289229905197,\n",
       "  0.9295876411600974,\n",
       "  0.9222154365610344,\n",
       "  -0.6584419245115708,\n",
       "  -0.05464617079715269,\n",
       "  1767571200.0,\n",
       "  -0.807285834460949,\n",
       "  0.32942425043982526,\n",
       "  -1.2231332505758925,\n",
       "  0.944780627514293],\n",
       " [0.11276859682619103,\n",
       "  1.2823089597686836,\n",
       "  0.3930227423039119,\n",
       "  1.0801769764436773,\n",
       "  1.205683519916272,\n",
       "  0.9033308817153439,\n",
       "  -0.6868714609756107,\n",
       "  -0.4077161249902399,\n",
       "  1769126400.0,\n",
       "  1.6700514351661766,\n",
       "  -0.39607755360272245,\n",
       "  -0.3763316173000611,\n",
       "  0.33277924366564565],\n",
       " [0.6306777736166573,\n",
       "  -0.4874372982488548,\n",
       "  -1.328726371293968,\n",
       "  0.4850080717229541,\n",
       "  -1.148363580076913,\n",
       "  -1.6460699162726686,\n",
       "  0.780200826784521,\n",
       "  -0.9411129196960453,\n",
       "  1790208000.0,\n",
       "  -0.06998718873186668,\n",
       "  -0.3802725619230246,\n",
       "  -0.09399304155342618,\n",
       "  -0.22420176866803912],\n",
       " [0.8343315160450225,\n",
       "  -1.2118912574498977,\n",
       "  -0.6080309665423589,\n",
       "  -1.169756250668692,\n",
       "  0.9115272876651679,\n",
       "  0.24144363845212916,\n",
       "  0.0779707639053158,\n",
       "  -0.9390642562190811,\n",
       "  1778716800.0,\n",
       "  -0.4819224748550619,\n",
       "  0.4432956707766191,\n",
       "  1.216005465990923,\n",
       "  -1.2074718005484621],\n",
       " [0.5996282435707172,\n",
       "  -1.5089132613517502,\n",
       "  -1.150921697124744,\n",
       "  -0.5016293276235045,\n",
       "  0.24836043640069802,\n",
       "  0.21557178682217776,\n",
       "  0.3716475624298838,\n",
       "  0.5805708791487364,\n",
       "  1749168000.0,\n",
       "  -0.4081131840649703,\n",
       "  0.7418608768605247,\n",
       "  1.0748508607535112,\n",
       "  1.0052437940118115],\n",
       " [-1.4657008035529775,\n",
       "  1.107049908965331,\n",
       "  0.9163954612612067,\n",
       "  0.006598736404224025,\n",
       "  0.9329678485983086,\n",
       "  -0.08299943893795472,\n",
       "  -0.7922058371005146,\n",
       "  1.2350696381864843,\n",
       "  1774828800.0,\n",
       "  0.717256429228835,\n",
       "  0.010215489357741107,\n",
       "  -0.7207135080773942,\n",
       "  -0.31718942024149327],\n",
       " [1.0054669342663414,\n",
       "  -0.9400503319524944,\n",
       "  1.119648901026622,\n",
       "  -0.3505355714208659,\n",
       "  -1.3503751251648417,\n",
       "  0.7497674792707205,\n",
       "  1.3678858290967921,\n",
       "  -0.8454394828930645,\n",
       "  1775952000.0,\n",
       "  -0.8620491097065259,\n",
       "  -1.439509999642287,\n",
       "  -1.5403379803310544,\n",
       "  -1.0140712458637753],\n",
       " [1.3009103811384886,\n",
       "  -1.6410281204997643,\n",
       "  0.4872823242340994,\n",
       "  1.438838409094641,\n",
       "  0.22305895267106587,\n",
       "  -1.1936756809394848,\n",
       "  -0.722009564163846,\n",
       "  -0.5506259118691506,\n",
       "  1755561600.0,\n",
       "  0.09767793563930073,\n",
       "  -1.440754438517236,\n",
       "  0.06786444560327706,\n",
       "  0.4138020930461729],\n",
       " [-1.6827964032611793,\n",
       "  -1.0076819285747507,\n",
       "  -1.6498400049086666,\n",
       "  1.29730537835789,\n",
       "  0.08443948937238542,\n",
       "  -0.4248795191012611,\n",
       "  -1.137707732362558,\n",
       "  -0.9036156512211242,\n",
       "  1775433600.0,\n",
       "  -0.26107749566815924,\n",
       "  -1.3245839985960162,\n",
       "  0.08855689764944667,\n",
       "  1.5594573814985526],\n",
       " [0.2133695944463809,\n",
       "  1.047939766673435,\n",
       "  1.4306172144462583,\n",
       "  -0.5596821515650571,\n",
       "  -1.1688841840649882,\n",
       "  -0.3396676582268726,\n",
       "  -0.9861097595011528,\n",
       "  1.6267130440624387,\n",
       "  1784332800.0,\n",
       "  -0.4395784278995979,\n",
       "  -1.0537264443063756,\n",
       "  -0.6483383441777778,\n",
       "  1.3433854600843276],\n",
       " [1.3850368547845227,\n",
       "  1.4797502455646647,\n",
       "  -0.9076228009017955,\n",
       "  -0.14924476863390818,\n",
       "  -0.28322300570089537,\n",
       "  -0.08739775566901789,\n",
       "  -0.3813881137815541,\n",
       "  1.721482590011914,\n",
       "  1744934400.0,\n",
       "  1.1650828683829613,\n",
       "  1.593029896896545,\n",
       "  1.726714176671226,\n",
       "  -1.0285160294633606],\n",
       " [-0.786912924127677,\n",
       "  0.4406711361427059,\n",
       "  -0.5666289434319317,\n",
       "  -0.9516073073492157,\n",
       "  -0.763500334013359,\n",
       "  -1.4603449494930996,\n",
       "  1.3709350447739022,\n",
       "  1.346532691130868,\n",
       "  1772409600.0,\n",
       "  1.3571177723063534,\n",
       "  -0.7800402102598016,\n",
       "  0.9494549463636243,\n",
       "  0.29579972016402234],\n",
       " [-1.2411539968021599,\n",
       "  -0.6754939569529684,\n",
       "  -0.9819357466730445,\n",
       "  -1.4118946432011485,\n",
       "  -1.1212534588055842,\n",
       "  -0.6022772139566779,\n",
       "  -1.1395233064293855,\n",
       "  -0.35492494522474677,\n",
       "  1787443200.0,\n",
       "  1.5079576707219762,\n",
       "  0.8731802004736016,\n",
       "  -1.5930518645489902,\n",
       "  0.2609629868689602],\n",
       " [-0.41382615313564963,\n",
       "  0.2892734665025838,\n",
       "  1.5648929300708105,\n",
       "  1.228588210904741,\n",
       "  0.2892441702774876,\n",
       "  -0.274812231605452,\n",
       "  -1.424914646724827,\n",
       "  -0.6401704681655646,\n",
       "  1781481600.0,\n",
       "  0.3093794278785926,\n",
       "  1.5633191732243485,\n",
       "  0.8177720247956639,\n",
       "  1.4781567242818883],\n",
       " [-0.5440855479883627,\n",
       "  1.0152965680189554,\n",
       "  0.45245162240507836,\n",
       "  0.34875138527376365,\n",
       "  1.0806004253315566,\n",
       "  1.3640019402783805,\n",
       "  1.5731270092291527,\n",
       "  -0.7287676926247456,\n",
       "  1742428800.0,\n",
       "  -1.4704498018132646,\n",
       "  -0.8745958840482535,\n",
       "  -0.15683052666912478,\n",
       "  -1.0314808531152808],\n",
       " [-0.8399150803447197,\n",
       "  1.6964546207814324,\n",
       "  -0.14611847729198718,\n",
       "  1.2525646669169468,\n",
       "  -1.1704077772764638,\n",
       "  -0.5734280971992808,\n",
       "  -0.32116428045320006,\n",
       "  -1.1172574885634803,\n",
       "  1745971200.0,\n",
       "  1.0402842358443138,\n",
       "  1.4696336189221566,\n",
       "  0.40404947420802667,\n",
       "  -0.8209958897457504],\n",
       " [-1.402185275320166,\n",
       "  -0.8944385514209097,\n",
       "  1.2675337213278903,\n",
       "  -1.0639468149498732,\n",
       "  -1.1381018446929334,\n",
       "  -1.7353388917980506,\n",
       "  -1.2693048623390983,\n",
       "  -1.3564280938799562,\n",
       "  1771200000.0,\n",
       "  -1.4895119985418763,\n",
       "  0.8063523944339941,\n",
       "  0.9629073374662379,\n",
       "  -1.4488369342468392],\n",
       " [1.1167047094846059,\n",
       "  -0.48900142386743545,\n",
       "  0.8713935590686056,\n",
       "  1.7843439074792016,\n",
       "  0.5150238382422049,\n",
       "  -0.2679492648988249,\n",
       "  1.5200415203722146,\n",
       "  -1.4940465596169465,\n",
       "  1794009600.0,\n",
       "  -1.7159491230126342,\n",
       "  -0.28653515539749297,\n",
       "  1.3349829276283698,\n",
       "  0.883789266317189],\n",
       " [1.099911445288732,\n",
       "  1.163958287107167,\n",
       "  -1.1382142450892743,\n",
       "  -0.27235052968720436,\n",
       "  -1.1427116478510846,\n",
       "  0.4325600201087707,\n",
       "  -0.8787798326326293,\n",
       "  1.0357946670532605,\n",
       "  1746316800.0,\n",
       "  -1.2661327635219342,\n",
       "  -0.5790717995332534,\n",
       "  -1.3597704992196251,\n",
       "  -0.06550482631514441],\n",
       " [-0.26073498074601414,\n",
       "  0.23818017996518323,\n",
       "  0.3967214770959097,\n",
       "  1.0939666931626668,\n",
       "  -0.6863403343202241,\n",
       "  1.4936004859923901,\n",
       "  -0.5040168164355318,\n",
       "  -0.5849717728583353,\n",
       "  1740614400.0,\n",
       "  0.6765197459735961,\n",
       "  -0.570693019709803,\n",
       "  -0.5485736678964942,\n",
       "  -1.5135726852078537],\n",
       " [0.13130350940957272,\n",
       "  0.5127933102801749,\n",
       "  -0.15960263667102215,\n",
       "  0.9394336970593755,\n",
       "  0.6008955689072475,\n",
       "  -1.5089890614676176,\n",
       "  -1.149295572015115,\n",
       "  -0.5048192019953142,\n",
       "  1749081600.0,\n",
       "  0.2504537269575108,\n",
       "  0.21490196235492082,\n",
       "  0.3728160761367286,\n",
       "  0.578177088000171],\n",
       " [-0.1963384765992712,\n",
       "  0.5215471325455533,\n",
       "  -1.2934558025749368,\n",
       "  -0.8588001300688287,\n",
       "  -0.7543079852994953,\n",
       "  0.016459033534181836,\n",
       "  0.05551793331316373,\n",
       "  0.060766318504917614,\n",
       "  1770854400.0,\n",
       "  0.11824520333219221,\n",
       "  0.5363697335433635,\n",
       "  -0.8365789452258969,\n",
       "  -1.2904751291644425],\n",
       " [0.25798550844917956,\n",
       "  0.034526025832762465,\n",
       "  -1.510122153365984,\n",
       "  1.1546162851548774,\n",
       "  -0.38693461391521494,\n",
       "  0.6359218221032141,\n",
       "  -1.5213769927809901,\n",
       "  -0.6527867542888174,\n",
       "  1792713600.0,\n",
       "  0.13689598543413328,\n",
       "  -0.04706092325675873,\n",
       "  0.3779158340541129,\n",
       "  -0.8648680613137696],\n",
       " [-0.8717181814491208,\n",
       "  -0.5498938272172675,\n",
       "  -0.03693451272114195,\n",
       "  1.657946233195868,\n",
       "  0.22526862072961348,\n",
       "  1.4068697590599823,\n",
       "  -0.2479321497702432,\n",
       "  -0.8741558151477175,\n",
       "  1753920000.0,\n",
       "  -0.7414135080846177,\n",
       "  0.9088841021638866,\n",
       "  0.08285894882356182,\n",
       "  -0.7337932014676231],\n",
       " [0.0830912066568146,\n",
       "  -0.4248404250419962,\n",
       "  -1.1393420047667548,\n",
       "  -0.9010113019397697,\n",
       "  -0.263124918256578,\n",
       "  -1.3231931816990463,\n",
       "  0.08744507593218385,\n",
       "  1.5614860127023682,\n",
       "  1775520000.0,\n",
       "  0.6150809992254619,\n",
       "  -1.6387209655310264,\n",
       "  0.5490504343312739,\n",
       "  -1.0110441644606027],\n",
       " [-0.45304923507870287,\n",
       "  -1.548033267509051,\n",
       "  0.528540515460988,\n",
       "  1.393944571370965,\n",
       "  -0.12725622075175907,\n",
       "  1.670319105192356,\n",
       "  -1.6242315934370781,\n",
       "  1.3119532119043469,\n",
       "  1777939200.0,\n",
       "  1.4862376697725754,\n",
       "  1.4007551664450577,\n",
       "  1.3126097498689024,\n",
       "  0.12942590155712366],\n",
       " [-1.31093021581543,\n",
       "  -1.4341031442799428,\n",
       "  -1.667026389435403,\n",
       "  0.8862901583045318,\n",
       "  1.3951872632857,\n",
       "  -0.3396096275666009,\n",
       "  0.19529813261780635,\n",
       "  1.5514860130853878,\n",
       "  1776384000.0,\n",
       "  -1.1168298084854078,\n",
       "  -0.7461342356816163,\n",
       "  -0.8611013342172719,\n",
       "  -1.1534160324064089],\n",
       " [-0.32210094299723196,\n",
       "  0.24090126483859983,\n",
       "  1.4028192039387244,\n",
       "  1.7603590380682665,\n",
       "  1.627349940779439,\n",
       "  0.6962858041977945,\n",
       "  0.2695664999999226,\n",
       "  0.9409531403424469,\n",
       "  1782345600.0,\n",
       "  -1.6805238517722305,\n",
       "  -0.7269973566966281,\n",
       "  0.448080812826249,\n",
       "  -1.0693504407941874],\n",
       " [1.2181031782836946,\n",
       "  -1.0275980081134113,\n",
       "  -1.7532562539046075,\n",
       "  1.6514670111268828,\n",
       "  0.8424565851289937,\n",
       "  -1.0240204819734748,\n",
       "  0.3441464134019195,\n",
       "  -1.014858495347451,\n",
       "  1736726400.0,\n",
       "  0.4310826751813547,\n",
       "  0.6767712635081425,\n",
       "  1.2651498738337277,\n",
       "  -0.06509061408941857],\n",
       " [-0.018082968677220927,\n",
       "  0.2645936479800045,\n",
       "  0.7372640027636237,\n",
       "  1.220889387900406,\n",
       "  1.2788161109924705,\n",
       "  0.7054719771894261,\n",
       "  1.4496967471879068,\n",
       "  1.113914870307583,\n",
       "  1793059200.0,\n",
       "  -0.7104514771821325,\n",
       "  0.7165013689962255,\n",
       "  0.7096141864438846,\n",
       "  -0.36526186255553295],\n",
       " [-0.809137443826899,\n",
       "  -0.6811735706691964,\n",
       "  -0.08956869846292337,\n",
       "  1.5137232871586053,\n",
       "  -1.4623733988261023,\n",
       "  -1.6799488468520474,\n",
       "  -0.10489525480304401,\n",
       "  0.9561349748310962,\n",
       "  1739145600.0,\n",
       "  -0.6353811490977782,\n",
       "  -0.019407694899710386,\n",
       "  -0.519125165992306,\n",
       "  0.8502323556924923],\n",
       " [1.0369112657776307,\n",
       "  -0.38467578046720907,\n",
       "  -1.2005492816130519,\n",
       "  -0.3990565023831938,\n",
       "  0.33052734402205763,\n",
       "  -0.6915595980173181,\n",
       "  1.6577324023041318,\n",
       "  -1.1375001715921786,\n",
       "  1775088000.0,\n",
       "  -0.08005281967602763,\n",
       "  -1.046620750951042,\n",
       "  -0.24591522036036004,\n",
       "  -0.16602094531028658],\n",
       " [1.6008081390890516,\n",
       "  0.18764572223049686,\n",
       "  0.19540657139521916,\n",
       "  1.033283557353103,\n",
       "  -0.05938989730928101,\n",
       "  -1.0990197328850138,\n",
       "  1.1517442954797221,\n",
       "  0.29987013068958374,\n",
       "  1748044800.0,\n",
       "  0.33782577272120423,\n",
       "  1.5142192548769682,\n",
       "  -1.732531026114846,\n",
       "  -0.641299722198266],\n",
       " [-1.1975230190579025,\n",
       "  -1.2522095654640872,\n",
       "  -1.800085008257161,\n",
       "  0.9321992228165037,\n",
       "  -1.2920273489343388,\n",
       "  1.41132756863445,\n",
       "  0.512655990166873,\n",
       "  -1.122596043223871,\n",
       "  1757894400.0,\n",
       "  -1.3770988486686777,\n",
       "  1.6470321251471254,\n",
       "  -1.7370280122719433,\n",
       "  -1.0873391299419615],\n",
       " [-0.3531064691823883,\n",
       "  1.1023879255353288,\n",
       "  1.4297796121260837,\n",
       "  0.4130603245258763,\n",
       "  -1.546818728466015,\n",
       "  -0.4298397937742101,\n",
       "  0.07349217078357989,\n",
       "  0.1680543844530182,\n",
       "  1762214400.0,\n",
       "  -0.06305050363639261,\n",
       "  -1.5231208171046002,\n",
       "  0.8137653446562484,\n",
       "  1.6086759186248627],\n",
       " [1.284492065898571,\n",
       "  -1.3734417189944583,\n",
       "  0.9429175916217394,\n",
       "  0.7034113726875735,\n",
       "  0.48710451731724164,\n",
       "  -1.3649600128912018,\n",
       "  -1.7699957485835702,\n",
       "  0.7732245898404324,\n",
       "  1781136000.0,\n",
       "  -0.471619619389832,\n",
       "  1.3471782430217583,\n",
       "  0.8465514895740348,\n",
       "  0.03799875088020223],\n",
       " [-1.1695386134792158,\n",
       "  0.060413966692020746,\n",
       "  1.1412649435100437,\n",
       "  0.47856111857672046,\n",
       "  -0.4123999880531359,\n",
       "  0.2892585519117509,\n",
       "  1.568429860845665,\n",
       "  1.2228617028190834,\n",
       "  1781395200.0,\n",
       "  0.2913411271246374,\n",
       "  -0.2757118268123419,\n",
       "  -1.4241045066807183,\n",
       "  -0.6430186980598391],\n",
       " [-0.594991297733765,\n",
       "  0.3843307068772489,\n",
       "  -0.533283779013751,\n",
       "  0.7864228090899061,\n",
       "  1.5515201803261665,\n",
       "  -0.951700375987416,\n",
       "  -0.9724675697833994,\n",
       "  -0.7786002378758328,\n",
       "  1767830400.0,\n",
       "  -0.2596083459041224,\n",
       "  -1.2703097597640154,\n",
       "  0.32348576368850485,\n",
       "  -0.8428069506463831],\n",
       " [0.22666566253230122,\n",
       "  -0.06873824144250898,\n",
       "  -1.7840711383733898,\n",
       "  -0.3309586199028227,\n",
       "  1.1568914964660018,\n",
       "  0.804632120749804,\n",
       "  0.819985520627029,\n",
       "  -1.5949725026456172,\n",
       "  1741132800.0,\n",
       "  0.04750184298863188,\n",
       "  -1.1820506759981801,\n",
       "  -0.5764773833828544,\n",
       "  1.4058573439320086],\n",
       " [-1.096742471900883,\n",
       "  -0.3841575837663814,\n",
       "  -0.42656120775069545,\n",
       "  0.3053656933198757,\n",
       "  0.5447675821865333,\n",
       "  1.5755794760352402,\n",
       "  0.8619179511497141,\n",
       "  -0.27556196716858344,\n",
       "  1745625600.0,\n",
       "  -1.2204026439500928,\n",
       "  0.2943977549504343,\n",
       "  -0.6712107977172145,\n",
       "  -0.9885555204820072],\n",
       " [1.4829046804576824,\n",
       "  1.400846893833884,\n",
       "  1.3078976930432258,\n",
       "  0.13611153687132058,\n",
       "  -1.5174323365607423,\n",
       "  0.029674852031996917,\n",
       "  -0.4485450646422689,\n",
       "  -0.681180271273321,\n",
       "  1778112000.0,\n",
       "  -0.8166352108905469,\n",
       "  1.4668909935872836,\n",
       "  -1.3768628688875386,\n",
       "  -1.3889535558978139],\n",
       " [0.9413856011872284,\n",
       "  1.601835019766252,\n",
       "  -0.5571581625673543,\n",
       "  -1.605000129886863,\n",
       "  -1.3062155963200175,\n",
       "  0.17817462473338147,\n",
       "  1.4272961883600188,\n",
       "  0.6445788844495296,\n",
       "  1779321600.0,\n",
       "  -0.7750730017347831,\n",
       "  0.013769482160304857,\n",
       "  0.6941465116847053,\n",
       "  1.5111565165101621],\n",
       " [-0.5058370435926156,\n",
       "  1.6084029041905155,\n",
       "  1.1707479683218187,\n",
       "  0.3557526835962033,\n",
       "  1.1510603752640722,\n",
       "  0.7480037005932358,\n",
       "  0.10775462577320327,\n",
       "  -0.11121758472058349,\n",
       "  1794441600.0,\n",
       "  -1.2827833120595384,\n",
       "  -0.7547454264363029,\n",
       "  0.8770856908816802,\n",
       "  -0.7424747310767513],\n",
       " [-1.0435909826557626,\n",
       "  0.9446526871105055,\n",
       "  1.580439835417072,\n",
       "  0.8643030419258813,\n",
       "  -1.1565630451646793,\n",
       "  -1.1310037314401027,\n",
       "  1.0774323182693446,\n",
       "  0.443961335664906,\n",
       "  1758672000.0,\n",
       "  -0.47205825006166996,\n",
       "  -0.7586175763921313,\n",
       "  0.2773091445310929,\n",
       "  -1.5363379689921934],\n",
       " [1.5395371342672135,\n",
       "  0.6624209711333906,\n",
       "  1.6257412448406734,\n",
       "  0.6116053699639581,\n",
       "  0.9523779013230577,\n",
       "  1.3062732436882327,\n",
       "  1.7175785156656118,\n",
       "  0.9485645889647448,\n",
       "  1786492800.0,\n",
       "  -0.651371038057081,\n",
       "  -0.7269467124396695,\n",
       "  -1.0984037983887995,\n",
       "  -0.37416196004239805],\n",
       " [-1.0351381988775945,\n",
       "  -0.20397445513657647,\n",
       "  -1.761356072417699,\n",
       "  1.3720326419636613,\n",
       "  -0.9808037813005915,\n",
       "  -1.3025585011640046,\n",
       "  -0.268074824532819,\n",
       "  0.6325030378115297,\n",
       "  1761696000.0,\n",
       "  0.6218944500150195,\n",
       "  0.42486951596886496,\n",
       "  -0.08375916969484994,\n",
       "  -1.1543641886374216],\n",
       " [-0.7316098514215288,\n",
       "  0.9448397092940604,\n",
       "  -0.036130421204324775,\n",
       "  1.7445322068686127,\n",
       "  -0.4571610110382303,\n",
       "  -0.12988699312156818,\n",
       "  0.024716911198014724,\n",
       "  -0.7406323731498348,\n",
       "  1771804800.0,\n",
       "  -1.4097558361605984,\n",
       "  1.633895024979457,\n",
       "  0.5639306129717243,\n",
       "  -0.7115747054856674],\n",
       " [0.9450397164203227,\n",
       "  -1.1342034015466376,\n",
       "  -0.1716967025304708,\n",
       "  0.06740821675086685,\n",
       "  0.13264423576153467,\n",
       "  0.5127859639373072,\n",
       "  -0.15727903462103318,\n",
       "  0.93413111201923,\n",
       "  1748995200.0,\n",
       "  0.6030204734099306,\n",
       "  -1.5104669335195495,\n",
       "  -1.148430452178589,\n",
       "  -0.5076170454094684],\n",
       " [0.46920766035732475,\n",
       "  0.5542508729140755,\n",
       "  -1.3433651601812822,\n",
       "  0.26891696609648985,\n",
       "  0.963172298558844,\n",
       "  -1.5939481418931571,\n",
       "  1.035329719727658,\n",
       "  1.5282995733255365,\n",
       "  1773446400.0,\n",
       "  0.20920519362167347,\n",
       "  -1.6329611325433107,\n",
       "  0.07706403492210014,\n",
       "  -0.9066026458925897],\n",
       " [1.2896066189209077,\n",
       "  0.7256321154227103,\n",
       "  0.4506436311268569,\n",
       "  1.469536571141793,\n",
       "  -0.32615321298151073,\n",
       "  0.2814047794196143,\n",
       "  1.260790851670208,\n",
       "  0.7923533479093127,\n",
       "  1774051200.0,\n",
       "  0.8731470246403845,\n",
       "  -1.0115359881413588,\n",
       "  0.529660979356056,\n",
       "  0.8733690490595968],\n",
       " [-1.6394709476289278,\n",
       "  0.8579949684544445,\n",
       "  -0.2688668693016606,\n",
       "  -1.325053995788757,\n",
       "  0.011063682226945211,\n",
       "  -1.5947680949492498,\n",
       "  -0.4118567813828846,\n",
       "  0.9092886191194137,\n",
       "  1759017600.0,\n",
       "  1.4234689039573325,\n",
       "  -0.12593211170117757,\n",
       "  -0.19229761242281915,\n",
       "  -0.17432786270431036],\n",
       " [-0.2151397045168771,\n",
       "  -0.9867293433145171,\n",
       "  -1.0545366556212,\n",
       "  -1.6178128367489957,\n",
       "  -0.20563377142975844,\n",
       "  -1.499199353317068,\n",
       "  1.1133293420072088,\n",
       "  1.3518443483667755,\n",
       "  1788307200.0,\n",
       "  -0.0009402501364219113,\n",
       "  -1.34869226805411,\n",
       "  -0.7260906791250149,\n",
       "  1.298781062822757],\n",
       " [-1.6222512664211999,\n",
       "  -1.2985892237410752,\n",
       "  -0.8482611358508912,\n",
       "  -0.09433098422797438,\n",
       "  0.05973651535530049,\n",
       "  -1.4401348836905863,\n",
       "  1.231273458018258,\n",
       "  -0.9861244477740291,\n",
       "  1767052800.0,\n",
       "  -1.4535081910386403,\n",
       "  -1.318478436481074,\n",
       "  -0.7167980171331972,\n",
       "  -1.5906042119630899],\n",
       " [1.1717750893233299,\n",
       "  0.9117261965085031,\n",
       "  -0.3769654477780235,\n",
       "  0.8682233045095193,\n",
       "  0.6061215914840514,\n",
       "  0.38435960111766404,\n",
       "  1.1874905589483826,\n",
       "  1.2229255776480241,\n",
       "  1789344000.0,\n",
       "  0.015976079125696013,\n",
       "  -1.6081993418541325,\n",
       "  1.1404405707710583,\n",
       "  -0.6286909431193447],\n",
       " [-0.6388564429463185,\n",
       "  -0.01860279633769895,\n",
       "  -0.5221842881532441,\n",
       "  0.85770767631943,\n",
       "  0.9706333887334534,\n",
       "  1.3223730168882746,\n",
       "  0.07270772080354074,\n",
       "  -0.11677056107280252,\n",
       "  1739318400.0,\n",
       "  0.011115095996336402,\n",
       "  -1.5474732410683811,\n",
       "  1.261819502729991,\n",
       "  1.572813390888256],\n",
       " [0.5598088008402768,\n",
       "  -1.5088157951137762,\n",
       "  -0.6787505041498787,\n",
       "  -0.2566816122984387,\n",
       "  0.3346459563792209,\n",
       "  0.07941278380323213,\n",
       "  -0.308632619585984,\n",
       "  0.0802820409891123,\n",
       "  1747008000.0,\n",
       "  -1.1916009138219845,\n",
       "  0.9206471661930858,\n",
       "  0.872116122262452,\n",
       "  0.8880650269002566],\n",
       " [1.3537761224598748,\n",
       "  -0.7788533405886257,\n",
       "  0.9450705958879125,\n",
       "  0.3026676276543696,\n",
       "  -0.1880476607960332,\n",
       "  -0.2550074650330579,\n",
       "  0.9098387409693557,\n",
       "  0.5621232617379479,\n",
       "  1772582400.0,\n",
       "  -0.5345331593329615,\n",
       "  0.12196856919702864,\n",
       "  -0.9627505410610546,\n",
       "  0.7101190262074533],\n",
       " [-1.4132830700785473,\n",
       "  1.6338696752139987,\n",
       "  0.5598941548298026,\n",
       "  -0.7058104351558954,\n",
       "  -1.0489906151632777,\n",
       "  1.1746596568195633,\n",
       "  1.0429748946614519,\n",
       "  0.3185956119816483,\n",
       "  1771977600.0,\n",
       "  0.1708553426986691,\n",
       "  0.9614053358011535,\n",
       "  -1.4416128091241218,\n",
       "  -1.5164872535414076],\n",
       " [1.3142644856750945,\n",
       "  0.5018100249779678,\n",
       "  -0.6186839896541484,\n",
       "  -1.4502629214726068,\n",
       "  -0.33532792767753594,\n",
       "  -1.0705136482821493,\n",
       "  -0.5045327007310222,\n",
       "  0.4841170802590673,\n",
       "  1762560000.0,\n",
       "  -0.3745346974677391,\n",
       "  0.04183451696939877,\n",
       "  0.639640801971695,\n",
       "  0.21336369001608604],\n",
       " [-1.6771536538817375,\n",
       "  0.2055365181333214,\n",
       "  0.43811847971841966,\n",
       "  -1.1489978555681455,\n",
       "  1.4068573332054077,\n",
       "  -0.5523766629498412,\n",
       "  -0.5131593951119088,\n",
       "  -1.375636587491944,\n",
       "  1753142400.0,\n",
       "  0.18813442636932012,\n",
       "  -0.4109935097535138,\n",
       "  0.6490019496422297,\n",
       "  -0.2282901306332935],\n",
       " [-0.9665397785424648,\n",
       "  0.7533399971208564,\n",
       "  1.1502022876667113,\n",
       "  1.6867429034017145,\n",
       "  0.3761501112512322,\n",
       "  -0.3574620543025515,\n",
       "  -0.83350013995593,\n",
       "  0.6310510413968202,\n",
       "  1766361600.0,\n",
       "  -1.6701414344715992,\n",
       "  1.157578461386121,\n",
       "  1.2298352981803866,\n",
       "  0.008360718597237205],\n",
       " [-0.35336068190981446,\n",
       "  1.5751218936113152,\n",
       "  -0.6503186592134222,\n",
       "  0.07644774470468413,\n",
       "  0.48720756478956045,\n",
       "  -0.4033854848413359,\n",
       "  1.0623065666649476,\n",
       "  -0.5161389630065994,\n",
       "  1788912000.0,\n",
       "  -0.04823393426665432,\n",
       "  -0.5828356946900779,\n",
       "  -0.17364914874154927,\n",
       "  -1.0137549567272572],\n",
       " [-0.06702744362560183,\n",
       "  1.4351789320512138,\n",
       "  -1.5755305582657588,\n",
       "  0.648345207037812,\n",
       "  0.8445874936185539,\n",
       "  -0.13208542777111668,\n",
       "  0.22150895655691621,\n",
       "  -0.00246062633448588,\n",
       "  1748649600.0,\n",
       "  0.6345355100015477,\n",
       "  1.6275690443383957,\n",
       "  1.7042871220738736,\n",
       "  0.6556012826265167],\n",
       " [0.9317525774489225,\n",
       "  -0.08297192034139292,\n",
       "  -0.7940830284437738,\n",
       "  1.2408140703345907,\n",
       "  0.7151212814194305,\n",
       "  0.010981175301646027,\n",
       "  -0.7216639307867,\n",
       "  -0.3144624399044292,\n",
       "  1774915200.0,\n",
       "  1.0402741674536211,\n",
       "  -0.3856646043217974,\n",
       "  -1.198102860426472,\n",
       "  -0.40515647167543717],\n",
       " [-1.550862380978937,\n",
       "  1.628809463928368,\n",
       "  1.485909816239513,\n",
       "  0.6430809833423059,\n",
       "  -0.2860150903483325,\n",
       "  -0.09049062231789615,\n",
       "  -0.4810813552384026,\n",
       "  -0.504342010010393,\n",
       "  1791763200.0,\n",
       "  -1.6158342630467395,\n",
       "  0.7006909496357581,\n",
       "  -0.2208112100661909,\n",
       "  1.7031116082043922],\n",
       " [0.5212918128684925,\n",
       "  -0.2153176599486097,\n",
       "  0.0736170134053313,\n",
       "  -1.4105428428068538,\n",
       "  1.2856520518265147,\n",
       "  -1.3735129321250834,\n",
       "  0.9460169100542646,\n",
       "  0.6984548147636087,\n",
       "  1781049600.0,\n",
       "  0.48921921749186265,\n",
       "  -1.366370399748314,\n",
       "  -1.7692544444404863,\n",
       "  0.7709025168415271],\n",
       " [0.4142187627739567,\n",
       "  -0.012663215544616394,\n",
       "  -0.009603761493017242,\n",
       "  1.4310096072126433,\n",
       "  -0.3553611750431796,\n",
       "  0.6932679097609958,\n",
       "  0.9114231153956647,\n",
       "  -1.6393030678740572,\n",
       "  1772236800.0,\n",
       "  -0.7834277002694502,\n",
       "  0.44009698963306265,\n",
       "  -0.5636099637958243,\n",
       "  -0.9571025876314009],\n",
       " [0.8697729131514407,\n",
       "  -1.0102328669331284,\n",
       "  0.5256554457026401,\n",
       "  0.8808697172771847,\n",
       "  -0.6842025324496739,\n",
       "  1.4037737162160493,\n",
       "  -1.5219101615904624,\n",
       "  -0.3702117770362625,\n",
       "  1774224000.0,\n",
       "  0.4979379798092691,\n",
       "  -0.7866370729273261,\n",
       "  0.03649464550229156,\n",
       "  -0.8547622880121266],\n",
       " [0.012544474127280814,\n",
       "  -1.6065965908530477,\n",
       "  1.1358838772579802,\n",
       "  -0.6228358688165646,\n",
       "  -0.13749775978153386,\n",
       "  -1.1384025234959978,\n",
       "  0.8336274994147698,\n",
       "  0.1226512734666488,\n",
       "  1789516800.0,\n",
       "  -0.8078760045654294,\n",
       "  -0.4961582292897046,\n",
       "  0.08135645192023823,\n",
       "  1.5227339844332413],\n",
       " [0.8433583683542074,\n",
       "  -0.1320562472086611,\n",
       "  0.2189190324455775,\n",
       "  0.0014668261953683962,\n",
       "  0.6324077796093815,\n",
       "  1.6275772698709112,\n",
       "  1.7028530628776384,\n",
       "  0.6579662622165302,\n",
       "  1748736000.0,\n",
       "  0.8266510919046733,\n",
       "  -0.5205565087110087,\n",
       "  -1.261274730398484,\n",
       "  0.1864614114838841],\n",
       " [0.45463250001537137,\n",
       "  -0.35041978398979573,\n",
       "  1.5681643895988164,\n",
       "  0.08204816676981942,\n",
       "  -0.37832379077822303,\n",
       "  -0.9313346542484364,\n",
       "  0.639814574086834,\n",
       "  -0.764918287822745,\n",
       "  1783123200.0,\n",
       "  -0.2721054248579874,\n",
       "  -0.3250423661322875,\n",
       "  1.7273099849072913,\n",
       "  0.01658634877296122],\n",
       " [-0.2957989111281044,\n",
       "  -0.4835099111321013,\n",
       "  -1.0655712305407343,\n",
       "  1.250227278194472,\n",
       "  0.9747368010124872,\n",
       "  0.5299483046054759,\n",
       "  -1.0346024464992576,\n",
       "  -1.4746484796678117,\n",
       "  1766102400.0,\n",
       "  1.1633256069218374,\n",
       "  -1.235033657835034,\n",
       "  0.4030076828762492,\n",
       "  1.6728702602912746],\n",
       " [-1.3519483230962555,\n",
       "  0.7497668018331716,\n",
       "  1.364489898831908,\n",
       "  -0.8427497175898554,\n",
       "  -0.8640426443878548,\n",
       "  -1.4380653590802543,\n",
       "  -1.541124939041451,\n",
       "  -1.011084937656145,\n",
       "  1776038400.0,\n",
       "  -0.9523875336862562,\n",
       "  1.590837330811309,\n",
       "  0.5167031913037816,\n",
       "  -1.3411786401437873],\n",
       " [0.8341807458801909,\n",
       "  0.3582018241662812,\n",
       "  -1.0170397059631475,\n",
       "  0.8127835764374433,\n",
       "  1.0885062093325297,\n",
       "  0.16725334549159437,\n",
       "  1.343335001197882,\n",
       "  -1.1696935471208545,\n",
       "  1764115200.0,\n",
       "  0.43727516939715605,\n",
       "  0.5500388869749867,\n",
       "  -1.5196514479347687,\n",
       "  -0.15942578728562076],\n",
       " [0.6394031458209175,\n",
       "  1.435527439867474,\n",
       "  0.5846165022460592,\n",
       "  -0.20704075010052517,\n",
       "  -0.9715834758446108,\n",
       "  1.0262237529347336,\n",
       "  -0.7866079600773697,\n",
       "  0.9054780644514528,\n",
       "  1752105600.0,\n",
       "  0.2705668749727738,\n",
       "  -0.31437016994206823,\n",
       "  -1.355384590643877,\n",
       "  -1.5513158243676608],\n",
       " [-0.19740737445235318,\n",
       "  -1.703090331686214,\n",
       "  -0.6653823112061101,\n",
       "  1.558464128055131,\n",
       "  -1.5473431452602995,\n",
       "  -0.849780396947833,\n",
       "  0.116702323675955,\n",
       "  -1.6247669976891048,\n",
       "  1746662400.0,\n",
       "  1.1549024075956964,\n",
       "  -1.589726824583309,\n",
       "  -0.6887096851947488,\n",
       "  -1.0946021547808398],\n",
       " [-1.7247622647337675,\n",
       "  1.1199972576367796,\n",
       "  -1.1428922103668087,\n",
       "  -1.5332333115820607,\n",
       "  -1.2768840509699633,\n",
       "  1.6520696938322332,\n",
       "  0.0221048446038346,\n",
       "  -1.313371538559635,\n",
       "  1787011200.0,\n",
       "  0.6649071496984815,\n",
       "  0.23141129976890862,\n",
       "  0.10502754444647704,\n",
       "  -0.6158808054049177],\n",
       " [-0.4436030655149031,\n",
       "  1.7022025704155188,\n",
       "  -0.5246734982736111,\n",
       "  -1.1956941572575033,\n",
       "  -1.0111035286622785,\n",
       "  1.3451387893942524,\n",
       "  -1.7626422061021678,\n",
       "  0.12895299094970858,\n",
       "  1744329600.0,\n",
       "  -1.6267319473692678,\n",
       "  -1.0467751111292336,\n",
       "  -0.15968948364079588,\n",
       "  -1.1454709056389514],\n",
       " [-0.572876689679952,\n",
       "  0.45044061111063594,\n",
       "  -1.0930988906054933,\n",
       "  -0.7179479574926066,\n",
       "  -0.9109366924913518,\n",
       "  1.344588916875433,\n",
       "  -0.28737584526281135,\n",
       "  1.72702360095142,\n",
       "  1748390400.0,\n",
       "  0.1368719658287759,\n",
       "  1.5225156493836804,\n",
       "  -0.5235191477392476,\n",
       "  -1.6022272244725915],\n",
       " [1.2517235196487293,\n",
       "  -0.22063338305323493,\n",
       "  -1.7694326502590636,\n",
       "  -1.2313722297448144,\n",
       "  0.2912341210450512,\n",
       "  1.2445602135994893,\n",
       "  -1.2698948867642135,\n",
       "  -0.005022133413140808,\n",
       "  1756684800.0,\n",
       "  -1.694564296724399,\n",
       "  -1.700389657142975,\n",
       "  -0.17137510299184008,\n",
       "  -1.1421128577817772],\n",
       " [-1.328774610292419,\n",
       "  -0.9372740251896202,\n",
       "  0.4943615092782489,\n",
       "  0.9808138647917931,\n",
       "  -0.8615960580908297,\n",
       "  0.021856866054307773,\n",
       "  -1.2743652133904653,\n",
       "  0.9939047193477952,\n",
       "  1770076800.0,\n",
       "  -0.44240788116814167,\n",
       "  1.1340166545226356,\n",
       "  0.6692915646836625,\n",
       "  0.6827725532465769],\n",
       " [-1.1203373948109658,\n",
       "  -0.7449643927644318,\n",
       "  -0.863851861363681,\n",
       "  -1.1481358248988125,\n",
       "  -0.6481126023831495,\n",
       "  1.7192264106725572,\n",
       "  1.6994996933874522,\n",
       "  1.3972293536468816,\n",
       "  1776556800.0,\n",
       "  0.7354168111244871,\n",
       "  -0.6062021835980512,\n",
       "  0.761992663435701,\n",
       "  -1.282759193071718],\n",
       " [-0.06564187836712157,\n",
       "  -0.47097794797427317,\n",
       "  1.6300805705088244,\n",
       "  0.4195156634839602,\n",
       "  -1.6755294861856236,\n",
       "  0.2055187682595965,\n",
       "  0.4408626292107799,\n",
       "  -1.1512386372410883,\n",
       "  1753056000.0,\n",
       "  1.409054513147446,\n",
       "  -0.5534063117112705,\n",
       "  -0.5121673804478317,\n",
       "  -1.3787586053606438],\n",
       " [-1.0126235438733717,\n",
       "  1.345117953723467,\n",
       "  -1.7638370933063818,\n",
       "  0.13307338895411946,\n",
       "  -1.628656914489756,\n",
       "  -1.0455144013653273,\n",
       "  -0.16075179567701064,\n",
       "  -1.1424357001969412,\n",
       "  1744416000.0,\n",
       "  -0.29275682205788506,\n",
       "  -0.21015902526951544,\n",
       "  -1.7284162891084507,\n",
       "  -0.5590956171117949],\n",
       " [1.6902165080693772,\n",
       "  1.013205027137217,\n",
       "  -0.8180855107202485,\n",
       "  -0.47120233585884175,\n",
       "  1.0777796059505795,\n",
       "  -1.1631612698333162,\n",
       "  -1.5337776439521742,\n",
       "  1.4192833825771962,\n",
       "  1768089600.0,\n",
       "  -0.39517900663102445,\n",
       "  -1.3494090996524586,\n",
       "  -0.25416360860321585,\n",
       "  -0.7436421894919297],\n",
       " [-1.1239976391678816,\n",
       "  -0.783516080389497,\n",
       "  -0.011068782453054366,\n",
       "  -1.6128961989868995,\n",
       "  0.8354113095627111,\n",
       "  0.3581892434483333,\n",
       "  -1.0153193835306888,\n",
       "  0.8076666703415222,\n",
       "  1764028800.0,\n",
       "  1.0906748408143723,\n",
       "  0.16656088128979216,\n",
       "  1.3446973446450452,\n",
       "  -1.1727388996933719],\n",
       " [0.3127031402262189,\n",
       "  -0.10749085666113375,\n",
       "  -1.1251416533570178,\n",
       "  -0.935167389327601,\n",
       "  -1.1462339312810441,\n",
       "  -1.5619382414520586,\n",
       "  -0.7645855479307806,\n",
       "  1.5910197867355893,\n",
       "  1760140800.0,\n",
       "  0.4918961378967791,\n",
       "  -1.333838432829599,\n",
       "  -0.43232580940453313,\n",
       "  0.24572622960121415],\n",
       " [-0.014631914362697736,\n",
       "  1.441596503943014,\n",
       "  -0.7093305917311417,\n",
       "  -0.0809524970583157,\n",
       "  -1.6395959802410176,\n",
       "  -0.11167061822808333,\n",
       "  1.5100986750167131,\n",
       "  -0.023796300627494004,\n",
       "  1761350400.0,\n",
       "  1.7184852365342143,\n",
       "  1.160926009264764,\n",
       "  0.22462784369943029,\n",
       "  1.2235100231010976],\n",
       " [-1.2935914005254856,\n",
       "  1.4113044919271436,\n",
       "  0.5098613634779638,\n",
       "  -1.1203132076222002,\n",
       "  -1.3790461998833812,\n",
       "  1.6470312354721768,\n",
       "  -1.737775743579724,\n",
       "  -1.0843255568471433,\n",
       "  1757980800.0,\n",
       "  1.6850433986375397,\n",
       "  0.7974604396836037,\n",
       "  -1.468761184189318,\n",
       "  1.3356637114995518],\n",
       " [1.4774628814390345,\n",
       "  1.6955161977530706,\n",
       "  1.6138618104735392,\n",
       "  0.31983940327723054,\n",
       "  -1.0181582767332384,\n",
       "  0.6162175060337187,\n",
       "  1.164563584776313,\n",
       "  -1.4184739118768,\n",
       "  1770595200.0,\n",
       "  -1.506981189563138,\n",
       "  1.4127636589449342,\n",
       "  -0.07752767034196315,\n",
       "  1.4309133257046622],\n",
       " [0.1325113955711112,\n",
       "  0.37046756832330435,\n",
       "  0.0909421123046422,\n",
       "  1.4024925521615723,\n",
       "  -0.19601512890676562,\n",
       "  -1.7031727065213216,\n",
       "  -0.6634145680051676,\n",
       "  1.552253996174085,\n",
       "  1746576000.0,\n",
       "  -1.545410886245013,\n",
       "  -0.8509493950219692,\n",
       "  0.1178199815546277,\n",
       "  -1.6279817579813958],\n",
       " [-0.5459944649104417,\n",
       "  0.06053966557213685,\n",
       "  0.3261746923789032,\n",
       "  -0.7218943081983961,\n",
       "  -0.9789705386188235,\n",
       "  -0.9005071323656544,\n",
       "  0.13101725253954818,\n",
       "  -0.5210203582769378,\n",
       "  1751846400.0,\n",
       "  0.25292981656346475,\n",
       "  0.0772376687585596,\n",
       "  -0.4265436852720177,\n",
       "  -1.280433253649285],\n",
       " [1.2874259538779353,\n",
       "  -0.8643557739708404,\n",
       "  -1.6516523693565135,\n",
       "  1.6375660198619157,\n",
       "  1.0000159506296273,\n",
       "  -0.6819033316799241,\n",
       "  -0.6717138557921146,\n",
       "  1.001496788783363,\n",
       "  1753488000.0,\n",
       "  0.08032815103817885,\n",
       "  0.952086309847956,\n",
       "  0.6481916276171124,\n",
       "  1.0022246710558618],\n",
       " [0.14807012863824137,\n",
       "  1.1804784407171702,\n",
       "  -1.5620996728503085,\n",
       "  -0.9438009165427774,\n",
       "  0.9083348091569887,\n",
       "  -0.9386223568554879,\n",
       "  -1.7049321850410766,\n",
       "  1.5662312262008962,\n",
       "  1773878400.0,\n",
       "  1.2929525725559583,\n",
       "  0.7252011412687428,\n",
       "  0.45458141392001017,\n",
       "  1.4613916899868273],\n",
       " [0.2724261308167813,\n",
       "  -0.469939760147415,\n",
       "  -1.6406974431436672,\n",
       "  -1.411005360438348,\n",
       "  0.5057044595977163,\n",
       "  1.4463637730374461,\n",
       "  0.48449102487494966,\n",
       "  0.2752639060882091,\n",
       "  1757289600.0,\n",
       "  -0.6778329464505594,\n",
       "  0.9618006599323645,\n",
       "  -0.5939840835618089,\n",
       "  -0.22618773995736727],\n",
       " [-0.4585941926614484,\n",
       "  -0.1298578869942721,\n",
       "  0.02226534961241034,\n",
       "  -0.7377887268566322,\n",
       "  -1.4117002590893952,\n",
       "  1.6339002878450382,\n",
       "  0.5627239838260434,\n",
       "  -0.7087009641161806,\n",
       "  1771891200.0,\n",
       "  -1.047013665878971,\n",
       "  1.1744392155315726,\n",
       "  1.044277323038059,\n",
       "  0.316104296724409],\n",
       " [0.4047328171225891,\n",
       "  1.4689010540098928,\n",
       "  -0.4470067354518148,\n",
       "  -1.34647399912738,\n",
       "  1.1729527414985024,\n",
       "  0.911732357794101,\n",
       "  -0.3747947788799196,\n",
       "  0.8630251194528996,\n",
       "  1789257600.0,\n",
       "  0.6082469646356141,\n",
       "  0.38376886263093324,\n",
       "  1.1888218149423524,\n",
       "  1.2207709123913837],\n",
       " [-1.1951135153119918,\n",
       "  0.9209799921172386,\n",
       "  0.8678015613737488,\n",
       "  0.8955817954146585,\n",
       "  -1.2270356925786658,\n",
       "  -1.2194605753784653,\n",
       "  0.3776684172846054,\n",
       "  -1.3335532692069474,\n",
       "  1747180800.0,\n",
       "  -1.5897081410722003,\n",
       "  1.4734500539990858,\n",
       "  1.182652561181727,\n",
       "  1.1368929376446024],\n",
       " [-1.5105149447319597,\n",
       "  1.4128493559615283,\n",
       "  -0.08098528455658312,\n",
       "  1.439024816042312,\n",
       "  -0.19494639858313936,\n",
       "  0.5215400826018618,\n",
       "  -1.291929962283518,\n",
       "  -0.8614663642168456,\n",
       "  1770768000.0,\n",
       "  -0.7523046100512195,\n",
       "  0.0156959142553606,\n",
       "  0.05662338628517365,\n",
       "  0.05817902253809357],\n",
       " [0.8842628073691162,\n",
       "  1.3607278129320852,\n",
       "  1.1968737652015058,\n",
       "  -0.2453471310771931,\n",
       "  0.8136237725279375,\n",
       "  0.15808554369603336,\n",
       "  0.6665279459800014,\n",
       "  -0.828916348880079,\n",
       "  1783382400.0,\n",
       "  1.6056538866393215,\n",
       "  1.4208406748876319,\n",
       "  -1.4853563654325739,\n",
       "  -0.812901730598483],\n",
       " [-0.14228120565056368,\n",
       "  1.6445678960238497,\n",
       "  -0.7912830209593589,\n",
       "  -1.3736750353670066,\n",
       "  0.3392165275830996,\n",
       "  -0.8010652403609432,\n",
       "  -0.34705760967011356,\n",
       "  -0.7744811989340393,\n",
       "  1790467200.0,\n",
       "  1.5385528995761486,\n",
       "  0.8562576229985905,\n",
       "  0.10564226539027843,\n",
       "  -1.3832577255098653],\n",
       " [0.21547324568988893,\n",
       "  -0.5452333448602441,\n",
       "  0.6509401545463159,\n",
       "  0.7131585414402505,\n",
       "  -0.6241741373938121,\n",
       "  -1.0955755340743707,\n",
       "  -0.6271080247675269,\n",
       "  -1.5018666817623028,\n",
       "  1754956800.0,\n",
       "  0.22983455604060413,\n",
       "  0.0303531596513367,\n",
       "  -1.152432839906686,\n",
       "  -0.6084000326317807],\n",
       " [1.5352234192301208,\n",
       "  0.8566227837818716,\n",
       "  0.10201936091794266,\n",
       "  -1.3782293229191893,\n",
       "  -0.3634135836346097,\n",
       "  1.699056769081682,\n",
       "  0.2631738169575922,\n",
       "  0.7492139859634085,\n",
       "  1790640000.0,\n",
       "  -1.584390278968566,\n",
       "  0.5826904470970475,\n",
       "  -0.5170215826245094,\n",
       "  1.669979008858727],\n",
       " [0.30596750248819343,\n",
       "  1.5633292649313892,\n",
       "  0.8135065033404228,\n",
       "  1.4863199725051208,\n",
       "  0.8201292707710225,\n",
       "  0.5337678017149238,\n",
       "  -1.0073402350994354,\n",
       "  1.1420722518119149,\n",
       "  1781654400.0,\n",
       "  -1.4687547304719015,\n",
       "  -1.3108547624330245,\n",
       "  0.13201306446591482,\n",
       "  0.8144646111167739],\n",
       " [1.4665952588815048,\n",
       "  -0.6500319788265505,\n",
       "  1.2454448425552866,\n",
       "  0.32569775523001604,\n",
       "  -0.7961052591038275,\n",
       "  0.140332451282642,\n",
       "  -1.171520716953213,\n",
       "  0.11963306648228501,\n",
       "  1790899200.0,\n",
       "  -0.6204144648827623,\n",
       "  0.6927795290850576,\n",
       "  -1.185523028044113,\n",
       "  1.5293252293771498],\n",
       " [0.02637081752611206,\n",
       "  -0.9205947082231563,\n",
       "  -0.633964075534981,\n",
       "  0.9148024308848742,\n",
       "  -0.32068915410088505,\n",
       "  0.2408847123940059,\n",
       "  1.4062421021168852,\n",
       "  1.7538529125193787,\n",
       "  1782259200.0,\n",
       "  1.6295668936198862,\n",
       "  0.6958412195653888,\n",
       "  0.27071465083591745,\n",
       "  0.9386935067393051],\n",
       " [1.7024404645591213,\n",
       "  0.5808896657737973,\n",
       "  1.1484017860606586,\n",
       "  0.9766258855306943,\n",
       "  -0.945976249959575,\n",
       "  -0.48037608950102867,\n",
       "  1.6554823170078123,\n",
       "  0.8851873535690488,\n",
       "  1769385600.0,\n",
       "  -0.33759108822825695,\n",
       "  1.2654598314440197,\n",
       "  -0.28469573077769417,\n",
       "  -1.3055533549084029],\n",
       " [1.4913260772812942,\n",
       "  0.18936820267219226,\n",
       "  -1.137848789662779,\n",
       "  1.2464231932273264,\n",
       "  -0.8045272998150158,\n",
       "  0.08294575279942341,\n",
       "  0.8551567281015383,\n",
       "  -0.6969278317666238,\n",
       "  1794268800.0,\n",
       "  -0.502370671230751,\n",
       "  1.6084154587388602,\n",
       "  1.1753361511699465,\n",
       "  0.34882668199100203],\n",
       " [-1.553053992298137,\n",
       "  0.09465800819651256,\n",
       "  1.4994062412261915,\n",
       "  -1.324120932278226,\n",
       "  0.5583220682990983,\n",
       "  -1.501652500506661,\n",
       "  1.1862943385588016,\n",
       "  1.0821911375615225,\n",
       "  1780012800.0,\n",
       "  -1.2580162673144881,\n",
       "  0.29521261236739443,\n",
       "  0.443639339175087,\n",
       "  0.2438201383802591],\n",
       " [0.009703897443208535,\n",
       "  -1.594689390505051,\n",
       "  -0.4140013923564127,\n",
       "  0.914554729655008,\n",
       "  1.4212704315060734,\n",
       "  -0.12510266331177014,\n",
       "  -0.19335342116965187,\n",
       "  -0.17165404487219296,\n",
       "  1759104000.0,\n",
       "  -0.8119806576863122,\n",
       "  -1.2765887534925753,\n",
       "  -0.4496134831856965,\n",
       "  -1.4475115436131818],\n",
       " [-0.327565858399648,\n",
       "  0.2814199599254736,\n",
       "  1.2574702188165745,\n",
       "  0.7974477705189347,\n",
       "  0.8709978984371167,\n",
       "  -1.0102917820296768,\n",
       "  0.5284611848664177,\n",
       "  0.8756529915941573,\n",
       "  1774137600.0,\n",
       "  -0.6821928704237489,\n",
       "  1.40366062693161,\n",
       "  -1.5211193699651029,\n",
       "  -0.3729595108760207],\n",
       " [-0.4853874756835374,\n",
       "  0.44386821098655843,\n",
       "  1.211380583662059,\n",
       "  -1.2022508142727593,\n",
       "  -1.285334087049593,\n",
       "  -1.2457011619966536,\n",
       "  -0.771265842055055,\n",
       "  -1.3199296138597487,\n",
       "  1778889600.0,\n",
       "  0.48946987661695374,\n",
       "  0.6342463054194285,\n",
       "  0.8426080228281905,\n",
       "  0.41904643371301065],\n",
       " [0.5434914584741569,\n",
       "  1.5755508380450793,\n",
       "  0.8588777618570097,\n",
       "  -0.27203549034351726,\n",
       "  -1.222364045796014,\n",
       "  0.29503034889652435,\n",
       "  -0.672171093131968,\n",
       "  -0.9855787073400911,\n",
       "  1745712000.0,\n",
       "  -0.10655124335899412,\n",
       "  -1.1093756489884206,\n",
       "  -1.7069189009777146,\n",
       "  1.5125807012361752],\n",
       " [1.3477349639936054,\n",
       "  1.348697170127306,\n",
       "  1.5699308517998696,\n",
       "  0.55802319397507,\n",
       "  0.5657561455447109,\n",
       "  0.4956521636301169,\n",
       "  -1.420200036222361,\n",
       "  -1.5921770847214907,\n",
       "  1756080000.0,\n",
       "  0.1816339972019561,\n",
       "  -0.8795866602921465,\n",
       "  1.6264792788458726,\n",
       "  0.2781949795703663],\n",
       " [1.3405515612375485,\n",
       "  -0.5230826336401782,\n",
       "  1.6588305935562913,\n",
       "  -1.4531647748516168,\n",
       "  -0.21374467976502995,\n",
       "  -0.9867874625958406,\n",
       "  -1.0528427154694453,\n",
       "  -1.6193662991338496,\n",
       "  1788220800.0,\n",
       "  -0.20358119326438798,\n",
       "  -1.5006726383751379,\n",
       "  1.1146458045101362,\n",
       "  1.3497376750001393],\n",
       " [-0.3986381892660136,\n",
       "  -1.3479363068031207,\n",
       "  -0.2574618287576678,\n",
       "  -0.7379130509523782,\n",
       "  -1.0601619736942998,\n",
       "  -0.04467386257439086,\n",
       "  0.3330567118705805,\n",
       "  0.17136685100350366,\n",
       "  1768262400.0,\n",
       "  0.08044216043498649,\n",
       "  0.36047266555460294,\n",
       "  -1.5550595274291477,\n",
       "  0.9409437719546967],\n",
       " [0.5644833119070314,\n",
       "  0.4956600900935529,\n",
       "  -1.4216356911032162,\n",
       "  -1.5905837023041014,\n",
       "  0.17954687757088492,\n",
       "  -0.8784042504351223,\n",
       "  1.6250607374649677,\n",
       "  0.2807004018714841,\n",
       "  1756166400.0,\n",
       "  0.45708135768870756,\n",
       "  -1.3878333689609548,\n",
       "  1.33912593960727,\n",
       "  -1.3674219096027627],\n",
       " [0.8123897935271279,\n",
       "  0.15810489957593904,\n",
       "  0.663625133452548,\n",
       "  -0.8262023238083682,\n",
       "  1.6034390780297636,\n",
       "  1.420945718184753,\n",
       "  -1.4861542895483995,\n",
       "  -0.8099902828049123,\n",
       "  1783468800.0,\n",
       "  -1.1670280810234472,\n",
       "  0.17774337671703436,\n",
       "  -0.43621300333692925,\n",
       "  0.9276625610690414],\n",
       " [0.08669695733111828,\n",
       "  1.0118966394730415,\n",
       "  1.6898583727870142,\n",
       "  -1.191995266958455,\n",
       "  0.7948929511743582,\n",
       "  0.21738085748489094,\n",
       "  -1.3940472581755317,\n",
       "  0.517855904790189,\n",
       "  1763424000.0,\n",
       "  0.2632299102727963,\n",
       "  0.8235444028005402,\n",
       "  1.1197505852111023,\n",
       "  0.4482439289297153],\n",
       " [-0.40602095784615394,\n",
       "  0.8906845741118649,\n",
       "  -1.1732341101697235,\n",
       "  0.4986301417495842,\n",
       "  -1.2333107475991316,\n",
       "  -0.7752311765149248,\n",
       "  0.45899763216337247,\n",
       "  -0.005769280694022653,\n",
       "  1771459200.0,\n",
       "  1.3614763619877177,\n",
       "  -1.397063224340016,\n",
       "  1.059354895657819,\n",
       "  0.9984542111180705],\n",
       " [-0.8113628682585362,\n",
       "  -0.495113918229886,\n",
       "  0.07775546266205183,\n",
       "  1.5309460696326438,\n",
       "  -0.04263097031633951,\n",
       "  -1.3196382289514568,\n",
       "  -0.025011471010709926,\n",
       "  -0.9906986290087046,\n",
       "  1789689600.0,\n",
       "  0.8957514710451173,\n",
       "  -1.7473294624547324,\n",
       "  -0.31637112483210716,\n",
       "  1.251507782952696],\n",
       " [-0.9570114976912834,\n",
       "  1.3173649595840258,\n",
       "  -0.14679226007172366,\n",
       "  -1.3331554931373184,\n",
       "  -1.6206357036325256,\n",
       "  -1.2986579024110667,\n",
       "  -0.8464220633959862,\n",
       "  -0.09811798970407877,\n",
       "  1766966400.0,\n",
       "  0.06181289087051904,\n",
       "  -1.4415804939338943,\n",
       "  1.232613447713641,\n",
       "  -0.98910146407577],\n",
       " [-0.31431133748979917,\n",
       "  -1.593570614489076,\n",
       "  -0.9249734455764211,\n",
       "  -0.10234727676911835,\n",
       "  -1.4620077709082935,\n",
       "  1.0031042547849143,\n",
       "  -0.7944303027744938,\n",
       "  0.6874096589538732,\n",
       "  1758326400.0,\n",
       "  1.4627006483804297,\n",
       "  0.01079514508773309,\n",
       "  1.1702832629938025,\n",
       "  -1.2784649986678494],\n",
       " [0.7385423611985353,\n",
       "  0.6625462269211669,\n",
       "  -1.6060075997921681,\n",
       "  0.2747542938318992,\n",
       "  1.0275953982490993,\n",
       "  0.6353173427774949,\n",
       "  -1.679704379571393,\n",
       "  -0.8477389924891086,\n",
       "  1760400000.0,\n",
       "  0.7218487217664807,\n",
       "  0.7166426874805718,\n",
       "  -1.4940090607091454,\n",
       "  -0.09633012709210824],\n",
       " [0.642437063404125,\n",
       "  1.5059003166950526,\n",
       "  -1.2912941264773985,\n",
       "  -1.4100304088573392,\n",
       "  -1.577492134191739,\n",
       "  1.306521047155888,\n",
       "  -1.129282182221058,\n",
       "  0.8616667912618782,\n",
       "  1768521600.0,\n",
       "  0.1253190320662237,\n",
       "  1.0489969015787324,\n",
       "  -1.5063368800356731,\n",
       "  0.5331645361380799],\n",
       " [1.204510998473682,\n",
       "  0.9033250048890599,\n",
       "  -0.6888227118688923,\n",
       "  -0.40438368092389754,\n",
       "  1.667830852158909,\n",
       "  -0.39512158712645173,\n",
       "  -0.37735072273288733,\n",
       "  0.3352643537409975,\n",
       "  1769212800.0,\n",
       "  1.7057587298143497,\n",
       "  0.5803859689701011,\n",
       "  1.1529697857805639,\n",
       "  0.9690204256775359],\n",
       " [-1.0881937167860816,\n",
       "  0.30897694447779805,\n",
       "  -0.6834408268307003,\n",
       "  -0.8550219184292541,\n",
       "  1.3863209826211857,\n",
       "  -1.4745898789272354,\n",
       "  0.31645365583289786,\n",
       "  0.41417673149711803,\n",
       "  1755388800.0,\n",
       "  1.304255576640782,\n",
       "  -1.6426481708631038,\n",
       "  0.4912531991873471,\n",
       "  1.4307271227531333],\n",
       " [-0.05540375840538506,\n",
       "  0.3668830378328591,\n",
       "  -0.26949825786766946,\n",
       "  0.9370941265292191,\n",
       "  0.09818716529561146,\n",
       "  0.7793181928475331,\n",
       "  1.092469653658529,\n",
       "  0.8646833914468053,\n",
       "  1794700800.0,\n",
       "  -1.5258490949672354,\n",
       "  0.7720580312089127,\n",
       "  0.6159547218126472,\n",
       "  -1.2392543835625625],\n",
       " [-0.3019074681608591,\n",
       "  1.0466666840354344,\n",
       "  1.1857112488339163,\n",
       "  -0.7672548398207929,\n",
       "  -0.8856343277049049,\n",
       "  -0.6620681757821589,\n",
       "  1.6157135494547747,\n",
       "  0.600162858770668,\n",
       "  1785024000.0,\n",
       "  0.9676421888275741,\n",
       "  -0.14747907533565804,\n",
       "  1.7374663392275016,\n",
       "  -1.1664652448355335],\n",
       " [0.09194258615889116,\n",
       "  -0.37866696676183054,\n",
       "  0.5709961960089458,\n",
       "  1.33886427397904,\n",
       "  1.7197427429523144,\n",
       "  -0.5299393232708283,\n",
       "  -0.8299771434236036,\n",
       "  0.29324520584591657,\n",
       "  1776816000.0,\n",
       "  0.5054792573031182,\n",
       "  0.6020868399564916,\n",
       "  1.0425136751370985,\n",
       "  -0.18810911086569868],\n",
       " [0.0628603500556671,\n",
       "  0.4104333038221929,\n",
       "  1.6763589599319204,\n",
       "  -0.6545278634336922,\n",
       "  -0.2943912445761615,\n",
       "  -0.48355099170500726,\n",
       "  -1.0638850541472489,\n",
       "  1.244469045550254,\n",
       "  1766016000.0,\n",
       "  0.9768952301071502,\n",
       "  0.5294257820940329,\n",
       "  -1.0337144479695966,\n",
       "  -1.4778073561554066],\n",
       " [0.7152276348993583,\n",
       "  -1.1765110651515154,\n",
       "  0.0008413083852737078,\n",
       "  1.5680867110129513,\n",
       "  -1.3769375714534957,\n",
       "  -1.5114359608309846,\n",
       "  1.3187622259758933,\n",
       "  -1.5802420756241957,\n",
       "  1779667200.0,\n",
       "  1.494792891496929,\n",
       "  -0.9711055817570032,\n",
       "  -1.3968866204422667,\n",
       "  1.3074312198812215],\n",
       " [-1.0673591353771996,\n",
       "  0.6261234433580458,\n",
       "  -1.1758117628553066,\n",
       "  -1.561138903250728,\n",
       "  1.01043292908352,\n",
       "  0.7576853187407486,\n",
       "  0.3132053840674383,\n",
       "  -0.7516016710052481,\n",
       "  1795305600.0,\n",
       "  -0.6488726901194003,\n",
       "  -1.5197388419582034,\n",
       "  1.6252406484284987,\n",
       "  0.3599668300993211],\n",
       " [-0.22425789765410772,\n",
       "  -1.6218479974856057,\n",
       "  -0.17780747394367455,\n",
       "  0.1971920128965974,\n",
       "  1.0213796843627978,\n",
       "  0.5853124808477219,\n",
       "  -0.20465346020248218,\n",
       "  -0.052210813434316994,\n",
       "  1791590400.0,\n",
       "  -1.547325919745311,\n",
       "  1.628832271302332,\n",
       "  1.490782654064182,\n",
       "  0.6358405413932057],\n",
       " [0.7637311591681775,\n",
       "  -0.7024415135301065,\n",
       "  0.7391300156920022,\n",
       "  0.9663029076302065,\n",
       "  0.6319402325285302,\n",
       "  -0.4874785118007351,\n",
       "  -1.3272253468356514,\n",
       "  0.4803717100541457,\n",
       "  1790121600.0,\n",
       "  -1.1463955421641097,\n",
       "  -1.6476120179246985,\n",
       "  0.781450837658023,\n",
       "  -0.9440731798009004],\n",
       " [-1.5283449177977406,\n",
       "  -0.7127557296198475,\n",
       "  1.4681855514528273,\n",
       "  -0.03902689643716536,\n",
       "  1.3666102585515587,\n",
       "  1.36206861263589,\n",
       "  -1.5710125596148858,\n",
       "  -1.2745069188127196,\n",
       "  1792108800.0,\n",
       "  -0.5320699060440278,\n",
       "  -0.045753188606147924,\n",
       "  0.20984725272531626,\n",
       "  0.7263847882994034],\n",
       " [-0.6154453388893358,\n",
       "  1.2088245611378317,\n",
       "  0.8221861527977906,\n",
       "  1.7088515406505829,\n",
       "  1.540262976953456,\n",
       "  -0.789384495364956,\n",
       "  0.23615087380023322,\n",
       "  -1.539167499812119,\n",
       "  1784073600.0,\n",
       "  1.7406632246906895,\n",
       "  1.2589508995795202,\n",
       "  0.22638040427437345,\n",
       "  -0.39691165301728354],\n",
       " [0.44780567031639856,\n",
       "  1.1486889474355777,\n",
       "  -0.15469822881411407,\n",
       "  -0.12847166267163984,\n",
       "  -1.5751378635633062,\n",
       "  -0.649904061231758,\n",
       "  1.4394848559885514,\n",
       "  -0.7554103857728923,\n",
       "  1743379200.0,\n",
       "  0.9975717873633533,\n",
       "  -0.3465189062197549,\n",
       "  -1.0403910186793288,\n",
       "  -1.4794868469400633],\n",
       " [0.8035891933225708,\n",
       "  -1.705447463258296,\n",
       "  -0.09880332654358084,\n",
       "  1.6042496956791024,\n",
       "  -0.5514933433482376,\n",
       "  -0.1728527162955012,\n",
       "  0.243740350842853,\n",
       "  0.6001724946734351,\n",
       "  1756944000.0,\n",
       "  -0.6587793950582044,\n",
       "  1.334880647224832,\n",
       "  -0.8348840535467819,\n",
       "  -1.342869456104382],\n",
       " [1.663096166381838,\n",
       "  -1.123703337712695,\n",
       "  0.8760362785480934,\n",
       "  0.8757093837593661,\n",
       "  -0.11200789729968877,\n",
       "  -0.0766692761877688,\n",
       "  0.009602287410188438,\n",
       "  -0.3339240554470569,\n",
       "  1749772800.0,\n",
       "  -0.44746939426465593,\n",
       "  0.9160624390711027,\n",
       "  1.0743126198256763,\n",
       "  -0.4912525227385579],\n",
       " [-0.4750839291690817,\n",
       "  1.347296875435616,\n",
       "  0.8422599978899397,\n",
       "  0.04458422244355994,\n",
       "  -1.1679940048084878,\n",
       "  0.06039130305566932,\n",
       "  1.1445038161079657,\n",
       "  0.4739342086435107,\n",
       "  1781308800.0,\n",
       "  -0.410365951858132,\n",
       "  0.28862325357479096,\n",
       "  1.5698371056432538,\n",
       "  1.2207070137841076],\n",
       " [1.7024558366921922,\n",
       "  -0.8400600223553075,\n",
       "  0.613907745228203,\n",
       "  -1.1518586887724442,\n",
       "  -0.8076493212007583,\n",
       "  -0.6812213440151635,\n",
       "  -0.08719582160435725,\n",
       "  1.5075787488361014,\n",
       "  1739059200.0,\n",
       "  -1.4604335200625504,\n",
       "  -1.6815068225673515,\n",
       "  -0.10382180064603946,\n",
       "  0.9538809928869547],\n",
       " [0.2802486047668892,\n",
       "  -1.0938490712515396,\n",
       "  1.1099206960790957,\n",
       "  0.759099683721589,\n",
       "  -1.557363458325298,\n",
       "  -0.8814312785258915,\n",
       "  -1.156143896500705,\n",
       "  0.7024590331563089,\n",
       "  1782691200.0,\n",
       "  -0.8346475807771402,\n",
       "  0.19505901233466338,\n",
       "  -0.19447206723223637,\n",
       "  1.1947876177328847],\n",
       " [1.715504887098146,\n",
       "  1.3097481235302568,\n",
       "  0.7189822487515206,\n",
       "  0.9899547256777909,\n",
       "  -1.142859173629033,\n",
       "  -0.35208672462018387,\n",
       "  1.5359072658004709,\n",
       "  0.2822359016207668,\n",
       "  1750723200.0,\n",
       "  -0.9962205980521891,\n",
       "  1.0453401039519126,\n",
       "  0.4610723238459894,\n",
       "  -0.546139830063308],\n",
       " [-0.5558910746665244,\n",
       "  -0.630746107124364,\n",
       "  1.1293272339295284,\n",
       "  -1.244507544366965,\n",
       "  -1.239598163779026,\n",
       "  -0.6755415379906187,\n",
       "  -0.9801907256313318,\n",
       "  -1.4137499977009627,\n",
       "  1787356800.0,\n",
       "  -1.1192829897651362,\n",
       "  -0.6033302437543605,\n",
       "  -1.1386562372461613,\n",
       "  -0.35766698831872196],\n",
       " [-0.6548474044044467,\n",
       "  -0.7257865050289705,\n",
       "  -1.1009401867612736,\n",
       "  -0.36802803446345417,\n",
       "  -0.07190657888659861,\n",
       "  -0.8148962186581373,\n",
       "  -1.6513608248252547,\n",
       "  -1.3221506001864,\n",
       "  1786665600.0,\n",
       "  -0.8054002272063562,\n",
       "  0.7380801705987544,\n",
       "  0.20429397727383394,\n",
       "  -0.9344323371789641],\n",
       " [-0.5160387925904069,\n",
       "  -0.8674485257011211,\n",
       "  -0.41417817351056696,\n",
       "  -0.3453921394144455,\n",
       "  0.25930637980163335,\n",
       "  0.03450248564624699,\n",
       "  -1.5087487562076163,\n",
       "  1.1489982256755695,\n",
       "  1792627200.0,\n",
       "  -0.3848982940869351,\n",
       "  0.6354489537660141,\n",
       "  -1.5205860948004717,\n",
       "  -0.655639680779348],\n",
       " [0.4381955696265177,\n",
       "  1.1323761531742305,\n",
       "  1.1711639844457091,\n",
       "  0.22869650079445852,\n",
       "  -0.4421722334664026,\n",
       "  1.7022354967574411,\n",
       "  -0.522606754502377,\n",
       "  -1.1978664785140305,\n",
       "  1744243200.0,\n",
       "  -1.00912318181503,\n",
       "  1.344998226558478,\n",
       "  -1.7618994350931219,\n",
       "  0.12639107846478925],\n",
       " [-0.6882952638800708,\n",
       "  -1.3482297291189949,\n",
       "  -1.7549044030993146,\n",
       "  -0.9050318019940675,\n",
       "  1.6655547245047686,\n",
       "  -0.5150820685502753,\n",
       "  0.6990455985281553,\n",
       "  -0.06302661662457924,\n",
       "  1784678400.0,\n",
       "  0.5945284451987427,\n",
       "  1.599611068248014,\n",
       "  -0.09911607768134911,\n",
       "  -0.6272470252879973],\n",
       " [0.2899182545446113,\n",
       "  1.244542783343703,\n",
       "  -1.271436219697614,\n",
       "  -0.0010984417659795508,\n",
       "  -1.6964831814555457,\n",
       "  -1.6988228379687984,\n",
       "  -0.17243508447530354,\n",
       "  -1.139078901956801,\n",
       "  1756771200.0,\n",
       "  0.806967743691689,\n",
       "  -1.7070998796988337,\n",
       "  -0.09536180562945816,\n",
       "  1.5959573899883546],\n",
       " [-1.6943513516445485,\n",
       "  -1.2372774835695168,\n",
       "  0.7431274471407714,\n",
       "  -1.4509819796442802,\n",
       "  1.6304918727863738,\n",
       "  0.6408155351417009,\n",
       "  -0.4471729263302291,\n",
       "  -1.327359093226503,\n",
       "  1775779200.0,\n",
       "  1.0088319448842302,\n",
       "  -0.9413181914947739,\n",
       "  1.1241909310681892,\n",
       "  -0.3566886400361887],\n",
       " [-0.5742901922018879,\n",
       "  -1.7217159084841351,\n",
       "  0.19942383193112745,\n",
       "  -1.6004296458562002,\n",
       "  -0.6474270794971534,\n",
       "  -0.5469274297977947,\n",
       "  -0.10642782220290455,\n",
       "  1.0475360823427,\n",
       "  1783814400.0,\n",
       "  -0.21104111588024213,\n",
       "  0.3435851174137808,\n",
       "  0.4672650473136983,\n",
       "  0.14968566027127406],\n",
       " [0.09743954307375448,\n",
       "  0.5220616548034038,\n",
       "  -0.44553265109625245,\n",
       "  0.24364001432372157,\n",
       "  0.3892148658116714,\n",
       "  0.06872060642217485,\n",
       "  0.10251520314398332,\n",
       "  0.8225238333514115,\n",
       "  1788652800.0,\n",
       "  1.6229008251323422,\n",
       "  -0.46519459413288533,\n",
       "  -0.8592487702721874,\n",
       "  0.7003927377554483],\n",
       " [-0.7680082820981182,\n",
       "  -0.39165171739259474,\n",
       "  0.8147821727113129,\n",
       "  -1.3868950982065247,\n",
       "  -0.8702202504798523,\n",
       "  -0.5499371555097914,\n",
       "  -0.034524603253909256,\n",
       "  1.651590252797971,\n",
       "  1753833600.0,\n",
       "  0.22735984050441516,\n",
       "  1.4067581204346744,\n",
       "  -0.24688722824945608,\n",
       "  -0.8770911494952252],\n",
       " [-0.5420532297132836,\n",
       "  -1.5957142969919094,\n",
       "  -1.717069326830055,\n",
       "  0.43859857349745507,\n",
       "  1.084741709534028,\n",
       "  0.24981514756308093,\n",
       "  -0.9430178474827873,\n",
       "  -1.0759391194475572,\n",
       "  1769904000.0,\n",
       "  -1.3252530442778108,\n",
       "  -0.9385404898378327,\n",
       "  0.49833877816929706,\n",
       "  0.9732038217853559],\n",
       " [0.1372294519937431,\n",
       "  -0.9960751560683484,\n",
       "  1.3216980832057288,\n",
       "  0.006304272987500903,\n",
       "  0.23932709511113942,\n",
       "  -0.8662261055763323,\n",
       "  -0.39568372076650216,\n",
       "  1.1114181579382825,\n",
       "  1770336000.0,\n",
       "  1.293295790993497,\n",
       "  -1.3285411874172914,\n",
       "  -0.6639033917901119,\n",
       "  -1.4484105154576106],\n",
       " [-0.07327936972282306,\n",
       "  -0.8148439193142675,\n",
       "  -1.652633952859542,\n",
       "  -1.320160756661873,\n",
       "  -0.8073988414782108,\n",
       "  0.7385049733268709,\n",
       "  0.20315907322252924,\n",
       "  -0.931475664682647,\n",
       "  1786752000.0,\n",
       "  -0.7457249009149505,\n",
       "  -0.00397278005630288,\n",
       "  -1.0414309708082954,\n",
       "  1.4779821250957939],\n",
       " [0.06775972926476606,\n",
       "  -0.17552671124623617,\n",
       "  0.7032843248348969,\n",
       "  -0.25675272460950116,\n",
       "  -1.5017621981421805,\n",
       "  0.6391771721660293,\n",
       "  0.8077068072924881,\n",
       "  -0.47940759573072933,\n",
       "  1754784000.0,\n",
       "  0.21889124044543454,\n",
       "  -0.546302837319965,\n",
       "  0.6550588456649914,\n",
       "  0.7058414094766705],\n",
       " [-0.8252070474669435,\n",
       "  -0.44064766541431116,\n",
       "  1.3265548892332635,\n",
       "  1.059206800074186,\n",
       "  0.8343514039634635,\n",
       "  -1.424597088077032,\n",
       "  1.0342686006811648,\n",
       "  -0.6106027509768598,\n",
       "  1736380800.0,\n",
       "  -0.12996437112148926,\n",
       "  1.0545566441961376,\n",
       "  -1.0333926192924652,\n",
       "  -0.7852135356966258],\n",
       " [-0.1388808324022195,\n",
       "  -1.1383392707933826,\n",
       "  0.8306072008567192,\n",
       "  0.12676241909755823,\n",
       "  -0.8098743968393441,\n",
       "  -0.49515539170751854,\n",
       "  0.08024606624312876,\n",
       "  1.524776281369195,\n",
       "  1789603200.0,\n",
       "  -0.04056377470931306,\n",
       "  -1.321027380165836,\n",
       "  -0.02392208183957394,\n",
       "  -0.9936773481160297],\n",
       " [-0.37974461422622346,\n",
       "  -0.9312784125024011,\n",
       "  0.6369305434649158,\n",
       "  -0.7621102988489926,\n",
       "  -0.2741518585943378,\n",
       "  -0.32411966779467377,\n",
       "  1.7258713340848266,\n",
       "  0.019189122456554582,\n",
       "  1783209600.0,\n",
       "  0.8876359470344102,\n",
       "  1.360615928596386,\n",
       "  1.2014855449353194,\n",
       "  -0.25161531362102596],\n",
       " [-1.6302737346480953,\n",
       "  -1.0454542936923752,\n",
       "  -0.16307295606331296,\n",
       "  -1.140181993783773,\n",
       "  -0.2948014040252874,\n",
       "  -0.20929013061778332,\n",
       "  -1.7291657379182748,\n",
       "  -0.5562786171808706,\n",
       "  1744502400.0,\n",
       "  0.0793428973620282,\n",
       "  0.6522426965264115,\n",
       "  -0.2430791207858737,\n",
       "  -0.07636654976751733],\n",
       " [1.419514519520268,\n",
       "  -0.4523118125487036,\n",
       "  -0.6613746705575017,\n",
       "  -1.2547437750066612,\n",
       "  0.29166971394223595,\n",
       "  -0.21915046734729174,\n",
       "  -0.2704552315938535,\n",
       "  -1.2954110230359743,\n",
       "  1785542400.0,\n",
       "  1.470884245277617,\n",
       "  -0.41549282473747684,\n",
       "  1.5423470697959587,\n",
       "  0.15288079828615728],\n",
       " [1.4033854786285602,\n",
       "  1.509608284906763,\n",
       "  0.6127556729794013,\n",
       "  0.05976645306128115,\n",
       "  -1.4006042036997572,\n",
       "  -0.8944935457913252,\n",
       "  1.270861434708088,\n",
       "  -1.0663122880747438,\n",
       "  1771113600.0,\n",
       "  -1.1361328865485927,\n",
       "  -1.7369228206666332,\n",
       "  -1.2684636816507504,\n",
       "  -1.359542961107152],\n",
       " [-1.3077818719982977,\n",
       "  0.1781933004320722,\n",
       "  1.423858487263659,\n",
       "  0.6494563400920379,\n",
       "  -0.7770743353875044,\n",
       "  0.014533503651287895,\n",
       "  0.6929139125829704,\n",
       "  1.5132031217233481,\n",
       "  1779408000.0,\n",
       "  -1.1025469440208497,\n",
       "  -0.7117233120459511,\n",
       "  -0.4450519780340189,\n",
       "  -0.9521401694528938],\n",
       " [-1.6049194454156193,\n",
       "  1.6797357648691207,\n",
       "  -0.0822712958944152,\n",
       "  -1.632476006379541,\n",
       "  -0.9558723517000339,\n",
       "  -0.4086000741571678,\n",
       "  1.1938015131981754,\n",
       "  -1.4797129726969402,\n",
       "  1740096000.0,\n",
       "  1.2744323232517458,\n",
       "  -0.3322780607557141,\n",
       "  0.653076535017344,\n",
       "  0.10113854679055782],\n",
       " [-0.215473032897759,\n",
       "  -1.0122430601318997,\n",
       "  1.6035899600718635,\n",
       "  1.2733339562943382,\n",
       "  1.3579061351066382,\n",
       "  0.7729224342638883,\n",
       "  0.4366881135999337,\n",
       "  -0.3806570001074085,\n",
       "  1738800000.0,\n",
       "  0.6748664833296629,\n",
       "  1.4786362898420489,\n",
       "  -0.3355495490600636,\n",
       "  -0.7540691733489349],\n",
       " [0.1847143686446659,\n",
       "  -0.4099919663399974,\n",
       "  0.6448887241907258,\n",
       "  -0.22199639399748947,\n",
       "  -0.7727544938502376,\n",
       "  1.712537824784947,\n",
       "  1.2749705996838172,\n",
       "  -1.4794981725748109,\n",
       "  1753315200.0,\n",
       "  1.2907720537681506,\n",
       "  -0.8655856024528481,\n",
       "  -1.6496133856174158,\n",
       "  1.6292372541481113],\n",
       " [1.4995402972814926,\n",
       "  -1.064928946144013,\n",
       "  0.3879973462095618,\n",
       "  1.6406782245058302,\n",
       "  1.165397344904565,\n",
       "  1.0627895736172013,\n",
       "  1.7355024036012228,\n",
       "  1.3635988439772817,\n",
       "  1747612800.0,\n",
       "  0.9162054724583706,\n",
       "  1.3230205461513553,\n",
       "  -0.7725276083911966,\n",
       "  1.079717307508375],\n",
       " [0.8538910480094885,\n",
       "  0.627019103228589,\n",
       "  -1.5374930236407818,\n",
       "  0.618084858097324,\n",
       "  -1.522448821214742,\n",
       "  -1.6107827921039772,\n",
       "  0.7414927255114963,\n",
       "  1.0060146963492211,\n",
       "  1738368000.0,\n",
       "  1.7273234648114666,\n",
       "  0.08208212935369137,\n",
       "  0.3350820514978365,\n",
       "  -0.43009403349437103],\n",
       " [1.619577002302219,\n",
       "  -0.46416583225591884,\n",
       "  -0.8620009691491166,\n",
       "  0.7077039003828666,\n",
       "  -0.35194399364255896,\n",
       "  1.5751505170776745,\n",
       "  -0.6483403174571593,\n",
       "  0.07241036430648341,\n",
       "  1788825600.0,\n",
       "  0.48932227420506813,\n",
       "  -0.4043453233889199,\n",
       "  1.0636128512743463,\n",
       "  -0.5189410203666538],\n",
       " [0.280755813785268,\n",
       "  -1.0894454015352297,\n",
       "  -1.5788816326618922,\n",
       "  0.42347124284773147,\n",
       "  1.302823109664055,\n",
       "  -0.2754604155707098,\n",
       "  -0.8246322642550504,\n",
       "  0.3404551436202944,\n",
       "  1755907200.0,\n",
       "  1.3510770190149308,\n",
       "  1.348579241260615,\n",
       "  1.5748795776359348,\n",
       "  0.5508758357930876],\n",
       " [-0.8201226620948315,\n",
       "  1.4669495091757478,\n",
       "  -1.3791479792795838,\n",
       "  -1.3839313934199664,\n",
       "  0.7129802370014413,\n",
       "  -1.577048311183879,\n",
       "  -1.5287219372851597,\n",
       "  -0.7434628996759194,\n",
       "  1778284800.0,\n",
       "  0.096584697505466,\n",
       "  1.4711885202038126,\n",
       "  0.6177220730743173,\n",
       "  1.4793406424704718],\n",
       " [0.12189476108925824,\n",
       "  1.0492652733942371,\n",
       "  -1.5085051547003672,\n",
       "  0.5402924905631636,\n",
       "  -0.4742233280336659,\n",
       "  0.7029557789551089,\n",
       "  -0.6162224119243488,\n",
       "  1.6116595869770443,\n",
       "  1768694400.0,\n",
       "  -0.21176578384642683,\n",
       "  -1.250865954056262,\n",
       "  1.2205999094631361,\n",
       "  -1.4949933166738076],\n",
       " [-1.5143525364212398,\n",
       "  0.9173308722564293,\n",
       "  -1.3935679728978727,\n",
       "  -1.5697575435552171,\n",
       "  1.4642419255174133,\n",
       "  1.5478549441713763,\n",
       "  0.925958318000405,\n",
       "  -1.1836817381148594,\n",
       "  1760918400.0,\n",
       "  -0.6253750847801596,\n",
       "  1.331703247878575,\n",
       "  -1.471997476317014,\n",
       "  -1.2062183041112178],\n",
       " [0.1674341260043066,\n",
       "  0.9617176939659897,\n",
       "  -1.443839489980414,\n",
       "  -1.5116048116325573,\n",
       "  0.4155151475283832,\n",
       "  -0.012688353530566564,\n",
       "  -0.007174622526923097,\n",
       "  1.4249863335892166,\n",
       "  1772150400.0,\n",
       "  -0.3533220238347183,\n",
       "  0.6928219110861034,\n",
       "  0.9126993021577403,\n",
       "  -1.6425232394301814],\n",
       " [0.21010435715285358,\n",
       "  -0.05843400218642323,\n",
       "  0.4383706679136145,\n",
       "  -0.3753343891913027,\n",
       "  -0.5406069674696761,\n",
       "  -1.5957930361388277,\n",
       "  -1.7158415345401117,\n",
       "  0.43403025176883925,\n",
       "  1769817600.0,\n",
       "  1.08691000343053,\n",
       "  0.2491613679138223,\n",
       "  -0.9421115798901165,\n",
       "  -1.0789495705689112],\n",
       " [0.6615190708191532,\n",
       "  0.23209024314538904,\n",
       "  0.10140519469062799,\n",
       "  -0.6100116968526532,\n",
       "  -1.5590107677229281,\n",
       "  0.1905363708750109,\n",
       "  -1.6759544209646213,\n",
       "  0.30168364224567296,\n",
       "  1787184000.0,\n",
       "  -0.552421345227621,\n",
       "  -0.6318585635844355,\n",
       "  1.1338780054658026,\n",
       "  -1.2496822866049082],\n",
       " [0.4860700305346254,\n",
       "  0.6347229548749794,\n",
       "  0.8383200896791362,\n",
       "  0.42604936513242353,\n",
       "  1.1156032773781883,\n",
       "  1.4138742026538487,\n",
       "  -1.3461819570068119,\n",
       "  1.5554683403707517,\n",
       "  1779062400.0,\n",
       "  -0.922863512942405,\n",
       "  1.0474402806201906,\n",
       "  -1.1192333727279298,\n",
       "  -1.5454193877492866],\n",
       " [1.0844783631996797,\n",
       "  -1.4466122360195326,\n",
       "  -1.1496887645895548,\n",
       "  -1.5524800887654282,\n",
       "  1.601918548474746,\n",
       "  0.1876273665851438,\n",
       "  0.19797995249830963,\n",
       "  1.0278433811058636,\n",
       "  1747958400.0,\n",
       "  -0.05732420457604484,\n",
       "  -1.1003055127146963,\n",
       "  1.15306842089992,\n",
       "  0.297371844599211],\n",
       " [0.6251538211711646,\n",
       "  1.5598033775463183,\n",
       "  0.8198181863581372,\n",
       "  1.4693062200733324,\n",
       "  0.2780896979708673,\n",
       "  0.1103105400622451,\n",
       "  -0.1559270913166268,\n",
       "  -1.5228165003025254,\n",
       "  1741392000.0,\n",
       "  -1.3131229385709073,\n",
       "  -0.5446303155712123,\n",
       "  1.0536457964226917,\n",
       "  -1.427727650036688],\n",
       " [0.732033461579381,\n",
       "  -0.605102611146647,\n",
       "  0.7577774765780977,\n",
       "  -1.277620688504897,\n",
       "  0.09328948158868348,\n",
       "  -0.3787044974154677,\n",
       "  0.5738338362316849,\n",
       "  1.332976092593236,\n",
       "  1776729600.0,\n",
       "  1.7219679812110855,\n",
       "  -0.5309584589569131,\n",
       "  -0.8290483267586294,\n",
       "  0.2907444535307838],\n",
       " [0.33333689492677493,\n",
       "  0.07943480340545075,\n",
       "  -0.31084980643887233,\n",
       "  0.08433097882271791,\n",
       "  -1.1935648982606952,\n",
       "  0.9209864667308104,\n",
       "  0.8708480293154084,\n",
       "  0.8903435006788543,\n",
       "  1747094400.0,\n",
       "  -1.225074709667412,\n",
       "  -1.2208027880861003,\n",
       "  0.37883813201627203,\n",
       "  -1.336659620947504],\n",
       " [1.1498792913380471,\n",
       "  0.7480030828741538,\n",
       "  0.10524468119808895,\n",
       "  -0.1074498124687765,\n",
       "  -1.2847391203573308,\n",
       "  -0.753621483877331,\n",
       "  0.8758166068154267,\n",
       "  -0.7395894910032628,\n",
       "  1794528000.0,\n",
       "  -0.051967596182579213,\n",
       "  0.3662718181215355,\n",
       "  -0.26621090904637085,\n",
       "  0.9295319286168662],\n",
       " [-1.5755574701242867,\n",
       "  -0.13424736562978482,\n",
       "  1.2283506963225956,\n",
       "  -0.9493013979937196,\n",
       "  0.5225714159540703,\n",
       "  -0.21534965969260592,\n",
       "  0.07610470523676015,\n",
       "  -1.4124001791513656,\n",
       "  1780963200.0,\n",
       "  1.2878383625619083,\n",
       "  -1.3749273264753121,\n",
       "  0.9472999974985634,\n",
       "  0.696104907626966],\n",
       " [-1.3166436909761055,\n",
       "  -0.5435616630111468,\n",
       "  1.049167425427788,\n",
       "  -1.4227479668297747,\n",
       "  1.3336821996348995,\n",
       "  -1.1352466048177337,\n",
       "  -0.252048484470863,\n",
       "  -0.48999122132162337,\n",
       "  1741564800.0,\n",
       "  -0.21207697223611396,\n",
       "  -0.19156437998166223,\n",
       "  0.4840470532703183,\n",
       "  1.3697623281217952],\n",
       " [1.7011967137934114,\n",
       "  1.414479106111855,\n",
       "  -0.4069131679513978,\n",
       "  -0.7831134442081044,\n",
       "  -0.7952638607992275,\n",
       "  0.9579791131809463,\n",
       "  -1.774072556846698,\n",
       "  -0.06904259747870992,\n",
       "  1737244800.0,\n",
       "  0.4276942215091987,\n",
       "  -1.0076749386045647,\n",
       "  0.3998145298022454,\n",
       "  0.038630539433907075],\n",
       " [0.5158947989947232,\n",
       "  -1.041737681405771,\n",
       "  -1.7465039494458925,\n",
       "  0.44151258408818084,\n",
       "  -0.8821125379208212,\n",
       "  -1.21632343152377,\n",
       "  0.5311285192345993,\n",
       "  -0.47008158819902895,\n",
       "  1749513600.0,\n",
       "  -0.5345015930786906,\n",
       "  -1.2408460626337883,\n",
       "  -0.25432744257271783,\n",
       "  -0.9544938143076721],\n",
       " [0.007683164954462718,\n",
       "  -1.5459009852349417,\n",
       "  1.2571532783877155,\n",
       "  1.5810803409844991,\n",
       "  -0.08455962027910485,\n",
       "  1.1226094028478866,\n",
       "  -1.2865867127371238,\n",
       "  -0.9795417281841723,\n",
       "  1739491200.0,\n",
       "  0.06992440937507859,\n",
       "  0.3741540901016666,\n",
       "  -0.7284281094639755,\n",
       "  -0.852397184634136],\n",
       " [0.9674220287203429,\n",
       "  -0.05689279790137885,\n",
       "  -0.6693530234622496,\n",
       "  1.074625829339878,\n",
       "  0.8558853341417867,\n",
       "  1.0141835683586253,\n",
       "  -0.10011370259070458,\n",
       "  -1.4189305328088324,\n",
       "  1778544000.0,\n",
       "  0.837708004555315,\n",
       "  -1.213295697466356,\n",
       "  -0.6050493813180279,\n",
       "  -1.1750127976662712],\n",
       " [-0.47565918427050374,\n",
       "  0.7029566864800145,\n",
       "  -0.6182233354598841,\n",
       "  1.6179569399554594,\n",
       "  -0.21381762811614138,\n",
       "  -1.249509661769061,\n",
       "  1.2192623157198874,\n",
       "  -1.4918280448428687,\n",
       "  1768780800.0,\n",
       "  0.31731523847407417,\n",
       "  0.46915178801912527,\n",
       "  0.9022488837703528,\n",
       "  0.6289610636310607],\n",
       " [-0.9730972960663866,\n",
       "  1.026213715170361,\n",
       "  -0.7884890872321716,\n",
       "  0.9107385802146488,\n",
       "  0.2684717809107268,\n",
       "  -0.3134524697485472,\n",
       "  -1.3562084360282487,\n",
       "  -1.548129593465258,\n",
       "  1752192000.0,\n",
       "  1.4787720202730377,\n",
       "  -0.7495906762466482,\n",
       "  -0.7288407399084967,\n",
       "  -0.8662353596614206],\n",
       " [-0.7401845005351472,\n",
       "  1.0829029305476712,\n",
       "  1.6360896375928058,\n",
       "  0.659179544258444,\n",
       "  0.0691104148984972,\n",
       "  -0.1755573636925542,\n",
       "  0.7062150409632856,\n",
       "  -0.26030160715982353,\n",
       "  1754697600.0,\n",
       "  -1.4998258516091914,\n",
       "  0.6387058291317829,\n",
       "  0.8089623049890635,\n",
       "  -0.48219597930435076],\n",
       " [1.475932175137033,\n",
       "  0.3016845955009684,\n",
       "  1.2595268409807567,\n",
       "  -0.5198107224813744,\n",
       "  -0.25933280979980655,\n",
       "  0.2381635353862861,\n",
       "  0.39943650028990546,\n",
       "  1.0884375507104684,\n",
       "  1740528000.0,\n",
       "  -0.684330864003852,\n",
       "  1.4935294852804875,\n",
       "  -0.5030229780331003,\n",
       "  -0.5877994542343546],\n",
       " [-1.0808574903511738,\n",
       "  -1.115843595883507,\n",
       "  -0.08998749164883342,\n",
       "  -1.5555554753419798,\n",
       "  -0.5862343159516619,\n",
       "  -0.32553307928174136,\n",
       "  -0.16518016948389017,\n",
       "  -1.3242706484927658,\n",
       "  1765152000.0,\n",
       "  1.148277069860805,\n",
       "  1.2114670629138007,\n",
       "  -0.8387600170680479,\n",
       "  -0.5492711825454512],\n",
       " [1.715167824891137,\n",
       "  1.1611381730106065,\n",
       "  0.22089756813027908,\n",
       "  1.2313942910811502,\n",
       "  1.732822285941083,\n",
       "  0.39815783020887396,\n",
       "  0.12978918713174928,\n",
       "  -1.5709091879329653,\n",
       "  1761523200.0,\n",
       "  -1.031636326782404,\n",
       "  -0.20487248959787074,\n",
       "  -1.7594161733401101,\n",
       "  1.3639944651223654],\n",
       " [1.2853367895771017,\n",
       "  0.03742561242451919,\n",
       "  0.9361228548546701,\n",
       "  -1.4412938515809035,\n",
       "  -0.29618065682233835,\n",
       "  -1.3887184159525474,\n",
       "  -1.1828225782110022,\n",
       "  1.4787539589372556,\n",
       "  1757721600.0,\n",
       "  -1.194010255964733,\n",
       "  -1.2536342625246848,\n",
       "  -1.798180089252178,\n",
       "  0.9246423816866471],\n",
       " [1.6293859424290777,\n",
       "  0.6408185466267855,\n",
       "  -0.4492927068742284,\n",
       "  -1.3253768969700603,\n",
       "  1.0066706520890556,\n",
       "  -0.9401068707104657,\n",
       "  1.122872564907416,\n",
       "  -0.35394696101108064,\n",
       "  1775865600.0,\n",
       "  -1.3484252028424084,\n",
       "  0.7493479536197999,\n",
       "  1.3692530698806977,\n",
       "  -0.8483641271676587],\n",
       " [-0.9551471620550518,\n",
       "  1.1294909826338804,\n",
       "  1.0542633900097618,\n",
       "  1.6018360207111344,\n",
       "  -1.6811713511711734,\n",
       "  -1.007740757298055,\n",
       "  -1.6485649110953018,\n",
       "  1.291478125550947,\n",
       "  1775347200.0,\n",
       "  0.08651808015187526,\n",
       "  -0.4258494287359197,\n",
       "  -1.1368403010132337,\n",
       "  -0.9065619524216703],\n",
       " [0.05742311571285092,\n",
       "  -1.4986358053048237,\n",
       "  1.3696110884365735,\n",
       "  -1.1664411943441053,\n",
       "  -0.6428938012224192,\n",
       "  -0.2597474505314304,\n",
       "  -1.3116180511167632,\n",
       "  1.3069599357020047,\n",
       "  1795996800.0,\n",
       "  -1.358102223898829,\n",
       "  0.8050247971942919,\n",
       "  -0.4069122076316842,\n",
       "  1.30220677548248],\n",
       " [-0.815467796693129,\n",
       "  -1.275152529246118,\n",
       "  -0.4527353318192921,\n",
       "  -1.4425535348101206,\n",
       "  1.7323183565090463,\n",
       "  -1.384367033233695,\n",
       "  -1.2777358776654548,\n",
       "  -0.8307312043158471,\n",
       "  1759276800.0,\n",
       "  0.2998631025710544,\n",
       "  1.4595016747998604,\n",
       "  1.3570136713364103,\n",
       "  -1.4957242952971246],\n",
       " [-0.774237146517022,\n",
       "  1.7125045496241822,\n",
       "  1.2716399971906798,\n",
       "  -1.477739351547436,\n",
       "  1.2885854799746101,\n",
       "  -0.8644097497564387,\n",
       "  -1.6503785506950752,\n",
       "  1.6312399184446016,\n",
       "  1753401600.0,\n",
       "  1.0021766466576933,\n",
       "  -0.6829936705074199,\n",
       "  -0.6707534691688188,\n",
       "  0.9992596934351256],\n",
       " [-0.4509320842022577,\n",
       "  0.9163975673334657,\n",
       "  1.0698155993479697,\n",
       "  -0.48524687666806077,\n",
       "  -0.8743265733273591,\n",
       "  1.5187991208177,\n",
       "  -1.7298135145430453,\n",
       "  -0.31406555649593276,\n",
       "  1749945600.0,\n",
       "  -1.355856760038894,\n",
       "  1.0857047822847903,\n",
       "  -0.34307323579213567,\n",
       "  0.7126966399312079],\n",
       " [-0.21448794773080337,\n",
       "  0.34420772983322245,\n",
       "  0.4633158189685005,\n",
       "  0.15639349132720504,\n",
       "  -0.6139875738252594,\n",
       "  1.2088407819960185,\n",
       "  0.8252005264351279,\n",
       "  1.7024209291058916,\n",
       "  1783987200.0,\n",
       "  1.5424721201820188,\n",
       "  -0.7905251947783365,\n",
       "  0.23729235897205417,\n",
       "  -1.5423503944446335],\n",
       " [-1.0196793978155496,\n",
       "  0.6162213503651287,\n",
       "  1.161310608354969,\n",
       "  -1.416625493171626,\n",
       "  -1.5089168944914693,\n",
       "  1.4128724849770051,\n",
       "  -0.07860636853917495,\n",
       "  1.4329897914982708,\n",
       "  1770681600.0,\n",
       "  -0.19289286201676,\n",
       "  0.5210136203955752,\n",
       "  -1.2910932947925955,\n",
       "  -0.8643969747314321],\n",
       " [0.8978482379785194,\n",
       "  -0.8469610460128759,\n",
       "  0.9387444877039733,\n",
       "  -1.4398608599281237,\n",
       "  -1.4320595048359528,\n",
       "  -1.4143273857817509,\n",
       "  0.8879940412585257,\n",
       "  0.8469354225347799,\n",
       "  1777161600.0,\n",
       "  -0.9249268220722509,\n",
       "  -1.116129253685269,\n",
       "  -0.7211990060049415,\n",
       "  0.6843918712436933],\n",
       " [1.1617283380712435,\n",
       "  1.593025068602342,\n",
       "  1.7216284371931325,\n",
       "  -1.0230989867521956,\n",
       "  -0.3675689808035546,\n",
       "  0.9781635375836919,\n",
       "  -1.68320894751213,\n",
       "  0.7018500897455385,\n",
       "  1745107200.0,\n",
       "  0.7416380398464962,\n",
       "  1.2856094135468026,\n",
       "  0.48279482959607456,\n",
       "  0.41502791066034284],\n",
       " [0.5911356457689396,\n",
       "  1.5996029350499712,\n",
       "  -0.10255421078735519,\n",
       "  -0.6213903690894147,\n",
       "  1.4970834067807408,\n",
       "  -0.30627311609491703,\n",
       "  0.6737112316528805,\n",
       "  0.9637509466389066,\n",
       "  1784851200.0,\n",
       "  -0.2984547731648433,\n",
       "  1.0463970066160506,\n",
       "  1.1903129465547717,\n",
       "  -0.7729518679062382],\n",
       " [-1.013378006490156,\n",
       "  -0.026582120708757186,\n",
       "  -0.0679400344014702,\n",
       "  1.7738171647655407,\n",
       "  1.677478503692816,\n",
       "  -1.0417480747038101,\n",
       "  -1.5422983687007663,\n",
       "  -0.8018407484567566,\n",
       "  1769644800.0,\n",
       "  0.2135227119947308,\n",
       "  -0.05925891305884003,\n",
       "  0.4422973657354153,\n",
       "  -0.38146031899435084],\n",
       " [0.7627065741251793,\n",
       "  -0.8757807152722356,\n",
       "  0.5601941782164146,\n",
       "  -1.0481326056269116,\n",
       "  0.9704208756405557,\n",
       "  -0.19220964244006541,\n",
       "  1.503498903296284,\n",
       "  1.199814424966187,\n",
       "  1736121600.0,\n",
       "  1.1308995655221108,\n",
       "  -1.7474316093383133,\n",
       "  0.7913086663104798,\n",
       "  0.5506001704931226],\n",
       " [1.3654629632753237,\n",
       "  1.3620472037508438,\n",
       "  -1.5723421797136394,\n",
       "  -1.2724471233844077,\n",
       "  -0.5340930292920265,\n",
       "  -0.04496129067061947,\n",
       "  0.20871124114166828,\n",
       "  0.7287234275041141,\n",
       "  1792195200.0,\n",
       "  0.6705435008313294,\n",
       "  -0.38846848880072093,\n",
       "  0.18670965451590982,\n",
       "  0.5386786942494723],\n",
       " [-0.44304058856196954,\n",
       "  -1.0524021360794311,\n",
       "  -0.6512808659837659,\n",
       "  1.351401058564268,\n",
       "  1.4224554659784217,\n",
       "  0.3776178535281668,\n",
       "  0.5104041877086117,\n",
       "  0.8502981874429711,\n",
       "  1784505600.0,\n",
       "  -0.6848166542160603,\n",
       "  -1.3497026693919003,\n",
       "  -1.7529586768577126,\n",
       "  -0.9105780526050857],\n",
       " [-0.7469377765339312,\n",
       "  1.3381617558326955,\n",
       "  1.5379203829521806,\n",
       "  0.37136999612139876,\n",
       "  -1.4866743974343872,\n",
       "  1.6804314503698936,\n",
       "  1.0024433573997251,\n",
       "  -1.1785142715072194,\n",
       "  1742947200.0,\n",
       "  -1.096531448622179,\n",
       "  -1.2550159007747907,\n",
       "  -0.7194989132315568,\n",
       "  0.1625160600875891],\n",
       " [1.4661824437148643,\n",
       "  -0.6197181528749759,\n",
       "  -0.9503191090483881,\n",
       "  -1.4426217349522525,\n",
       "  -0.7665266056876363,\n",
       "  -0.3916896877021071,\n",
       "  0.8177913370214182,\n",
       "  -1.3887871039870316,\n",
       "  1753747200.0,\n",
       "  -0.8682272697816206,\n",
       "  -0.5509656612335038,\n",
       "  -0.033437111738211366,\n",
       "  1.649595164209831],\n",
       " [0.6714790724583269,\n",
       "  1.47868890722902,\n",
       "  -0.3387743275603556,\n",
       "  -0.7483514581754768,\n",
       "  1.703550314730093,\n",
       "  -0.8401131755013155,\n",
       "  0.616775577361145,\n",
       "  -1.1540952762410202,\n",
       "  1738972800.0,\n",
       "  -0.805650729390927,\n",
       "  -0.6823113632955202,\n",
       "  -0.08611883680940906,\n",
       "  1.5055300498681934],\n",
       " [1.5949882099128478,\n",
       "  1.4962356031947808,\n",
       "  0.9495765282248805,\n",
       "  -0.26304039453408024,\n",
       "  -1.5514492748691358,\n",
       "  0.0946365040428856,\n",
       "  1.5028970965676243,\n",
       "  -1.3261049698767597,\n",
       "  1779926400.0,\n",
       "  0.5604431549798974,\n",
       "  -1.503126934993389,\n",
       "  1.1876253559337688,\n",
       "  1.0799840818598698],\n",
       " [1.6834535569253644,\n",
       "  -0.5667825665883915,\n",
       "  1.4326041442159707,\n",
       "  0.5014997965782975,\n",
       "  -0.25759343997804207,\n",
       "  -1.1061069190759103,\n",
       "  1.2381514915563645,\n",
       "  1.0702133397770817,\n",
       "  1772928000.0,\n",
       "  0.8606418884666911,\n",
       "  0.4833680702238504,\n",
       "  -0.330783622911518,\n",
       "  -1.3733795501077761],\n",
       " [-0.08349086567484267,\n",
       "  -1.0453000110301023,\n",
       "  -0.2492208837571375,\n",
       "  -0.159658989167285,\n",
       "  -0.9536361551761713,\n",
       "  1.12950451730464,\n",
       "  1.0574410496443074,\n",
       "  1.5955623022563226,\n",
       "  1775260800.0,\n",
       "  -1.6792510933361027,\n",
       "  -1.0089837681202958,\n",
       "  -1.647799384237425,\n",
       "  1.2893489799786795],\n",
       " [0.9283718401442895,\n",
       "  0.9222089203366896,\n",
       "  -0.6604131639285931,\n",
       "  -0.050795338672774124,\n",
       "  -0.8092842796542215,\n",
       "  0.3300404403142136,\n",
       "  -1.223983471860009,\n",
       "  0.9470379959413169,\n",
       "  1767657600.0,\n",
       "  -0.5915189458794785,\n",
       "  0.383728253362211,\n",
       "  -0.5302346819409743,\n",
       "  0.7790254997072011],\n",
       " [-0.5722675272211,\n",
       "  -1.4923402315523722,\n",
       "  -1.001837328051927,\n",
       "  1.1693800640839278,\n",
       "  1.5805414324789988,\n",
       "  0.7197775027512796,\n",
       "  0.37497078510616266,\n",
       "  1.3504777136894424,\n",
       "  1743897600.0,\n",
       "  -1.198453247817114,\n",
       "  0.048182197859023536,\n",
       "  0.45931142002683445,\n",
       "  -0.6690610682708586],\n",
       " [1.1449214123243001,\n",
       "  1.2116538461744146,\n",
       "  -0.841530704739461,\n",
       "  -0.543329099284709,\n",
       "  1.3185560943428836,\n",
       "  0.6588575179461134,\n",
       "  -1.1247104976067612,\n",
       "  1.7516711250888617,\n",
       "  1765324800.0,\n",
       "  1.4885521667764026,\n",
       "  1.677774063715538,\n",
       "  0.6794931779133199,\n",
       "  1.219796115738171],\n",
       " [1.6644542904455883,\n",
       "  -0.5150399203901503,\n",
       "  0.6961199231632873,\n",
       "  -0.05918808892595643,\n",
       "  0.592404302159025,\n",
       "  1.5996323874297231,\n",
       "  -0.10019047033679973,\n",
       "  -0.6244046644437752,\n",
       "  1784764800.0,\n",
       "  1.4992886778375165,\n",
       "  -0.3071874523831371,\n",
       "  0.6749400002526356,\n",
       "  0.9614997998511914],\n",
       " [-1.6541775606693134,\n",
       "  0.11311169099160753,\n",
       "  0.5170167906466275,\n",
       "  -0.38295526055627416,\n",
       "  0.9875374462296078,\n",
       "  1.1497045884516344,\n",
       "  -0.05875687262901543,\n",
       "  0.9779074365248952,\n",
       "  1765843200.0,\n",
       "  0.06628858041535411,\n",
       "  0.40984396498097214,\n",
       "  1.6814038119038863,\n",
       "  -0.6603482553132822],\n",
       " [-1.6981106337605887,\n",
       "  -1.6987406104126466,\n",
       "  -0.17474803045769502,\n",
       "  -1.1368202669902394,\n",
       "  0.8048245516504676,\n",
       "  -1.705529917904466,\n",
       "  -0.09643694702819716,\n",
       "  1.5979724385887366,\n",
       "  1756857600.0,\n",
       "  -0.5494717804910653,\n",
       "  -0.17370453809957817,\n",
       "  0.24488334994426245,\n",
       "  0.5977860005117315],\n",
       " [0.597231114831489,\n",
       "  -0.928994391595218,\n",
       "  -0.6902738964548678,\n",
       "  0.7966402940989145,\n",
       "  1.702291389174934,\n",
       "  1.414502290309695,\n",
       "  -0.4047635698115094,\n",
       "  -0.7858906409343916,\n",
       "  1737158400.0,\n",
       "  -0.793264158310662,\n",
       "  0.957657145646371,\n",
       "  -1.7733320659349634,\n",
       "  -0.07167821670507722],\n",
       " [-1.3871524504316635,\n",
       "  1.514392243500808,\n",
       "  -1.0421914338551117,\n",
       "  0.016365876641500295,\n",
       "  0.2785910990390437,\n",
       "  1.5313124530118762,\n",
       "  -0.6163382379114827,\n",
       "  1.132129028933384,\n",
       "  1763251200.0,\n",
       "  0.09012358899185437,\n",
       "  1.0116094926120538,\n",
       "  1.694915417462745,\n",
       "  -1.1972274764858433],\n",
       " [-0.9793272820348159,\n",
       "  -1.0781752552597945,\n",
       "  -0.03878987371181363,\n",
       "  0.6869219788135007,\n",
       "  -0.25068766123834546,\n",
       "  -0.5729060264730844,\n",
       "  0.6250192681325989,\n",
       "  -1.6564646590727348,\n",
       "  1787875200.0,\n",
       "  -0.3327939980770755,\n",
       "  -0.6261115128510889,\n",
       "  -1.3138593554487603,\n",
       "  -0.0679884274733867],\n",
       " [-0.9474860561054703,\n",
       "  -0.48033511642476895,\n",
       "  1.651884180518652,\n",
       "  0.8904180778926574,\n",
       "  -0.33963164999784395,\n",
       "  1.2656376447531361,\n",
       "  -0.28573311185865147,\n",
       "  -1.3024585786192882,\n",
       "  1769472000.0,\n",
       "  -1.0098775938307125,\n",
       "  -0.027391028306215478,\n",
       "  -0.06447063768398253,\n",
       "  1.7653392913693466],\n",
       " [1.2496018775162632,\n",
       "  1.0275209572182162,\n",
       "  -1.4359643839858751,\n",
       "  1.29269692437788,\n",
       "  0.214429096667221,\n",
       "  1.588767601008707,\n",
       "  1.0460979085476272,\n",
       "  0.5616102948347905,\n",
       "  1759622400.0,\n",
       "  -0.7559147098232509,\n",
       "  -1.4040027382126907,\n",
       "  -0.4619510730859113,\n",
       "  -0.09725008517229246],\n",
       " [-0.9461762772457699,\n",
       "  0.2567618257189623,\n",
       "  -0.12354909122842679,\n",
       "  1.625928320155685,\n",
       "  -0.7840382534665847,\n",
       "  0.559821891019308,\n",
       "  -0.08190113712502721,\n",
       "  1.557322332199847,\n",
       "  1750377600.0,\n",
       "  1.108332239394672,\n",
       "  -0.8796463021757103,\n",
       "  0.8993232991606405,\n",
       "  1.2794593079920167],\n",
       " [-1.3474470237929086,\n",
       "  -0.34735531423670296,\n",
       "  0.05227272360398526,\n",
       "  -0.8015090185929392,\n",
       "  -1.2609013962691595,\n",
       "  -0.6974783217738839,\n",
       "  0.5987689592005189,\n",
       "  -0.6684961366959106,\n",
       "  1795737600.0,\n",
       "  -0.69194048886907,\n",
       "  0.3271062011612049,\n",
       "  -1.3837255690873846,\n",
       "  -0.4611892477098404],\n",
       " [-0.28742144389125185,\n",
       "  -0.09046285008294225,\n",
       "  -0.48317729510399005,\n",
       "  -0.5011514350107802,\n",
       "  -1.6177602073405026,\n",
       "  0.7011332629784245,\n",
       "  -0.22186133212741105,\n",
       "  1.7050867819304263,\n",
       "  1791849600.0,\n",
       "  0.9795794028876541,\n",
       "  -0.8223402595156665,\n",
       "  0.33252324735465694,\n",
       "  0.6471780621578004],\n",
       " [-0.9840674885856825,\n",
       "  1.5966242899731422,\n",
       "  -1.595260867761445,\n",
       "  -0.5700746737172139,\n",
       "  -0.4516169225223681,\n",
       "  -1.548110392204884,\n",
       "  0.5313482845157543,\n",
       "  1.3879756379778432,\n",
       "  1777852800.0,\n",
       "  -0.12519661399996954,\n",
       "  1.6703309064607679,\n",
       "  -1.6234612126308487,\n",
       "  1.3098316884811785],\n",
       " [0.09684103760513328,\n",
       "  0.7793165148744083,\n",
       "  1.089267365761619,\n",
       "  0.8698840112288623,\n",
       "  -1.5277831080487145,\n",
       "  0.7724669209758855,\n",
       "  0.6147377170996684,\n",
       "  -1.236184278846773,\n",
       "  1794787200.0,\n",
       "  -0.6260981875334648,\n",
       "  1.0511353324765376,\n",
       "  -1.579972300078119,\n",
       "  0.7790420361705191],\n",
       " [-1.1060535723437974,\n",
       "  -0.7105707494558668,\n",
       "  -0.44817794291277824,\n",
       "  -0.9466394525535299,\n",
       "  0.7164768422248422,\n",
       "  -1.1765756103282128,\n",
       "  0.0032777963428996214,\n",
       "  1.5618624716755876,\n",
       "  1779580800.0,\n",
       "  -1.3749900311453973,\n",
       "  -1.5129149793841388,\n",
       "  1.3201196677083176,\n",
       "  -1.5834402608657763],\n",
       " [-0.5529413120921524,\n",
       "  -0.17282215542382262,\n",
       "  0.2411347960597644,\n",
       "  0.6049847515022606,\n",
       "  -0.6607911565230307,\n",
       "  1.3350259484591964,\n",
       "  -0.8358117063479751,\n",
       "  -1.3397607935224911,\n",
       "  1757030400.0,\n",
       "  -0.7936062891827896,\n",
       "  -0.40564448341495285,\n",
       "  -1.792275429238345,\n",
       "  -0.5669676535304787],\n",
       " [1.495956563900236,\n",
       "  -0.3062380378414098,\n",
       "  0.6708033686288638,\n",
       "  0.9690970204221907,\n",
       "  -0.3004988442085136,\n",
       "  1.0466774143250763,\n",
       "  1.1889813931729805,\n",
       "  -0.7700552864966661,\n",
       "  1784937600.0,\n",
       "  -0.8836427292796953,\n",
       "  -0.6631492207944606,\n",
       "  1.6171302262823752,\n",
       "  0.5977763610218592],\n",
       " [1.4213169247507969,\n",
       "  0.37762977642729345,\n",
       "  0.507611144239568,\n",
       "  0.8554776864304676,\n",
       "  -0.6868260809726083,\n",
       "  -1.348300088586751,\n",
       "  -1.7537032309907914,\n",
       "  -0.9076302569091026,\n",
       "  1784592000.0,\n",
       "  1.6677751033979784,\n",
       "  -0.5160942428300382,\n",
       "  0.7002794207630162,\n",
       "  -0.0656599963144554],\n",
       " [1.475438530210432,\n",
       "  -0.748419097589261,\n",
       "  -0.7317106173600286,\n",
       "  -0.8606405290562249,\n",
       "  -1.6668026670374894,\n",
       "  0.4913277267703161,\n",
       "  0.5540595100282921,\n",
       "  0.3640398457298269,\n",
       "  1752364800.0,\n",
       "  0.4287101089696707,\n",
       "  0.6237003890527202,\n",
       "  0.44997872854411236,\n",
       "  -0.15534877433037725],\n",
       " [-0.669559052088313,\n",
       "  1.5358057629419628,\n",
       "  0.9196203114192714,\n",
       "  0.4730155344259642,\n",
       "  0.8990688229897693,\n",
       "  -0.8470144328234094,\n",
       "  0.9418408700043607,\n",
       "  -1.4416752137753504,\n",
       "  1777075200.0,\n",
       "  -1.4301169076431854,\n",
       "  -1.415760903853088,\n",
       "  0.8892655544484476,\n",
       "  0.8446407894668875],\n",
       " [0.5570480693282313,\n",
       "  -1.5015769487939405,\n",
       "  1.183026083461056,\n",
       "  1.0877111088397269,\n",
       "  -1.2599742964230058,\n",
       "  0.2958448246886799,\n",
       "  0.442456700641344,\n",
       "  0.24633835245472946,\n",
       "  1780099200.0,\n",
       "  -1.1991813643872014,\n",
       "  -1.5352469857746684,\n",
       "  1.4336909163157054,\n",
       "  1.7447485157757743],\n",
       " [0.9081871011279027,\n",
       "  -0.4996331052592283,\n",
       "  1.6527889922046999,\n",
       "  1.458623225988053,\n",
       "  0.22799144267629595,\n",
       "  -0.06876527809523286,\n",
       "  -1.782890487534043,\n",
       "  -0.3343987108292159,\n",
       "  1741046400.0,\n",
       "  1.159066260467887,\n",
       "  0.8042383020729661,\n",
       "  0.8212434676501287,\n",
       "  -1.598176171503194],\n",
       " [0.5020804850269949,\n",
       "  0.6025796391117266,\n",
       "  1.0380453496291295,\n",
       "  -0.1817713535902633,\n",
       "  -0.6680928057265219,\n",
       "  1.535833055187698,\n",
       "  0.9227032382415042,\n",
       "  0.46839675475117953,\n",
       "  1776988800.0,\n",
       "  0.9012204664816915,\n",
       "  -0.8481821348976786,\n",
       "  0.9431231244228057,\n",
       "  -1.4448218154844865],\n",
       " [-1.1704289322762937,\n",
       "  -0.3396314492924648,\n",
       "  -0.9878506189291446,\n",
       "  1.6330324989849374,\n",
       "  -0.4416098446710582,\n",
       "  -1.0524624790021628,\n",
       "  -0.6493032012214809,\n",
       "  1.3454944972755132,\n",
       "  1784419200.0,\n",
       "  1.42465404469885,\n",
       "  0.37702395617762346,\n",
       "  0.5116003802343567,\n",
       "  0.8480048062132918],\n",
       " [-0.2975886038746592,\n",
       "  -1.3886466879907837,\n",
       "  -1.184425130816727,\n",
       "  1.4848561758254897,\n",
       "  -1.1959740243626151,\n",
       "  -1.2522766737466424,\n",
       "  -1.7989156245319202,\n",
       "  0.9269072440792409,\n",
       "  1757808000.0,\n",
       "  -1.2900721942158426,\n",
       "  1.4112180187277066,\n",
       "  0.5138526318764485,\n",
       "  -1.1256238630646236],\n",
       " [0.815657239497837,\n",
       "  1.4185186909058278,\n",
       "  -0.2723094089737366,\n",
       "  0.6067387913644117,\n",
       "  1.6193157165211756,\n",
       "  1.3989953201482477,\n",
       "  1.220620205136412,\n",
       "  1.3664074362397913,\n",
       "  1737849600.0,\n",
       "  1.268368556422685,\n",
       "  1.4030237340921146,\n",
       "  -1.2508962854665227,\n",
       "  -1.4622031755758047],\n",
       " [1.4384780022513692,\n",
       "  0.48776764990947935,\n",
       "  -0.4455982478714158,\n",
       "  0.04271486860764283,\n",
       "  1.1792647037420605,\n",
       "  1.0458410250076948,\n",
       "  0.9046273531410722,\n",
       "  -0.9162970483409553,\n",
       "  1763078400.0,\n",
       "  -1.3836269690699292,\n",
       "  1.5143575644672649,\n",
       "  -1.0396019834607249,\n",
       "  0.0098112860820886],\n",
       " [0.6116895783286874,\n",
       "  -1.637102887314481,\n",
       "  0.5450274038763385,\n",
       "  -1.0056079803070992,\n",
       "  -1.6927244885356434,\n",
       "  -1.2373440862607272,\n",
       "  0.7460861962810822,\n",
       "  -1.452780029063549,\n",
       "  1775692800.0,\n",
       "  1.632709107382763,\n",
       "  0.6403449597667961,\n",
       "  -0.44616774885309285,\n",
       "  -1.3304631390948372],\n",
       " [-0.11338697424186385,\n",
       "  -0.0766419719194673,\n",
       "  0.007161352765927105,\n",
       "  -0.330483267617178,\n",
       "  -0.44950010346914904,\n",
       "  0.9164038867888803,\n",
       "  1.0730042012793175,\n",
       "  -0.4884607689893384,\n",
       "  1749859200.0,\n",
       "  -0.8723339608677971,\n",
       "  1.5187399269933466,\n",
       "  -1.7290641949500556,\n",
       "  -0.31679238908736773],\n",
       " [-1.6950634879890167,\n",
       "  -0.04063506301468011,\n",
       "  -0.9146398910162056,\n",
       "  0.823060504562059,\n",
       "  1.231955751574897,\n",
       "  -1.2243347825700366,\n",
       "  -0.8499160537342819,\n",
       "  -1.283539798523205,\n",
       "  1759881600.0,\n",
       "  -1.4072169808945918,\n",
       "  1.1487873809686326,\n",
       "  1.45984168688573,\n",
       "  -1.1334668020178336],\n",
       " [0.4253061875132353,\n",
       "  0.6241823344104189,\n",
       "  0.4460450991566418,\n",
       "  -0.14897512620455622,\n",
       "  -0.13264627961295566,\n",
       "  -0.6722376428938063,\n",
       "  0.28921032706913224,\n",
       "  0.6667366258295582,\n",
       "  1752537600.0,\n",
       "  1.041077262838574,\n",
       "  0.4286437453102928,\n",
       "  -1.560425926080576,\n",
       "  -1.5030453230841248],\n",
       " [1.6667307748954687,\n",
       "  -0.3950835006188158,\n",
       "  -0.37951959457234247,\n",
       "  0.3396876643706206,\n",
       "  1.7035349450063122,\n",
       "  0.5808846251327197,\n",
       "  1.151645680031925,\n",
       "  0.9712687738445824,\n",
       "  1769299200.0,\n",
       "  -0.9439900627574974,\n",
       "  -0.48137200220175114,\n",
       "  1.656906926808075,\n",
       "  0.8829069603395941],\n",
       " [0.8965741220830632,\n",
       "  -1.0009824431545797,\n",
       "  -1.7847399387613503,\n",
       "  0.6393539400573236,\n",
       "  -0.7301338797743808,\n",
       "  0.9448469917833578,\n",
       "  -0.03371994599058998,\n",
       "  1.738049284687342,\n",
       "  1771718400.0,\n",
       "  -0.45513098883340014,\n",
       "  -0.13071868322146726,\n",
       "  0.025816220060427345,\n",
       "  -0.7435180014513911],\n",
       " [0.09315849921429926,\n",
       "  1.4712448776791602,\n",
       "  0.6136370741919748,\n",
       "  1.4875051877448056,\n",
       "  0.9686317093600842,\n",
       "  -0.05691943347448287,\n",
       "  -0.6673880739937651,\n",
       "  1.069125042100903,\n",
       "  1778457600.0,\n",
       "  0.8580331051105103,\n",
       "  1.0138879355714145,\n",
       "  -0.09903929462181911,\n",
       "  -1.4220686674792198],\n",
       " [-0.7916237423126099,\n",
       "  -0.8295069495335731,\n",
       "  -0.8195416797522495,\n",
       "  -1.2128793807113174,\n",
       "  -0.2796109244338313,\n",
       "  -0.7478870124763571,\n",
       "  1.0911842881897273,\n",
       "  -0.43209842196272974,\n",
       "  1765670400.0,\n",
       "  -1.6506341701832368,\n",
       "  0.11237296946715125,\n",
       "  0.521014521844992,\n",
       "  -0.38907285038927786],\n",
       " [-0.33674201128351666,\n",
       "  -1.0704526941783372,\n",
       "  -0.5066121521893251,\n",
       "  0.4887589409944604,\n",
       "  -0.37657194657873166,\n",
       "  0.04258539467203282,\n",
       "  0.6384190733619655,\n",
       "  0.21589323772792346,\n",
       "  1762646400.0,\n",
       "  0.8967777535302596,\n",
       "  1.3396341589184682,\n",
       "  1.1195331633148924,\n",
       "  1.0141319925030803],\n",
       " [1.277655053492567,\n",
       "  0.7054727995202521,\n",
       "  1.4462432964818936,\n",
       "  1.1194814193362206,\n",
       "  -0.7124586053160401,\n",
       "  0.7169362777941551,\n",
       "  0.7083785025050621,\n",
       "  -0.36251699321112235,\n",
       "  1793145600.0,\n",
       "  -0.33611114364147954,\n",
       "  -0.45092207093302555,\n",
       "  0.12619442216501217,\n",
       "  -0.31825438874221545],\n",
       " [-1.228589556364176,\n",
       "  -1.2193945781917146,\n",
       "  0.37496869901281576,\n",
       "  -1.3315801674282974,\n",
       "  -1.5916364280423905,\n",
       "  1.473530458575859,\n",
       "  1.181322535569382,\n",
       "  1.139078816079401,\n",
       "  1747267200.0,\n",
       "  -0.09581295068836777,\n",
       "  0.3518149597350662,\n",
       "  0.06677209786611649,\n",
       "  -0.4312666200809436],\n",
       " [-0.3395663643844353,\n",
       "  -0.44990047636932423,\n",
       "  0.12255297168360384,\n",
       "  -0.3120592131735226,\n",
       "  0.8518890628179642,\n",
       "  -0.22468029866545977,\n",
       "  1.0597342671066432,\n",
       "  -1.485288436580128,\n",
       "  1793318400.0,\n",
       "  -1.657050815674775,\n",
       "  -1.0702520384918963,\n",
       "  1.1916274857949576,\n",
       "  0.9103317965415711],\n",
       " [-0.296209134872018,\n",
       "  -0.20925833603886362,\n",
       "  -1.7303841620936207,\n",
       "  -0.5531642970894207,\n",
       "  0.07726494996664253,\n",
       "  0.6527076997958526,\n",
       "  -0.24412480178675855,\n",
       "  -0.07372918589035718,\n",
       "  1744588800.0,\n",
       "  -0.7601036335796825,\n",
       "  -0.5292035308082081,\n",
       "  -1.6903377316141417,\n",
       "  -1.0094340711858947],\n",
       " [1.0765870348541002,\n",
       "  -1.1630971788427709,\n",
       "  -1.5351334435490227,\n",
       "  1.4252982829542873,\n",
       "  -0.39721440460863877,\n",
       "  -1.348006656335773,\n",
       "  -0.2552070789396247,\n",
       "  -0.7407565149767703,\n",
       "  1768176000.0,\n",
       "  -1.0581860262129095,\n",
       "  -0.04546562583471829,\n",
       "  0.3342175275726512,\n",
       "  0.16882072769571504],\n",
       " [0.9942060214865788,\n",
       "  -0.34554974038059594,\n",
       "  -1.042979757058209,\n",
       "  -1.4745638689379374,\n",
       "  0.3836769465844779,\n",
       "  -1.2510807423311716,\n",
       "  0.644255044508965,\n",
       "  -0.5791383745220582,\n",
       "  1743552000.0,\n",
       "  -0.7902901628995896,\n",
       "  0.7270241292440536,\n",
       "  0.8289292731882654,\n",
       "  -0.16697772056415222],\n",
       " [-0.26452768363699575,\n",
       "  -1.323123672307329,\n",
       "  0.08494941079914456,\n",
       "  1.5677096993112039,\n",
       "  0.612955013279863,\n",
       "  -1.6371830278542654,\n",
       "  0.5478467728538207,\n",
       "  -1.0080589827087725,\n",
       "  1775606400.0,\n",
       "  -1.6908052667398934,\n",
       "  -1.2386946783350796,\n",
       "  0.7473294020548087,\n",
       "  -1.4559307647019095],\n",
       " [1.4514262706047505,\n",
       "  -0.9198911470974244,\n",
       "  1.6476820955580462,\n",
       "  1.0605065296790084,\n",
       "  -1.294113097165186,\n",
       "  0.733934054578832,\n",
       "  -0.07358263450415116,\n",
       "  -1.2187951761725542,\n",
       "  1764547200.0,\n",
       "  -0.5038474768218907,\n",
       "  1.3250318950684075,\n",
       "  -0.4643491748609969,\n",
       "  1.6422831066029229],\n",
       " [-1.3943030811405428,\n",
       "  -0.3221524602523235,\n",
       "  -0.7518502088553304,\n",
       "  1.0065911644479633,\n",
       "  1.6377014397799872,\n",
       "  -0.20231697983289149,\n",
       "  -0.414970873343426,\n",
       "  0.7516589349300651,\n",
       "  1754524800.0,\n",
       "  -0.7367024107085764,\n",
       "  1.0826514592307057,\n",
       "  1.641098118211191,\n",
       "  0.6519214847024626],\n",
       " [0.5244389772625567,\n",
       "  0.4490109937245017,\n",
       "  1.359944132881396,\n",
       "  1.6984134286215005,\n",
       "  -1.3093634466939974,\n",
       "  -1.4341764113700763,\n",
       "  -1.6657633876995273,\n",
       "  0.8810654858326483,\n",
       "  1776297600.0,\n",
       "  1.3973833967023717,\n",
       "  -0.3405395837661757,\n",
       "  0.19643146858866123,\n",
       "  1.5494536592360724],\n",
       " [-1.2696503641286627,\n",
       "  -0.5779858512994366,\n",
       "  -1.3620710335521555,\n",
       "  -0.05903274892890371,\n",
       "  0.13385193260983744,\n",
       "  0.3704554029161033,\n",
       "  0.09344199381087283,\n",
       "  1.3965110867626325,\n",
       "  1746489600.0,\n",
       "  -0.19396168817986292,\n",
       "  -1.704741563838009,\n",
       "  -0.6624525258610403,\n",
       "  1.5502219282176597],\n",
       " [-0.05166984605945219,\n",
       "  -0.5817478563198565,\n",
       "  -0.17702002413697832,\n",
       "  -1.0083217424040412,\n",
       "  1.3359070749955495,\n",
       "  0.8866756576364494,\n",
       "  0.6633689869042413,\n",
       "  -1.4719964290478866,\n",
       "  1789084800.0,\n",
       "  0.40813811841573033,\n",
       "  1.4688435189320648,\n",
       "  -0.4438797127355205,\n",
       "  -1.3515371534461054],\n",
       " [0.1056423034735987,\n",
       "  -1.620395110145235,\n",
       "  1.6231643639142934,\n",
       "  -0.5372589151144724,\n",
       "  0.8168907063884917,\n",
       "  1.4185420118815886,\n",
       "  -0.2700651056862142,\n",
       "  0.6019239629764899,\n",
       "  1737763200.0,\n",
       "  1.6215319488844069,\n",
       "  1.3988799919335875,\n",
       "  1.22195806974799,\n",
       "  1.3643061841947162],\n",
       " [1.3177643440854232,\n",
       "  1.5349630341060763,\n",
       "  -1.4729386444703987,\n",
       "  1.7774955482246113,\n",
       "  -0.27477612352718017,\n",
       "  -0.9197458933440145,\n",
       "  -0.06773430973292455,\n",
       "  -0.038030191041741386,\n",
       "  1742169600.0,\n",
       "  -0.17790201071108608,\n",
       "  -0.3654859621634786,\n",
       "  -1.7670153380904874,\n",
       "  1.2026528230712292],\n",
       " [-0.36898811837493917,\n",
       "  0.9781551270543136,\n",
       "  -1.684459683448775,\n",
       "  0.7068116327156208,\n",
       "  0.7395007057874637,\n",
       "  1.285777790137088,\n",
       "  0.48160438198236855,\n",
       "  0.4174824138653697,\n",
       "  1745193600.0,\n",
       "  -0.608966235076481,\n",
       "  1.2070817691347198,\n",
       "  -1.4875825567998804,\n",
       "  -1.3203138595467823],\n",
       " [1.7312283880225963,\n",
       "  -1.3842954526021543,\n",
       "  -1.279271697676301,\n",
       "  -0.828019843870151,\n",
       "  0.2977653815756315,\n",
       "  1.459588611866091,\n",
       "  1.3556488715496906,\n",
       "  -1.492558751450009,\n",
       "  1759363200.0,\n",
       "  -0.21223481972297184,\n",
       "  0.6409370331997393,\n",
       "  -0.17844041974413927,\n",
       "  -0.7609169699778272],\n",
       " [0.20578654918845538,\n",
       "  -1.6313459467744984,\n",
       "  0.0734669190872952,\n",
       "  -0.9010520399927487,\n",
       "  -1.6167505013706034,\n",
       "  0.4850379393450975,\n",
       "  -0.2121035288185653,\n",
       "  1.203640048703186,\n",
       "  1773619200.0,\n",
       "  0.2851163443130464,\n",
       "  -1.321159075105906,\n",
       "  0.3231059197187373,\n",
       "  0.8422080515241173],\n",
       " [0.3976953853356076,\n",
       "  0.520275452168203,\n",
       "  0.6984043525777225,\n",
       "  -0.2523232724156877,\n",
       "  1.3861810822246858,\n",
       "  1.479775639804173,\n",
       "  -0.9058254944071813,\n",
       "  -0.15295126622370508,\n",
       "  1744848000.0,\n",
       "  -0.28117738542887,\n",
       "  -0.0882095373233946,\n",
       "  -0.38036981371723144,\n",
       "  1.7195135198642306]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[num_col_names] = scaler.fit_transform(x_train[num_col_names])\n",
    "x_train = x_train.values.tolist()\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d94c446-5579-410c-b781-a366b2d65c2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.5903120476659803,\n",
       "  -1.3616681706696379,\n",
       "  -0.5607913282484407,\n",
       "  1.7457102685851866,\n",
       "  -0.6794221763041048,\n",
       "  -0.3388173505851365,\n",
       "  -0.19960539614811565,\n",
       "  0.7679140257547803,\n",
       "  1796256000.0,\n",
       "  1.316607298553949,\n",
       "  1.6590406276033878,\n",
       "  1.189218869012612,\n",
       "  1.0488345635987633],\n",
       " [-0.6808901986081,\n",
       "  -0.33878117044066103,\n",
       "  -0.20189923895516698,\n",
       "  0.7729725658074162,\n",
       "  1.3144184081663497,\n",
       "  1.6590341139477194,\n",
       "  1.1878875338311017,\n",
       "  1.0510532108471358,\n",
       "  1796342400.0,\n",
       "  -1.0777191440715848,\n",
       "  1.6280076753067314,\n",
       "  1.1544691919613894,\n",
       "  -0.48290300175715795],\n",
       " [1.3132629315256543,\n",
       "  1.6590026503292035,\n",
       "  1.1846181585736388,\n",
       "  1.0565274644731608,\n",
       "  -1.0796933400578699,\n",
       "  1.6280156954137897,\n",
       "  1.1531447871746683,\n",
       "  -0.48011435508207456,\n",
       "  1796428800.0,\n",
       "  0.8838637164198925,\n",
       "  -1.4937011901750916,\n",
       "  1.736166652106881,\n",
       "  -0.1417730042959211],\n",
       " [-1.0812241071055269,\n",
       "  1.6279852820247773,\n",
       "  1.1498998391961108,\n",
       "  -0.47688820830174267,\n",
       "  0.8817136292725843,\n",
       "  -1.4922311700778619,\n",
       "  1.7347262349313042,\n",
       "  -0.13911130097418012,\n",
       "  1796515200.0,\n",
       "  -1.1586702838602523,\n",
       "  1.625483391713076,\n",
       "  1.0831578090674239,\n",
       "  -1.6524671137796478],\n",
       " [0.8804903237376506,\n",
       "  -1.4921559373549431,\n",
       "  1.731072382833248,\n",
       "  -0.1353844831259648,\n",
       "  -1.1606372211218359,\n",
       "  1.6254925940260183,\n",
       "  1.08184762645709,\n",
       "  -1.6492432418489904,\n",
       "  1796601600.0,\n",
       "  0.013091391710978872,\n",
       "  0.059976359730731205,\n",
       "  -0.7547119789261608,\n",
       "  -0.5544396020203143],\n",
       " [-1.1621806765755742,\n",
       "  1.6254622660648144,\n",
       "  1.0786528068016392,\n",
       "  -1.6477336457012102,\n",
       "  0.011019384953882426,\n",
       "  0.060718741005581084,\n",
       "  -0.7556556210594957,\n",
       "  -0.5516243347138243,\n",
       "  1796688000.0,\n",
       "  1.3088226230673063,\n",
       "  0.9252838444567244,\n",
       "  -0.3440448233896172,\n",
       "  -1.2861225988854676],\n",
       " [0.00965959322630044,\n",
       "  0.06074139355545513,\n",
       "  -0.7575585104953699,\n",
       "  -0.5485031810631295,\n",
       "  1.3066344307157864,\n",
       "  0.9256209734839501,\n",
       "  -0.3450703680255459,\n",
       "  -1.283035053286547,\n",
       "  1796774400.0,\n",
       "  -1.1374590555361426,\n",
       "  -0.5623858289124423,\n",
       "  0.5207454086452963,\n",
       "  -1.6015780239363342],\n",
       " [1.3054777338930894,\n",
       "  0.9256143419540699,\n",
       "  -0.3472619358606687,\n",
       "  -1.2809877791249589,\n",
       "  -1.139427894765597,\n",
       "  -0.5613519747447354,\n",
       "  0.5195473922563495,\n",
       "  -1.5983730891609,\n",
       "  1796860800.0,\n",
       "  0.8328029131293074,\n",
       "  1.3783950485874206,\n",
       "  0.9880898747826624,\n",
       "  -1.5765226974432562],\n",
       " [-1.1409680255388037,\n",
       "  -0.5613082599663588,\n",
       "  0.5167479202913154,\n",
       "  -1.5967888039059024,\n",
       "  0.8306574045007834,\n",
       "  1.3785199705817257,\n",
       "  0.9867986523000849,\n",
       "  -1.5733270864071234,\n",
       "  1796947200.0,\n",
       "  -0.23518274054719515,\n",
       "  1.6151124156452785,\n",
       "  -0.2859184250214346,\n",
       "  -1.165148575109982],\n",
       " [0.8294260956170558,\n",
       "  1.378498004682418,\n",
       "  0.9836706606310439,\n",
       "  -1.5717060278482098,\n",
       "  -0.23723248506584405,\n",
       "  1.6151264750309213,\n",
       "  -0.2869555622510951,\n",
       "  -1.1621060470948554,\n",
       "  1797033600.0,\n",
       "  0.7130350713659953,\n",
       "  -0.712588327480906,\n",
       "  0.12319750123499511,\n",
       "  -0.4790223632696506],\n",
       " [-0.23863119166254096,\n",
       "  1.6150964980484106,\n",
       "  -0.28918799002694795,\n",
       "  -1.1598812212839822,\n",
       "  0.7109003020771981,\n",
       "  -0.7114841284921751,\n",
       "  0.12207877087630148,\n",
       "  -0.47623516068118044,\n",
       "  1797120000.0,\n",
       "  -0.21108652199444528,\n",
       "  -1.480418316675288,\n",
       "  0.3526539246330131,\n",
       "  -1.3320738851214526],\n",
       " [0.7096502205978561,\n",
       "  -0.7114353305011546,\n",
       "  0.11955875513752891,\n",
       "  -0.4730033183495043,\n",
       "  -0.21313842717219397,\n",
       "  -1.4789545173890828,\n",
       "  0.35148943201878197,\n",
       "  -1.328969239852586,\n",
       "  1797206400.0,\n",
       "  -1.5550767655042494,\n",
       "  1.1736562778484807,\n",
       "  -0.09001867274690592,\n",
       "  -1.031397113286018],\n",
       " [-0.2145333568905564,\n",
       "  -1.4788797341904474,\n",
       "  0.34880811993061595,\n",
       "  -1.3269894076624504,\n",
       "  -1.5570081577997255,\n",
       "  1.173877085812204,\n",
       "  -0.09109487976764286,\n",
       "  -1.0284043576720427,\n",
       "  1797292800.0,\n",
       "  0.8759336051961208,\n",
       "  1.4082890176697023,\n",
       "  -1.7226012486529982,\n",
       "  -0.1256954872371319],\n",
       " [-1.5586137466147172,\n",
       "  1.1738620487637348,\n",
       "  -0.09346501523727492,\n",
       "  -1.0259832269694251,\n",
       "  0.8737842291258201,\n",
       "  1.4083999393249662,\n",
       "  -1.7233518572009696,\n",
       "  -0.1230397667780651,\n",
       "  1797379200.0,\n",
       "  -1.0137943497873716,\n",
       "  0.8142475485125865,\n",
       "  1.5239169077989645,\n",
       "  -1.4446874875137015],\n",
       " [0.8725596806130637,\n",
       "  1.4083769617420776,\n",
       "  -1.7245743690579027,\n",
       "  -0.1192893522139507,\n",
       "  -1.0157742777804515,\n",
       "  0.8146366795267285,\n",
       "  1.5225188212188574,\n",
       "  -1.4415409357915,\n",
       "  1797465600.0,\n",
       "  -1.6275169263580747,\n",
       "  0.9295269641317391,\n",
       "  -1.140986335781109,\n",
       "  -0.08222780206494675],\n",
       " [-1.017295025157593,\n",
       "  0.8146338057312993,\n",
       "  1.5190141700383855,\n",
       "  -1.4397263847932493,\n",
       "  -1.6294418230910872,\n",
       "  0.9298621059650302,\n",
       "  -1.1418529402548996,\n",
       "  -0.07958825706320959,\n",
       "  1797552000.0,\n",
       "  0.027698645113798284,\n",
       "  -1.416096286993893,\n",
       "  -1.1264999097349335,\n",
       "  0.25787914909406806],\n",
       " [-1.6310587662882399,\n",
       "  0.9298553308378078,\n",
       "  -1.1434842982047413,\n",
       "  -0.07577404566939525,\n",
       "  0.025625328553882835,\n",
       "  -1.4146626118514865,\n",
       "  -1.12736940334785,\n",
       "  0.2603921314446268,\n",
       "  1797638400.0,\n",
       "  -0.5543726470014779,\n",
       "  -0.04692858031145822,\n",
       "  -1.0154274978485969,\n",
       "  0.37016032233266466],\n",
       " [0.02426782638965217,\n",
       "  -1.41459000546454,\n",
       "  -1.1290109445281387,\n",
       "  0.2647055123975495,\n",
       "  -0.5563937704078792,\n",
       "  -0.046136131900938133,\n",
       "  -1.0163191434850682,\n",
       "  0.3726315219354317,\n",
       "  1797724800.0,\n",
       "  -0.2207042189904437,\n",
       "  -0.8822179760178943,\n",
       "  -0.6923029964541841,\n",
       "  0.9767164847050094],\n",
       " [-0.5578425073211439,\n",
       "  -0.046109861431601264,\n",
       "  -1.0180387629962675,\n",
       "  0.3771096961792609,\n",
       "  -0.22275526176878777,\n",
       "  -0.8810343338282821,\n",
       "  -0.6932590852898664,\n",
       "  0.9789619689681256,\n",
       "  1797811200.0,\n",
       "  -0.5662831248012525,\n",
       "  0.08431880582540949,\n",
       "  -1.2150094955494422,\n",
       "  -1.6241977833321763],\n",
       " [-0.2241516989797608,\n",
       "  -0.8809797951632882,\n",
       "  -0.6952058451081559,\n",
       "  0.9843303760375824,\n",
       "  -0.5683031802192395,\n",
       "  0.0850497867238999,\n",
       "  -1.2158613370163713,\n",
       "  -1.6209844311553676,\n",
       "  1797897600.0,\n",
       "  1.695209920295309,\n",
       "  1.163964593307547,\n",
       "  -0.7088253378110844,\n",
       "  0.5927893561673382],\n",
       " [-0.5697537839991024,\n",
       "  0.08507161546704001,\n",
       "  -1.2174406604000658,\n",
       "  -1.6194333445612215,\n",
       "  1.6929870813776495,\n",
       "  1.164189940209177,\n",
       "  -0.709778131469425,\n",
       "  0.5951777097104896,\n",
       "  1797984000.0,\n",
       "  0.7971812205505524,\n",
       "  -1.3058048364766441,\n",
       "  0.2838655834293583,\n",
       "  -0.31197580149267773],\n",
       " [1.6918909474938402,\n",
       "  1.1641752311505473,\n",
       "  -0.7117132769109852,\n",
       "  0.5999826330439368,\n",
       "  0.7950389060470341,\n",
       "  -1.3044228144852907,\n",
       "  0.2827148098019463,\n",
       "  -0.3092507612788862,\n",
       "  1798070400.0,\n",
       "  1.1028745840344125,\n",
       "  0.9124368451872811,\n",
       "  1.3637906724020636,\n",
       "  -1.4537452950975787],\n",
       " [0.7938020137644571,\n",
       "  -1.3043539406254403,\n",
       "  0.28008185246520834,\n",
       "  -0.3057737473671861,\n",
       "  1.1007048586263113,\n",
       "  0.9127799908911461,\n",
       "  1.3624245210260095,\n",
       "  -1.4505953727293566,\n",
       "  1798156800.0,\n",
       "  -0.5493495969446873,\n",
       "  1.6026619467013108,\n",
       "  1.3286582906891546,\n",
       "  -0.18152804457140867],\n",
       " [1.0995158811914114,\n",
       "  0.9127737941345203,\n",
       "  1.359032430552399,\n",
       "  -1.448794115731133,\n",
       "  -0.5513711707578107,\n",
       "  1.6026818370552653,\n",
       "  1.3272991460336174,\n",
       "  -0.17885154736416248,\n",
       "  1798243200.0,\n",
       "  -0.982203570101774,\n",
       "  1.6452832356929885,\n",
       "  0.4408149331417723,\n",
       "  0.11922486480036652],\n",
       " [-0.5528191203504886,\n",
       "  1.6026522814264723,\n",
       "  1.323931751861082,\n",
       "  -0.17518307735582228,\n",
       "  -0.9841863307760668,\n",
       "  1.6452831650810837,\n",
       "  0.4396328579010011,\n",
       "  0.12178944401996208,\n",
       "  1798329600.0,\n",
       "  0.5413642502314989,\n",
       "  -1.224554038672684,\n",
       "  0.9790859950784713,\n",
       "  -0.9776555483083964],\n",
       " [-0.9857021265658417,\n",
       "  1.6452521670456919,\n",
       "  0.436889573048592,\n",
       "  0.12589932428663442,\n",
       "  0.5392448743174356,\n",
       "  -1.2232100691297525,\n",
       "  0.9777965683087256,\n",
       "  -0.9746827913299058,\n",
       "  1798416000.0,\n",
       "  -1.177098199297863,\n",
       "  -0.120013221903588,\n",
       "  0.7113774838176972,\n",
       "  1.507105362708179],\n",
       " [0.5379678848897119,\n",
       "  -1.2231439449916885,\n",
       "  0.9746749059152184,\n",
       "  -0.9721827849877158,\n",
       "  -1.1790634841656036,\n",
       "  -0.11918654552694626,\n",
       "  0.7101414482109465,\n",
       "  1.5091534754611662,\n",
       "  1798502400.0,\n",
       "  -0.3355006869311886,\n",
       "  -0.8593436781978263,\n",
       "  -0.5021097731728675,\n",
       "  -0.7470458780323257],\n",
       " [-1.1806098280391333,\n",
       "  -0.11915780169812623,\n",
       "  0.707207971464755,\n",
       "  1.5153003258452526,\n",
       "  -0.33754143614282484,\n",
       "  -0.8581707488019529,\n",
       "  -0.5031037937027529,\n",
       "  -0.7441589369160456,\n",
       "  1798588800.0,\n",
       "  -0.8777266860623946,\n",
       "  -1.5429009055003104,\n",
       "  0.004102388230085491,\n",
       "  1.151342519062038],\n",
       " [-0.33895586672863776,\n",
       "  -0.8581169842580356,\n",
       "  -0.505184249811346,\n",
       "  -0.7413204684311516,\n",
       "  -0.8797188149672138,\n",
       "  -1.5414078435415806,\n",
       "  0.0030074099238028887,\n",
       "  1.153523020431398,\n",
       "  1798675200.0,\n",
       "  1.688134313763779,\n",
       "  -0.5111228331213351,\n",
       "  1.6277214513208953,\n",
       "  -0.41297018514254963],\n",
       " [-0.8812182348895918,\n",
       "  -1.541330945782345,\n",
       "  0.0005711120721733954,\n",
       "  1.1591477233521503,\n",
       "  1.6859121093014224,\n",
       "  -0.5101129871179293,\n",
       "  1.6263026622040002,\n",
       "  -0.4102075622892228,\n",
       "  1798761600.0,\n",
       "  -0.3161060730581748,\n",
       "  -0.4301160739567763,\n",
       "  -1.408629031106926,\n",
       "  -0.988335514902332],\n",
       " [1.6848148663761693,\n",
       "  -0.5100710072022272,\n",
       "  1.6227250416393089,\n",
       "  -0.40687877622698926,\n",
       "  -0.3181485613455444,\n",
       "  -0.4291441661103883,\n",
       "  -1.4094422575438987,\n",
       "  -0.9853587836302198,\n",
       "  1798848000.0,\n",
       "  -1.0072333039200634,\n",
       "  0.020282843899612827,\n",
       "  -1.6056546463349999,\n",
       "  0.04085000506517283],\n",
       " [-0.3195599519897672,\n",
       "  -0.4291049276576203,\n",
       "  -1.4108854761117238,\n",
       "  -0.9828744521050184,\n",
       "  -1.0092138202288339,\n",
       "  0.021043814966866685,\n",
       "  -1.6064285784414065,\n",
       "  0.04344374961055787,\n",
       "  1798934400.0,\n",
       "  0.5439360358801412,\n",
       "  1.1436862753498536,\n",
       "  -1.3095897759553974,\n",
       "  -0.5774224547719224],\n",
       " [-1.010733539217561,\n",
       "  0.02106781084047691,\n",
       "  -1.6077332978903023,\n",
       "  0.04743860034300319,\n",
       "  0.541816429359269,\n",
       "  1.1439211192615932,\n",
       "  -1.3104227545511258,\n",
       "  -0.5745986349475672,\n",
       "  1799020800.0,\n",
       "  -0.946761719380369,\n",
       "  -0.10768663749739055,\n",
       "  1.6695479739867227,\n",
       "  0.9548621094033029],\n",
       " [0.5405398430371811,\n",
       "  1.143907096469858,\n",
       "  -1.3119355927446121,\n",
       "  -0.5715112128640631,\n",
       "  -0.9487476580536124,\n",
       "  -0.10686573406981525,\n",
       "  1.6681208430854046,\n",
       "  0.9571157262484454,\n",
       "  1799107200.0,\n",
       "  -0.4638876125831929,\n",
       "  1.6855558994028357,\n",
       "  -1.3510285989401614,\n",
       "  -0.9839602557215996],\n",
       " [-0.9502578986332272,\n",
       "  -0.10683740740216305,\n",
       "  1.6645138205745227,\n",
       "  0.9624520579991039,\n",
       "  -0.46591684959931196,\n",
       "  1.6855369677643313,\n",
       "  -1.3518533130733896,\n",
       "  -0.9809851525973381,\n",
       "  1799193600.0,\n",
       "  -1.6233034957357733,\n",
       "  0.8740706768396586,\n",
       "  -0.6146517811243495,\n",
       "  0.002162147258342316],\n",
       " [-0.4673514037491965,\n",
       "  1.6855046068054504,\n",
       "  -1.353337021854103,\n",
       "  -0.9784943995738734,\n",
       "  -1.6252287702785735,\n",
       "  0.8744317906949958,\n",
       "  -0.6156233565378582,\n",
       "  0.004770288562851982,\n",
       "  1799280000.0,\n",
       "  -0.7739002874374099,\n",
       "  -1.1265421154962372,\n",
       "  0.28339789083280786,\n",
       "  0.2795628377318409],\n",
       " [-1.6268450530561338,\n",
       "  0.8744268923414852,\n",
       "  -0.617624701263265,\n",
       "  0.008708357742146233,\n",
       "  -0.7759017262450463,\n",
       "  -1.1252440481936794,\n",
       "  0.2822472104809198,\n",
       "  0.28206775101732473,\n",
       "  1799366400.0,\n",
       "  0.13177188650472907,\n",
       "  -0.9239001182586133,\n",
       "  -1.5445109353678488,\n",
       "  0.559130078675452],\n",
       " [-0.7773848722581113,\n",
       "  -1.1251812410140676,\n",
       "  0.27961458190860405,\n",
       "  0.2864129567749457,\n",
       "  0.12968923790810574,\n",
       "  -0.9226969549367712,\n",
       "  -1.545297061833796,\n",
       "  0.5615309577120742,\n",
       "  1799452800.0,\n",
       "  0.8356097478764556,\n",
       "  -1.686078948970379,\n",
       "  1.0726481263816836,\n",
       "  1.3501453575991973],\n",
       " [0.12834804834370275,\n",
       "  -0.9226410056481559,\n",
       "  -1.5466447622427422,\n",
       "  0.5662864798596643,\n",
       "  0.8334639875647464,\n",
       "  -1.684518831976357,\n",
       "  1.0713400397980268,\n",
       "  1.3522518792565243,\n",
       "  1799539200.0,\n",
       "  -1.2572184733019407,\n",
       "  -0.3979955862728373,\n",
       "  -0.9893017205916056,\n",
       "  0.40799294794020485],\n",
       " [0.8322331186286115,\n",
       "  -1.6844370887288782,\n",
       "  1.0681526079220307,\n",
       "  1.358168361939272,\n",
       "  -1.259176573947031,\n",
       "  -0.3970387215181346,\n",
       "  -0.9901985766923439,\n",
       "  0.4104500690380145,\n",
       "  1799625600.0,\n",
       "  -0.1619845351734757,\n",
       "  -1.4026052372850972,\n",
       "  -1.7347728525154709,\n",
       "  1.0761024467428926],\n",
       " [-1.260735475995462,\n",
       "  -0.3970005700996749,\n",
       "  -0.9919365613137204,\n",
       "  0.41498376962430766,\n",
       "  -0.16404084322690424,\n",
       "  -1.4011778804495516,\n",
       "  -1.7355210335870699,\n",
       "  1.0783109469020304,\n",
       "  1799712000.0,\n",
       "  -0.1702744818989509,\n",
       "  1.1010687701102733,\n",
       "  1.6441225320985609,\n",
       "  0.5530008761284283],\n",
       " [-0.16542807662437714,\n",
       "  -1.4011057306320702,\n",
       "  -1.736734989417372,\n",
       "  1.0838252211661534,\n",
       "  -0.17233004660965162,\n",
       "  1.1013235732158155,\n",
       "  1.6427004719882523,\n",
       "  0.5554040360008915,\n",
       "  1799798400.0,\n",
       "  -1.18094713212236,\n",
       "  0.7416089454429687,\n",
       "  -1.7417766804218404,\n",
       "  -1.1514820031878088],\n",
       " [-0.17371857938611684,\n",
       "  1.1013109927026279,\n",
       "  1.6391113222869327,\n",
       "  0.560150562415455,\n",
       "  -1.1829120718640915,\n",
       "  0.7420320955285712,\n",
       "  -1.7425234646662875,\n",
       "  -1.1484445608599023,\n",
       "  1799884800.0,\n",
       "  -0.7056504142148843,\n",
       "  0.9842996200194045,\n",
       "  0.23351580600907113,\n",
       "  0.5020908471279367],\n",
       " [-1.1844590190252684,\n",
       "  0.7420316799976122,\n",
       "  -1.7437324971570887,\n",
       "  -1.1461996768389346,\n",
       "  -0.7076579728503813,\n",
       "  0.9846091099979518,\n",
       "  0.2323750740241917,\n",
       "  0.5045129519476287,\n",
       "  1799971200.0,\n",
       "  0.4939635607375579,\n",
       "  0.7637324347796347,\n",
       "  -1.0923501907771784,\n",
       "  -0.22698297057672884],\n",
       " [-0.7091304212734099,\n",
       "  0.9846004812327434,\n",
       "  0.22977751005396052,\n",
       "  0.5091847585229071,\n",
       "  0.4918484351472899,\n",
       "  0.7641452237000592,\n",
       "  -1.0932264951306372,\n",
       "  -0.22428955840810139,\n",
       "  1800057600.0,\n",
       "  0.0980933102986549,\n",
       "  -1.3228687823486929,\n",
       "  1.1309542670001103,\n",
       "  0.367021857580065],\n",
       " [0.49056401606263483,\n",
       "  0.7641440594571827,\n",
       "  -1.094892041849403,\n",
       "  -0.2206878018712032,\n",
       "  0.09601368159172868,\n",
       "  -1.321478768744485,\n",
       "  1.1296345519753452,\n",
       "  0.3694942250872761,\n",
       "  1800144000.0,\n",
       "  0.3920592065566704,\n",
       "  0.500399708310509,\n",
       "  -0.7311177319222136,\n",
       "  1.726796269886234],\n",
       " [0.09466721319552349,\n",
       "  -1.3214093173997974,\n",
       "  1.126406133808838,\n",
       "  0.3739677930563394,\n",
       "  0.38995321852338827,\n",
       "  0.5009358246967861,\n",
       "  -0.7320660796373083,\n",
       "  1.7287626299330283,\n",
       "  1800230400.0,\n",
       "  1.242745911368354,\n",
       "  -1.700452530019251,\n",
       "  0.4216985366687058,\n",
       "  1.3108625257807962],\n",
       " [0.3886528267936206,\n",
       "  0.500943572264682,\n",
       "  -0.7339855546446479,\n",
       "  1.735231917165002,\n",
       "  1.2405636439817038,\n",
       "  -1.6988856813996172,\n",
       "  0.4205202739575967,\n",
       "  1.3129836656025677,\n",
       "  1800316800.0,\n",
       "  -0.47890116274864386,\n",
       "  -1.1481904368822586,\n",
       "  -0.5006962597718817,\n",
       "  -1.0700488600567488],\n",
       " [1.239396590193648,\n",
       "  -1.6988034517156965,\n",
       "  0.4177904269724698,\n",
       "  1.318842493498277,\n",
       "  -0.4809290535301363,\n",
       "  -1.146882230951463,\n",
       "  -0.5016905622095931,\n",
       "  -1.0670417211215055,\n",
       "  1800403200.0,\n",
       "  -0.2589219304763766,\n",
       "  -0.4832613800393095,\n",
       "  -1.483801501564159,\n",
       "  -0.8400993615543259],\n",
       " [-0.4823659609269513,\n",
       "  -1.1468186911407563,\n",
       "  -0.5037720119471638,\n",
       "  -1.064677318972446,\n",
       "  -0.2609695463499591,\n",
       "  -0.4822645824801653,\n",
       "  -1.484599735778419,\n",
       "  -0.8371777928141887,\n",
       "  1800489600.0,\n",
       "  1.214296245333161,\n",
       "  0.5359960316442075,\n",
       "  -0.8904661940992751,\n",
       "  1.1403353581586206],\n",
       " [-0.26237197386377525,\n",
       "  -0.48222354546282997,\n",
       "  -1.4859901118723657,\n",
       "  -0.8344758974460301,\n",
       "  1.2121165289704263,\n",
       "  0.5365154770894691,\n",
       "  -0.8913827617275991,\n",
       "  1.1425199555791228,\n",
       "  1800576000.0,\n",
       "  0.84115174880956,\n",
       "  0.7105189472399693,\n",
       "  0.9000188274329626,\n",
       "  -1.2223135074492941],\n",
       " [1.2109450159379858,\n",
       "  0.5365220199924455,\n",
       "  -0.8931902227636147,\n",
       "  1.1481285034650062,\n",
       "  0.839005491557855,\n",
       "  0.710956657804792,\n",
       "  0.8987451696352807,\n",
       "  -1.2192497068745605,\n",
       "  1800662400.0,\n",
       "  -0.7110857421043777,\n",
       "  0.15568521970462454,\n",
       "  1.2370437981427878,\n",
       "  0.9831417831357095],\n",
       " [0.8377754912834648,\n",
       "  0.7109572944339068,\n",
       "  0.8956790874923032,\n",
       "  -1.2171087811250503,\n",
       "  -0.7130928133650347,\n",
       "  0.1563827773401247,\n",
       "  1.235702924868617,\n",
       "  0.9853848763779977,\n",
       "  1800748800.0,\n",
       "  -0.602346341511246,\n",
       "  0.3246020495590341,\n",
       "  0.5754494678248256,\n",
       "  -0.014870108174512231],\n",
       " [-0.7145661137297112,\n",
       "  0.1564021908727267,\n",
       "  1.232399931086275,\n",
       "  0.9907627137556968,\n",
       "  -0.6043631632136531,\n",
       "  0.32522049783032747,\n",
       "  0.5742405413855172,\n",
       "  -0.012255628724322848,\n",
       "  1800835200.0,\n",
       "  0.5406033371665924,\n",
       "  0.22916741333669147,\n",
       "  0.5766869926915438,\n",
       "  1.2860949018997594],\n",
       " [-0.6058194195975362,\n",
       "  0.3252341948124493,\n",
       "  0.5714026152124378,\n",
       "  -0.00834255751524375,\n",
       "  0.538484029482062,\n",
       "  0.22983055681923978,\n",
       "  0.5754778194431533,\n",
       "  1.2882252583991998,\n",
       "  1800921600.0,\n",
       "  -0.45332576768516886,\n",
       "  0.15490208430346006,\n",
       "  -1.7301744925578302,\n",
       "  -1.5341416231024048],\n",
       " [0.5372069207876549,\n",
       "  0.2298474835382445,\n",
       "  0.5726390233522032,\n",
       "  1.2940477352475377,\n",
       "  -0.45535595176052207,\n",
       "  0.15560000870729068,\n",
       "  -1.7309235907156466,\n",
       "  -1.5309617831674214,\n",
       "  1801008000.0,\n",
       "  -1.3553770764087991,\n",
       "  1.7120747926991218,\n",
       "  -1.0167699197986284,\n",
       "  -1.2954392391447411],\n",
       " [-0.4567888504306026,\n",
       "  0.15561944874307215,\n",
       "  -1.7321407789622105,\n",
       "  -1.5292785225802306,\n",
       "  -1.3573263753708138,\n",
       "  1.7120434413817143,\n",
       "  -1.0176612977055877,\n",
       "  -1.2923482265814221,\n",
       "  1801094400.0,\n",
       "  1.1547418952308992,\n",
       "  -0.10902742137770029,\n",
       "  -0.11434934100133921,\n",
       "  -1.3653043218814775],\n",
       " [-1.3589006629495763,\n",
       "  1.7120101829599084,\n",
       "  -1.019379973561531,\n",
       "  -1.2903146263044596,\n",
       "  1.1525675189860838,\n",
       "  -0.10820589001648213,\n",
       "  -0.11542069557017454,\n",
       "  -1.3621873107019413,\n",
       "  1801180800.0,\n",
       "  0.8606224002694579,\n",
       "  -0.7203249148062068,\n",
       "  0.6457984984101326,\n",
       "  -0.4112522020428954],\n",
       " [1.1513866713132666,\n",
       "  -0.10817751797348905,\n",
       "  -0.11777372780116273,\n",
       "  -1.360256250294946,\n",
       "  0.8584743971238832,\n",
       "  -0.7192170925165594,\n",
       "  0.6445755417237435,\n",
       "  -0.40849021849580747,\n",
       "  1801267200.0,\n",
       "  0.009284123560621147,\n",
       "  -0.7447926983081633,\n",
       "  -0.2928340897429625,\n",
       "  0.29113608859020546],\n",
       " [0.8572474487093314,\n",
       "  -0.7191680327008763,\n",
       "  0.6416881637129308,\n",
       "  -0.4051589109771218,\n",
       "  0.007212458193546392,\n",
       "  -0.7436734169424839,\n",
       "  -0.29386984772853153,\n",
       "  0.29363669516773644,\n",
       "  1801353600.0,\n",
       "  -0.5022918101846073,\n",
       "  -1.6855048469260796,\n",
       "  -1.0010913472670069,\n",
       "  0.30346255696600577],\n",
       " [0.005852069708902326,\n",
       "  -0.7436235290783484,\n",
       "  -0.2960974141391775,\n",
       "  0.29799888680144354,\n",
       "  -0.5043176035741327,\n",
       "  -1.6839449988031214,\n",
       "  -1.001985852072015,\n",
       "  0.3059585765437357,\n",
       "  1801440000.0,\n",
       "  0.9900999726357756,\n",
       "  0.26821341955998046,\n",
       "  0.4647266128301535,\n",
       "  1.0253593455362195],\n",
       " [-0.5057581772569807,\n",
       "  -1.683863274984632,\n",
       "  -1.0037155491775518,\n",
       "  0.3103388595388911,\n",
       "  0.9879403594986024,\n",
       "  0.2688582765003897,\n",
       "  0.4635397686995861,\n",
       "  1.0275867285244082,\n",
       "  1801526400.0,\n",
       "  -0.9865056795038954,\n",
       "  -0.32217326429258586,\n",
       "  -0.267967013098879,\n",
       "  -1.649354933386338],\n",
       " [0.9867337055977647,\n",
       "  0.2688738818089357,\n",
       "  0.46077967513646634,\n",
       "  1.033026527946512,\n",
       "  -0.988488054416754,\n",
       "  -0.32125190965069844,\n",
       "  -0.2690077305163916,\n",
       "  -1.6461322195790304,\n",
       "  1801612800.0,\n",
       "  0.9931922571026123,\n",
       "  -0.67520509386955,\n",
       "  -0.6021947360677753,\n",
       "  -0.40198018721468987],\n",
       " [-0.9900045245257695,\n",
       "  -0.3212163242413895,\n",
       "  -0.27125277723385743,\n",
       "  -1.64461805573362,\n",
       "  0.9910323666865557,\n",
       "  -0.6741184026912934,\n",
       "  -0.6031687958853842,\n",
       "  -0.3992216540257155,\n",
       "  1801699200.0,\n",
       "  0.8600230817053656,\n",
       "  -1.6634167377519857,\n",
       "  1.6569378718254302,\n",
       "  0.2887483631276008],\n",
       " [0.9898261974751387,\n",
       "  -0.67407086983852,\n",
       "  -0.6051788972882556,\n",
       "  -0.39587673811843893,\n",
       "  0.8578751322994722,\n",
       "  -1.6618672342245,\n",
       "  1.6555132558535655,\n",
       "  0.29124985823994065,\n",
       "  1801785600.0,\n",
       "  -0.8246576162836263,\n",
       "  -0.6971236208693219,\n",
       "  -1.1527044472722854,\n",
       "  0.7268081936196357],\n",
       " [0.8566480899468076,\n",
       "  -1.6617862579205784,\n",
       "  1.6519150976116108,\n",
       "  0.29560854544698906,\n",
       "  -0.8266545037844171,\n",
       "  -0.6960266645165603,\n",
       "  -1.1535687147131677,\n",
       "  0.7291466752642033,\n",
       "  1801872000.0,\n",
       "  -0.35906788176929905,\n",
       "  -0.976158660412606,\n",
       "  0.34863047479817283,\n",
       "  0.865949811497518],\n",
       " [-0.828145605579225,\n",
       "  -0.6959783898882861,\n",
       "  -1.155191835418755,\n",
       "  0.7341482959123491,\n",
       "  -0.3611065177583202,\n",
       "  -0.974931022679021,\n",
       "  0.3474667846114212,\n",
       "  0.8682365149235346,\n",
       "  1801958400.0,\n",
       "  0.9648415271246947,\n",
       "  -1.2594349051382,\n",
       "  -1.7111380453769676,\n",
       "  0.10470899647624446],\n",
       " [-0.36252464230247744,\n",
       "  -0.9748733048360556,\n",
       "  0.344788300806555,\n",
       "  0.8734423515096759,\n",
       "  0.962684178861158,\n",
       "  -1.2580745997264773,\n",
       "  -1.7118909401195452,\n",
       "  0.10727897742836266,\n",
       "  1802044800.0,\n",
       "  0.5350781813547458,\n",
       "  -1.2608560758029224,\n",
       "  -0.725668734415205,\n",
       "  -0.6989857583416527],\n",
       " [0.9614735659127459,\n",
       "  -1.2580072951362697,\n",
       "  -1.7131215100330515,\n",
       "  0.11136755298612878,\n",
       "  0.5329593690997434,\n",
       "  -1.2594951048097547,\n",
       "  -0.7266181688656921,\n",
       "  -0.6961167016471501,\n",
       "  1802131200.0,\n",
       "  0.3258888675651408,\n",
       "  -0.8416212331795845,\n",
       "  -0.8047556831785236,\n",
       "  -0.9013863441163023],\n",
       " [0.5316813943839216,\n",
       "  -1.2594277521237247,\n",
       "  -0.7285414742447978,\n",
       "  -0.693207696089506,\n",
       "  0.3237888128920979,\n",
       "  -0.8404566037935962,\n",
       "  -0.8056893447118468,\n",
       "  -0.8984419688943529,\n",
       "  1802217600.0,\n",
       "  0.45367431371897504,\n",
       "  -0.9592253269979399,\n",
       "  0.09326198431361113,\n",
       "  -0.0410426377532942],\n",
       " [0.32247804952168563,\n",
       "  -0.8404034390197058,\n",
       "  -0.8075570559352898,\n",
       "  -0.8958300234550631,\n",
       "  0.451562800783863,\n",
       "  -0.9580056197070556,\n",
       "  0.09214922422480454,\n",
       "  -0.038418418823449235,\n",
       "  1802304000.0,\n",
       "  -0.7792985186105642,\n",
       "  1.3302594976571487,\n",
       "  -0.3924483476327741,\n",
       "  1.5199218298599828],\n",
       " [0.4502720667007012,\n",
       "  -0.9579484749286886,\n",
       "  0.08965025165198531,\n",
       "  -0.03454376061947359,\n",
       "  -0.7812994733697479,\n",
       "  1.3304069631294075,\n",
       "  -0.3934642387823783,\n",
       "  1.5219651732718675,\n",
       "  1802390400.0,\n",
       "  -1.5760342301364818,\n",
       "  -1.6968395097068065,\n",
       "  -1.1935562720521764,\n",
       "  -1.4687484313145849],\n",
       " [-0.7827834655098646,\n",
       "  1.3303866262525426,\n",
       "  -0.3956217813692968,\n",
       "  1.528130834180807,\n",
       "  -1.5779637432185631,\n",
       "  -1.6952743531846388,\n",
       "  -1.1944123921001155,\n",
       "  -1.4655929258887712,\n",
       "  1802476800.0,\n",
       "  -1.6656243548104324,\n",
       "  0.6257766391727257,\n",
       "  -0.4592421054787141,\n",
       "  0.05093733884683868],\n",
       " [-1.5795726169387752,\n",
       "  -1.6951922457739874,\n",
       "  -1.1960067960232066,\n",
       "  -1.463813688754785,\n",
       "  -1.6675458345275396,\n",
       "  0.6262540373762424,\n",
       "  -0.4602446754365661,\n",
       "  0.05352732963270079,\n",
       "  1802563200.0,\n",
       "  -0.7239686177594431,\n",
       "  -0.14139129510706738,\n",
       "  -0.9684923497468573,\n",
       "  1.7018291227866638],\n",
       " [-1.669168750741603,\n",
       "  0.6262575418882217,\n",
       "  -0.4623552653640503,\n",
       "  0.05753698538438848,\n",
       "  -0.7259745338387402,\n",
       "  -0.14055460666839162,\n",
       "  -0.9693933560201299,\n",
       "  1.7038047737589113,\n",
       "  1802649600.0,\n",
       "  0.08815762624887079,\n",
       "  -0.020434726031577206,\n",
       "  -1.2804888525900677,\n",
       "  0.4315738776448861],\n",
       " [-0.7274498534851493,\n",
       "  -0.14052513935432304,\n",
       "  -0.9711459685848026,\n",
       "  1.7102374171064614,\n",
       "  0.0860788884546041,\n",
       "  -0.01965468557335693,\n",
       "  -1.2813276350062852,\n",
       "  0.43402222366482535,\n",
       "  1802736000.0,\n",
       "  0.29708745655133256,\n",
       "  -1.4181707133199268,\n",
       "  0.28113143455521594,\n",
       "  1.7296101914383486],\n",
       " [0.08473086272400868,\n",
       "  -0.019629311719564734,\n",
       "  -1.2828609296883426,\n",
       "  0.43859053360633443,\n",
       "  0.29498998444246494,\n",
       "  -1.4167360666547428,\n",
       "  0.2799812062200978,\n",
       "  1.7315755043516732,\n",
       "  1802822400.0,\n",
       "  1.541200341310651,\n",
       "  1.0525273944735731,\n",
       "  0.04121896500798857,\n",
       "  0.7965775779171254],\n",
       " [0.29367470669461937,\n",
       "  -1.4166633900642362,\n",
       "  0.27735017085279334,\n",
       "  1.7380489215315227,\n",
       "  1.5389913121199228,\n",
       "  1.0528049311182641,\n",
       "  0.04011658425793894,\n",
       "  0.7988900965573567,\n",
       "  1802908800.0,\n",
       "  1.520625262102609,\n",
       "  1.5573089243542688,\n",
       "  -0.6457303471268535,\n",
       "  0.8589076544451294],\n",
       " [1.5378710385379735,\n",
       "  1.0527939933616002,\n",
       "  0.03765419531568928,\n",
       "  0.8039941166203934,\n",
       "  1.5184180778375493,\n",
       "  1.5573500550355834,\n",
       "  -0.6466957243034241,\n",
       "  0.8611969784411271,\n",
       "  1802995200.0,\n",
       "  -1.1360574930847294,\n",
       "  -1.032000576536312,\n",
       "  -1.2776724530621835,\n",
       "  1.4598074310642115],\n",
       " [1.5172945792860586,\n",
       "  1.557322034261795,\n",
       "  -0.6486752223567425,\n",
       "  0.8663924793654448,\n",
       "  -1.1380264579894492,\n",
       "  -1.0307467861778854,\n",
       "  -1.2785117971745739,\n",
       "  1.4618731446089606,\n",
       "  1803081600.0,\n",
       "  0.6777200504595622,\n",
       "  1.1705997768591885,\n",
       "  -1.481421616131068,\n",
       "  1.2364612452948651],\n",
       " [-1.139566369079603,\n",
       "  -1.030687178510604,\n",
       "  -1.2800470716441463,\n",
       "  1.4679505765715624,\n",
       "  0.675588447797143,\n",
       "  1.170822016283887,\n",
       "  -1.482220324984145,\n",
       "  1.2386100717701356,\n",
       "  1803168000.0,\n",
       "  1.4208435856918151,\n",
       "  -1.1185843499292971,\n",
       "  1.021051483192704,\n",
       "  -1.2374593209071565],\n",
       " [0.674332830987141,\n",
       "  1.1708070826747385,\n",
       "  -1.4836123740181062,\n",
       "  1.244359702090639,\n",
       "  1.418645348647526,\n",
       "  -1.1172900095127758,\n",
       "  1.0197536869235895,\n",
       "  -1.2343898841809153,\n",
       "  1803254400.0,\n",
       "  0.11435455639293574,\n",
       "  -0.46645724466524036,\n",
       "  -0.6023163949913697,\n",
       "  0.0981826591311084],\n",
       " [1.4175062101626994,\n",
       "  -1.1172274716430286,\n",
       "  1.016602524898156,\n",
       "  -1.2322711877007582,\n",
       "  0.1122734695730168,\n",
       "  -0.46546831704106134,\n",
       "  -0.6032904305456057,\n",
       "  0.10075506870326531,\n",
       "  1803340800.0,\n",
       "  -0.5866719410346204,\n",
       "  -0.20413627568291592,\n",
       "  -0.1760270387457351,\n",
       "  1.0134462717253707],\n",
       " [0.11092954998951975,\n",
       "  -0.465427848715953,\n",
       "  -0.6053004464283598,\n",
       "  0.1048340656595825,\n",
       "  -0.5886901682287626,\n",
       "  -0.20327020168493976,\n",
       "  -0.17708609245794873,\n",
       "  1.0156780878784804,\n",
       "  1803427200.0,\n",
       "  0.70834492902717,\n",
       "  0.09066011235046488,\n",
       "  1.263823821355427,\n",
       "  -1.2794676324178749],\n",
       " [-0.5901439677830218,\n",
       "  -0.2032386109303049,\n",
       "  -0.1793957683629826,\n",
       "  1.0211004026717592,\n",
       "  0.7062105802939342,\n",
       "  0.09138812340440002,\n",
       "  1.2624776071356971,\n",
       "  -1.2763825633052381,\n",
       "  1803513600.0,\n",
       "  0.5138390982073442,\n",
       "  -0.4457502833435156,\n",
       "  1.667573967400545,\n",
       "  0.3086959831421238],\n",
       " [0.7049597636744728,\n",
       "  0.0914097375425248,\n",
       "  1.259155788341107,\n",
       "  -1.2743255217552851,\n",
       "  0.5117221904178981,\n",
       "  -0.44477105347737655,\n",
       "  1.6661472301905103,\n",
       "  0.31119005522572185,\n",
       "  1803600000.0,\n",
       "  0.8140481672097798,\n",
       "  -0.03831227977516611,\n",
       "  1.1524848999657615,\n",
       "  0.20392602767712545],\n",
       " [0.510440886655537,\n",
       "  -0.44473128592548183,\n",
       "  1.6625415953071845,\n",
       "  0.3155780192371813,\n",
       "  0.8119043402813262,\n",
       "  -0.0375238666644905,\n",
       "  1.151160890921622,\n",
       "  0.20645908738882784,\n",
       "  1803686400.0,\n",
       "  1.0159576704031295,\n",
       "  1.5992923821941882,\n",
       "  0.8044732300793879,\n",
       "  0.21551304723876555],\n",
       " [0.810670091749895,\n",
       "  -0.037497887791420326,\n",
       "  1.1479173378007475,\n",
       "  0.2106932822041593,\n",
       "  1.013795738658584,\n",
       "  1.5993138506271658,\n",
       "  0.8032186276734742,\n",
       "  0.21804179511882207,\n",
       "  1803772800.0,\n",
       "  0.3948284278555416,\n",
       "  -1.522417111607698,\n",
       "  -0.8310755021222476,\n",
       "  1.7377429902601231],\n",
       " [1.0125931377330406,\n",
       "  1.5992844090325138,\n",
       "  0.8002197092900704,\n",
       "  0.22229299601834634,\n",
       "  0.3927221915117958,\n",
       "  -1.5209336428902858,\n",
       "  -0.832003914492081,\n",
       "  1.7397052767472696,\n",
       "  1803859200.0,\n",
       "  0.5335409469294485,\n",
       "  1.572446418577557,\n",
       "  -0.8484142375551691,\n",
       "  0.45537024834618595],\n",
       " [0.3914222338340312,\n",
       "  -1.5208574383517428,\n",
       "  -0.8338531242037795,\n",
       "  1.7461906303065091,\n",
       "  0.5314222725151426,\n",
       "  1.5724804598673368,\n",
       "  -0.8493391919279247,\n",
       "  0.45780973911705103,\n",
       "  1803945600.0,\n",
       "  0.659434320521771,\n",
       "  -0.4194230718501588,\n",
       "  1.203696161958198,\n",
       "  0.961619137642049],\n",
       " [0.5301440568508341,\n",
       "  1.5724519268044537,\n",
       "  -0.8511762133788329,\n",
       "  0.4624129746130977,\n",
       "  0.6573043575037093,\n",
       "  -0.4184561718919655,\n",
       "  1.2023619394590461,\n",
       "  0.9638702400210654,\n",
       "  1804032000.0,\n",
       "  -1.6014288443683313,\n",
       "  0.8464262042078444,\n",
       "  0.2783547149949878,\n",
       "  -0.5306518279943577],\n",
       " [0.6560458745602897,\n",
       "  -0.41841729531602406,\n",
       "  1.1990823873912477,\n",
       "  0.9692164889545256,\n",
       "  -1.6033560803668028,\n",
       "  0.8468002648882885,\n",
       "  0.27720504044236216,\n",
       "  -0.5278454127378954,\n",
       "  1804118400.0,\n",
       "  -1.3250770814401767,\n",
       "  -0.6534983257058212,\n",
       "  -0.5759852948093985,\n",
       "  1.7505641745819418],\n",
       " [-1.604968934477884,\n",
       "  0.8467963020900062,\n",
       "  0.274575956969547,\n",
       "  -0.5246893461498664,\n",
       "  -1.3270290973413537,\n",
       "  -0.6524218005283705,\n",
       "  -0.5769645817770284,\n",
       "  1.7525216899726037,\n",
       "  1804204800.0,\n",
       "  1.4464802636295886,\n",
       "  0.717317452909247,\n",
       "  0.3402141868494979,\n",
       "  0.6038472336549939],\n",
       " [-1.3285986356523303,\n",
       "  -0.6523750022846712,\n",
       "  -0.5789931071016711,\n",
       "  1.7590258609800116,\n",
       "  1.4442797277963275,\n",
       "  0.7177519795079632,\n",
       "  0.3390521751876447,\n",
       "  0.6062314722740414,\n",
       "  1804291200.0,\n",
       "  -1.1446256867458695,\n",
       "  1.3977401025892124,\n",
       "  -0.8250468914486107,\n",
       "  0.43400518775046104],\n",
       " [1.4431446076438073,\n",
       "  0.7177523860593475,\n",
       "  0.3363796076107989,\n",
       "  0.6110526250782812,\n",
       "  -1.1465938833580227,\n",
       "  1.397855964651929,\n",
       "  -0.8259765061505387,\n",
       "  0.4364526290166111,\n",
       "  1804377600.0,\n",
       "  -1.5382187186296268,\n",
       "  1.302097639307865,\n",
       "  1.7415276152056531,\n",
       "  0.30419793643986376],\n",
       " [-1.148135137440021,\n",
       "  1.3978333440696165,\n",
       "  -0.8278299536729692,\n",
       "  0.44102450735326565,\n",
       "  -1.5401516225520124,\n",
       "  1.3022582939141538,\n",
       "  1.7400861288520615,\n",
       "  0.30669368236374595,\n",
       "  1804464000.0,\n",
       "  1.337315717234208,\n",
       "  1.2095929085508652,\n",
       "  -1.6313350921181027,\n",
       "  1.1673440431268165],\n",
       " [-1.5417545690108243,\n",
       "  1.30223891010209,\n",
       "  1.7364285082660098,\n",
       "  0.31107504466365093,\n",
       "  1.33512496996466,\n",
       "  1.2097968861963246,\n",
       "  -1.632103902576116,\n",
       "  1.1695185899124736,\n",
       "  1804550400.0,\n",
       "  -0.42044878162932386,\n",
       "  -0.758951906639121,\n",
       "  1.0604616669342113,\n",
       "  -1.2259442317465843],\n",
       " [1.3339727391933396,\n",
       "  1.2097806329661185,\n",
       "  -1.6333905699605096,\n",
       "  1.1751667780154174,\n",
       "  -0.4224819137174095,\n",
       "  -0.7578259940456966,\n",
       "  1.05915601078969,\n",
       "  -1.2228790800848142,\n",
       "  1804636800.0,\n",
       "  0.36315268471314355,\n",
       "  1.2025130122097245,\n",
       "  1.6071715415635366,\n",
       "  -0.22049275255330428],\n",
       " [-0.42390965919816004,\n",
       "  -0.7577756270000062,\n",
       "  1.0559771453830558,\n",
       "  -1.2207434830915689,\n",
       "  0.36104928866911173,\n",
       "  1.202720305605892,\n",
       "  1.6057568508728597,\n",
       "  -0.21780175556377554,\n",
       "  1804723200.0,\n",
       "  1.0571341992087027,\n",
       "  -1.0632140683693545,\n",
       "  -1.3113178620410872,\n",
       "  -1.2512403025312577],\n",
       " [0.35974436608667787,\n",
       "  1.2027042919763513,\n",
       "  1.6021936758633424,\n",
       "  -0.21419047343718206,\n",
       "  1.054968575248241,\n",
       "  -1.0619456596955372,\n",
       "  -1.3121504959913448,\n",
       "  -1.2481657375429678,\n",
       "  1804809600.0,\n",
       "  -0.8450819410635787,\n",
       "  0.45218194071766726,\n",
       "  -1.6714170620440625,\n",
       "  0.1070273947291908],\n",
       " [1.0537724283951153,\n",
       "  -1.0618849956888616,\n",
       "  -1.3136621194270446,\n",
       "  -1.2460672671902036,\n",
       "  -0.8470769971565453,\n",
       "  0.4527406390866932,\n",
       "  -1.6721778786471946,\n",
       "  0.10959651294495981,\n",
       "  1804896000.0,\n",
       "  -0.4820283209262085,\n",
       "  0.20521293998558737,\n",
       "  -1.3798271479074424,\n",
       "  -0.713540321926397],\n",
       " [-0.8485713002914136,\n",
       "  0.45275001845944074,\n",
       "  -1.6734363704184159,\n",
       "  0.11368849117894239,\n",
       "  -0.48405593130176267,\n",
       "  0.20588730214396775,\n",
       "  -1.3806461185250287,\n",
       "  -0.710665849099858,\n",
       "  1804982400.0,\n",
       "  -1.3428927117113014,\n",
       "  -1.3295639411167535,\n",
       "  0.9914989074503463,\n",
       "  -1.5494593083160588],\n",
       " [-0.48549332885415714,\n",
       "  0.20590503953977865,\n",
       "  -1.3821095833711967,\n",
       "  -0.7077782050435383,\n",
       "  -1.3448431301210058,\n",
       "  -1.3281707919472274,\n",
       "  0.9902070050782203,\n",
       "  -1.5462737682716128,\n",
       "  1805068800.0,\n",
       "  1.0553480779157176,\n",
       "  1.326348405695332,\n",
       "  0.9702431178171388,\n",
       "  1.3615258134602215],\n",
       " [-1.3464154608812555,\n",
       "  -1.3281011140223162,\n",
       "  0.987076617030311,\n",
       "  -1.5446129892072156,\n",
       "  1.0531826141131335,\n",
       "  1.326497702861915,\n",
       "  0.9689554546502722,\n",
       "  1.3636281001536334,\n",
       "  1805155200.0,\n",
       "  -0.8966769562941515,\n",
       "  -0.2980674127980769,\n",
       "  -1.5878766447285924,\n",
       "  -1.1384183059840602],\n",
       " [1.051986187300611,\n",
       "  1.326477498345778,\n",
       "  0.965840008355662,\n",
       "  1.369561285750318,\n",
       "  -0.8986673859666313,\n",
       "  -0.2971573477274361,\n",
       "  -1.5886541224383008,\n",
       "  -1.1353857249979955,\n",
       "  1805241600.0,\n",
       "  -1.182405757915749,\n",
       "  -0.6175465575498881,\n",
       "  -1.512152244814591,\n",
       "  1.558710722843308],\n",
       " [-0.9001697761834943,\n",
       "  -0.29712257811793263,\n",
       "  -1.5899713389300607,\n",
       "  -1.1331216675965623,\n",
       "  -1.1843705668654612,\n",
       "  -0.6164868697800738,\n",
       "  -1.51294482482254,\n",
       "  1.5607396318982483,\n",
       "  1805328000.0,\n",
       "  -1.3871815457606542,\n",
       "  1.0190702910278768,\n",
       "  0.3844696809979922,\n",
       "  1.6565786179880901],\n",
       " [-1.185917742653887,\n",
       "  -0.6164412882303989,\n",
       "  -1.514315271766885,\n",
       "  1.5669622226480593,\n",
       "  -1.3891279928803364,\n",
       "  1.0193634967458274,\n",
       "  0.38329884312329143,\n",
       "  1.6585711078512657,\n",
       "  1805414400.0,\n",
       "  -0.5997913206846937,\n",
       "  0.4171168040931785,\n",
       "  -0.32163990301751416,\n",
       "  1.4066085657902474],\n",
       " [-1.3907072655405122,\n",
       "  1.0193536912577537,\n",
       "  0.38059516615521116,\n",
       "  1.6649373377531254,\n",
       "  -0.6018083714906419,\n",
       "  0.41769192463083366,\n",
       "  -0.3226699160386647,\n",
       "  1.4086940760177924,\n",
       "  1805500800.0,\n",
       "  -0.23297298048108384,\n",
       "  1.4775942366188615,\n",
       "  0.8819052226040957,\n",
       "  1.3194697802746695],\n",
       " [-0.6032642273966333,\n",
       "  0.417702490691869,\n",
       "  -0.324877233408322,\n",
       "  1.4146934288525392,\n",
       "  -0.23502292314444098,\n",
       "  1.4776727003372108,\n",
       "  0.8806351773416421,\n",
       "  1.3215877171129549,\n",
       "  1805587200.0,\n",
       "  -0.8513715001050567,\n",
       "  0.3428148522529103,\n",
       "  -1.5836216266058556,\n",
       "  0.295440003861345],\n",
       " [-0.2364212833799485,\n",
       "  1.4776473772995617,\n",
       "  0.8775818281537502,\n",
       "  1.3274591777390925,\n",
       "  -0.8533659922260063,\n",
       "  0.34342477086352524,\n",
       "  -1.5843999529264845,\n",
       "  0.29793900883995156,\n",
       "  1805673600.0,\n",
       "  1.4870696728691764,\n",
       "  1.1537142389107615,\n",
       "  -0.3208363923068049,\n",
       "  1.0330414802712957],\n",
       " [-0.8548612811960267,\n",
       "  0.3434378514807409,\n",
       "  -1.5857201604824283,\n",
       "  0.30230751726160143,\n",
       "  1.484865497465821,\n",
       "  1.1539443863939556,\n",
       "  -0.32186656557826315,\n",
       "  1.035266004537146,\n",
       "  1805760000.0,\n",
       "  -0.6616362517295901,\n",
       "  -1.4230221942019385,\n",
       "  -1.1967625008640705,\n",
       "  -0.4183329405762258],\n",
       " [1.4837367393596954,\n",
       "  1.1539300242318926,\n",
       "  -0.3240744477756225,\n",
       "  1.0407170789061324,\n",
       "  -0.6636477570258665,\n",
       "  -1.421585275427052,\n",
       "  -1.197617981469191,\n",
       "  -0.41556832210198325,\n",
       "  1805846400.0,\n",
       "  -0.2257145932958255,\n",
       "  0.8557875695144044,\n",
       "  1.6271766641507188,\n",
       "  1.4254178493555103],\n",
       " [-0.6651133066014124,\n",
       "  -1.4215124346508015,\n",
       "  -1.1992101315743455,\n",
       "  -0.4122474068705467,\n",
       "  -0.22776518680405639,\n",
       "  0.8561572459564151,\n",
       "  1.6257579836849103,\n",
       "  1.4274963601589425,\n",
       "  1805932800.0,\n",
       "  0.8272311205036191,\n",
       "  0.26466026377541907,\n",
       "  1.2716860250564936,\n",
       "  -1.525483841070817],\n",
       " [-0.22916240934879953,\n",
       "  0.8561529663470879,\n",
       "  1.6221807460782571,\n",
       "  1.4335233190798116,\n",
       "  0.8250861114864517,\n",
       "  0.2653067847767468,\n",
       "  1.2703382428171393,\n",
       "  -1.5223072229219319,\n",
       "  1806019200.0,\n",
       "  -1.231493643801832,\n",
       "  -0.39821172472055905,\n",
       "  0.7493026876293052,\n",
       "  -0.12721153754608716],\n",
       " [0.8238539292713835,\n",
       "  0.26532251033260285,\n",
       "  1.2670108972879457,\n",
       "  -1.5206112554458497,\n",
       "  -1.2334540511402665,\n",
       "  -0.3972547587410394,\n",
       "  0.7480590883080921,\n",
       "  -0.12455525292523018,\n",
       "  1806105600.0,\n",
       "  1.7637506966023013,\n",
       "  1.0353147873171198,\n",
       "  -1.54831979619142,\n",
       "  0.8494195107058904],\n",
       " [-1.2350089210393795,\n",
       "  -0.39721660000793646,\n",
       "  0.7450989520470602,\n",
       "  -0.12080706344402495,\n",
       "  1.7615217117720912,\n",
       "  1.0356003851976843,\n",
       "  -1.549105163027021,\n",
       "  0.8517123654871963,\n",
       "  1806192000.0,\n",
       "  -0.23225569389816114,\n",
       "  -1.393918696283516,\n",
       "  0.49605704711423204,\n",
       "  -1.1584109844621149],\n",
       " [1.7604363210749148,\n",
       "  1.0355900299569119,\n",
       "  -1.5504501859979722,\n",
       "  0.8568939408139604,\n",
       "  -0.234305700879153,\n",
       "  -1.3924954076437588,\n",
       "  0.4948639545147022,\n",
       "  -1.155370963679881,\n",
       "  1806278400.0,\n",
       "  -1.6714383108153688,\n",
       "  -0.1985373324624507,\n",
       "  -1.6885677547012536,\n",
       "  -1.6154887630125099],\n",
       " [-0.23570394868605898,\n",
       "  -1.3924235517996497,\n",
       "  0.4920818372287331,\n",
       "  -1.1531362492144486,\n",
       "  -1.6733592692068198,\n",
       "  -0.19767388063562694,\n",
       "  -1.689325150810122,\n",
       "  -1.6122786516889007,\n",
       "  1806364800.0,\n",
       "  0.17733676459747183,\n",
       "  0.26991568235816776,\n",
       "  -0.7060471523772697,\n",
       "  -1.132777231459034],\n",
       " [-1.6749830967092842,\n",
       "  -0.19764247936265344,\n",
       "  -1.6905715865051865,\n",
       "  -1.6107147830042432,\n",
       "  0.17525003029054226,\n",
       "  0.27055974207234557,\n",
       "  -0.7070005001104532,\n",
       "  -1.1297467496636648,\n",
       "  1806451200.0,\n",
       "  1.3204296791906114,\n",
       "  0.2848678256233428,\n",
       "  -1.4978315539915559,\n",
       "  1.461636206440638],\n",
       " [0.1739159826351698,\n",
       "  0.2705752897722375,\n",
       "  -0.7089375984769383,\n",
       "  -1.127474412946934,\n",
       "  1.3182404460578843,\n",
       "  0.28550488275199815,\n",
       "  -1.4986269900847833,\n",
       "  1.4637012394504576,\n",
       "  1806537600.0,\n",
       "  1.2240546887306414,\n",
       "  1.166979118482536,\n",
       "  -0.9652747515257509,\n",
       "  -0.07435512279485915],\n",
       " [1.3170855685430054,\n",
       "  0.28551992443551605,\n",
       "  -1.5000075037560319,\n",
       "  1.4697813554775727,\n",
       "  1.2218740973480573,\n",
       "  1.1672030535818598,\n",
       "  -0.966176399509331,\n",
       "  -0.07171850742204285,\n",
       "  1806624000.0,\n",
       "  0.5155538216032837,\n",
       "  1.3929840075420625,\n",
       "  0.9626147054400064,\n",
       "  0.15623888345909515],\n",
       " [1.2207041138690347,\n",
       "  1.167188242504471,\n",
       "  -0.9679312738840642,\n",
       "  -0.06789274142216456,\n",
       "  0.5134367600580647,\n",
       "  1.3931020970421257,\n",
       "  0.9613285636659662,\n",
       "  0.15878968879869132,\n",
       "  1806710400.0,\n",
       "  -0.6348567809612206,\n",
       "  -0.5954144555178009,\n",
       "  -0.1802268797333665,\n",
       "  -0.8520453415593878],\n",
       " [0.5121557250640844,\n",
       "  1.3930796374174717,\n",
       "  0.9582184797623925,\n",
       "  0.16295389395143772,\n",
       "  -0.6368706875183869,\n",
       "  -0.5943651329467761,\n",
       "  -0.18128509583905927,\n",
       "  -0.8491193274090784,\n",
       "  1806796800.0,\n",
       "  1.3040437525789312,\n",
       "  1.0547492070252629,\n",
       "  -1.7833103691935919,\n",
       "  0.903257060740937],\n",
       " [-0.6383320396385215,\n",
       "  -0.594320300400493,\n",
       "  -0.18359181946666586,\n",
       "  -0.8464349649656422,\n",
       "  1.3018559887390464,\n",
       "  1.0550257031213093,\n",
       "  -1.7840488700557267,\n",
       "  0.9055298811682194,\n",
       "  1806883200.0,\n",
       "  0.06922262367097777,\n",
       "  1.486298837582875,\n",
       "  -1.17139759056824,\n",
       "  -1.4415316086163805],\n",
       " [1.3006985428688433,\n",
       "  1.055014690173182,\n",
       "  -1.7852287064478678,\n",
       "  0.9107904730102969,\n",
       "  0.06714558374003078,\n",
       "  1.486373224647355,\n",
       "  -1.1722581298920898,\n",
       "  -1.4383862312788807,\n",
       "  1806969600.0,\n",
       "  0.9689817908181633,\n",
       "  0.3669044864869757,\n",
       "  -0.707491620707565,\n",
       "  -0.0006240490109030737],\n",
       " [0.06579459010802612,\n",
       "  1.4863476070251413,\n",
       "  -1.1738681102561355,\n",
       "  -1.4365670484474,\n",
       "  0.966824071305569,\n",
       "  0.36750312312142597,\n",
       "  -0.7084446803593436,\n",
       "  0.0019851291097767337,\n",
       "  1807056000.0,\n",
       "  -0.39668196123225824,\n",
       "  0.13790525027737627,\n",
       "  -0.7746373068980497,\n",
       "  -1.473705917768101],\n",
       " [0.9656141073084524,\n",
       "  0.3675153884876671,\n",
       "  -0.7103807633370892,\n",
       "  0.005919109033151431,\n",
       "  -0.39871722444297836,\n",
       "  0.13861113486335389,\n",
       "  -0.7755769751703053,\n",
       "  -1.47054856753251,\n",
       "  1807142400.0,\n",
       "  -0.19986215407692537,\n",
       "  -1.227955749132185,\n",
       "  -0.9225253426419877,\n",
       "  0.4414860325984939],\n",
       " [-0.4001412446757676,\n",
       "  0.13863115011274665,\n",
       "  -0.7774658581006535,\n",
       "  -1.4687766064224888,\n",
       "  -0.20191506572100518,\n",
       "  -1.2266101864552128,\n",
       "  -0.9234355164682722,\n",
       "  0.4439306900475129,\n",
       "  1807228800.0,\n",
       "  0.9273448385012703,\n",
       "  1.6539324338419195,\n",
       "  0.33988564095384927,\n",
       "  -0.9288921314630075],\n",
       " [-0.2033082361146871,\n",
       "  -1.2265439471951118,\n",
       "  -0.9252204415318881,\n",
       "  0.44851354790108655,\n",
       "  0.9251908524898358,\n",
       "  1.653928312523125,\n",
       "  0.33872369481642556,\n",
       "  -0.925937520621476,\n",
       "  1807315200.0,\n",
       "  1.611788614601999,\n",
       "  0.9583453722266143,\n",
       "  1.2578240848707825,\n",
       "  -1.3704823242760322],\n",
       " [0.9239743622528124,\n",
       "  1.6538970217781324,\n",
       "  0.3360513581908549,\n",
       "  -0.9233659449884957,\n",
       "  1.6095732559038134,\n",
       "  0.9586670174418135,\n",
       "  1.256479067224546,\n",
       "  -1.3673633862269963,\n",
       "  1807401600.0,\n",
       "  -0.5614964654658569,\n",
       "  1.4692051047405004,\n",
       "  0.9472366915586402,\n",
       "  -0.24980798880542784],\n",
       " [1.6084640464363218,\n",
       "  0.9586592670305726,\n",
       "  1.2531614659435824,\n",
       "  -1.365439925491703,\n",
       "  -0.563516950093889,\n",
       "  1.469287497368063,\n",
       "  0.9459536167399307,\n",
       "  -0.2471060828532703,\n",
       "  1807488000.0,\n",
       "  1.5410598292476676,\n",
       "  1.633590355985342,\n",
       "  -0.5041561529071448,\n",
       "  1.692391063624972],\n",
       " [-0.56496680360541,\n",
       "  1.4692624582387488,\n",
       "  0.9428543428083039,\n",
       "  -0.24353782623234574,\n",
       "  1.5388508126563714,\n",
       "  1.6335957615375365,\n",
       "  -0.5051497653118144,\n",
       "  1.6943702267447525,\n",
       "  1807574400.0,\n",
       "  0.7255581721030536,\n",
       "  1.116553547981857,\n",
       "  0.5905117794162479,\n",
       "  0.02625444496214832],\n",
       " [1.5377305170503455,\n",
       "  1.6335651592172262,\n",
       "  -0.5072287829181606,\n",
       "  1.700789018003086,\n",
       "  0.7234222798931845,\n",
       "  1.1168010990513921,\n",
       "  0.5892998489845392,\n",
       "  0.02885362089544172,\n",
       "  1807660800.0,\n",
       "  0.1284977002401863,\n",
       "  0.7206589191209448,\n",
       "  0.08512957991545021,\n",
       "  1.5967253313429648],\n",
       " [0.7221741613039014,\n",
       "  1.1167879944961985,\n",
       "  0.586451334762378,\n",
       "  0.03282704995662528,\n",
       "  0.12641534523321193,\n",
       "  0.7210918808000035,\n",
       "  0.08401844173446688,\n",
       "  1.5987400941723757,\n",
       "  1807747200.0,\n",
       "  -0.733891180970303,\n",
       "  -0.15084688026552057,\n",
       "  1.3860136986122842,\n",
       "  -1.1521036989248932],\n",
       " [0.12507364246782107,\n",
       "  0.7210921742681605,\n",
       "  0.08152518583377993,\n",
       "  1.6050184783580452,\n",
       "  -0.7358962073134597,\n",
       "  -0.15000576346212394,\n",
       "  1.3846431151275571,\n",
       "  -1.149066025247817,\n",
       "  1807833600.0,\n",
       "  1.565341936168371,\n",
       "  0.2891767293078265,\n",
       "  1.2162169112553862,\n",
       "  -1.3815903025708711],\n",
       " [-0.7373730822376786,\n",
       "  -0.14997597614838493,\n",
       "  1.3812354029818787,\n",
       "  -1.146822053679788,\n",
       "  1.5631307422497416,\n",
       "  0.28981176843370976,\n",
       "  1.2148801916471086,\n",
       "  -1.3784672309539168,\n",
       "  1807920000.0,\n",
       "  1.7314586062705517,\n",
       "  0.7248591411010565,\n",
       "  -1.6033292776609096,\n",
       "  -0.5059088750213366],\n",
       " [1.5620142526584786,\n",
       "  0.2898266642935969,\n",
       "  1.2115918381209616,\n",
       "  -1.3765600732215733,\n",
       "  1.7292325170066591,\n",
       "  0.7252901356765965,\n",
       "  -1.6041036735334375,\n",
       "  -0.503111667261856,\n",
       "  1808006400.0,\n",
       "  1.7022591467031492,\n",
       "  -1.1909049393063398,\n",
       "  -0.6348912150696491,\n",
       "  -0.9933563111345773],\n",
       " [1.7281420647976076,\n",
       "  0.7252902869991722,\n",
       "  -1.6054100275998027,\n",
       "  -0.4999192858355547,\n",
       "  1.7000356756956392,\n",
       "  -1.1895767287547372,\n",
       "  -0.6358587539775135,\n",
       "  -0.9903777114934712,\n",
       "  1808092800.0,\n",
       "  -1.6285147512136258,\n",
       "  0.8987004330962888,\n",
       "  -0.10365573719124489,\n",
       "  1.040466552815714],\n",
       " [1.6989406467184123,\n",
       "  -1.1895117433828655,\n",
       "  -0.6378458713966596,\n",
       "  -0.9879007489109896,\n",
       "  -1.630439558473705,\n",
       "  0.8990500120183709,\n",
       "  -0.10472922446755872,\n",
       "  1.0426883140187593,\n",
       "  1808179200.0,\n",
       "  -1.192265227840834,\n",
       "  0.9580898107127785,\n",
       "  -0.43313725778421247,\n",
       "  -0.24206909867866308],\n",
       " [-1.6320566580714593,\n",
       "  0.8990442801348617,\n",
       "  -0.10708977376532101,\n",
       "  1.0481502860485425,\n",
       "  -1.194229152711853,\n",
       "  0.9584115756159265,\n",
       "  -0.43414503403218824,\n",
       "  -0.239370072569003,\n",
       "  1808265600.0,\n",
       "  -0.11239934604215757,\n",
       "  1.0606886275693908,\n",
       "  0.801623432433771,\n",
       "  0.9192299680496806],\n",
       " [-1.19577787388875,\n",
       "  0.9584038338534998,\n",
       "  -0.4362739743574179,\n",
       "  -0.23579045770221077,\n",
       "  -0.11446010029903819,\n",
       "  1.0609623420374408,\n",
       "  0.8003693983848732,\n",
       "  0.9214968445423002,\n",
       "  1808352000.0,\n",
       "  -1.2424090609820904,\n",
       "  -0.8313810808464909,\n",
       "  -1.2144603858274683,\n",
       "  0.42069069125051756],\n",
       " [-0.11583956163774875,\n",
       "  1.0609511280850832,\n",
       "  0.7973724832661849,\n",
       "  0.9267808795662116,\n",
       "  -1.2443684895571803,\n",
       "  -0.8302212472641011,\n",
       "  -1.2153123368075638,\n",
       "  0.42314308718745686,\n",
       "  1808438400.0,\n",
       "  -0.7080072986937384,\n",
       "  -0.9946963519627767,\n",
       "  -1.7295232927581525,\n",
       "  1.5167452313287866],\n",
       " [-1.2459250703555604,\n",
       "  -0.8301684290415152,\n",
       "  -1.2168920461878334,\n",
       "  0.4276954240495106,\n",
       "  -0.7100146459921791,\n",
       "  -0.9934600324122663,\n",
       "  -1.730272520789743,\n",
       "  1.5187897568356872,\n",
       "  1808524800.0,\n",
       "  0.9920177063140295,\n",
       "  1.593457449896086,\n",
       "  0.28662740800535835,\n",
       "  0.6076513163765208],\n",
       " [-0.7114874638369035,\n",
       "  -0.993401687209377,\n",
       "  -1.7314901667970828,\n",
       "  1.524950755501521,\n",
       "  0.9898579212175626,\n",
       "  1.5934816510217424,\n",
       "  0.2854760835660749,\n",
       "  0.6100341393973486,\n",
       "  1808611200.0,\n",
       "  0.18653660586515616,\n",
       "  1.177091633391819,\n",
       "  0.3874404320824013,\n",
       "  0.8723796661620777],\n",
       " [0.9886515679052494,\n",
       "  1.593452406895188,\n",
       "  0.28284118480527404,\n",
       "  0.6148608753932534,\n",
       "  0.18444904662709857,\n",
       "  1.1773108324643913,\n",
       "  0.38626900172801204,\n",
       "  0.874663976871773,\n",
       "  1808697600.0,\n",
       "  0.8709851818795654,\n",
       "  0.05110937053256299,\n",
       "  0.3875743805476015,\n",
       "  -1.1118838129136939],\n",
       " [0.18311644096898758,\n",
       "  1.1772956791552545,\n",
       "  0.3835632364710193,\n",
       "  0.8798792504532685,\n",
       "  0.8688362495243582,\n",
       "  0.05185590451308761,\n",
       "  0.38640292347884175,\n",
       "  -1.1088611061033236,\n",
       "  1808784000.0,\n",
       "  -0.3446016449560933,\n",
       "  0.40417763483338626,\n",
       "  1.615785099340816,\n",
       "  0.4237341912596278],\n",
       " [0.8676109253881249,\n",
       "  0.051878857143133665,\n",
       "  0.38369706406280074,\n",
       "  -1.1065581044487314,\n",
       "  -0.34664157810326157,\n",
       "  0.40475881521394985,\n",
       "  1.6143686907822048,\n",
       "  0.42618545463097646,\n",
       "  1808870400.0,\n",
       "  -1.3725258721785312,\n",
       "  0.9651579354310464,\n",
       "  0.1567637385792796,\n",
       "  1.2760539189312612],\n",
       " [-0.3480574351872245,\n",
       "  0.40476981916749305,\n",
       "  1.6107994608738783,\n",
       "  0.43074225838955355,\n",
       "  -1.3744736334427718,\n",
       "  0.9654763900965284,\n",
       "  0.15563831384826016,\n",
       "  1.2781880119418803,\n",
       "  1808956800.0,\n",
       "  0.37026089035480864,\n",
       "  0.14450368807092703,\n",
       "  1.4845660417017106,\n",
       "  -0.7632392351457784],\n",
       " [-1.376050608950143,\n",
       "  0.9654684091318163,\n",
       "  0.15309470272930023,\n",
       "  1.2839957517993266,\n",
       "  0.3681568569323779,\n",
       "  0.14520648238923234,\n",
       "  1.483175803166837,\n",
       "  -0.7603462680597239,\n",
       "  1809043200.0,\n",
       "  -0.6762574948396981,\n",
       "  -1.7285519343637037,\n",
       "  -1.5816754868616432,\n",
       "  1.1683377285096384],\n",
       " [0.36685304850102235,\n",
       "  0.1452262743316712,\n",
       "  1.4796988136702391,\n",
       "  -0.7575315663073335,\n",
       "  -0.6782676890787268,\n",
       "  -1.7269719258593255,\n",
       "  -1.5824542013158576,\n",
       "  1.170511905519094,\n",
       "  1809129600.0,\n",
       "  0.17318756245655928,\n",
       "  1.612308766430201,\n",
       "  0.2631338341309322,\n",
       "  -0.3491151947076493],\n",
       " [-0.6797355304103923,\n",
       "  -1.7268887452241968,\n",
       "  -1.583775776910366,\n",
       "  1.1761615520382587,\n",
       "  0.1711012002001796,\n",
       "  1.612324138857931,\n",
       "  0.26198719519539365,\n",
       "  -0.3463763339587219,\n",
       "  1809216000.0,\n",
       "  -1.0905907934555206,\n",
       "  -1.7472346741293896,\n",
       "  -0.7031309989115478,\n",
       "  0.45584559683953724],\n",
       " [0.1697665021924858,\n",
       "  1.6122942567576313,\n",
       "  0.2593688112379007,\n",
       "  -0.3429538289433366,\n",
       "  -1.0925638352670828,\n",
       "  -1.745645915877187,\n",
       "  -0.7040849282355978,\n",
       "  0.45828491072085226,\n",
       "  1809302400.0,\n",
       "  -0.8817964156440651,\n",
       "  -1.0803564918417239,\n",
       "  0.9086676991514364,\n",
       "  0.17752851749109205],\n",
       " [-1.0940966198368494,\n",
       "  -1.745562102973355,\n",
       "  -0.7060240765116096,\n",
       "  0.4628888438783171,\n",
       "  -0.8837881796244778,\n",
       "  -1.0790800548013841,\n",
       "  0.9073923164428899,\n",
       "  0.18007140040359135,\n",
       "  1809388800.0,\n",
       "  -0.5442731807976016,\n",
       "  -1.611610225244465,\n",
       "  0.6275343386428852,\n",
       "  -0.5716619307170837],\n",
       " [-0.8852882374425262,\n",
       "  -1.0790188106540015,\n",
       "  0.904320154577175,\n",
       "  0.18426685201336285,\n",
       "  -0.5462952098026763,\n",
       "  -1.6100849844282188,\n",
       "  0.6263150245180513,\n",
       "  -0.568840254533704,\n",
       "  1809475200.0,\n",
       "  0.3896107027326893,\n",
       "  1.563505757465605,\n",
       "  -1.5408431070118687,\n",
       "  -0.21636124974391124],\n",
       " [-0.5477423637100842,\n",
       "  -1.6100057613808805,\n",
       "  0.6234404852948897,\n",
       "  -0.5657443778207285,\n",
       "  0.3875049342517844,\n",
       "  1.5635439859640647,\n",
       "  -1.5416299649809746,\n",
       "  -0.21367179019414118,\n",
       "  1809561600.0,\n",
       "  0.49336339520321915,\n",
       "  -1.1128788618789531,\n",
       "  -1.2270786182155033,\n",
       "  0.7097614811460471],\n",
       " [0.38620415873976377,\n",
       "  1.5635157554745878,\n",
       "  -1.5429802436891693,\n",
       "  -0.21005444432663092,\n",
       "  0.49124832342857866,\n",
       "  -1.1115871935320683,\n",
       "  -1.2279280526446719,\n",
       "  0.7121063063161357,\n",
       "  1809648000.0,\n",
       "  -1.1428925967316772,\n",
       "  0.28519380355953583,\n",
       "  0.5291600869716466,\n",
       "  1.5663240424635143],\n",
       " [0.4899638102730552,\n",
       "  -1.111524848749715,\n",
       "  -1.229498892040873,\n",
       "  0.7170829077756977,\n",
       "  -1.1448609487465007,\n",
       "  0.2858307080218921,\n",
       "  0.5279603923788208,\n",
       "  1.5683501184040118,\n",
       "  1809734400.0,\n",
       "  -0.7973590650404339,\n",
       "  -1.5459726464784718,\n",
       "  0.5415521091761966,\n",
       "  -0.12934767513399456],\n",
       " [-1.1464019311813063,\n",
       "  0.2858457386735351,\n",
       "  0.52515500531725,\n",
       "  1.5745838831018568,\n",
       "  -0.799358400347009,\n",
       "  -1.544478145921374,\n",
       "  0.5403499431472768,\n",
       "  -0.12669059560072699,\n",
       "  1809820800.0,\n",
       "  -0.05664250851894158,\n",
       "  -0.2113528151785878,\n",
       "  -0.20950057544725095,\n",
       "  -1.3136761618212356],\n",
       " [-0.8008452233249341,\n",
       "  -1.5444011442070593,\n",
       "  0.537535845116043,\n",
       "  -0.12294554129466097,\n",
       "  -0.0587082623784821,\n",
       "  -0.21048336143537388,\n",
       "  -0.21055295327513937,\n",
       "  -1.310578362824192,\n",
       "  1809907200.0,\n",
       "  -1.3520487217314572,\n",
       "  -0.6292831021659969,\n",
       "  0.2812229850355404,\n",
       "  0.6128296171804422],\n",
       " [-0.06007898430477484,\n",
       "  -0.2104515264557417,\n",
       "  -0.21283909896388517,\n",
       "  -1.308571528588385,\n",
       "  -1.3539983191402927,\n",
       "  -0.6282179177823558,\n",
       "  0.2800727384418073,\n",
       "  0.6152105132207243,\n",
       "  1809993600.0,\n",
       "  1.2556261545915774,\n",
       "  0.7358266382634308,\n",
       "  1.0610069214631763,\n",
       "  -1.5065438899567845],\n",
       " [-1.355572085027627,\n",
       "  -0.6281719390398741,\n",
       "  0.2774416387191101,\n",
       "  0.6200448493263017,\n",
       "  1.2534427322596122,\n",
       "  0.7362524963956205,\n",
       "  1.0597011565743597,\n",
       "  -1.5033743198568088,\n",
       "  1810080000.0,\n",
       "  -1.5800681067269522,\n",
       "  -1.517186032218851,\n",
       "  1.6299686851831794,\n",
       "  0.015211748915208026],\n",
       " [1.2522776973406775,\n",
       "  0.7362522765517989,\n",
       "  1.0565219078811574,\n",
       "  -1.501650554515923,\n",
       "  -1.5819972580994919,\n",
       "  -1.5157050133897354,\n",
       "  1.6285494478831883,\n",
       "  0.017815034123196034,\n",
       "  1810166400.0,\n",
       "  -0.07068791558122536,\n",
       "  0.6927688755943536,\n",
       "  -1.6655060598387577,\n",
       "  1.133626749195602],\n",
       " [-1.5836067640957214,\n",
       "  -1.51562898588346,\n",
       "  1.6249702476258787,\n",
       "  0.02177225599514593,\n",
       "  -0.07275241001756996,\n",
       "  0.6932148991075292,\n",
       "  -1.666268055318425,\n",
       "  1.1358138430641576,\n",
       "  1810252800.0,\n",
       "  1.530886357894839,\n",
       "  -0.1255815524696663,\n",
       "  -1.6643243853347138,\n",
       "  -0.21115222196475603],\n",
       " [-0.074125333442555,\n",
       "  0.693216136441622,\n",
       "  -1.6675307022275276,\n",
       "  1.1414125448314394,\n",
       "  1.528678253538108,\n",
       "  -0.12475226825879539,\n",
       "  -1.6650866164847966,\n",
       "  -0.20846470082983912,\n",
       "  1810339200.0,\n",
       "  -1.475308904449125,\n",
       "  -1.6317027293705912,\n",
       "  -1.3738586689984993,\n",
       "  0.8023068516071862],\n",
       " [1.5275563633265445,\n",
       "  -0.1247233359843196,\n",
       "  -1.6663500940517681,\n",
       "  -0.20483970975516377,\n",
       "  -1.4772474493670957,\n",
       "  -1.6301680785670267,\n",
       "  -1.3746788299556407,\n",
       "  0.8046172382355163,\n",
       "  1810425600.0,\n",
       "  -1.48018411028482,\n",
       "  -0.24428681075816502,\n",
       "  -0.2955690508678832,\n",
       "  0.2593174347079772],\n",
       " [-1.4788405352449336,\n",
       "  -1.6300881755411794,\n",
       "  -1.3761464903429281,\n",
       "  0.8097296670623614,\n",
       "  -1.4821222180529605,\n",
       "  -0.24340193293048695,\n",
       "  -0.296604263399165,\n",
       "  0.2618298818350134,\n",
       "  1810512000.0,\n",
       "  -0.6383359175242835,\n",
       "  -0.7290102733122612,\n",
       "  1.2899031959766403,\n",
       "  -0.22135760364452803],\n",
       " [-1.4837160680780548,\n",
       "  -0.24336898338548904,\n",
       "  -0.2988299072694059,\n",
       "  0.26614537373684,\n",
       "  -0.6403495121143228,\n",
       "  -0.7278983833806274,\n",
       "  1.2885517805470772,\n",
       "  -0.21866628482139192,\n",
       "  1810598400.0,\n",
       "  -1.7202169451617408,\n",
       "  0.8400800094330031,\n",
       "  -0.6139748881752473,\n",
       "  0.907700600169842],\n",
       " [-0.6418114095596701,\n",
       "  -0.7278490296315903,\n",
       "  1.2852116292610336,\n",
       "  -0.21505627202298014,\n",
       "  -1.7221335296718734,\n",
       "  0.8404570422473322,\n",
       "  -0.6149465985867117,\n",
       "  0.9099717670404158,\n",
       "  1810684800.0,\n",
       "  -1.5684714809469456,\n",
       "  0.07555155473939287,\n",
       "  -0.9024722213777843,\n",
       "  1.349368025053546],\n",
       " [-1.7237650028124634,\n",
       "  0.8404532942194953,\n",
       "  -0.616948419133889,\n",
       "  0.9152388805945901,\n",
       "  -1.5704016721654248,\n",
       "  0.076286641632886,\n",
       "  -0.903386394551945,\n",
       "  1.3514748359765512,\n",
       "  1810771200.0,\n",
       "  -0.16353880090092712,\n",
       "  0.9508622439467826,\n",
       "  0.0495009790005729,\n",
       "  0.9002121757115034],\n",
       " [-1.5720093604887042,\n",
       "  0.0763087670808213,\n",
       "  -0.9051854159533578,\n",
       "  1.3573901777806934,\n",
       "  -0.16559496958649678,\n",
       "  0.9511873937596055,\n",
       "  0.048396946504910394,\n",
       "  0.9024861292197786,\n",
       "  1810857600.0,\n",
       "  -0.13397644579937532,\n",
       "  -1.569595182918652,\n",
       "  0.5699180742117018,\n",
       "  -0.729798251940182],\n",
       " [-0.16698244660196887,\n",
       "  0.9511798965953654,\n",
       "  0.04592873572249236,\n",
       "  0.9077422521325603,\n",
       "  -0.13603526528143495,\n",
       "  -1.568089619142807,\n",
       "  0.5687102509406736,\n",
       "  -0.726917729114611,\n",
       "  1810944000.0,\n",
       "  0.22789730098235597,\n",
       "  -0.2770220409789886,\n",
       "  0.26766948849375316,\n",
       "  0.9562894515646481],\n",
       " [-0.13741810864792783,\n",
       "  -1.5680118179852272,\n",
       "  0.5658762130596876,\n",
       "  -0.724053946563413,\n",
       "  0.22580603301456212,\n",
       "  -0.2761218321552685,\n",
       "  0.26652194497785503,\n",
       "  0.9585425372586117,\n",
       "  1811030400.0,\n",
       "  -0.7374783947999166,\n",
       "  -0.5178772368177871,\n",
       "  -1.2820542922570624,\n",
       "  -0.5327129148576757],\n",
       " [0.22447991029537975,\n",
       "  -0.27608777477160107,\n",
       "  0.2639003726829863,\n",
       "  0.963880963896643,\n",
       "  -0.7394830994848767,\n",
       "  -0.5168642275026942,\n",
       "  -1.2828927624656326,\n",
       "  -0.5299057326171313,\n",
       "  1811116800.0,\n",
       "  -1.1752271489579509,\n",
       "  0.021686141623897766,\n",
       "  -1.5871915742210327,\n",
       "  -0.7129032830132516],\n",
       " [-0.7409605366745051,\n",
       "  -0.5168220190017782,\n",
       "  -1.2844249567221726,\n",
       "  -0.5267526910534874,\n",
       "  -1.1771926015989846,\n",
       "  0.02244645548019842,\n",
       "  -1.5879691885596106,\n",
       "  -0.7100290472454773,\n",
       "  1811203200.0,\n",
       "  1.7420050321980232,\n",
       "  -0.8962800296485982,\n",
       "  -0.012337496588423471,\n",
       "  -1.2566347074588908],\n",
       " [-1.1787386522012082,\n",
       "  0.022470403862849417,\n",
       "  -1.589286886621554,\n",
       "  -0.7071404682172839,\n",
       "  1.7397779972574843,\n",
       "  -0.8950898017320154,\n",
       "  -0.013429196162304816,\n",
       "  -1.2535581350720844,\n",
       "  1811289600.0,\n",
       "  -1.096414632807574,\n",
       "  -0.5207305339408059,\n",
       "  -1.260566498163761,\n",
       "  -0.18951548618526046],\n",
       " [1.7386891981114436,\n",
       "  -0.8950347871734146,\n",
       "  -0.015853937600013072,\n",
       "  -1.2514675820015757,\n",
       "  -1.0983871524072604,\n",
       "  -0.5197161883318606,\n",
       "  -1.2614092538480204,\n",
       "  -0.18683601664303745,\n",
       "  1811376000.0,\n",
       "  0.3287493696711076,\n",
       "  -1.1783484902452888,\n",
       "  0.9903498666963811,\n",
       "  -0.18832925914311988],\n",
       " [-1.0999208498145587,\n",
       "  -0.5196738832685295,\n",
       "  -1.2629565529453508,\n",
       "  -0.18317926967562662,\n",
       "  0.32664905850263615,\n",
       "  -1.1770261602960084,\n",
       "  0.9890581934862714,\n",
       "  -0.18565023102686257,\n",
       "  1811462400.0,\n",
       "  -1.4608334387346331,\n",
       "  -1.53591451900434,\n",
       "  0.35126074680099173,\n",
       "  1.6459039851393102],\n",
       " [0.3253387434917208,\n",
       "  -1.1769615998644756,\n",
       "  0.9859286131563426,\n",
       "  -0.18199174305290186,\n",
       "  -1.462773281638288,\n",
       "  -1.5344247290025506,\n",
       "  0.35009653203890795,\n",
       "  1.647900447311282,\n",
       "  1811548800.0,\n",
       "  -0.38997661420186064,\n",
       "  -0.40568064105833684,\n",
       "  0.06881100191995418,\n",
       "  1.5430855194962592],\n",
       " [-1.4643640986093793,\n",
       "  -1.5343480676793828,\n",
       "  0.34741619928483525,\n",
       "  1.6542510102244057,\n",
       "  -0.39201247866746425,\n",
       "  -0.4047201771371182,\n",
       "  0.06770311827822138,\n",
       "  1.5451202430961657,\n",
       "  1811635200.0,\n",
       "  1.2705659493813828,\n",
       "  0.7175605322932704,\n",
       "  -0.17855868830388136,\n",
       "  0.42642966738565913],\n",
       " [-0.3934354478938531,\n",
       "  -0.4046817656379806,\n",
       "  0.0652213335188474,\n",
       "  1.5513199009837135,\n",
       "  1.268381187428286,\n",
       "  0.7179949450498341,\n",
       "  -0.17961723710979383,\n",
       "  0.42887992770016486,\n",
       "  1811721600.0,\n",
       "  1.6693156249410273,\n",
       "  -1.1696870267197759,\n",
       "  1.018630989180773,\n",
       "  -0.3622193662594049],\n",
       " [1.2672184941957507,\n",
       "  0.7179953433748293,\n",
       "  -0.18192513339225003,\n",
       "  0.4334406875661512,\n",
       "  1.6670951079123717,\n",
       "  -1.1683687532216684,\n",
       "  1.0173336756493558,\n",
       "  -0.3594756291070772,\n",
       "  1811808000.0,\n",
       "  -1.040246102669592,\n",
       "  0.9662218883620988,\n",
       "  -1.502529029326507,\n",
       "  -1.110051356750451],\n",
       " [1.665994915316906,\n",
       "  -1.1683044859148262,\n",
       "  1.01418421510973,\n",
       "  -0.3560723568757137,\n",
       "  -1.0422236587875808,\n",
       "  0.9665398447430701,\n",
       "  -1.5033235285661763,\n",
       "  -1.107029331844727,\n",
       "  1811894400.0,\n",
       "  -1.600440769956393,\n",
       "  1.6256843276017383,\n",
       "  0.18583480581045586,\n",
       "  -1.3905412913169832],\n",
       " [-1.0437485522531282,\n",
       "  0.96653182777164,\n",
       "  -1.5047007401480272,\n",
       "  -1.1047236407233891,\n",
       "  -1.602368094553495,\n",
       "  1.625693435809727,\n",
       "  0.18470358321338548,\n",
       "  -1.387414888804078,\n",
       "  1811980800.0,\n",
       "  -0.23077704015484735,\n",
       "  0.2622748434139509,\n",
       "  -0.26708180497246486,\n",
       "  -0.9907986032120226],\n",
       " [-1.603980793792274,\n",
       "  1.625663101048371,\n",
       "  0.18213953659321833,\n",
       "  -1.3855208682954543,\n",
       "  -0.2328271797237247,\n",
       "  0.2629224815868969,\n",
       "  -0.26812269893382795,\n",
       "  -0.9878209553606242,\n",
       "  1812067200.0,\n",
       "  0.07521140131616229,\n",
       "  0.29679302108292827,\n",
       "  1.5176845973414033,\n",
       "  0.8046397716528378],\n",
       " [-0.23422519576417006,\n",
       "  0.2629382878710967,\n",
       "  -0.27036836790817864,\n",
       "  -0.9853402388709328,\n",
       "  0.07313382438365684,\n",
       "  0.2974244932462983,\n",
       "  1.5162877537188022,\n",
       "  0.8069492901408817,\n",
       "  1812153600.0,\n",
       "  0.2725573146098109,\n",
       "  -1.5058536581297546,\n",
       "  0.6646366958412255,\n",
       "  0.7444877458545306],\n",
       " [0.0717837694418657,\n",
       "  0.29743913135261263,\n",
       "  1.5127874835397865,\n",
       "  0.8120651429573473,\n",
       "  0.2704620420690742,\n",
       "  -1.504377946627978,\n",
       "  0.6634099821085445,\n",
       "  0.7468196484774262,\n",
       "  1812240000.0,\n",
       "  0.695919361686732,\n",
       "  1.280298272816329,\n",
       "  0.2066617568839574,\n",
       "  1.4944298685163424],\n",
       " [0.2691429194290752,\n",
       "  -1.5043023026364097,\n",
       "  0.6605093617904135,\n",
       "  0.7518472171230013,\n",
       "  0.693786127128946,\n",
       "  1.2804691367902976,\n",
       "  0.20552638060819295,\n",
       "  1.4964826981507238,\n",
       "  1812326400.0,\n",
       "  0.5779196730653832,\n",
       "  1.389641551368346,\n",
       "  1.1949616558229454,\n",
       "  -0.808657090957601],\n",
       " [0.6925333629069602,\n",
       "  1.2804504907210572,\n",
       "  0.20294769368671103,\n",
       "  1.5026109449137268,\n",
       "  0.575797019300614,\n",
       "  1.3897612062516989,\n",
       "  1.193629175313387,\n",
       "  -0.8057472227049494,\n",
       "  1812412800.0,\n",
       "  0.7808403163673618,\n",
       "  1.4563941099592104,\n",
       "  0.10038304017382411,\n",
       "  -1.0509144065398786],\n",
       " [0.574525759626055,\n",
       "  1.389738859743775,\n",
       "  1.190355763165023,\n",
       "  -0.8029991800166679,\n",
       "  0.7786994671196157,\n",
       "  1.4564825024013144,\n",
       "  0.09926885987819505,\n",
       "  -1.0479143880329527,\n",
       "  1812499200.0,\n",
       "  0.7350676480537904,\n",
       "  0.5248310226469383,\n",
       "  0.6253000635298109,\n",
       "  1.1355066297807432],\n",
       " [0.7774600135385993,\n",
       "  1.4564578968267763,\n",
       "  0.09676488156050683,\n",
       "  -1.0455219025510085,\n",
       "  0.7329309031484786,\n",
       "  0.5253556970369054,\n",
       "  0.6240811950036104,\n",
       "  1.1376930240967904,\n",
       "  1812585600.0,\n",
       "  -1.5605601314025115,\n",
       "  -0.33657033205895415,\n",
       "  1.719890209106407,\n",
       "  1.1124989535318914],\n",
       " [0.7316842750890731,\n",
       "  0.5253626177905529,\n",
       "  0.6212082263637165,\n",
       "  1.143294484934887,\n",
       "  -1.5624910320156764,\n",
       "  -0.3356422347918445,\n",
       "  1.7184530380667753,\n",
       "  1.1146939096032735,\n",
       "  1812672000.0,\n",
       "  0.1465127199610974,\n",
       "  -1.1237594740145682,\n",
       "  -1.566436350435928,\n",
       "  0.5044650711917382],\n",
       " [-1.5640974803018677,\n",
       "  -0.33560616215124706,\n",
       "  1.7148106274912454,\n",
       "  1.1202616024411276,\n",
       "  0.1444287495838023,\n",
       "  -1.122462709915478,\n",
       "  -1.5672181041480762,\n",
       "  0.5068862925008434,\n",
       "  1812758400.0,\n",
       "  -0.6186558312264959,\n",
       "  -1.7125436295629899,\n",
       "  1.2435232785723518,\n",
       "  1.0474300826181364],\n",
       " [0.14308987052029357,\n",
       "  -1.1223999969071252,\n",
       "  -1.5685503920906505,\n",
       "  0.5115615836869923,\n",
       "  -0.6206711904900025,\n",
       "  -1.7109711182796754,\n",
       "  1.2421811130456706,\n",
       "  1.0496492525104475,\n",
       "  1812844800.0,\n",
       "  0.46435417867095297,\n",
       "  0.06974968048363304,\n",
       "  0.4607186353964151,\n",
       "  1.6812459379620215],\n",
       " [-0.6221300032483731,\n",
       "  -1.7108884794039592,\n",
       "  1.2388735645137872,\n",
       "  1.055121444802091,\n",
       "  0.4622417080939876,\n",
       "  0.07048748458762542,\n",
       "  0.4595325906075474,\n",
       "  1.6832292484732234,\n",
       "  1812931200.0,\n",
       "  -0.7679163657353447,\n",
       "  1.1507911526981016,\n",
       "  -0.2737494007533527,\n",
       "  0.43905372440443324],\n",
       " [0.46095264798927454,\n",
       "  0.07050980638489482,\n",
       "  0.45677531445140607,\n",
       "  1.6896316822080062,\n",
       "  -0.7699183411091169,\n",
       "  1.1510226691596976,\n",
       "  -0.27478896494491706,\n",
       "  0.4414992869786562,\n",
       "  1813017600.0,\n",
       "  -1.1656490443266592,\n",
       "  -1.2846853243029204,\n",
       "  -1.192102771629101,\n",
       "  -1.5670404110218012],\n",
       " [-0.7714005491930963,\n",
       "  1.15100840592188,\n",
       "  -0.2770299469340757,\n",
       "  0.44607857497220577,\n",
       "  -1.1676153558169304,\n",
       "  -1.2833131932808794,\n",
       "  -1.1929591815597849,\n",
       "  -1.5638483285913163,\n",
       "  1813104000.0,\n",
       "  1.504594698080691,\n",
       "  -0.019988505582883776,\n",
       "  -0.4130575565441986,\n",
       "  1.010796654045556],\n",
       " [-1.1691599051323114,\n",
       "  -1.2832450341559523,\n",
       "  -1.1945546072207232,\n",
       "  -1.562213353031541,\n",
       "  1.50238895124383,\n",
       "  -0.01920867410452668,\n",
       "  -0.4140693374410992,\n",
       "  1.0130294561903865,\n",
       "  1813190400.0,\n",
       "  0.09157390784885555,\n",
       "  1.5575518604768517,\n",
       "  0.8323909142282558,\n",
       "  0.10003697855201861],\n",
       " [1.5012629400370938,\n",
       "  -0.01918331535190423,\n",
       "  -0.4162123927885146,\n",
       "  1.018447882181968,\n",
       "  0.08949486372353901,\n",
       "  1.557592877383108,\n",
       "  0.8311307439843313,\n",
       "  0.10260869808364197,\n",
       "  1813276800.0,\n",
       "  1.4929169747774411,\n",
       "  0.22058354437942151,\n",
       "  0.24656424138924152,\n",
       "  0.7949318789573205],\n",
       " [0.08814737346617278,\n",
       "  1.5575648483877789,\n",
       "  0.8281122008701396,\n",
       "  0.10669041659506007,\n",
       "  1.4907122750583701,\n",
       "  0.2212507079730282,\n",
       "  0.2454209070547508,\n",
       "  0.7972450100049804,\n",
       "  1813363200.0,\n",
       "  -0.08948278738271452,\n",
       "  -1.1880672658714244,\n",
       "  -1.7215563491277202,\n",
       "  -0.47607394843983153],\n",
       " [1.4895844334673334,\n",
       "  0.22126792519073724,\n",
       "  0.2428141706893391,\n",
       "  0.8023466147018466,\n",
       "  -0.09154559652098222,\n",
       "  -1.1867403842965818,\n",
       "  -1.7223071660680231,\n",
       "  -0.47328784303328125,\n",
       "  1813449600.0,\n",
       "  0.1218709267401606,\n",
       "  1.0860532856710126,\n",
       "  -1.7973244097196877,\n",
       "  -1.1359933212270004],\n",
       " [-0.09292146588306321,\n",
       "  -1.1866754949583822,\n",
       "  -1.72353041243688,\n",
       "  -0.4700516733600861,\n",
       "  0.11978916594254045,\n",
       "  1.0863151210268538,\n",
       "  -1.7980601156541662,\n",
       "  -1.132961642640898,\n",
       "  1813536000.0,\n",
       "  0.3611064342921831,\n",
       "  -0.46804603870065203,\n",
       "  -0.045987895175640545,\n",
       "  1.0370711635746335],\n",
       " [0.11844642448648511,\n",
       "  1.0863030486736576,\n",
       "  -1.7992301008791722,\n",
       "  -1.1306940261279328,\n",
       "  0.3590032217312809,\n",
       "  -0.46705636699143366,\n",
       "  -0.047072883592273455,\n",
       "  1.0392941882904139,\n",
       "  1813622400.0,\n",
       "  0.8928474738891338,\n",
       "  -0.5197600348546786,\n",
       "  -0.45134473714156,\n",
       "  0.40799280577933494],\n",
       " [0.3576979784164107,\n",
       "  -0.4670158448977262,\n",
       "  -0.04947397048866457,\n",
       "  1.0447511769614486,\n",
       "  0.890696581186494,\n",
       "  -0.5187461437627032,\n",
       "  -0.45234888213218977,\n",
       "  0.41044992693004634,\n",
       "  1813708800.0,\n",
       "  1.2018185924714506,\n",
       "  0.6526522736933749,\n",
       "  -0.9651688440519962,\n",
       "  0.11690451182636193],\n",
       " [0.889474683779515,\n",
       "  -0.5187038715433878,\n",
       "  -0.4544650235132517,\n",
       "  0.4149836273076923,\n",
       "  1.1996399949545689,\n",
       "  0.6531170851442193,\n",
       "  -0.9660705131575166,\n",
       "  0.11946995450970928,\n",
       "  1813795200.0,\n",
       "  -1.3925420616270352,\n",
       "  -0.9645186821356433,\n",
       "  0.5467097107340024,\n",
       "  -1.2934022860648255],\n",
       " [1.1984665261556393,\n",
       "  0.6531196801202953,\n",
       "  -0.9678254619798884,\n",
       "  0.12357642923125219,\n",
       "  -1.3944880280801197,\n",
       "  -0.9632964957906598,\n",
       "  0.5455065160850208,\n",
       "  -1.2903120315047794,\n",
       "  1813881600.0,\n",
       "  -0.7028917194448023,\n",
       "  0.26148567756505986,\n",
       "  -1.3229977752923554,\n",
       "  -0.5766404272784696],\n",
       " [-1.396068140955792,\n",
       "  -0.9632391718724648,\n",
       "  0.5426887925187482,\n",
       "  -1.2882754416242015,\n",
       "  -0.7048995254468705,\n",
       "  0.2621336853305954,\n",
       "  -1.323828079827873,\n",
       "  -0.5738168984669049,\n",
       "  1813968000.0,\n",
       "  1.7543776236960416,\n",
       "  0.2434079053260484,\n",
       "  1.4061476648841706,\n",
       "  1.1611093927066827],\n",
       " [-0.7063715414678402,\n",
       "  0.26214951832205946,\n",
       "  -1.3253314928707636,\n",
       "  -0.5707283286140953,\n",
       "  1.7521494793302892,\n",
       "  0.24406437951301352,\n",
       "  1.4047730659280269,\n",
       "  1.1632862595680795,\n",
       "  1814054400.0,\n",
       "  -1.503869947336586,\n",
       "  1.1510179439346326,\n",
       "  -0.9326619803321946,\n",
       "  -1.4644396179840542],\n",
       " [1.7510626194832581,\n",
       "  0.24408082429962946,\n",
       "  1.401351200614569,\n",
       "  1.1689252971738318,\n",
       "  -1.5058059312437044,\n",
       "  1.1512493541823567,\n",
       "  -0.9335701325310284,\n",
       "  -1.4612857159798602,\n",
       "  1814140800.0,\n",
       "  0.7036801470412573,\n",
       "  -0.8498372656619151,\n",
       "  -0.3099617665101657,\n",
       "  -0.6374021454871751],\n",
       " [-1.507403493823306,\n",
       "  1.1512350832693798,\n",
       "  -0.9353479320470989,\n",
       "  -1.4595001548691275,\n",
       "  0.7015462165895716,\n",
       "  -0.8486687884349122,\n",
       "  -0.31099410859170656,\n",
       "  -0.6345560056583394,\n",
       "  1814227200.0,\n",
       "  0.6221939712199014,\n",
       "  -1.4993925969871502,\n",
       "  0.8612728027616041,\n",
       "  0.7884451518105744],\n",
       " [0.7002946688050113,\n",
       "  -0.8486153456107857,\n",
       "  -0.31320963510521116,\n",
       "  -0.6315566148122673,\n",
       "  0.6200673474685143,\n",
       "  -1.4979199114149957,\n",
       "  0.8600068723809883,\n",
       "  0.7907606967382869,\n",
       "  1814313600.0,\n",
       "  1.3506859729752096,\n",
       "  -1.6307787037530566,\n",
       "  0.5589722516430247,\n",
       "  -1.0725558599909006],\n",
       " [0.6188030274155026,\n",
       "  -1.4978444860812261,\n",
       "  0.8569680267487191,\n",
       "  0.795852780968962,\n",
       "  1.3484940268219168,\n",
       "  -1.6292444857013924,\n",
       "  0.5577666113813977,\n",
       "  -1.0695477881357125,\n",
       "  1814400000.0,\n",
       "  0.3358921633188518,\n",
       "  0.28491795786545354,\n",
       "  1.2125814060165754,\n",
       "  0.9330832824938803],\n",
       " [1.3473438917250329,\n",
       "  -1.6291646139467872,\n",
       "  0.5549402678643144,\n",
       "  -1.067187065470555,\n",
       "  0.3337912116705449,\n",
       "  0.2855549915155141,\n",
       "  1.2112454114650089,\n",
       "  0.9353450038075255,\n",
       "  1814486400.0,\n",
       "  0.7768862064501546,\n",
       "  -0.9522719076736441,\n",
       "  -1.5795442269795985,\n",
       "  0.014229679454353024],\n",
       " [0.33248201623208523,\n",
       "  0.28557003150243676,\n",
       "  1.2079596135165815,\n",
       "  0.9406493711205587,\n",
       "  0.7747457117594339,\n",
       "  -0.9510554569000782,\n",
       "  -1.580323366487328,\n",
       "  0.016833330115955503,\n",
       "  1814572800.0,\n",
       "  0.2152288604049629,\n",
       "  -0.88285943111247,\n",
       "  -0.39163949070559945,\n",
       "  -1.3306371639924701],\n",
       " [0.7735056384051512,\n",
       "  -0.9509985474420911,\n",
       "  -1.581646440250567,\n",
       "  0.02078911062018822,\n",
       "  0.21313872839056994,\n",
       "  -0.8816754885081227,\n",
       "  -0.3926555431717484,\n",
       "  -1.3275330533649405,\n",
       "  1814659200.0,\n",
       "  -1.3861668851759603,\n",
       "  -0.02051662673780324,\n",
       "  -0.8154147181822832,\n",
       "  -1.181853731438353],\n",
       " [0.21181062000053869,\n",
       "  -0.8816209281347506,\n",
       "  -0.3948136543444907,\n",
       "  -1.3255511125220705,\n",
       "  -1.3881134232782015,\n",
       "  -0.019736547922760833,\n",
       "  -0.8163462539024502,\n",
       "  -1.1788049869996395,\n",
       "  1814745600.0,\n",
       "  -1.397432948382884,\n",
       "  1.0936784479767983,\n",
       "  1.058170826736329,\n",
       "  -0.8146626914413767],\n",
       " [-1.3896925368989175,\n",
       "  -0.019711171297252396,\n",
       "  -0.8182064723592549,\n",
       "  -1.176604679080832,\n",
       "  -1.399378476280062,\n",
       "  1.0939367122157622,\n",
       "  1.05686562747165,\n",
       "  -0.8117505883484298,\n",
       "  1814832000.0,\n",
       "  0.4829090343080353,\n",
       "  -1.0227834282766208,\n",
       "  -1.6756225443555604,\n",
       "  1.0289717548256572],\n",
       " [-1.4009593557608422,\n",
       "  1.093924381808793,\n",
       "  1.053688372410699,\n",
       "  -0.809011359984394,\n",
       "  0.4807948999547562,\n",
       "  -1.0215339546149924,\n",
       "  -1.676382522227079,\n",
       "  1.0311977935423005,\n",
       "  1814918400.0,\n",
       "  -0.4785763331678471,\n",
       "  1.4456706888508082,\n",
       "  -1.1417397569457937,\n",
       "  -0.3550921332351965],\n",
       " [0.4795087481666366,\n",
       "  -1.0214746588781054,\n",
       "  -1.6776380577553056,\n",
       "  1.036642894840024,\n",
       "  -0.48060425307614996,\n",
       "  1.445764103427336,\n",
       "  -1.1426062111590192,\n",
       "  -0.352351048311834,\n",
       "  1815004800.0,\n",
       "  -0.3333621140152398,\n",
       "  1.380139783268247,\n",
       "  1.0854912861633117,\n",
       "  -1.4888512536553613],\n",
       " [-0.4820411095586771,\n",
       "  1.4457398607590763,\n",
       "  -1.1442370394915957,\n",
       "  -0.3489373155539972,\n",
       "  -0.3354030549883767,\n",
       "  1.3802638881453266,\n",
       "  1.0841806381697316,\n",
       "  -1.4856882674459795,\n",
       "  1815091200.0,\n",
       "  -0.7144991500590386,\n",
       "  -1.433211710867135,\n",
       "  1.036032616650295,\n",
       "  0.4406930835269165],\n",
       " [-0.3368171503709836,\n",
       "  1.3802418632000146,\n",
       "  1.080984178196998,\n",
       "  -1.4839385349043883,\n",
       "  -0.7165059152463198,\n",
       "  -1.4317700200030157,\n",
       "  1.0347318325787584,\n",
       "  0.44313803605292934,\n",
       "  1815177600.0,\n",
       "  -0.73218449136843,\n",
       "  0.2093266383324751,\n",
       "  0.6278657696626533,\n",
       "  1.4228123034357885],\n",
       " [-0.7179797506338059,\n",
       "  -1.431696834389093,\n",
       "  1.0315701395683967,\n",
       "  0.4477197301077711,\n",
       "  -0.7341896707469855,\n",
       "  0.20999907390922923,\n",
       "  0.6266463894379874,\n",
       "  1.4248917838306927,\n",
       "  1815264000.0,\n",
       "  0.6485058966106171,\n",
       "  1.6461674327268985,\n",
       "  -0.2006158383069265,\n",
       "  -1.2016373198656582],\n",
       " [-0.7356662781620529,\n",
       "  0.21001667208762598,\n",
       "  0.6237716172354533,\n",
       "  1.4309149186332848,\n",
       "  0.6463769135221871,\n",
       "  1.6461669480161425,\n",
       "  -0.2016699880861309,\n",
       "  -1.1985812134386271,\n",
       "  1815350400.0,\n",
       "  -0.17782864500559195,\n",
       "  0.4196241546507888,\n",
       "  1.0576017502572206,\n",
       "  -1.4498012620389344],\n",
       " [0.6451167176408054,\n",
       "  1.646135920057403,\n",
       "  -0.2039623792991677,\n",
       "  -1.1964099415776805,\n",
       "  -0.1798835323497913,\n",
       "  0.4201981009128633,\n",
       "  1.0562966644878313,\n",
       "  -1.446652807348096,\n",
       "  1815436800.0,\n",
       "  1.3087312788304886,\n",
       "  1.21775378247235,\n",
       "  -1.0719214842953357,\n",
       "  -0.26796595301346104],\n",
       " [-0.18127324917739346,\n",
       "  0.4202085821191447,\n",
       "  1.0531198094590837,\n",
       "  -1.444845761755325,\n",
       "  1.3065430946696213,\n",
       "  1.2179539381093816,\n",
       "  -1.0728018629025131,\n",
       "  -0.26525729001008086,\n",
       "  1815523200.0,\n",
       "  0.8898298507599419,\n",
       "  0.773702706215473,\n",
       "  0.5082537548143564,\n",
       "  -0.2756014222880103],\n",
       " [1.3053863835294883,\n",
       "  1.2179374086956374,\n",
       "  -1.0744817699766334,\n",
       "  -0.2617156835442241,\n",
       "  0.8876792286414545,\n",
       "  0.7741108257264908,\n",
       "  0.5070582297318034,\n",
       "  -0.2728899179277243,\n",
       "  1815609600.0,\n",
       "  -0.29768523709371014,\n",
       "  0.9208377229925642,\n",
       "  0.8433536790493651,\n",
       "  0.6758749932135524],\n",
       " [0.8864568582475879,\n",
       "  0.7741093240657264,\n",
       "  0.5042675387724651,\n",
       "  -0.26935951791859647,\n",
       "  -0.29972937714012093,\n",
       "  0.9211769342862077,\n",
       "  0.8420913224171158,\n",
       "  0.6782324284280322,\n",
       "  1815696000.0,\n",
       "  0.05037035051521224,\n",
       "  -0.6674683763234862,\n",
       "  -1.53572204444681,\n",
       "  -1.0937636756698348],\n",
       " [-0.3011378804741998,\n",
       "  0.9211704532237369,\n",
       "  0.8390650730294683,\n",
       "  0.6831592952285896,\n",
       "  0.04829500102940529,\n",
       "  -0.6663853085071328,\n",
       "  -1.536509923748726,\n",
       "  -1.090747711834289,\n",
       "  1815782400.0,\n",
       "  -0.28818081264388895,\n",
       "  -0.9642462177896788,\n",
       "  1.1215167265897596,\n",
       "  -0.5217610738866407],\n",
       " [0.04694105246312816,\n",
       "  -0.6663380374834291,\n",
       "  -1.5378638023068814,\n",
       "  -1.0884181155426622,\n",
       "  -0.2902258049327846,\n",
       "  -0.9630241590488019,\n",
       "  1.1201988937661094,\n",
       "  -0.5189579671112518,\n",
       "  1815868800.0,\n",
       "  -0.6882518152864274,\n",
       "  0.6023880647673395,\n",
       "  -0.2519992233230307,\n",
       "  -0.5777219524417024],\n",
       " [-0.2916328185287659,\n",
       "  -0.9629668443514535,\n",
       "  1.1169771097168473,\n",
       "  -0.5157888517049232,\n",
       "  -0.6902609340190418,\n",
       "  0.6028764166174082,\n",
       "  -0.25304312531940704,\n",
       "  -0.5748980211664669,\n",
       "  1815955200.0,\n",
       "  -1.6587285293313194,\n",
       "  1.1773916337723862,\n",
       "  1.2733434787056637,\n",
       "  1.3436709015445862],\n",
       " [-0.6917306553589305,\n",
       "  0.6028807126548168,\n",
       "  -0.2552993965916732,\n",
       "  -0.571811038650926,\n",
       "  -1.6606506273831267,\n",
       "  1.1776106923448115,\n",
       "  1.2719953659076075,\n",
       "  1.3457798325155732,\n",
       "  1816041600.0,\n",
       "  -0.7633989778250583,\n",
       "  -0.898095214321246,\n",
       "  -1.5579929329039675,\n",
       "  0.9043144867199747],\n",
       " [-1.662272462734905,\n",
       "  1.1775955288829427,\n",
       "  1.268666855271685,\n",
       "  1.3516868127422161,\n",
       "  -0.7654013582638524,\n",
       "  -0.8969041362933657,\n",
       "  -1.558776370551675,\n",
       "  0.9065869136515203,\n",
       "  1816128000.0,\n",
       "  1.303432541059305,\n",
       "  -1.5087101289003875,\n",
       "  -0.06342199228958928,\n",
       "  0.28832452626090727],\n",
       " [-0.7668828582855071,\n",
       "  -0.8968490603045639,\n",
       "  -1.5601145937930052,\n",
       "  0.9118490574608774,\n",
       "  1.3012448320255188,\n",
       "  -1.507233079618434,\n",
       "  -0.06450350369043252,\n",
       "  0.29082617909397973,\n",
       "  1816214400.0,\n",
       "  1.2138804831396988,\n",
       "  -0.6297194124404032,\n",
       "  0.9897800340759546,\n",
       "  -1.650193556547721],\n",
       " [1.3000872903530827,\n",
       "  -1.5071573389570467,\n",
       "  -0.06689233529155753,\n",
       "  0.2951842442424047,\n",
       "  1.211700804057518,\n",
       "  -0.6286540237181628,\n",
       "  0.9884884745119377,\n",
       "  -1.6469705306669014,\n",
       "  1816300800.0,\n",
       "  0.2899737873556989,\n",
       "  -0.5364811617421684,\n",
       "  -0.1775099927176156,\n",
       "  -1.4401922391279747],\n",
       " [1.210529225857872,\n",
       "  -0.6286080302098955,\n",
       "  0.9853592947457415,\n",
       "  -1.6454575976553576,\n",
       "  0.28787695311513606,\n",
       "  -0.5354594395908603,\n",
       "  -0.17856875067293734,\n",
       "  -1.4370473602047313,\n",
       "  1816387200.0,\n",
       "  -1.2281057826423787,\n",
       "  -1.213032589789646,\n",
       "  -0.6576650549462584,\n",
       "  -1.6280588485868193],\n",
       " [0.2865605603598463,\n",
       "  -0.5354166014885241,\n",
       "  -0.18087738413575738,\n",
       "  -1.4352262116019703,\n",
       "  -1.2300664937634596,\n",
       "  -1.211694016124062,\n",
       "  -0.6586280518924528,\n",
       "  -1.624844059607107,\n",
       "  1816473600.0,\n",
       "  -1.6721840355942368,\n",
       "  0.6980932871220676,\n",
       "  -0.8649110864378494,\n",
       "  1.0525144793546732],\n",
       " [-1.231620832644007,\n",
       "  -1.2116282818994497,\n",
       "  -0.6605991604451686,\n",
       "  -1.6232986398369826,\n",
       "  -1.6741049271180577,\n",
       "  0.6985368170364046,\n",
       "  -0.8658327507174233,\n",
       "  1.0547317572105868,\n",
       "  1816560000.0,\n",
       "  0.8712384202764076,\n",
       "  -0.0036116839075212414,\n",
       "  0.9503672652308801,\n",
       "  0.09306306271748617],\n",
       " [-1.6757288715065703,\n",
       "  0.6985378741796467,\n",
       "  -0.867658175711532,\n",
       "  1.0602114117903978,\n",
       "  0.8690894652138265,\n",
       "  -0.0028395222389254503,\n",
       "  0.9490835660578368,\n",
       "  0.0956373774247568,\n",
       "  1816646400.0,\n",
       "  1.5446202891468968,\n",
       "  -0.01471274667046527,\n",
       "  -1.5262923169048126,\n",
       "  0.8883755685726822],\n",
       " [0.8678641807705687,\n",
       "  -0.0028147177172099637,\n",
       "  0.9459820914900398,\n",
       "  0.09970886043090069,\n",
       "  1.5424109532963748,\n",
       "  -0.013935386005310326,\n",
       "  -1.527082076849663,\n",
       "  0.8906539267906386,\n",
       "  1816732800.0,\n",
       "  0.379849528688259,\n",
       "  0.05000157499454613,\n",
       "  -0.1466265209872306,\n",
       "  0.5844974326130055],\n",
       " [1.5412912157623062,\n",
       "  -0.013910205797017473,\n",
       "  -1.5284425840330091,\n",
       "  0.895892677303513,\n",
       "  0.37774463547205506,\n",
       "  0.05074862779253115,\n",
       "  -0.14769143827034226,\n",
       "  0.586888871796791,\n",
       "  1816819200.0,\n",
       "  -1.143720274307174,\n",
       "  0.322998831787956,\n",
       "  0.5356094204003116,\n",
       "  -0.09478725935622204],\n",
       " [0.37644232997861066,\n",
       "  0.05077161791303402,\n",
       "  -0.1500217812637692,\n",
       "  0.5916816252060109,\n",
       "  -1.145688552105826,\n",
       "  0.3236180308994035,\n",
       "  0.534408439567423,\n",
       "  -0.0921430406534425,\n",
       "  1816905600.0,\n",
       "  0.3474806243219182,\n",
       "  0.13748318116175864,\n",
       "  1.0258305588027532,\n",
       "  -0.7873512082696462],\n",
       " [-1.1472296642720872,\n",
       "  0.3236317821382583,\n",
       "  0.5315985189481394,\n",
       "  -0.08834726257519952,\n",
       "  0.34537863355979076,\n",
       "  0.13818926341672766,\n",
       "  1.0245318094059115,\n",
       "  -0.7844492684906395,\n",
       "  1816992000.0,\n",
       "  0.7458544184504716,\n",
       "  0.03180060211491803,\n",
       "  -0.7705655072417743,\n",
       "  1.4684129700844413],\n",
       " [0.3440712545145215,\n",
       "  0.13820929294995116,\n",
       "  1.0213772879301826,\n",
       "  -0.7816699554974391,\n",
       "  0.7437167063173118,\n",
       "  0.03255617903328639,\n",
       "  -0.7715059875842853,\n",
       "  1.4704754812840766,\n",
       "  1817078400.0,\n",
       "  1.2256234504881822,\n",
       "  -0.11372146792188068,\n",
       "  1.48810516091551,\n",
       "  -0.9135025426433899],\n",
       " [0.7424717689928787,\n",
       "  0.032579785118346166,\n",
       "  -0.7733977327854312,\n",
       "  1.4765655434593334,\n",
       "  1.2234427184379097,\n",
       "  -0.11289773818269162,\n",
       "  1.4867142165469298,\n",
       "  -0.9105536586685247,\n",
       "  1817164800.0,\n",
       "  -0.2747737317711381,\n",
       "  1.6839579373023315,\n",
       "  -1.7455255785242554,\n",
       "  -0.005441040762698729],\n",
       " [1.2222729808490163,\n",
       "  -0.11286920728191006,\n",
       "  1.4832347392271508,\n",
       "  -0.9079594959809729,\n",
       "  -0.27681992624581353,\n",
       "  1.683939754042576,\n",
       "  -1.746271615097182,\n",
       "  -0.0028300701139781564,\n",
       "  1817251200.0,\n",
       "  -0.510914835953635,\n",
       "  0.9720289381148369,\n",
       "  -0.22593493094530379,\n",
       "  -1.240486655310159],\n",
       " [-0.27822483839533063,\n",
       "  1.6839074471625637,\n",
       "  -1.7474780123007718,\n",
       "  0.0010968399872691823,\n",
       "  -0.5129398561339094,\n",
       "  0.9723441748614517,\n",
       "  -0.22698403114354576,\n",
       "  -1.23741609203397,\n",
       "  1817337600.0,\n",
       "  -0.06937470243787669,\n",
       "  0.38979325294377276,\n",
       "  -0.30393088261945084,\n",
       "  0.9830917125353955],\n",
       " [-0.514381781403071,\n",
       "  0.9723359613655363,\n",
       "  -0.2292586243052051,\n",
       "  -1.2353018387243333,\n",
       "  -0.07143931462738334,\n",
       "  0.390381170008341,\n",
       "  -0.30496442748645153,\n",
       "  0.9853348244102577,\n",
       "  1817424000.0,\n",
       "  0.6125324768617747,\n",
       "  -0.26360031500402337,\n",
       "  0.22729400770439687,\n",
       "  0.09334483212341663],\n",
       " [-0.07281203221732173,\n",
       "  0.3903926607638522,\n",
       "  -0.3071841934086455,\n",
       "  0.9907125883001336,\n",
       "  0.610406719437013,\n",
       "  -0.26270639202055585,\n",
       "  0.22615451658050403,\n",
       "  0.09591904197695546,\n",
       "  1817510400.0,\n",
       "  -0.1400780589996252,\n",
       "  -0.26620667104634776,\n",
       "  0.7106597509339676,\n",
       "  -0.05056213295349471],\n",
       " [0.6091408850265247,\n",
       "  -0.26267278886027245,\n",
       "  0.22356132622221342,\n",
       "  0.09999093853157182,\n",
       "  -0.1421363313623907,\n",
       "  -0.26531152741974134,\n",
       "  0.7094238584701943,\n",
       "  -0.047934371571646595,\n",
       "  1817596800.0,\n",
       "  1.765425286045403,\n",
       "  0.18440695992470876,\n",
       "  -0.9269340315544123,\n",
       "  1.1176103566523146],\n",
       " [-0.14352013110511547,\n",
       "  -0.26527783605412103,\n",
       "  0.7064908862541975,\n",
       "  -0.04407368497926496,\n",
       "  1.7631961510581498,\n",
       "  0.18509106621489488,\n",
       "  -0.9278433261220314,\n",
       "  1.1198034106375205,\n",
       "  1817683200.0,\n",
       "  1.0492014269053143,\n",
       "  -0.7589300133445914,\n",
       "  0.22089859099425313,\n",
       "  1.7391297817813856],\n",
       " [1.7621110228386967,\n",
       "  0.1851095077349509,\n",
       "  -0.9296251520986109,\n",
       "  1.1253786054003818,\n",
       "  1.0470365142604734,\n",
       "  -0.7578041110045244,\n",
       "  0.21976037535739798,\n",
       "  1.7410915522073018,\n",
       "  1817769600.0,\n",
       "  1.7281745113263396,\n",
       "  -1.6936218567020418,\n",
       "  1.361326930378541,\n",
       "  1.5339553285529135],\n",
       " [1.0458391240124234,\n",
       "  -0.7577537446997555,\n",
       "  0.21717168065607315,\n",
       "  1.747578941138385,\n",
       "  1.7259487165405873,\n",
       "  -1.6920582071136927,\n",
       "  1.359961270365467,\n",
       "  1.5359934497345737,\n",
       "  1817856000.0,\n",
       "  0.923236213537418,\n",
       "  0.5809571440152119,\n",
       "  -1.7254241865981756,\n",
       "  0.16183691047834975],\n",
       " [1.7248577495774462,\n",
       "  -1.6919762085961327,\n",
       "  1.3565709117788458,\n",
       "  1.5421797073861891,\n",
       "  0.9210825959380602,\n",
       "  0.5814555326775778,\n",
       "  -1.7261742321459672,\n",
       "  0.16438563264634795,\n",
       "  1817942400.0,\n",
       "  -0.9511652034002731,\n",
       "  -1.4626639099392682,\n",
       "  -1.1986811315602974,\n",
       "  -1.2605096871814743],\n",
       " [0.9198654617088445,\n",
       "  0.5814605539887227,\n",
       "  -1.7273947596192063,\n",
       "  0.16855805393425288,\n",
       "  -0.9531507472220258,\n",
       "  -1.4612084256316829,\n",
       "  -1.199536229518173,\n",
       "  -1.2574316728138284,\n",
       "  1818028800.0,\n",
       "  0.6621274495426598,\n",
       "  -1.7094922604740106,\n",
       "  0.9716938337644486,\n",
       "  -1.5242384991988427],\n",
       " [-0.9546616780104945,\n",
       "  -1.4611342432847354,\n",
       "  -1.2011270309222428,\n",
       "  -1.2553468069893847,\n",
       "  0.6599972450371749,\n",
       "  -1.7079211782482318,\n",
       "  0.9704058812701668,\n",
       "  -1.5210623444740905,\n",
       "  1818115200.0,\n",
       "  -1.6305577899444024,\n",
       "  1.3786918943700994,\n",
       "  -0.5323351011987606,\n",
       "  -0.8112934226430623],\n",
       " [0.6587391842189377,\n",
       "  -1.7078386426381609,\n",
       "  0.967289415195056,\n",
       "  -1.5193645492295638,\n",
       "  -1.632482414009338,\n",
       "  1.378816677341661,\n",
       "  -0.5333230936595061,\n",
       "  -0.8083825733427539,\n",
       "  1818201600.0,\n",
       "  0.14394269318750766,\n",
       "  -0.1508108564644397,\n",
       "  -0.20098629240398655,\n",
       "  0.3662171071397299],\n",
       " [-1.634099833836123,\n",
       "  1.3787947013963802,\n",
       "  -0.5353823028794849,\n",
       "  -0.8056383999565276,\n",
       "  0.14185895325930656,\n",
       "  -0.1499697565321861,\n",
       "  -0.20204036830068725,\n",
       "  0.3686897741155314,\n",
       "  1818288000.0,\n",
       "  0.10806595611633585,\n",
       "  -1.1291592045612988,\n",
       "  0.16445691246863806,\n",
       "  -0.5490732433832934],\n",
       " [0.14051967136585092,\n",
       "  -0.14993997043757892,\n",
       "  -0.2043324991030866,\n",
       "  0.3731621609651818,\n",
       "  0.1059854331824633,\n",
       "  -1.127859911588971,\n",
       "  0.1633299534289067,\n",
       "  -0.5462599730385651,\n",
       "  1818374400.0,\n",
       "  -0.3793487837348607,\n",
       "  0.8488342473469319,\n",
       "  -1.7135858219776858,\n",
       "  0.7924314819684469],\n",
       " [0.10464052791409262,\n",
       "  -1.127797015840791,\n",
       "  0.1607809343948175,\n",
       "  -0.543130943268709,\n",
       "  -0.38138560117649073,\n",
       "  0.8492071802607593,\n",
       "  -1.71433822854139,\n",
       "  0.794745543478924,\n",
       "  1818460800.0,\n",
       "  0.9435964530487466,\n",
       "  -0.12275020576479104,\n",
       "  -0.6394208312856225,\n",
       "  1.0595975665264354],\n",
       " [-0.38280690458039607,\n",
       "  0.849203135968524,\n",
       "  -1.715567077790798,\n",
       "  0.7998434783829257,\n",
       "  0.9414410097879607,\n",
       "  -0.12192224756766232,\n",
       "  -0.6403874668173614,\n",
       "  1.0618122085812047,\n",
       "  1818547200.0,\n",
       "  0.43171871479493307,\n",
       "  -0.9281375959089928,\n",
       "  1.5037309020885445,\n",
       "  -0.6419251226661103],\n",
       " [0.9402270668539819,\n",
       "  -0.12189341111274683,\n",
       "  -0.6423714001436459,\n",
       "  1.067302258895324,\n",
       "  0.4296091705738955,\n",
       "  -0.9269324480355636,\n",
       "  1.5023368413584786,\n",
       "  -0.639077299719711,\n",
       "  1818633600.0,\n",
       "  -0.37149655106371227,\n",
       "  -1.384595786930349,\n",
       "  -0.9338769606110843,\n",
       "  1.2080542674071173],\n",
       " [0.4283149951364102,\n",
       "  -0.9268763553405459,\n",
       "  1.4988463799268996,\n",
       "  -0.6360845471752572,\n",
       "  -0.3735340725991377,\n",
       "  -1.3831768645188243,\n",
       "  -0.9347848704970764,\n",
       "  1.210213664858433,\n",
       "  1818720000.0,\n",
       "  0.8053382230261418,\n",
       "  0.10440731233226799,\n",
       "  1.5431199286265505,\n",
       "  -0.6212922413659148],\n",
       " [-0.37495414523202436,\n",
       "  -1.3831053241843183,\n",
       "  -0.9365618159429898,\n",
       "  1.215921602709613,\n",
       "  0.8031951771007372,\n",
       "  0.10512888511565827,\n",
       "  1.5417180122406213,\n",
       "  -0.6184520964518223,\n",
       "  1818806400.0,\n",
       "  0.5197918980751773,\n",
       "  1.5963985373261558,\n",
       "  0.6007077999647855,\n",
       "  0.517315655784954],\n",
       " [0.8019595633592664,\n",
       "  0.10515003401557839,\n",
       "  1.5381998623002935,\n",
       "  -0.615429061355875,\n",
       "  0.5176744565102273,\n",
       "  1.596421361042842,\n",
       "  0.599493836062447,\n",
       "  0.5197320950569683,\n",
       "  1818892800.0,\n",
       "  -0.9819912365474337,\n",
       "  -1.3408275329818298,\n",
       "  1.607591306056721,\n",
       "  0.41649630644283436],\n",
       " [0.5163940857988675,\n",
       "  1.5963920173828379,\n",
       "  0.5966381545495711,\n",
       "  0.5244262468415961,\n",
       "  -0.9839740162612461,\n",
       "  -1.3394291086979655,\n",
       "  1.6061765316491898,\n",
       "  0.418950263219561,\n",
       "  1818979200.0,\n",
       "  1.6572147772048833,\n",
       "  -0.23799649172708595,\n",
       "  -1.0813204793111646,\n",
       "  -0.8155090071206332],\n",
       " [-0.9854897787695334,\n",
       "  -1.3393590495861023,\n",
       "  1.6026130615663012,\n",
       "  0.4234964440497899,\n",
       "  1.6549953452347286,\n",
       "  -0.23711455986482552,\n",
       "  -1.0821989834046313,\n",
       "  -0.8125965890915883,\n",
       "  1819065600.0,\n",
       "  1.4222382480156341,\n",
       "  0.0795851135339291,\n",
       "  1.1626114033346706,\n",
       "  -0.2023620265994175],\n",
       " [1.6538932559337882,\n",
       "  -0.23708182319930393,\n",
       "  -1.0838722834569843,\n",
       "  -0.8098586028516049,\n",
       "  1.4200398859148,\n",
       "  0.08031831137781123,\n",
       "  1.161285374684246,\n",
       "  -0.19967777652504792,\n",
       "  1819152000.0,\n",
       "  1.0217811132850958,\n",
       "  -1.6090209403931492,\n",
       "  -0.0852376680398533,\n",
       "  -0.15027099497470414],\n",
       " [1.4189009660314897,\n",
       "  0.08034030032044694,\n",
       "  1.1580347031397449,\n",
       "  -0.19603988422053872,\n",
       "  1.019618659364225,\n",
       "  -1.6074969122250358,\n",
       "  -0.08631482857305196,\n",
       "  -0.14760612932938721,\n",
       "  1819238400.0,\n",
       "  -0.36983634310324487,\n",
       "  -1.008996063312645,\n",
       "  -0.08823716209111383,\n",
       "  0.1854304143339033],\n",
       " [1.0184169712140703,\n",
       "  -1.6074177768053044,\n",
       "  -0.08868832484903784,\n",
       "  -0.14389178384683798,\n",
       "  -0.3718740135061546,\n",
       "  -1.0077530467321572,\n",
       "  -0.0893137244121935,\n",
       "  0.18797035674486226,\n",
       "  1819324800.0,\n",
       "  -0.1552941680992277,\n",
       "  1.1586400619508128,\n",
       "  -0.8277815172181711,\n",
       "  -0.22239641175116154],\n",
       " [-0.37329382591549365,\n",
       "  -1.007694217592754,\n",
       "  -0.09168511219440383,\n",
       "  0.19217740584286416,\n",
       "  -0.1573510760643174,\n",
       "  1.1588679025074013,\n",
       "  -0.8287105865326944,\n",
       "  -0.2197047063604837,\n",
       "  1819411200.0,\n",
       "  -0.16251439508704119,\n",
       "  1.6652919625198266,\n",
       "  -0.9345461516419306,\n",
       "  0.2904429782056855],\n",
       " [-0.15873726080337125,\n",
       "  1.1588533736436777,\n",
       "  -0.8305621117504578,\n",
       "  -0.21609621820419644,\n",
       "  -0.16457065562900475,\n",
       "  1.6652825211562967,\n",
       "  -0.9354539280660196,\n",
       "  0.2929438427076356,\n",
       "  1819497600.0,\n",
       "  1.0765510963006142,\n",
       "  0.9863426419476454,\n",
       "  -0.8716675231979762,\n",
       "  -0.4952244436456502],\n",
       " [-0.16595797207753496,\n",
       "  1.6652508459776203,\n",
       "  -0.9372304031042245,\n",
       "  0.2973050170742628,\n",
       "  1.0743837312663278,\n",
       "  0.9866511751111381,\n",
       "  -0.8725878399895132,\n",
       "  -0.49243121184125255,\n",
       "  1819584000.0,\n",
       "  0.9445936354510284,\n",
       "  1.526824722997877,\n",
       "  0.016568404762750857,\n",
       "  -0.6605008475310459],\n",
       " [1.0731906278474985,\n",
       "  0.9866424772051697,\n",
       "  -0.8744085155476804,\n",
       "  -0.4892231490450736,\n",
       "  0.9424381027749168,\n",
       "  1.526880130443619,\n",
       "  0.015470940263117664,\n",
       "  -0.657646112073807,\n",
       "  1819670400.0,\n",
       "  0.6859175814553417,\n",
       "  -0.3633792771559109,\n",
       "  0.08094530452559362,\n",
       "  0.7272412815748891],\n",
       " [0.9412243161408406,\n",
       "  1.5268531413282869,\n",
       "  0.013025879427526248,\n",
       "  -0.6546806228250881,\n",
       "  0.6837852437369258,\n",
       "  -0.3624386243690019,\n",
       "  0.07983500084676452,\n",
       "  0.7295796020561532,\n",
       "  1819756800.0,\n",
       "  0.3894671007310387,\n",
       "  -0.23901630975177912,\n",
       "  -1.2632966835389026,\n",
       "  0.019686303416461964],\n",
       " [0.6825309118205327,\n",
       "  -0.3624016444494312,\n",
       "  0.07734468628167084,\n",
       "  0.734581858340598,\n",
       "  0.3873613451266344,\n",
       "  -0.23813390027485112,\n",
       "  -1.2641388947213392,\n",
       "  0.022287923526225453,\n",
       "  1819843200.0,\n",
       "  -0.6135684902706341,\n",
       "  -1.6506964284175045,\n",
       "  1.010227004905276,\n",
       "  1.7331811581884502],\n",
       " [0.3860605471062153,\n",
       "  -0.23810112909624265,\n",
       "  -1.265684274635377,\n",
       "  0.026251712630600287,\n",
       "  -0.6155843057056974,\n",
       "  -1.6491528822335517,\n",
       "  1.0089313674449414,\n",
       "  1.7351451422520774,\n",
       "  1819929600.0,\n",
       "  -1.144464536332937,\n",
       "  0.5720650934380304,\n",
       "  1.2041810947108176,\n",
       "  0.30486937005584963],\n",
       " [-0.6170423210664268,\n",
       "  -1.6490723364153936,\n",
       "  1.0057878144844712,\n",
       "  1.741623800482991,\n",
       "  -1.1464327473951212,\n",
       "  0.5725676465431475,\n",
       "  1.202846775497805,\n",
       "  0.3073648661218026,\n",
       "  1820016000.0,\n",
       "  -1.0740460464730517,\n",
       "  0.23804015818627566,\n",
       "  1.716151188900074,\n",
       "  -0.02393058329189695],\n",
       " [-1.1479739762181562,\n",
       "  0.5725729687826014,\n",
       "  1.19956688254662,\n",
       "  0.3117472138741393,\n",
       "  -1.076020571818557,\n",
       "  0.23869914626758643,\n",
       "  1.714714763561938,\n",
       "  -0.021312732203027783,\n",
       "  1820102400.0,\n",
       "  0.7222446911682259,\n",
       "  1.564473900856596,\n",
       "  -1.5234499720835974,\n",
       "  -0.4062206683573658],\n",
       " [-1.0775507631392502,\n",
       "  0.2387157727116341,\n",
       "  1.7110749813299544,\n",
       "  -0.017412958909072865,\n",
       "  0.7201090960714792,\n",
       "  1.564511675941336,\n",
       "  -1.52424029889909,\n",
       "  -0.40346055717495777,\n",
       "  1820188800.0,\n",
       "  -1.3303223479007569,\n",
       "  -1.1987593308987858,\n",
       "  -1.2427073637052066,\n",
       "  1.569106922615635],\n",
       " [0.7188604581221012,\n",
       "  1.5644834126875655,\n",
       "  -1.52560280410819,\n",
       "  -0.40012186495436325,\n",
       "  -1.332273893469517,\n",
       "  -1.1974274418746138,\n",
       "  -1.2435536811737156,\n",
       "  1.5711319629739757,\n",
       "  1820275200.0,\n",
       "  1.0066498818014116,\n",
       "  -1.0079522907933463,\n",
       "  -0.5832426649061031,\n",
       "  1.6329531203703296],\n",
       " [-1.3338442539316213,\n",
       "  -1.1973621906913008,\n",
       "  -1.245113534346233,\n",
       "  1.577369812060728,\n",
       "  1.0044887846674126,\n",
       "  -1.0067097630462118,\n",
       "  -0.584220504480716,\n",
       "  1.6349544018962563,\n",
       "  1820361600.0,\n",
       "  -1.2877589165831467,\n",
       "  -0.2029434396716105,\n",
       "  -0.7552721953065703,\n",
       "  -0.14957088086133646],\n",
       " [1.0032847248247767,\n",
       "  -1.006650969230573,\n",
       "  -0.5862439282384231,\n",
       "  1.6412859570312834,\n",
       "  -1.2897142787285616,\n",
       "  -0.2020779243183741,\n",
       "  -0.7562157257116529,\n",
       "  -0.1469062757467085,\n",
       "  1820448000.0,\n",
       "  0.5229192767371134,\n",
       "  -1.3704314854870314,\n",
       "  -0.1818406400203263,\n",
       "  1.0045708535203763],\n",
       " [-1.2912779677330164,\n",
       "  -0.20204637393216954,\n",
       "  -0.7581182213435286,\n",
       "  -0.14319090271781804,\n",
       "  0.5208015547464546,\n",
       "  -1.3690191966885255,\n",
       "  -0.18289853428141983,\n",
       "  1.0068059724476706,\n",
       "  1820534400.0,\n",
       "  0.07619666245219514,\n",
       "  -1.171015758349893,\n",
       "  -0.7912001110443645,\n",
       "  -1.6406594696441263],\n",
       " [0.5195216742252335,\n",
       "  -1.3689481357079378,\n",
       "  -0.1852041235165382,\n",
       "  1.0122152609309103,\n",
       "  0.07411899717331973,\n",
       "  -1.1696968625626118,\n",
       "  -0.792136476069474,\n",
       "  -1.6374399916452627,\n",
       "  1820620800.0,\n",
       "  0.22457813110544048,\n",
       "  1.5121106433979896,\n",
       "  -0.40623589395958604,\n",
       "  -0.8265542578599385],\n",
       " [0.0727690966628735,\n",
       "  -1.1696325502883058,\n",
       "  -0.7940137161797828,\n",
       "  -1.635913065606114,\n",
       "  0.22248716076088498,\n",
       "  1.5121729419361294,\n",
       "  -0.40724903535301044,\n",
       "  -0.8236377296055315,\n",
       "  1820707200.0,\n",
       "  -0.16088895407288256,\n",
       "  1.0300161047385628,\n",
       "  -1.6200784177125045,\n",
       "  1.163719564087823],\n",
       " [0.2211605177899142,\n",
       "  1.512146450780526,\n",
       "  -0.4093968859868483,\n",
       "  -0.8209159543042631,\n",
       "  -0.1629453603648488,\n",
       "  1.030304184168244,\n",
       "  -1.6208494731754866,\n",
       "  1.1658954596364937,\n",
       "  1820793600.0,\n",
       "  1.7553393345562345,\n",
       "  0.469263322062481,\n",
       "  0.06293857357260482,\n",
       "  0.14732984097430518],\n",
       " [-0.16433242203925597,\n",
       "  1.0302940082475929,\n",
       "  -1.6221440534370228,\n",
       "  1.1715383281492384,\n",
       "  1.7531111039558178,\n",
       "  0.46981402065304123,\n",
       "  0.06183186111432672,\n",
       "  0.14988396160055603,\n",
       "  1820880000.0,\n",
       "  1.6771274429660854,\n",
       "  1.4890690801892428,\n",
       "  -0.419637911962375,\n",
       "  1.2756823472975194],\n",
       " [1.752024394848825,\n",
       "  0.46982282195089353,\n",
       "  0.059354204377347904,\n",
       "  0.15403509109344293,\n",
       "  1.6749062254675338,\n",
       "  1.4891421698570606,\n",
       "  -0.420648380488492,\n",
       "  1.2778165785796172,\n",
       "  1820966400.0,\n",
       "  1.339342133288345,\n",
       "  -1.0168134661134813,\n",
       "  0.7267083055628231,\n",
       "  -0.005447401124520171],\n",
       " [1.673807257308433,\n",
       "  1.4891164584831957,\n",
       "  -0.4227868101763118,\n",
       "  1.2836237730872906,\n",
       "  1.3371512043141747,\n",
       "  -1.0155667883835044,\n",
       "  0.7254692124126316,\n",
       "  -0.0028364281089433736,\n",
       "  1821052800.0,\n",
       "  -0.23795456355241965,\n",
       "  -0.389968047065139,\n",
       "  -1.7114664419997654,\n",
       "  -1.2762999198159102],\n",
       " [1.3359992911664216,\n",
       "  -1.0155076946844492,\n",
       "  0.7225249588681963,\n",
       "  0.0010904726573021503,\n",
       "  -0.24000405952731527,\n",
       "  -0.3890149418737871,\n",
       "  -1.7122192712476842,\n",
       "  -1.2732160294916037,\n",
       "  1821139200.0,\n",
       "  -1.1136196770220408,\n",
       "  -1.3846551669244507,\n",
       "  -0.5469927168703271,\n",
       "  1.0439969359030923],\n",
       " [-0.24140320058381062,\n",
       "  -0.38897706212649924,\n",
       "  -1.7134496103148467,\n",
       "  -1.271154338740282,\n",
       "  -1.115590653880269,\n",
       "  -1.3832362167033017,\n",
       "  -0.5479777860502859,\n",
       "  1.0462173833586774,\n",
       "  1821225600.0,\n",
       "  -0.814378102105214,\n",
       "  1.051973971338873,\n",
       "  -0.19002152189682053,\n",
       "  -0.7743663970557463],\n",
       " [-1.1171270480326436,\n",
       "  -1.3831646743592345,\n",
       "  -0.5500266917021028,\n",
       "  1.0516845368755288,\n",
       "  -0.8163759113492154,\n",
       "  1.052251767170007,\n",
       "  -0.1910777845818553,\n",
       "  -0.7714692892630505,\n",
       "  1821312000.0,\n",
       "  -1.5230432465280208,\n",
       "  0.862279399274181,\n",
       "  -1.2935219389393113,\n",
       "  0.9147760334016812],\n",
       " [-0.8178654019171702,\n",
       "  1.0522408481425087,\n",
       "  -0.19337762306760714,\n",
       "  -0.7686709186690965,\n",
       "  -1.524977511204245,\n",
       "  0.8626460353766039,\n",
       "  -1.2943581220670926,\n",
       "  0.9170445673193413,\n",
       "  1821398400.0,\n",
       "  1.0571359003018168,\n",
       "  -1.6183743105457056,\n",
       "  0.07520283247322707,\n",
       "  1.2620345696826856],\n",
       " [-1.5265780790362333,\n",
       "  0.8626415360681944,\n",
       "  -1.2958822551435678,\n",
       "  0.9223220653742581,\n",
       "  1.0549702761888216,\n",
       "  -1.6168459018835548,\n",
       "  0.07409367405967136,\n",
       "  1.2641738796581525,\n",
       "  1821484800.0,\n",
       "  -0.6688074445534573,\n",
       "  -1.7324053762229779,\n",
       "  -0.5460269418700178,\n",
       "  -0.9867263954888797],\n",
       " [1.053774129602328,\n",
       "  -1.6167664499233538,\n",
       "  0.07160739616421988,\n",
       "  1.2699610435398374,\n",
       "  -0.6708183068234018,\n",
       "  -1.7308235630237343,\n",
       "  -0.547012203661897,\n",
       "  -0.9837502630119946,\n",
       "  1821571200.0,\n",
       "  1.5874075515866195,\n",
       "  0.02423558054411141,\n",
       "  -1.5436254324259953,\n",
       "  -0.21710324658328384],\n",
       " [-0.6722849804227339,\n",
       "  -1.730740251978895,\n",
       "  -0.5490617882050675,\n",
       "  -0.9812635698078408,\n",
       "  1.5851943790889595,\n",
       "  0.024994700413452704,\n",
       "  -1.54441173549459,\n",
       "  -0.21441351091717203,\n",
       "  1821657600.0,\n",
       "  1.4269878625943728,\n",
       "  0.4707635802096875,\n",
       "  -0.11565272488225957,\n",
       "  1.6952500877706795],\n",
       " [1.5840813480961744,\n",
       "  0.025018562516978666,\n",
       "  -1.5457600583676614,\n",
       "  -0.21079725406661337,\n",
       "  1.4247890746052219,\n",
       "  0.47131357617950664,\n",
       "  -0.11672381950724438,\n",
       "  1.697228186973141,\n",
       "  1821744000.0,\n",
       "  0.12145580681647779,\n",
       "  1.6043037351506042,\n",
       "  -1.107657797061971,\n",
       "  1.7721084112787784],\n",
       " [1.4236508991838013,\n",
       "  0.4713223267050265,\n",
       "  -0.11907593552478021,\n",
       "  1.7036511743757092,\n",
       "  0.1193740832418202,\n",
       "  1.6043228566004744,\n",
       "  -1.1085310485020263,\n",
       "  1.7740579094980633,\n",
       "  1821830400.0,\n",
       "  -1.2889005234455835,\n",
       "  -0.9127109609036476,\n",
       "  -1.102039566286116,\n",
       "  -1.2657003304503347],\n",
       " [0.11803127671922993,\n",
       "  1.6042932454096244,\n",
       "  -1.1101858347418518,\n",
       "  1.7805937006387753,\n",
       "  -1.290855783225424,\n",
       "  -0.9115130378359894,\n",
       "  -1.1029139382130535,\n",
       "  -1.2626203845091906,\n",
       "  1821916800.0,\n",
       "  0.8475778491543985,\n",
       "  -0.7544389590396348,\n",
       "  -1.5632502860104114,\n",
       "  -0.8730171346848825],\n",
       " [-1.2924196511670931,\n",
       "  -0.9114574672152836,\n",
       "  -1.1045726737871393,\n",
       "  -1.2605431369092588,\n",
       "  0.8454310156872945,\n",
       "  -0.7533151600095279,\n",
       "  -1.5640326751438403,\n",
       "  -0.8700833163843524,\n",
       "  1822003200.0,\n",
       "  -0.03519845028395067,\n",
       "  -0.17211508413717855,\n",
       "  -0.995567844105411,\n",
       "  1.453807852492027]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[num_col_names] = scaler.transform(x_test[num_col_names])\n",
    "x_test = x_test.values.tolist()\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471101f5-8c1e-4cca-9c2f-03422c3be5a3",
   "metadata": {},
   "source": [
    "### Variáveis de entrada mais importantes para as tomadas de decisão do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e69cad-b5c7-45d3-9374-252e50b9b44c",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f9cb1f5-9e9b-42c1-8b33-ddeeebb86066",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'classifier':\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # Realizando Random Forest para identificar a relevância das variáveis.\n",
    "    # Feature Extraction by Random Forest\n",
    "    model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                           criterion='gini', max_depth=None, max_features=3, # nao sei o que eh este max_features\n",
    "                           max_leaf_nodes=None, max_samples=None,\n",
    "                           min_impurity_decrease=0.0,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=10,\n",
    "                           n_jobs=None, oob_score=False, random_state=None,\n",
    "                           verbose=0, warm_start=False)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    feature_importances_val = model.feature_importances_\n",
    "    pd.options.display.float_format = '{:.10f}'.format\n",
    "    \n",
    "    x_pd = pd.DataFrame(x_train, columns=col_names_order[:-1])\n",
    "    feature_importances = pd.DataFrame(feature_importances_val,\n",
    "                                       index = x_pd.columns,\n",
    "                                       columns=['importance']).sort_values('importance', ascending = False)\n",
    "    print(f'Accuracy: {model.score(x_test, y_test) * 100}')\n",
    "    print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e73007-2f3d-4a6e-925e-08f49f3ac156",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34b57b03-3f6d-475d-8003-e1baa11ac100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5.732834949028288\n",
      "0-temperature_lag_2, Score: 0.0\n",
      "1-atmospheric_pressure_lag_2, Score: 0.0\n",
      "2-humidity_lag_2, Score: 0.0\n",
      "3-wind_speed_lag_2, Score: 0.0\n",
      "4-temperature_lag_1, Score: 0.24274925998473226\n",
      "5-atmospheric_pressure_lag_1, Score: 0.0\n",
      "6-humidity_lag_1, Score: 0.0\n",
      "7-wind_speed_lag_1, Score: 0.0\n",
      "8-date, Score: 0.0\n",
      "9-temperature, Score: 0.6252175940725619\n",
      "10-atmospheric_pressure, Score: 0.0\n",
      "11-humidity, Score: 0.1320331459427058\n",
      "12-wind_speed, Score: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    model = DecisionTreeClassifier(max_depth=3)\n",
    "else:\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    model = DecisionTreeRegressor(max_depth=3)    \n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    print(f'Accuracy: {model.score(x_test, y_test) * 100}')\n",
    "    print(f'Confusion matrix: {confusion_matrix(model.predict(x_test), y_test)}')\n",
    "else:\n",
    "    print(f'MSE: {mean_squared_error(model.predict(x_test), y_test)}')\n",
    "\n",
    "importance = model.feature_importances_\n",
    "for idx, score in enumerate(importance):\n",
    "    print(f'{idx}-{df.keys()[idx]}, Score: {score}')\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7a775-07df-43ad-b57c-a90dae2dc6ef",
   "metadata": {},
   "source": [
    "## Treinar diversos estimators disponíveis no Sklearn\n",
    "https://scikit-learn.org/stable/supervised_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "174d9ef1-cf9f-495a-bc0f-14ad12fc7900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ARDRegression\n",
      "Appending AdaBoostRegressor\n",
      "Appending BaggingRegressor\n",
      "Appending BayesianRidge\n",
      "Appending CCA\n",
      "Appending DecisionTreeRegressor\n",
      "Appending DummyRegressor\n",
      "Appending ElasticNet\n",
      "Appending ElasticNetCV\n",
      "Appending ExtraTreeRegressor\n",
      "Appending ExtraTreesRegressor\n",
      "Appending GammaRegressor\n",
      "Appending GaussianProcessRegressor\n",
      "Appending GradientBoostingRegressor\n",
      "Appending HistGradientBoostingRegressor\n",
      "Appending HuberRegressor\n",
      "Appending IsotonicRegression\n",
      "Appending KNeighborsRegressor\n",
      "Appending KernelRidge\n",
      "Appending Lars\n",
      "Appending LarsCV\n",
      "Appending Lasso\n",
      "Appending LassoCV\n",
      "Appending LassoLars\n",
      "Appending LassoLarsCV\n",
      "Appending LassoLarsIC\n",
      "Appending LinearRegression\n",
      "Appending LinearSVR\n",
      "Appending MLPRegressor\n",
      "Appending MultiOutputRegressor\n",
      "MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultiTaskElasticNet\n",
      "Appending MultiTaskElasticNetCV\n",
      "Appending MultiTaskLasso\n",
      "Appending MultiTaskLassoCV\n",
      "Appending NuSVR\n",
      "Appending OrthogonalMatchingPursuit\n",
      "Appending OrthogonalMatchingPursuitCV\n",
      "Appending PLSCanonical\n",
      "Appending PLSRegression\n",
      "Appending PassiveAggressiveRegressor\n",
      "Appending PoissonRegressor\n",
      "Appending QuantileRegressor\n",
      "Appending RANSACRegressor\n",
      "Appending RadiusNeighborsRegressor\n",
      "Appending RandomForestRegressor\n",
      "Appending RegressorChain\n",
      "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending Ridge\n",
      "Appending RidgeCV\n",
      "Appending SGDRegressor\n",
      "Appending SVR\n",
      "Appending StackingRegressor\n",
      "StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending TheilSenRegressor\n",
      "Appending TransformedTargetRegressor\n",
      "Appending TweedieRegressor\n",
      "Appending VotingRegressor\n",
      "VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# classifier, regressor, cluster, transformer\n",
    "estimators = all_estimators(type_filter=model_type)\n",
    "\n",
    "all_estimators = {}\n",
    "for name, estimator in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        est = estimator()\n",
    "        all_estimators[name] = est\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a626346-eda4-4754-be86-e8dbaddb3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_sklearn_estimators(estimators, x_train, y_train, x_test, y_test, model_type='classifier'):\n",
    "    if model_type == 'classifier':\n",
    "        best_acc = ['', 0.0]  # [estimator_name, accuracy]\n",
    "    else:\n",
    "        best_acc = ['', 99999.0]  # [estimator_name, error]\n",
    "    \n",
    "    for estimator_name, estimator in estimators.items():\n",
    "        try:\n",
    "            print(f'##### {estimator_name} #####')\n",
    "\n",
    "            estimator.fit(x_train, y_train)\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                print('Train ACC: %.3f%%' % (estimator.score(x_train, y_train) * 100.00))\n",
    "            else:\n",
    "                train_mse = mean_squared_error(estimator.predict(x_train), y_train)\n",
    "                print('Train MSE: %.3f' % (train_mse))\n",
    "                print(f'Train inference error (RMSE): ±{math.sqrt(train_mse)}')\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                test_acc = estimator.score(x_test, y_test) * 100.00\n",
    "                print('Test ACC: %.3f%%' % (test_acc))\n",
    "            else:\n",
    "                test_mse = mean_squared_error(estimator.predict(x_test), y_test)\n",
    "                print('Test MSE: %.3f' % (test_mse))\n",
    "                print(f'Test inference error (RMSE): ±{math.sqrt(test_mse)}')\n",
    "            print()\n",
    "    \n",
    "            if model_type == 'classifier' and test_acc > best_acc[1]:\n",
    "                best_acc = [estimator_name, test_acc]\n",
    "            elif model_type == 'regressor' and test_mse < best_acc[1]:\n",
    "                best_acc = [estimator_name, test_mse, math.sqrt(test_mse)]\n",
    "            \n",
    "            # Confusion Matrix\n",
    "            if model_type == 'classifier':\n",
    "                preds = estimator.predict(x_test)\n",
    "                matrix = confusion_matrix(y_test, preds)\n",
    "                print('Confusion Matrix Test:')\n",
    "                print(matrix)\n",
    "        except Exception as e:\n",
    "            print(f'Error ({estimator_name}): {e}')\n",
    "\n",
    "    print('########## Best Estimator ##########')\n",
    "    print(best_acc)\n",
    "    \n",
    "    return estimators, best_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c94079be-a30a-4a7b-97f4-7785c869ac03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ARDRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.911292916203003e-11\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.298390980753277e-11\n",
      "\n",
      "##### AdaBoostRegressor #####\n",
      "Train MSE: 1.454\n",
      "Train inference error (RMSE): ±1.205624180076466\n",
      "Test MSE: 2.297\n",
      "Test inference error (RMSE): ±1.5155490048129003\n",
      "\n",
      "##### BaggingRegressor #####\n",
      "Train MSE: 0.359\n",
      "Train inference error (RMSE): ±0.5990608225911257\n",
      "Test MSE: 1.871\n",
      "Test inference error (RMSE): ±1.3676637235526503\n",
      "\n",
      "##### BayesianRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.5529504187851013e-09\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.761658631230065e-09\n",
      "\n",
      "##### CCA #####\n",
      "Error (CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0\n",
      "Test MSE: 3.694\n",
      "Test inference error (RMSE): ±1.922007568794917\n",
      "\n",
      "##### DummyRegressor #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.3413737377774635\n",
      "Test MSE: 11.776\n",
      "Test inference error (RMSE): ±3.43162215568848\n",
      "\n",
      "##### ElasticNet #####\n",
      "Train MSE: 4.078\n",
      "Train inference error (RMSE): ±2.0194947143839097\n",
      "Test MSE: 5.099\n",
      "Test inference error (RMSE): ±2.258013430544022\n",
      "\n",
      "##### ElasticNetCV #####\n",
      "Train MSE: 11.071\n",
      "Train inference error (RMSE): ±3.3273082176855575\n",
      "Test MSE: 13.005\n",
      "Test inference error (RMSE): ±3.606284314560137\n",
      "\n",
      "##### ExtraTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0\n",
      "Test MSE: 4.622\n",
      "Test inference error (RMSE): ±2.14986468347348\n",
      "\n",
      "##### ExtraTreesRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.2009566852891976e-14\n",
      "Test MSE: 1.308\n",
      "Test inference error (RMSE): ±1.1435550696038348\n",
      "\n",
      "##### GammaRegressor #####\n",
      "Error (GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GaussianProcessRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.148435427771202e-10\n",
      "Test MSE: 90.878\n",
      "Test inference error (RMSE): ±9.533004514137723\n",
      "\n",
      "##### GradientBoostingRegressor #####\n",
      "Train MSE: 0.086\n",
      "Train inference error (RMSE): ±0.29295602294801387\n",
      "Test MSE: 0.675\n",
      "Test inference error (RMSE): ±0.8218767134187985\n",
      "\n",
      "##### HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.012\n",
      "Train inference error (RMSE): ±0.10776974189431601\n",
      "Test MSE: 0.691\n",
      "Test inference error (RMSE): ±0.831040954268068\n",
      "\n",
      "##### HuberRegressor #####\n",
      "Train MSE: 11.227\n",
      "Train inference error (RMSE): ±3.350618311872046\n",
      "Test MSE: 11.648\n",
      "Test inference error (RMSE): ±3.412926500514791\n",
      "\n",
      "##### IsotonicRegression #####\n",
      "Error (IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### KNeighborsRegressor #####\n",
      "Train MSE: 4.626\n",
      "Train inference error (RMSE): ±2.15089698548501\n",
      "Test MSE: 20.572\n",
      "Test inference error (RMSE): ±4.535589350190731\n",
      "\n",
      "##### KernelRidge #####\n",
      "Train MSE: 11.528\n",
      "Train inference error (RMSE): ±3.3953514467138106\n",
      "Test MSE: 11.732\n",
      "Test inference error (RMSE): ±3.425272844811648\n",
      "\n",
      "##### Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3096555805882874e-15\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.509739246438952e-15\n",
      "\n",
      "##### LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3096555805882874e-15\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.509739246438952e-15\n",
      "\n",
      "##### Lasso #####\n",
      "Train MSE: 5.487\n",
      "Train inference error (RMSE): ±2.342395738416682\n",
      "Test MSE: 7.084\n",
      "Test inference error (RMSE): ±2.661549118124318\n",
      "\n",
      "##### LassoCV #####\n",
      "Train MSE: 11.071\n",
      "Train inference error (RMSE): ±3.327308217684384\n",
      "Test MSE: 13.005\n",
      "Test inference error (RMSE): ±3.606284314774971\n",
      "\n",
      "##### LassoLars #####\n",
      "Train MSE: 5.487\n",
      "Train inference error (RMSE): ±2.342395712328968\n",
      "Test MSE: 7.084\n",
      "Test inference error (RMSE): ±2.661549074114653\n",
      "\n",
      "##### LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.4147349783998025e-15\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5198197401016615e-15\n",
      "\n",
      "##### LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.4147349783998025e-15\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5198197401016615e-15\n",
      "\n",
      "##### LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.374391517769534e-11\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.386175079315107e-11\n",
      "\n",
      "##### LinearSVR #####\n",
      "Train MSE: 83.694\n",
      "Train inference error (RMSE): ±9.148434924560487\n",
      "Test MSE: 90.878\n",
      "Test inference error (RMSE): ±9.533004514137723\n",
      "\n",
      "##### MLPRegressor #####\n",
      "Train MSE: 10.524\n",
      "Train inference error (RMSE): ±3.2440016949633463\n",
      "Test MSE: 10.961\n",
      "Test inference error (RMSE): ±3.310713296818803\n",
      "\n",
      "##### MultiTaskElasticNet #####\n",
      "Train MSE: 4.078\n",
      "Train inference error (RMSE): ±2.0194947143839097\n",
      "Test MSE: 5.099\n",
      "Test inference error (RMSE): ±2.2580134305440205\n",
      "\n",
      "##### MultiTaskElasticNetCV #####\n",
      "Train MSE: 11.071\n",
      "Train inference error (RMSE): ±3.327308217685557\n",
      "Test MSE: 13.005\n",
      "Test inference error (RMSE): ±3.606284314560136\n",
      "\n",
      "##### MultiTaskLasso #####\n",
      "Train MSE: 5.487\n",
      "Train inference error (RMSE): ±2.342395738416682\n",
      "Test MSE: 7.084\n",
      "Test inference error (RMSE): ±2.661549118124317\n",
      "\n",
      "##### MultiTaskLassoCV #####\n",
      "Train MSE: 11.071\n",
      "Train inference error (RMSE): ±3.327308217684384\n",
      "Test MSE: 13.005\n",
      "Test inference error (RMSE): ±3.6062843147749732\n",
      "\n",
      "##### NuSVR #####\n",
      "Train MSE: 11.160\n",
      "Train inference error (RMSE): ±3.3406543778382067\n",
      "Test MSE: 11.768\n",
      "Test inference error (RMSE): ±3.430424479018985\n",
      "\n",
      "##### OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.071\n",
      "Train inference error (RMSE): ±3.3272732157887077\n",
      "Test MSE: 13.099\n",
      "Test inference error (RMSE): ±3.6192819645250536\n",
      "\n",
      "##### OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0486056035359073\n",
      "Test MSE: 1.399\n",
      "Test inference error (RMSE): ±1.1827821118746753\n",
      "\n",
      "##### PLSCanonical #####\n",
      "Error (PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07621331251879143\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08500528635152635\n",
      "\n",
      "##### PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.978\n",
      "Train inference error (RMSE): ±3.460945412095799\n",
      "Test MSE: 12.743\n",
      "Test inference error (RMSE): ±3.569699546377553\n",
      "\n",
      "##### PoissonRegressor #####\n",
      "Error (PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### QuantileRegressor #####\n",
      "Train MSE: 11.169\n",
      "Train inference error (RMSE): ±3.342056797545071\n",
      "Test MSE: 15.907\n",
      "Test inference error (RMSE): ±3.9883853826297506\n",
      "\n",
      "##### RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.374391517769534e-11\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.386175079315107e-11\n",
      "\n",
      "##### RadiusNeighborsRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0\n",
      "Error (RadiusNeighborsRegressor): Input contains NaN.\n",
      "##### RandomForestRegressor #####\n",
      "Train MSE: 0.209\n",
      "Train inference error (RMSE): ±0.45676989325370576\n",
      "Test MSE: 1.641\n",
      "Test inference error (RMSE): ±1.2808573985496543\n",
      "\n",
      "##### Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.005430793613405223\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.005979401475405802\n",
      "\n",
      "##### RidgeCV #####\n",
      "Train MSE: 642451.869\n",
      "Train inference error (RMSE): ±801.5309533942603\n",
      "Test MSE: 4053869.866\n",
      "Test inference error (RMSE): ±2013.4224260766637\n",
      "\n",
      "##### SGDRegressor #####\n",
      "Train MSE: 557935122194099885518616994423604158733142729471033344.000\n",
      "Train inference error (RMSE): ±7.469505486938877e+26\n",
      "Test MSE: 585405234309231081143017035890892987551872082685984768.000\n",
      "Test inference error (RMSE): ±7.65117791133647e+26\n",
      "\n",
      "##### SVR #####\n",
      "Train MSE: 11.172\n",
      "Train inference error (RMSE): ±3.3424545316915553\n",
      "Test MSE: 11.933\n",
      "Test inference error (RMSE): ±3.4544659077080113\n",
      "\n",
      "##### TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.9645731863805718e-08\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.9285848436416017e-08\n",
      "\n",
      "##### TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.374391517769534e-11\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.386175079315107e-11\n",
      "\n",
      "##### TweedieRegressor #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.3413723745917774\n",
      "Test MSE: 11.778\n",
      "Test inference error (RMSE): ±3.431973235964259\n",
      "\n",
      "########## Best Estimator ##########\n",
      "['Lars', 2.033774807087176e-29, 4.509739246438952e-15]\n",
      "Total time: 2.215827226638794\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimators_trained, best_estimator_name = run_sklearn_estimators(\n",
    "    all_estimators,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    model_type\n",
    ")\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fda6aea5-fd41-49f6-b7da-a5ef7d849c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lars()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Lars<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Lars.html\">?<span>Documentation for Lars</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Lars()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Lars()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_trained[best_estimator_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9bb95-4f93-497e-a7bd-fe9ce5e291d8",
   "metadata": {},
   "source": [
    "### Save Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f2b4f21-99f9-42af-89c1-dd2a21e11b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(estimators_trained[best_estimator_name], open('results/estimator_sklearn.sav', 'wb'))\n",
    "\n",
    "# Scaler\n",
    "pickle.dump(scaler, open('results/scaler.pkl','wb'))\n",
    "\n",
    "# Save columns names and informations\n",
    "data_to_save = {\n",
    "    'col_names_order': col_names_order,\n",
    "    'num_col_names': num_col_names,\n",
    "    'cat_col_names': cat_col_names,\n",
    "    'date_col_names': date_col_names,\n",
    "    'target_cols': target_cols,\n",
    "    'category_mappings': category_mappings,\n",
    "    'window_size': window_size\n",
    "}\n",
    "with open('results/columns_metadata_sklearn.json', 'w') as json_file:\n",
    "    json.dump(data_to_save, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70756f5f-6703-4179-91f9-9a2ee059e073",
   "metadata": {},
   "source": [
    "## Stacking estimators\n",
    "Classificador: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier\n",
    "\n",
    "Regressor: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37139066-befd-458e-919e-9e21bffceed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ARDRegression\n",
      "Appending AdaBoostRegressor\n",
      "Appending BaggingRegressor\n",
      "Appending BayesianRidge\n",
      "Appending CCA\n",
      "Appending DecisionTreeRegressor\n",
      "Appending DummyRegressor\n",
      "Appending ElasticNet\n",
      "Appending ElasticNetCV\n",
      "Appending ExtraTreeRegressor\n",
      "Appending ExtraTreesRegressor\n",
      "Appending GammaRegressor\n",
      "Appending GaussianProcessRegressor\n",
      "Appending GradientBoostingRegressor\n",
      "Appending HistGradientBoostingRegressor\n",
      "Appending HuberRegressor\n",
      "Appending IsotonicRegression\n",
      "Appending KNeighborsRegressor\n",
      "Appending KernelRidge\n",
      "Appending Lars\n",
      "Appending LarsCV\n",
      "Appending Lasso\n",
      "Appending LassoCV\n",
      "Appending LassoLars\n",
      "Appending LassoLarsCV\n",
      "Appending LassoLarsIC\n",
      "Appending LinearRegression\n",
      "Appending LinearSVR\n",
      "Appending MLPRegressor\n",
      "Appending MultiOutputRegressor\n",
      "MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultiTaskElasticNet\n",
      "Appending MultiTaskElasticNetCV\n",
      "Appending MultiTaskLasso\n",
      "Appending MultiTaskLassoCV\n",
      "Appending NuSVR\n",
      "Appending OrthogonalMatchingPursuit\n",
      "Appending OrthogonalMatchingPursuitCV\n",
      "Appending PLSCanonical\n",
      "Appending PLSRegression\n",
      "Appending PassiveAggressiveRegressor\n",
      "Appending PoissonRegressor\n",
      "Appending QuantileRegressor\n",
      "Appending RANSACRegressor\n",
      "Appending RadiusNeighborsRegressor\n",
      "Appending RandomForestRegressor\n",
      "Appending RegressorChain\n",
      "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending Ridge\n",
      "Appending RidgeCV\n",
      "Appending SGDRegressor\n",
      "Appending SVR\n",
      "Appending StackingRegressor\n",
      "StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending TheilSenRegressor\n",
      "Appending TransformedTargetRegressor\n",
      "Appending TweedieRegressor\n",
      "Appending VotingRegressor\n",
      "VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# classifier, regressor, cluster, transformer\n",
    "estimators = all_estimators(type_filter=model_type)\n",
    "\n",
    "all_estimators = {}\n",
    "for name, estimator in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        est = estimator()\n",
    "        all_estimators[name] = est\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "837e27c3-4b1c-4ba2-94a1-d1040bad2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_sklearn_estimators_with_stacking(estimators, x_train, y_train, x_test, y_test, model_type):\n",
    "    if model_type == 'classifier':\n",
    "        best_acc = ['', 0.0]  # [estimator_name, accuracy]\n",
    "    else:\n",
    "        best_acc = ['', 99999.0]  # [estimator_name, error]\n",
    "    estimators_stacked_trained = {}\n",
    "    \n",
    "    idx = 0\n",
    "    for estimator_name, estimator in estimators.items():\n",
    "        count = 0\n",
    "        for estimator_name2, estimator2 in estimators.items():\n",
    "            if count <= idx:\n",
    "                count += 1\n",
    "                continue\n",
    "            try:\n",
    "                print(f'##### {estimator_name} - {estimator_name2} #####')\n",
    "\n",
    "                if model_type == 'classifier':\n",
    "                    stack = StackingClassifier([(estimator_name, copy.deepcopy(estimator)), (estimator_name2, copy.deepcopy(estimator2))],\n",
    "                                              final_estimator=LogisticRegression())\n",
    "                else:\n",
    "                    stack = StackingRegressor([(estimator_name, copy.deepcopy(estimator)), (estimator_name2, copy.deepcopy(estimator2))],\n",
    "                                              final_estimator=RidgeCV())\n",
    "\n",
    "                stack.fit(x_train, y_train)\n",
    "                \n",
    "                if model_type == 'classifier':\n",
    "                    print('Train ACC: %.3f%%' % (stack.score(x_train, y_train) * 100.00))\n",
    "                else:\n",
    "                    train_mse = mean_squared_error(stack.predict(x_train), y_train)\n",
    "                    print('Train MSE: %.3f' % (train_mse))\n",
    "                    print(f'Train inference error (RMSE): ±{math.sqrt(train_mse)}')\n",
    "                \n",
    "                if model_type == 'classifier':\n",
    "                    test_acc = stack.score(x_test, y_test) * 100.00\n",
    "                    print('Test ACC: %.3f%%' % (test_acc))\n",
    "                else:\n",
    "                    test_mse = mean_squared_error(stack.predict(x_test), y_test)\n",
    "                    print('Test MSE: %.3f' % (test_mse))\n",
    "                    print(f'Test inference error (RMSE): ±{math.sqrt(test_mse)}')\n",
    "        \n",
    "                if model_type == 'classifier' and test_acc > best_acc[1]:\n",
    "                    best_acc = [f'{estimator_name}-{estimator_name2}', test_acc]\n",
    "                elif model_type == 'regressor' and test_mse < best_acc[1]:\n",
    "                    best_acc = [f'{estimator_name}-{estimator_name2}', test_mse, math.sqrt(test_mse)]\n",
    "                \n",
    "                # Confusion Matrix\n",
    "                if model_type == 'classifier':\n",
    "                    preds = stack.predict(x_test)\n",
    "                    matrix = confusion_matrix(y_test, preds)\n",
    "                    print('Confusion Matrix Test:')\n",
    "                    print(matrix)\n",
    "\n",
    "                estimators_stacked_trained[f'{estimator_name}-{estimator_name2}'] = copy.deepcopy(stack)\n",
    "            except Exception as e:\n",
    "                print(f'Error ({estimator_name}-{estimator_name2}): {e}')\n",
    "                continue\n",
    "        \n",
    "        idx += 1\n",
    "\n",
    "    print('########## Best Estimator ##########')\n",
    "    print(best_acc)\n",
    "    \n",
    "    return estimators_stacked_trained, best_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f4d5044-760a-421c-9eee-908ad2d38951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ARDRegression - AdaBoostRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002999925111875948\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0027542345246124103\n",
      "##### ARDRegression - BaggingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.003298731864304635\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0029555432237974126\n",
      "##### ARDRegression - BayesianRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00030315646839339504\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0003161160481980623\n",
      "##### ARDRegression - CCA #####\n",
      "Error (ARDRegression-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ARDRegression - DecisionTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0027872984701848955\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0027865440752486348\n",
      "##### ARDRegression - DummyRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002561033496092558\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002664539481798683\n",
      "##### ARDRegression - ElasticNet #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002265733976638003\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0021986597469482185\n",
      "##### ARDRegression - ElasticNetCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.003499070003017762\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.008086294704872014\n",
      "##### ARDRegression - ExtraTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001999813896257689\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0023284472525602865\n",
      "##### ARDRegression - ExtraTreesRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.003285978085859899\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0024502461142065935\n",
      "##### ARDRegression - GammaRegressor #####\n",
      "Error (ARDRegression-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ARDRegression - GaussianProcessRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002161449798377421\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002253844280366452\n",
      "##### ARDRegression - GradientBoostingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0026846891280726923\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002341703175528902\n",
      "##### ARDRegression - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0022540633555859094\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002253798358536604\n",
      "##### ARDRegression - HuberRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002846389357883803\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.005660392696968576\n",
      "##### ARDRegression - IsotonicRegression #####\n",
      "Error (ARDRegression-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ARDRegression - KNeighborsRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0017926218928597541\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.003445035312426527\n",
      "##### ARDRegression - KernelRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0021614856972535907\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0022539396072941667\n",
      "##### ARDRegression - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00030315693912456756\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00031611584870268057\n",
      "##### ARDRegression - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00030315693912456756\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00031611584870268057\n",
      "##### ARDRegression - Lasso #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0024956262793612333\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0024360009772147126\n",
      "##### ARDRegression - LassoCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00349907004835912\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.008086294740432803\n",
      "##### ARDRegression - LassoLars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002495626025765173\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002436000739567261\n",
      "##### ARDRegression - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00030315687266507807\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0003161157803783353\n",
      "##### ARDRegression - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00030315687266507807\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0003161157803783353\n",
      "##### ARDRegression - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0003031567854815934\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0003161156897453941\n",
      "##### ARDRegression - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002161449798377421\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002253844280366452\n",
      "##### ARDRegression - MLPRegressor #####\n",
      "Train MSE: 318941.980\n",
      "Train inference error (RMSE): ±564.7494843655328\n",
      "Test MSE: 334641.587\n",
      "Test inference error (RMSE): ±578.4821407257924\n",
      "##### ARDRegression - MultiTaskElasticNet #####\n",
      "Error (ARDRegression-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ARDRegression - MultiTaskElasticNetCV #####\n",
      "Error (ARDRegression-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ARDRegression - MultiTaskLasso #####\n",
      "Error (ARDRegression-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ARDRegression - MultiTaskLassoCV #####\n",
      "Error (ARDRegression-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ARDRegression - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0025430675137743343\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0026464038121091905\n",
      "##### ARDRegression - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.003553238634177955\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00825639020895165\n",
      "##### ARDRegression - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0025881531810250974\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0026246417602293548\n",
      "##### ARDRegression - PLSCanonical #####\n",
      "Error (ARDRegression-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ARDRegression - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.004630116808066869\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.005377513505964593\n",
      "##### ARDRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002195071117662987\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0023155422653298664\n",
      "##### ARDRegression - PoissonRegressor #####\n",
      "Error (ARDRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ARDRegression - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0035896105493593553\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.008316557631332683\n",
      "##### ARDRegression - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0003031567854815934\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0003161156897453941\n",
      "##### ARDRegression - RadiusNeighborsRegressor #####\n",
      "Error (ARDRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ARDRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.003238108424933488\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002780229801983981\n",
      "##### ARDRegression - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0012064758965870505\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0014252284534047044\n",
      "##### ARDRegression - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.003767414052788209\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.009096728603861307\n",
      "##### ARDRegression - SGDRegressor #####\n",
      "Train MSE: 25442975368507685078393941384045608375634141829088195958367221001202016640876415025152.000\n",
      "Train inference error (RMSE): ±5.044103029132899e+42\n",
      "Test MSE: 26740497463306416382011539495065386673653157670573205671801296831041155542174985617408.000\n",
      "Test inference error (RMSE): ±5.171121489900079e+42\n",
      "##### ARDRegression - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002157715659940823\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0022627058557695267\n",
      "##### ARDRegression - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0003031554500840323\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0003161134989062854\n",
      "##### ARDRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0003031567854815934\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0003161156897453941\n",
      "##### ARDRegression - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.002560641737019565\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0026640398893753876\n",
      "##### AdaBoostRegressor - BaggingRegressor #####\n",
      "Train MSE: 0.528\n",
      "Train inference error (RMSE): ±0.7267417722789645\n",
      "Test MSE: 1.496\n",
      "Test inference error (RMSE): ±1.2233044702055367\n",
      "##### AdaBoostRegressor - BayesianRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.521341074267117e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012320595794802064\n",
      "##### AdaBoostRegressor - CCA #####\n",
      "Error (AdaBoostRegressor-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### AdaBoostRegressor - DecisionTreeRegressor #####\n",
      "Train MSE: 0.833\n",
      "Train inference error (RMSE): ±0.9126822122993241\n",
      "Test MSE: 1.764\n",
      "Test inference error (RMSE): ±1.3282692482830858\n",
      "##### AdaBoostRegressor - DummyRegressor #####\n",
      "Train MSE: 1.035\n",
      "Train inference error (RMSE): ±1.0171666789225946\n",
      "Test MSE: 1.766\n",
      "Test inference error (RMSE): ±1.3289005745891076\n",
      "##### AdaBoostRegressor - ElasticNet #####\n",
      "Train MSE: 0.973\n",
      "Train inference error (RMSE): ±0.9864894750724976\n",
      "Test MSE: 2.091\n",
      "Test inference error (RMSE): ±1.4460371636284717\n",
      "##### AdaBoostRegressor - ElasticNetCV #####\n",
      "Train MSE: 1.049\n",
      "Train inference error (RMSE): ±1.0243717130290673\n",
      "Test MSE: 1.870\n",
      "Test inference error (RMSE): ±1.3673567150966202\n",
      "##### AdaBoostRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.768\n",
      "Train inference error (RMSE): ±0.8766269489830176\n",
      "Test MSE: 1.771\n",
      "Test inference error (RMSE): ±1.3308209818788872\n",
      "##### AdaBoostRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.343\n",
      "Train inference error (RMSE): ±0.5855653105747225\n",
      "Test MSE: 0.983\n",
      "Test inference error (RMSE): ±0.9916568884131921\n",
      "##### AdaBoostRegressor - GammaRegressor #####\n",
      "Error (AdaBoostRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### AdaBoostRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 1.036\n",
      "Train inference error (RMSE): ±1.0176656375396091\n",
      "Test MSE: 1.848\n",
      "Test inference error (RMSE): ±1.359282051685867\n",
      "##### AdaBoostRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.166\n",
      "Train inference error (RMSE): ±0.4076826362160125\n",
      "Test MSE: 0.485\n",
      "Test inference error (RMSE): ±0.6962384641632259\n",
      "##### AdaBoostRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.117\n",
      "Train inference error (RMSE): ±0.3415033788877282\n",
      "Test MSE: 0.605\n",
      "Test inference error (RMSE): ±0.7776557479584142\n",
      "##### AdaBoostRegressor - HuberRegressor #####\n",
      "Train MSE: 1.053\n",
      "Train inference error (RMSE): ±1.0260937108929669\n",
      "Test MSE: 1.837\n",
      "Test inference error (RMSE): ±1.3554812262461482\n",
      "##### AdaBoostRegressor - IsotonicRegression #####\n",
      "Error (AdaBoostRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### AdaBoostRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.932\n",
      "Train inference error (RMSE): ±0.9654205724810649\n",
      "Test MSE: 2.117\n",
      "Test inference error (RMSE): ±1.4549262769797788\n",
      "##### AdaBoostRegressor - KernelRidge #####\n",
      "Train MSE: 1.036\n",
      "Train inference error (RMSE): ±1.0176407528866314\n",
      "Test MSE: 1.802\n",
      "Test inference error (RMSE): ±1.3425657060451537\n",
      "##### AdaBoostRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.185448158245782e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012327413320395043\n",
      "##### AdaBoostRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.963321333569399e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001217731273016326\n",
      "##### AdaBoostRegressor - Lasso #####\n",
      "Train MSE: 1.073\n",
      "Train inference error (RMSE): ±1.0360863228398534\n",
      "Test MSE: 1.818\n",
      "Test inference error (RMSE): ±1.3484151308435444\n",
      "##### AdaBoostRegressor - LassoCV #####\n",
      "Train MSE: 1.068\n",
      "Train inference error (RMSE): ±1.0335030864431125\n",
      "Test MSE: 1.916\n",
      "Test inference error (RMSE): ±1.384119919831458\n",
      "##### AdaBoostRegressor - LassoLars #####\n",
      "Train MSE: 1.115\n",
      "Train inference error (RMSE): ±1.0559815886528356\n",
      "Test MSE: 1.891\n",
      "Test inference error (RMSE): ±1.3751415433792125\n",
      "##### AdaBoostRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.720325829933628e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012010184439393773\n",
      "##### AdaBoostRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.940395828806572e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011432535826864751\n",
      "##### AdaBoostRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.780411726000146e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011324654911501039\n",
      "##### AdaBoostRegressor - LinearSVR #####\n",
      "Train MSE: 1.016\n",
      "Train inference error (RMSE): ±1.0080673728994918\n",
      "Test MSE: 1.766\n",
      "Test inference error (RMSE): ±1.3287489228617024\n",
      "##### AdaBoostRegressor - MLPRegressor #####\n",
      "Train MSE: 1.066\n",
      "Train inference error (RMSE): ±1.032627940969412\n",
      "Test MSE: 1.901\n",
      "Test inference error (RMSE): ±1.378676974695752\n",
      "##### AdaBoostRegressor - MultiTaskElasticNet #####\n",
      "Error (AdaBoostRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### AdaBoostRegressor - MultiTaskElasticNetCV #####\n",
      "Error (AdaBoostRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### AdaBoostRegressor - MultiTaskLasso #####\n",
      "Error (AdaBoostRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### AdaBoostRegressor - MultiTaskLassoCV #####\n",
      "Error (AdaBoostRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### AdaBoostRegressor - NuSVR #####\n",
      "Train MSE: 1.021\n",
      "Train inference error (RMSE): ±1.0104830322883027\n",
      "Test MSE: 1.857\n",
      "Test inference error (RMSE): ±1.3628797250337474\n",
      "##### AdaBoostRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 1.127\n",
      "Train inference error (RMSE): ±1.0616618252201024\n",
      "Test MSE: 1.800\n",
      "Test inference error (RMSE): ±1.3417503848188892\n",
      "##### AdaBoostRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.929\n",
      "Train inference error (RMSE): ±0.9638021443913659\n",
      "Test MSE: 1.286\n",
      "Test inference error (RMSE): ±1.1337998142267456\n",
      "##### AdaBoostRegressor - PLSCanonical #####\n",
      "Error (AdaBoostRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### AdaBoostRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07608485679334494\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08502309189109754\n",
      "##### AdaBoostRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 1.101\n",
      "Train inference error (RMSE): ±1.0491182026700503\n",
      "Test MSE: 1.880\n",
      "Test inference error (RMSE): ±1.3709906846647086\n",
      "##### AdaBoostRegressor - PoissonRegressor #####\n",
      "Error (AdaBoostRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### AdaBoostRegressor - QuantileRegressor #####\n",
      "Train MSE: 1.077\n",
      "Train inference error (RMSE): ±1.0378020764131444\n",
      "Test MSE: 1.926\n",
      "Test inference error (RMSE): ±1.3879273529636607\n",
      "##### AdaBoostRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.567342376770523e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012938737018865763\n",
      "##### AdaBoostRegressor - RadiusNeighborsRegressor #####\n",
      "Error (AdaBoostRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### AdaBoostRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.305\n",
      "Train inference error (RMSE): ±0.5522688732932169\n",
      "Test MSE: 1.366\n",
      "Test inference error (RMSE): ±1.1689514717081135\n",
      "##### AdaBoostRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016116209122024954\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0017975410825879965\n",
      "##### AdaBoostRegressor - RidgeCV #####\n",
      "Train MSE: 1.197\n",
      "Train inference error (RMSE): ±1.0942183661923859\n",
      "Test MSE: 2.246\n",
      "Test inference error (RMSE): ±1.4985152143579452\n",
      "##### AdaBoostRegressor - SGDRegressor #####\n",
      "Train MSE: 32166497618289631497860742961620037364624270104659921849344428999374242464546915614720.000\n",
      "Train inference error (RMSE): ±5.671551605891427e+42\n",
      "Test MSE: 33214136671507430813299259974570464759821616515528665700111683474521880512671252480000.000\n",
      "Test inference error (RMSE): ±5.763170713375357e+42\n",
      "##### AdaBoostRegressor - SVR #####\n",
      "Train MSE: 1.061\n",
      "Train inference error (RMSE): ±1.0298664375853532\n",
      "Test MSE: 1.903\n",
      "Test inference error (RMSE): ±1.3794464845739165\n",
      "##### AdaBoostRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.19376579225373e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011704985233144751\n",
      "##### AdaBoostRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.14861316205888e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011590466610338624\n",
      "##### AdaBoostRegressor - TweedieRegressor #####\n",
      "Train MSE: 1.051\n",
      "Train inference error (RMSE): ±1.0252805972635306\n",
      "Test MSE: 1.847\n",
      "Test inference error (RMSE): ±1.3591324890861114\n",
      "##### BaggingRegressor - BayesianRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.032746845950538e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011191553208243458\n",
      "##### BaggingRegressor - CCA #####\n",
      "Error (BaggingRegressor-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BaggingRegressor - DecisionTreeRegressor #####\n",
      "Train MSE: 0.285\n",
      "Train inference error (RMSE): ±0.5340634730938186\n",
      "Test MSE: 1.728\n",
      "Test inference error (RMSE): ±1.3145463639240118\n",
      "##### BaggingRegressor - DummyRegressor #####\n",
      "Train MSE: 0.366\n",
      "Train inference error (RMSE): ±0.6051184678566144\n",
      "Test MSE: 1.797\n",
      "Test inference error (RMSE): ±1.340426108089765\n",
      "##### BaggingRegressor - ElasticNet #####\n",
      "Train MSE: 0.684\n",
      "Train inference error (RMSE): ±0.8273154872230858\n",
      "Test MSE: 1.817\n",
      "Test inference error (RMSE): ±1.3478585913329024\n",
      "##### BaggingRegressor - ElasticNetCV #####\n",
      "Train MSE: 0.288\n",
      "Train inference error (RMSE): ±0.5369215664483598\n",
      "Test MSE: 2.000\n",
      "Test inference error (RMSE): ±1.4141180936801045\n",
      "##### BaggingRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.247\n",
      "Train inference error (RMSE): ±0.49718041514144184\n",
      "Test MSE: 1.417\n",
      "Test inference error (RMSE): ±1.1903580657410142\n",
      "##### BaggingRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.290\n",
      "Train inference error (RMSE): ±0.5388642769355237\n",
      "Test MSE: 0.999\n",
      "Test inference error (RMSE): ±0.9993294143342936\n",
      "##### BaggingRegressor - GammaRegressor #####\n",
      "Error (BaggingRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### BaggingRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.322\n",
      "Train inference error (RMSE): ±0.567710396305109\n",
      "Test MSE: 1.753\n",
      "Test inference error (RMSE): ±1.3240430838142216\n",
      "##### BaggingRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.38409962673438386\n",
      "Test MSE: 0.515\n",
      "Test inference error (RMSE): ±0.7177305144541659\n",
      "##### BaggingRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.090\n",
      "Train inference error (RMSE): ±0.30030336808050395\n",
      "Test MSE: 0.591\n",
      "Test inference error (RMSE): ±0.7686193759289557\n",
      "##### BaggingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.289\n",
      "Train inference error (RMSE): ±0.537922913546016\n",
      "Test MSE: 1.608\n",
      "Test inference error (RMSE): ±1.268043329950307\n",
      "##### BaggingRegressor - IsotonicRegression #####\n",
      "Error (BaggingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### BaggingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.416\n",
      "Train inference error (RMSE): ±0.6447371291694554\n",
      "Test MSE: 2.136\n",
      "Test inference error (RMSE): ±1.461569879856775\n",
      "##### BaggingRegressor - KernelRidge #####\n",
      "Train MSE: 0.305\n",
      "Train inference error (RMSE): ±0.552598849168502\n",
      "Test MSE: 1.597\n",
      "Test inference error (RMSE): ±1.2635816500523884\n",
      "##### BaggingRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.0373315140388544e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011264480817861805\n",
      "##### BaggingRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.503101570894947e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.000104792616126872\n",
      "##### BaggingRegressor - Lasso #####\n",
      "Train MSE: 0.326\n",
      "Train inference error (RMSE): ±0.5709178967354551\n",
      "Test MSE: 1.754\n",
      "Test inference error (RMSE): ±1.3244461260950247\n",
      "##### BaggingRegressor - LassoCV #####\n",
      "Train MSE: 0.320\n",
      "Train inference error (RMSE): ±0.5659361144683202\n",
      "Test MSE: 1.669\n",
      "Test inference error (RMSE): ±1.2917895795430547\n",
      "##### BaggingRegressor - LassoLars #####\n",
      "Train MSE: 0.376\n",
      "Train inference error (RMSE): ±0.6128900500680511\n",
      "Test MSE: 1.779\n",
      "Test inference error (RMSE): ±1.3337571092754743\n",
      "##### BaggingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.176747861467384e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011350024754589609\n",
      "##### BaggingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.4631332923122013e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00010174566687520223\n",
      "##### BaggingRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.601854370637418e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001010964381447924\n",
      "##### BaggingRegressor - LinearSVR #####\n",
      "Train MSE: 0.353\n",
      "Train inference error (RMSE): ±0.5937542999564934\n",
      "Test MSE: 1.780\n",
      "Test inference error (RMSE): ±1.3341266566175105\n",
      "##### BaggingRegressor - MLPRegressor #####\n",
      "Train MSE: 0.340\n",
      "Train inference error (RMSE): ±0.5830620576735485\n",
      "Test MSE: 1.873\n",
      "Test inference error (RMSE): ±1.368653830381503\n",
      "##### BaggingRegressor - MultiTaskElasticNet #####\n",
      "Error (BaggingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### BaggingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (BaggingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### BaggingRegressor - MultiTaskLasso #####\n",
      "Error (BaggingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### BaggingRegressor - MultiTaskLassoCV #####\n",
      "Error (BaggingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### BaggingRegressor - NuSVR #####\n",
      "Train MSE: 0.319\n",
      "Train inference error (RMSE): ±0.5643852026413446\n",
      "Test MSE: 1.745\n",
      "Test inference error (RMSE): ±1.32081363830376\n",
      "##### BaggingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.304\n",
      "Train inference error (RMSE): ±0.5514163196539802\n",
      "Test MSE: 1.608\n",
      "Test inference error (RMSE): ±1.2682494034319132\n",
      "##### BaggingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.665\n",
      "Train inference error (RMSE): ±0.8156832637430611\n",
      "Test MSE: 1.176\n",
      "Test inference error (RMSE): ±1.0842817402057001\n",
      "##### BaggingRegressor - PLSCanonical #####\n",
      "Error (BaggingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BaggingRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07631992744320033\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08492409351703599\n",
      "##### BaggingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.330\n",
      "Train inference error (RMSE): ±0.5741942534785985\n",
      "Test MSE: 1.766\n",
      "Test inference error (RMSE): ±1.3289070420043987\n",
      "##### BaggingRegressor - PoissonRegressor #####\n",
      "Error (BaggingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### BaggingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.304\n",
      "Train inference error (RMSE): ±0.5509691184031703\n",
      "Test MSE: 1.806\n",
      "Test inference error (RMSE): ±1.343707314357409\n",
      "##### BaggingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.537121884146785e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00010533465796660282\n",
      "##### BaggingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (BaggingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### BaggingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.217\n",
      "Train inference error (RMSE): ±0.46535581505042395\n",
      "Test MSE: 1.260\n",
      "Test inference error (RMSE): ±1.122685020092299\n",
      "##### BaggingRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001588834907192011\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018034626754939514\n",
      "##### BaggingRegressor - RidgeCV #####\n",
      "Train MSE: 0.346\n",
      "Train inference error (RMSE): ±0.5882881336488492\n",
      "Test MSE: 1.641\n",
      "Test inference error (RMSE): ±1.2809944584922424\n",
      "##### BaggingRegressor - SGDRegressor #####\n",
      "Train MSE: 12687563854543851593028764157305920573234771101889810961114294460319689347069640704.000\n",
      "Train inference error (RMSE): ±1.1263908670858377e+41\n",
      "Test MSE: 13283563498627850091944268419610532129929244165116487384686459348420731874364620800.000\n",
      "Test inference error (RMSE): ±1.1525434264541986e+41\n",
      "##### BaggingRegressor - SVR #####\n",
      "Train MSE: 0.296\n",
      "Train inference error (RMSE): ±0.5440736918782288\n",
      "Test MSE: 1.912\n",
      "Test inference error (RMSE): ±1.382814240294073\n",
      "##### BaggingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.046942421015105e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011036301451237768\n",
      "##### BaggingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.787638465125828e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00010459220720363004\n",
      "##### BaggingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.349\n",
      "Train inference error (RMSE): ±0.5906871035180276\n",
      "Test MSE: 1.985\n",
      "Test inference error (RMSE): ±1.408970471665645\n",
      "##### BayesianRidge - CCA #####\n",
      "Error (BayesianRidge-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BayesianRidge - DecisionTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.866045936748468e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.726455987000679e-05\n",
      "##### BayesianRidge - DummyRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312898464815449e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429403741171258e-05\n",
      "##### BayesianRidge - ElasticNet #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647203482351617\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019388374427706717\n",
      "##### BayesianRidge - ElasticNetCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293110845834011e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5347324639749874e-05\n",
      "##### BayesianRidge - ExtraTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.444544580963723e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.165758701866565e-05\n",
      "##### BayesianRidge - ExtraTreesRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.560491779610407e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00014857346716338313\n",
      "##### BayesianRidge - GammaRegressor #####\n",
      "Error (BayesianRidge-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### BayesianRidge - GaussianProcessRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293693866812926e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409708741600751e-05\n",
      "##### BayesianRidge - GradientBoostingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00010322260100556362\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019099559906431016\n",
      "##### BayesianRidge - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.762877335086453e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001934425087397358\n",
      "##### BayesianRidge - HuberRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.325104261915307e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.69800533700041e-05\n",
      "##### BayesianRidge - IsotonicRegression #####\n",
      "Error (BayesianRidge-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### BayesianRidge - KNeighborsRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.665902463071066e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.78213893522889e-05\n",
      "##### BayesianRidge - KernelRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.311031232985474e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.3869376426397786e-05\n",
      "##### BayesianRidge - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468025174096103e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048087552453687e-05\n",
      "##### BayesianRidge - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468025174096103e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048087552453687e-05\n",
      "##### BayesianRidge - Lasso #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383101369423178e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.970031826181127e-05\n",
      "##### BayesianRidge - LassoCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2931171043250946e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534738843129744e-05\n",
      "##### BayesianRidge - LassoLars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383100947820229e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.97003129742082e-05\n",
      "##### BayesianRidge - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468019921625234e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048082158280416e-05\n",
      "##### BayesianRidge - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468019921625234e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048082158280416e-05\n",
      "##### BayesianRidge - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146855043026603e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.204862642666346e-05\n",
      "##### BayesianRidge - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293693866812926e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409708741600751e-05\n",
      "##### BayesianRidge - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.303598606822872e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.78304770881362e-05\n",
      "##### BayesianRidge - MultiTaskElasticNet #####\n",
      "Error (BayesianRidge-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### BayesianRidge - MultiTaskElasticNetCV #####\n",
      "Error (BayesianRidge-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### BayesianRidge - MultiTaskLasso #####\n",
      "Error (BayesianRidge-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### BayesianRidge - MultiTaskLassoCV #####\n",
      "Error (BayesianRidge-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### BayesianRidge - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312016359370785e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.420835734328218e-05\n",
      "##### BayesianRidge - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293276805474052e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.544492925171723e-05\n",
      "##### BayesianRidge - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00013489396597898397\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00015222882707804317\n",
      "##### BayesianRidge - PLSCanonical #####\n",
      "Error (BayesianRidge-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BayesianRidge - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001494139160130748\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809068609855854\n",
      "##### BayesianRidge - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.309183030169788e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.3947206864809744e-05\n",
      "##### BayesianRidge - PoissonRegressor #####\n",
      "Error (BayesianRidge-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### BayesianRidge - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299906497454019e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.610100917971675e-05\n",
      "##### BayesianRidge - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146855043026603e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.204862642666346e-05\n",
      "##### BayesianRidge - RadiusNeighborsRegressor #####\n",
      "Error (BayesianRidge-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### BayesianRidge - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.033666047239527e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012241571208952495\n",
      "##### BayesianRidge - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281274548821361\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0009018681935256756\n",
      "##### BayesianRidge - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.284061308248332e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.740561653874102e-05\n",
      "##### BayesianRidge - SGDRegressor #####\n",
      "Train MSE: 2696684873857836223832109336502160801783430770146643272641648378268780711115826921472.000\n",
      "Train inference error (RMSE): ±1.642158601919387e+42\n",
      "Test MSE: 2805255515324035620485628260851137534838145781551299985183796528600244216357944557568.000\n",
      "Test inference error (RMSE): ±1.6748897024353682e+42\n",
      "##### BayesianRidge - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299938507872341e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4080103255146056e-05\n",
      "##### BayesianRidge - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146700339838635e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2051242807877492e-05\n",
      "##### BayesianRidge - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146855043026603e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.204862642666346e-05\n",
      "##### BayesianRidge - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312853709810072e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4292924305769234e-05\n",
      "##### CCA - DecisionTreeRegressor #####\n",
      "Error (CCA-DecisionTreeRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - DummyRegressor #####\n",
      "Error (CCA-DummyRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ElasticNet #####\n",
      "Error (CCA-ElasticNet): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ElasticNetCV #####\n",
      "Error (CCA-ElasticNetCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ExtraTreeRegressor #####\n",
      "Error (CCA-ExtraTreeRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ExtraTreesRegressor #####\n",
      "Error (CCA-ExtraTreesRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GammaRegressor #####\n",
      "Error (CCA-GammaRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GaussianProcessRegressor #####\n",
      "Error (CCA-GaussianProcessRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GradientBoostingRegressor #####\n",
      "Error (CCA-GradientBoostingRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - HistGradientBoostingRegressor #####\n",
      "Error (CCA-HistGradientBoostingRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - HuberRegressor #####\n",
      "Error (CCA-HuberRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - IsotonicRegression #####\n",
      "Error (CCA-IsotonicRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - KNeighborsRegressor #####\n",
      "Error (CCA-KNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - KernelRidge #####\n",
      "Error (CCA-KernelRidge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Lars #####\n",
      "Error (CCA-Lars): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LarsCV #####\n",
      "Error (CCA-LarsCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Lasso #####\n",
      "Error (CCA-Lasso): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoCV #####\n",
      "Error (CCA-LassoCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLars #####\n",
      "Error (CCA-LassoLars): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLarsCV #####\n",
      "Error (CCA-LassoLarsCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLarsIC #####\n",
      "Error (CCA-LassoLarsIC): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LinearRegression #####\n",
      "Error (CCA-LinearRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LinearSVR #####\n",
      "Error (CCA-LinearSVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MLPRegressor #####\n",
      "Error (CCA-MLPRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskElasticNet #####\n",
      "Error (CCA-MultiTaskElasticNet): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskElasticNetCV #####\n",
      "Error (CCA-MultiTaskElasticNetCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskLasso #####\n",
      "Error (CCA-MultiTaskLasso): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskLassoCV #####\n",
      "Error (CCA-MultiTaskLassoCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - NuSVR #####\n",
      "Error (CCA-NuSVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - OrthogonalMatchingPursuit #####\n",
      "Error (CCA-OrthogonalMatchingPursuit): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - OrthogonalMatchingPursuitCV #####\n",
      "Error (CCA-OrthogonalMatchingPursuitCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PLSCanonical #####\n",
      "Error (CCA-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PLSRegression #####\n",
      "Error (CCA-PLSRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PassiveAggressiveRegressor #####\n",
      "Error (CCA-PassiveAggressiveRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PoissonRegressor #####\n",
      "Error (CCA-PoissonRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - QuantileRegressor #####\n",
      "Error (CCA-QuantileRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RANSACRegressor #####\n",
      "Error (CCA-RANSACRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RadiusNeighborsRegressor #####\n",
      "Error (CCA-RadiusNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RandomForestRegressor #####\n",
      "Error (CCA-RandomForestRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Ridge #####\n",
      "Error (CCA-Ridge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RidgeCV #####\n",
      "Error (CCA-RidgeCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - SGDRegressor #####\n",
      "Error (CCA-SGDRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - SVR #####\n",
      "Error (CCA-SVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TheilSenRegressor #####\n",
      "Error (CCA-TheilSenRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TransformedTargetRegressor #####\n",
      "Error (CCA-TransformedTargetRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TweedieRegressor #####\n",
      "Error (CCA-TweedieRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor - DummyRegressor #####\n",
      "Train MSE: 0.222\n",
      "Train inference error (RMSE): ±0.47064582731504523\n",
      "Test MSE: 3.709\n",
      "Test inference error (RMSE): ±1.9258007890388138\n",
      "##### DecisionTreeRegressor - ElasticNet #####\n",
      "Train MSE: 0.959\n",
      "Train inference error (RMSE): ±0.9792391347350495\n",
      "Test MSE: 2.377\n",
      "Test inference error (RMSE): ±1.541777649415054\n",
      "##### DecisionTreeRegressor - ElasticNetCV #####\n",
      "Train MSE: 0.220\n",
      "Train inference error (RMSE): ±0.46860358229561655\n",
      "Test MSE: 3.394\n",
      "Test inference error (RMSE): ±1.8422360030971874\n",
      "##### DecisionTreeRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.007\n",
      "Train inference error (RMSE): ±0.08446916528025813\n",
      "Test MSE: 2.523\n",
      "Test inference error (RMSE): ±1.5883386802460338\n",
      "##### DecisionTreeRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.280\n",
      "Train inference error (RMSE): ±0.528886037821568\n",
      "Test MSE: 0.985\n",
      "Test inference error (RMSE): ±0.9925320921938873\n",
      "##### DecisionTreeRegressor - GammaRegressor #####\n",
      "Error (DecisionTreeRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### DecisionTreeRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.249\n",
      "Train inference error (RMSE): ±0.49879199963886084\n",
      "Test MSE: 3.507\n",
      "Test inference error (RMSE): ±1.8725720385156026\n",
      "##### DecisionTreeRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.149\n",
      "Train inference error (RMSE): ±0.3858607248952663\n",
      "Test MSE: 0.522\n",
      "Test inference error (RMSE): ±0.7221507652903146\n",
      "##### DecisionTreeRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.089\n",
      "Train inference error (RMSE): ±0.2987633243788361\n",
      "Test MSE: 0.598\n",
      "Test inference error (RMSE): ±0.7733894854531093\n",
      "##### DecisionTreeRegressor - HuberRegressor #####\n",
      "Train MSE: 0.243\n",
      "Train inference error (RMSE): ±0.49318091092017813\n",
      "Test MSE: 3.436\n",
      "Test inference error (RMSE): ±1.8537032242958482\n",
      "##### DecisionTreeRegressor - IsotonicRegression #####\n",
      "Error (DecisionTreeRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### DecisionTreeRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.187\n",
      "Train inference error (RMSE): ±0.43232465125936315\n",
      "Test MSE: 3.810\n",
      "Test inference error (RMSE): ±1.9519424692471914\n",
      "##### DecisionTreeRegressor - KernelRidge #####\n",
      "Train MSE: 0.191\n",
      "Train inference error (RMSE): ±0.43712401979208887\n",
      "Test MSE: 3.543\n",
      "Test inference error (RMSE): ±1.8823596192311496\n",
      "##### DecisionTreeRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.928482145609009e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.70638873093614e-05\n",
      "##### DecisionTreeRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.8805210684223123e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.969487513566626e-05\n",
      "##### DecisionTreeRegressor - Lasso #####\n",
      "Train MSE: 1.096\n",
      "Train inference error (RMSE): ±1.0469448324274997\n",
      "Test MSE: 3.329\n",
      "Test inference error (RMSE): ±1.8244404012234567\n",
      "##### DecisionTreeRegressor - LassoCV #####\n",
      "Train MSE: 0.206\n",
      "Train inference error (RMSE): ±0.45370941431687756\n",
      "Test MSE: 3.301\n",
      "Test inference error (RMSE): ±1.8168556198052548\n",
      "##### DecisionTreeRegressor - LassoLars #####\n",
      "Train MSE: 1.010\n",
      "Train inference error (RMSE): ±1.0047563286669174\n",
      "Test MSE: 3.234\n",
      "Test inference error (RMSE): ±1.7983914140483657\n",
      "##### DecisionTreeRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.0519204879864184e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.961034687226196e-05\n",
      "##### DecisionTreeRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9572746730585323e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.941473602948464e-05\n",
      "##### DecisionTreeRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.7885769378054968e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.961767026552893e-05\n",
      "##### DecisionTreeRegressor - LinearSVR #####\n",
      "Train MSE: 0.251\n",
      "Train inference error (RMSE): ±0.5005385384544149\n",
      "Test MSE: 3.358\n",
      "Test inference error (RMSE): ±1.8324838637677445\n",
      "##### DecisionTreeRegressor - MLPRegressor #####\n",
      "Train MSE: 0.547\n",
      "Train inference error (RMSE): ±0.7396465378346345\n",
      "Test MSE: 3.635\n",
      "Test inference error (RMSE): ±1.9065265057883458\n",
      "##### DecisionTreeRegressor - MultiTaskElasticNet #####\n",
      "Error (DecisionTreeRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### DecisionTreeRegressor - MultiTaskElasticNetCV #####\n",
      "Error (DecisionTreeRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### DecisionTreeRegressor - MultiTaskLasso #####\n",
      "Error (DecisionTreeRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### DecisionTreeRegressor - MultiTaskLassoCV #####\n",
      "Error (DecisionTreeRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### DecisionTreeRegressor - NuSVR #####\n",
      "Train MSE: 0.271\n",
      "Train inference error (RMSE): ±0.5203103426344171\n",
      "Test MSE: 3.507\n",
      "Test inference error (RMSE): ±1.872663176552838\n",
      "##### DecisionTreeRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.267\n",
      "Train inference error (RMSE): ±0.5171745984663286\n",
      "Test MSE: 3.585\n",
      "Test inference error (RMSE): ±1.8934514879437057\n",
      "##### DecisionTreeRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.924\n",
      "Train inference error (RMSE): ±0.9612289455254766\n",
      "Test MSE: 1.287\n",
      "Test inference error (RMSE): ±1.1346625171781146\n",
      "##### DecisionTreeRegressor - PLSCanonical #####\n",
      "Error (DecisionTreeRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07645904207565174\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08593222576053337\n",
      "##### DecisionTreeRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.252\n",
      "Train inference error (RMSE): ±0.5023104677449153\n",
      "Test MSE: 3.374\n",
      "Test inference error (RMSE): ±1.836844230780667\n",
      "##### DecisionTreeRegressor - PoissonRegressor #####\n",
      "Error (DecisionTreeRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### DecisionTreeRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.240\n",
      "Train inference error (RMSE): ±0.48994558040834796\n",
      "Test MSE: 3.536\n",
      "Test inference error (RMSE): ±1.8804082580310812\n",
      "##### DecisionTreeRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.8321736817862945e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.905684792811216e-05\n",
      "##### DecisionTreeRegressor - RadiusNeighborsRegressor #####\n",
      "Error (DecisionTreeRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### DecisionTreeRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.237\n",
      "Train inference error (RMSE): ±0.48720502952828243\n",
      "Test MSE: 1.397\n",
      "Test inference error (RMSE): ±1.1821398106592804\n",
      "##### DecisionTreeRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016287387323971664\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018139579746759582\n",
      "##### DecisionTreeRegressor - RidgeCV #####\n",
      "Train MSE: 0.325\n",
      "Train inference error (RMSE): ±0.5697179249278118\n",
      "Test MSE: 4.055\n",
      "Test inference error (RMSE): ±2.013662811441703\n",
      "##### DecisionTreeRegressor - SGDRegressor #####\n",
      "Train MSE: 4207844165384927731204127322494896135211432856797398461737855447869551899291156480.000\n",
      "Train inference error (RMSE): ±6.48678978030345e+40\n",
      "Test MSE: 4409372026527468754012967894890462930587663283705661934533678297265248381091971072.000\n",
      "Test inference error (RMSE): ±6.640310253691065e+40\n",
      "##### DecisionTreeRegressor - SVR #####\n",
      "Train MSE: 0.270\n",
      "Train inference error (RMSE): ±0.5199040604682993\n",
      "Test MSE: 3.450\n",
      "Test inference error (RMSE): ±1.8574831176838922\n",
      "##### DecisionTreeRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.8972377538384308e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.989473750110381e-05\n",
      "##### DecisionTreeRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.0622547429108178e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.789616413393896e-05\n",
      "##### DecisionTreeRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.289\n",
      "Train inference error (RMSE): ±0.5378365122205976\n",
      "Test MSE: 3.503\n",
      "Test inference error (RMSE): ±1.8716803233258006\n",
      "##### DummyRegressor - ElasticNet #####\n",
      "Train MSE: 1.146\n",
      "Train inference error (RMSE): ±1.0706806717919408\n",
      "Test MSE: 2.687\n",
      "Test inference error (RMSE): ±1.6391688475395745\n",
      "##### DummyRegressor - ElasticNetCV #####\n",
      "Train MSE: 11.083\n",
      "Train inference error (RMSE): ±3.3290763469173985\n",
      "Test MSE: 12.489\n",
      "Test inference error (RMSE): ±3.5340211865900715\n",
      "##### DummyRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.510\n",
      "Train inference error (RMSE): ±0.7144185087761201\n",
      "Test MSE: 4.734\n",
      "Test inference error (RMSE): ±2.1757005878798648\n",
      "##### DummyRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.284\n",
      "Train inference error (RMSE): ±0.5332542630499258\n",
      "Test MSE: 1.030\n",
      "Test inference error (RMSE): ±1.0146968389934157\n",
      "##### DummyRegressor - GammaRegressor #####\n",
      "Error (DummyRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### DummyRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.3413737407477635\n",
      "Test MSE: 11.776\n",
      "Test inference error (RMSE): ±3.4316063147276483\n",
      "##### DummyRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.3845025653747305\n",
      "Test MSE: 0.516\n",
      "Test inference error (RMSE): ±0.7182023751020865\n",
      "##### DummyRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.093\n",
      "Train inference error (RMSE): ±0.3048276678569205\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.7718444480787703\n",
      "##### DummyRegressor - HuberRegressor #####\n",
      "Train MSE: 11.075\n",
      "Train inference error (RMSE): ±3.327875573490789\n",
      "Test MSE: 12.724\n",
      "Test inference error (RMSE): ±3.5670960790035866\n",
      "##### DummyRegressor - IsotonicRegression #####\n",
      "Error (DummyRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### DummyRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 6.165\n",
      "Train inference error (RMSE): ±2.4829355951042817\n",
      "Test MSE: 15.330\n",
      "Test inference error (RMSE): ±3.9153118981148682\n",
      "##### DummyRegressor - KernelRidge #####\n",
      "Train MSE: 11.164\n",
      "Train inference error (RMSE): ±3.341269589312035\n",
      "Test MSE: 11.787\n",
      "Test inference error (RMSE): ±3.433278890398124\n",
      "##### DummyRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3129445908036826e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4294062411462926e-05\n",
      "##### DummyRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3129445908036826e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4294062411462926e-05\n",
      "##### DummyRegressor - Lasso #####\n",
      "Train MSE: 3.522\n",
      "Train inference error (RMSE): ±1.8766012071004905\n",
      "Test MSE: 6.398\n",
      "Test inference error (RMSE): ±2.5294950064307593\n",
      "##### DummyRegressor - LassoCV #####\n",
      "Train MSE: 11.083\n",
      "Train inference error (RMSE): ±3.329076346911444\n",
      "Test MSE: 12.489\n",
      "Test inference error (RMSE): ±3.534021186714437\n",
      "##### DummyRegressor - LassoLars #####\n",
      "Train MSE: 3.522\n",
      "Train inference error (RMSE): ±1.8766011629737045\n",
      "Test MSE: 6.398\n",
      "Test inference error (RMSE): ±2.529494917008289\n",
      "##### DummyRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3129339436607565e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429395306419426e-05\n",
      "##### DummyRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3129339436607565e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429395306419426e-05\n",
      "##### DummyRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3129445134644124e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429406048208044e-05\n",
      "##### DummyRegressor - LinearSVR #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.3413737407477635\n",
      "Test MSE: 11.776\n",
      "Test inference error (RMSE): ±3.4316063147276483\n",
      "##### DummyRegressor - MLPRegressor #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.341373959885735\n",
      "Test MSE: 11.780\n",
      "Test inference error (RMSE): ±3.4322569374047283\n",
      "##### DummyRegressor - MultiTaskElasticNet #####\n",
      "Error (DummyRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### DummyRegressor - MultiTaskElasticNetCV #####\n",
      "Error (DummyRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### DummyRegressor - MultiTaskLasso #####\n",
      "Error (DummyRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### DummyRegressor - MultiTaskLassoCV #####\n",
      "Error (DummyRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### DummyRegressor - NuSVR #####\n",
      "Train MSE: 11.152\n",
      "Train inference error (RMSE): ±3.3394454243751452\n",
      "Test MSE: 11.794\n",
      "Test inference error (RMSE): ±3.434169905142021\n",
      "##### DummyRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.080\n",
      "Train inference error (RMSE): ±3.3287304219201816\n",
      "Test MSE: 12.544\n",
      "Test inference error (RMSE): ±3.5417334376655063\n",
      "##### DummyRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.048628341652623\n",
      "Test MSE: 1.400\n",
      "Test inference error (RMSE): ±1.1834264148180238\n",
      "##### DummyRegressor - PLSCanonical #####\n",
      "Error (DummyRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DummyRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07624855396472958\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08581770770900515\n",
      "##### DummyRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.341415811230969\n",
      "Test MSE: 11.801\n",
      "Test inference error (RMSE): ±3.4352267536342964\n",
      "##### DummyRegressor - PoissonRegressor #####\n",
      "Error (DummyRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### DummyRegressor - QuantileRegressor #####\n",
      "Train MSE: 11.074\n",
      "Train inference error (RMSE): ±3.3277889975531183\n",
      "Test MSE: 12.753\n",
      "Test inference error (RMSE): ±3.571115492581073\n",
      "##### DummyRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3129445134644124e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429406048208044e-05\n",
      "##### DummyRegressor - RadiusNeighborsRegressor #####\n",
      "Error (DummyRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### DummyRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.207\n",
      "Train inference error (RMSE): ±0.455108499328056\n",
      "Test MSE: 1.271\n",
      "Test inference error (RMSE): ±1.1271794148857095\n",
      "##### DummyRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016615739436544067\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018113138426981317\n",
      "##### DummyRegressor - RidgeCV #####\n",
      "Train MSE: 11.088\n",
      "Train inference error (RMSE): ±3.3298570286009737\n",
      "Test MSE: 13.664\n",
      "Test inference error (RMSE): ±3.6964239591278507\n",
      "##### DummyRegressor - SGDRegressor #####\n",
      "Train MSE: 15450893510010979808322267903945824592494976790479684383832054003141216620882427904.000\n",
      "Train inference error (RMSE): ±1.243016231189721e+41\n",
      "Test MSE: 15915946243929277340858051052438398707164924352740799887990596453421858887412219904.000\n",
      "Test inference error (RMSE): ±1.2615841725358351e+41\n",
      "##### DummyRegressor - SVR #####\n",
      "Train MSE: 11.168\n",
      "Train inference error (RMSE): ±3.3418727559414676\n",
      "Test MSE: 11.760\n",
      "Test inference error (RMSE): ±3.429310435208654\n",
      "##### DummyRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.311753229995126e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.427120204198515e-05\n",
      "##### DummyRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3129445134644124e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429406048208044e-05\n",
      "##### DummyRegressor - TweedieRegressor #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.3413782030858696\n",
      "Test MSE: 11.776\n",
      "Test inference error (RMSE): ±3.431586536416981\n",
      "##### ElasticNet - ElasticNetCV #####\n",
      "Train MSE: 1.009\n",
      "Train inference error (RMSE): ±1.004715993324081\n",
      "Test MSE: 1.318\n",
      "Test inference error (RMSE): ±1.147925237267078\n",
      "##### ElasticNet - ExtraTreeRegressor #####\n",
      "Train MSE: 0.958\n",
      "Train inference error (RMSE): ±0.9787511046363736\n",
      "Test MSE: 2.510\n",
      "Test inference error (RMSE): ±1.5842155591866574\n",
      "##### ElasticNet - ExtraTreesRegressor #####\n",
      "Train MSE: 0.184\n",
      "Train inference error (RMSE): ±0.42873020279938445\n",
      "Test MSE: 1.153\n",
      "Test inference error (RMSE): ±1.0737957440497456\n",
      "##### ElasticNet - GammaRegressor #####\n",
      "Error (ElasticNet-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ElasticNet - GaussianProcessRegressor #####\n",
      "Train MSE: 1.146\n",
      "Train inference error (RMSE): ±1.070581677811733\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.6412101083720043\n",
      "##### ElasticNet - GradientBoostingRegressor #####\n",
      "Train MSE: 0.154\n",
      "Train inference error (RMSE): ±0.39218721825012687\n",
      "Test MSE: 0.562\n",
      "Test inference error (RMSE): ±0.7499908455338724\n",
      "##### ElasticNet - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.098\n",
      "Train inference error (RMSE): ±0.31291793740191537\n",
      "Test MSE: 0.607\n",
      "Test inference error (RMSE): ±0.779094060183382\n",
      "##### ElasticNet - HuberRegressor #####\n",
      "Train MSE: 1.022\n",
      "Train inference error (RMSE): ±1.0108088799377353\n",
      "Test MSE: 1.551\n",
      "Test inference error (RMSE): ±1.2454460133459122\n",
      "##### ElasticNet - IsotonicRegression #####\n",
      "Error (ElasticNet-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ElasticNet - KNeighborsRegressor #####\n",
      "Train MSE: 1.033\n",
      "Train inference error (RMSE): ±1.0162102851877952\n",
      "Test MSE: 3.273\n",
      "Test inference error (RMSE): ±1.809242306421163\n",
      "##### ElasticNet - KernelRidge #####\n",
      "Train MSE: 1.182\n",
      "Train inference error (RMSE): ±1.0870335633828725\n",
      "Test MSE: 2.065\n",
      "Test inference error (RMSE): ±1.437008617384213\n",
      "##### ElasticNet - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647106792554108\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001938811242659441\n",
      "##### ElasticNet - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647106792554108\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001938811242659441\n",
      "##### ElasticNet - Lasso #####\n",
      "Train MSE: 0.632\n",
      "Train inference error (RMSE): ±0.795132971251329\n",
      "Test MSE: 1.329\n",
      "Test inference error (RMSE): ±1.1529366544736166\n",
      "##### ElasticNet - LassoCV #####\n",
      "Train MSE: 1.009\n",
      "Train inference error (RMSE): ±1.0047159933250243\n",
      "Test MSE: 1.318\n",
      "Test inference error (RMSE): ±1.1479252371286823\n",
      "##### ElasticNet - LassoLars #####\n",
      "Train MSE: 0.632\n",
      "Train inference error (RMSE): ±0.7951329819145209\n",
      "Test MSE: 1.329\n",
      "Test inference error (RMSE): ±1.1529367147612903\n",
      "##### ElasticNet - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647099856391211\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019388104063821227\n",
      "##### ElasticNet - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647099856391211\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019388104063821227\n",
      "##### ElasticNet - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647113272722923\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001938812578922403\n",
      "##### ElasticNet - LinearSVR #####\n",
      "Train MSE: 1.146\n",
      "Train inference error (RMSE): ±1.070581677811733\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.6412101083720043\n",
      "##### ElasticNet - MLPRegressor #####\n",
      "Train MSE: 1.146\n",
      "Train inference error (RMSE): ±1.0707074533792904\n",
      "Test MSE: 2.716\n",
      "Test inference error (RMSE): ±1.647936350394121\n",
      "##### ElasticNet - MultiTaskElasticNet #####\n",
      "Error (ElasticNet-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNet - MultiTaskElasticNetCV #####\n",
      "Error (ElasticNet-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ElasticNet - MultiTaskLasso #####\n",
      "Error (ElasticNet-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNet - MultiTaskLassoCV #####\n",
      "Error (ElasticNet-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ElasticNet - NuSVR #####\n",
      "Train MSE: 1.141\n",
      "Train inference error (RMSE): ±1.068006811624617\n",
      "Test MSE: 2.689\n",
      "Test inference error (RMSE): ±1.6397444300984159\n",
      "##### ElasticNet - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 1.010\n",
      "Train inference error (RMSE): ±1.0048533901404009\n",
      "Test MSE: 1.301\n",
      "Test inference error (RMSE): ±1.1404923789828656\n",
      "##### ElasticNet - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.975\n",
      "Train inference error (RMSE): ±0.9874610088036345\n",
      "Test MSE: 1.606\n",
      "Test inference error (RMSE): ±1.2673250635387259\n",
      "##### ElasticNet - PLSCanonical #####\n",
      "Error (ElasticNet-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ElasticNet - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07536772400130556\n",
      "Test MSE: 0.006\n",
      "Test inference error (RMSE): ±0.07935521830825705\n",
      "##### ElasticNet - PassiveAggressiveRegressor #####\n",
      "Train MSE: 1.146\n",
      "Train inference error (RMSE): ±1.0706518523801554\n",
      "Test MSE: 2.676\n",
      "Test inference error (RMSE): ±1.6358446157954312\n",
      "##### ElasticNet - PoissonRegressor #####\n",
      "Error (ElasticNet-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ElasticNet - QuantileRegressor #####\n",
      "Train MSE: 1.010\n",
      "Train inference error (RMSE): ±1.005113470611584\n",
      "Test MSE: 1.289\n",
      "Test inference error (RMSE): ±1.135398296390564\n",
      "##### ElasticNet - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647113272722923\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001938812578922403\n",
      "##### ElasticNet - RadiusNeighborsRegressor #####\n",
      "Error (ElasticNet-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ElasticNet - RandomForestRegressor #####\n",
      "Train MSE: 0.513\n",
      "Train inference error (RMSE): ±0.7163784829653942\n",
      "Test MSE: 1.603\n",
      "Test inference error (RMSE): ±1.2662782969783695\n",
      "##### ElasticNet - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015592275155298615\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001551988620951767\n",
      "##### ElasticNet - RidgeCV #####\n",
      "Train MSE: 1.151\n",
      "Train inference error (RMSE): ±1.073065637272551\n",
      "Test MSE: 1.715\n",
      "Test inference error (RMSE): ±1.309748075088655\n",
      "##### ElasticNet - SGDRegressor #####\n",
      "Train MSE: 185016713531268073196957307711295337839973583970353398821985384970767091586408906752.000\n",
      "Train inference error (RMSE): ±4.3013569199877854e+41\n",
      "Test MSE: 193351724135373680932034802738119001870508481011173632271241586056299253347957866496.000\n",
      "Test inference error (RMSE): ±4.397177778250201e+41\n",
      "##### ElasticNet - SVR #####\n",
      "Train MSE: 1.140\n",
      "Train inference error (RMSE): ±1.0675624135777984\n",
      "Test MSE: 2.622\n",
      "Test inference error (RMSE): ±1.619409820360541\n",
      "##### ElasticNet - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647062433520344\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019385525710976568\n",
      "##### ElasticNet - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012647113272722923\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001938812578922403\n",
      "##### ElasticNet - TweedieRegressor #####\n",
      "Train MSE: 1.146\n",
      "Train inference error (RMSE): ±1.0706797182465921\n",
      "Test MSE: 2.687\n",
      "Test inference error (RMSE): ±1.6391633652962583\n",
      "##### ElasticNetCV - ExtraTreeRegressor #####\n",
      "Train MSE: 0.430\n",
      "Train inference error (RMSE): ±0.6557714082342962\n",
      "Test MSE: 4.626\n",
      "Test inference error (RMSE): ±2.1507194487355323\n",
      "##### ElasticNetCV - ExtraTreesRegressor #####\n",
      "Train MSE: 0.260\n",
      "Train inference error (RMSE): ±0.5102013529633589\n",
      "Test MSE: 0.996\n",
      "Test inference error (RMSE): ±0.9981865005209379\n",
      "##### ElasticNetCV - GammaRegressor #####\n",
      "Error (ElasticNetCV-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ElasticNetCV - GaussianProcessRegressor #####\n",
      "Train MSE: 11.095\n",
      "Train inference error (RMSE): ±3.3308927732623057\n",
      "Test MSE: 12.281\n",
      "Test inference error (RMSE): ±3.504368918909032\n",
      "##### ElasticNetCV - GradientBoostingRegressor #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.3842261145878674\n",
      "Test MSE: 0.519\n",
      "Test inference error (RMSE): ±0.7205170602271989\n",
      "##### ElasticNetCV - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.094\n",
      "Train inference error (RMSE): ±0.3061997141682317\n",
      "Test MSE: 0.601\n",
      "Test inference error (RMSE): ±0.7750887660899048\n",
      "##### ElasticNetCV - HuberRegressor #####\n",
      "Train MSE: 11.075\n",
      "Train inference error (RMSE): ±3.3278709581214625\n",
      "Test MSE: 12.725\n",
      "Test inference error (RMSE): ±3.567187743190464\n",
      "##### ElasticNetCV - IsotonicRegression #####\n",
      "Error (ElasticNetCV-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ElasticNetCV - KNeighborsRegressor #####\n",
      "Train MSE: 6.174\n",
      "Train inference error (RMSE): ±2.4846842718226005\n",
      "Test MSE: 15.254\n",
      "Test inference error (RMSE): ±3.90566146537378\n",
      "##### ElasticNetCV - KernelRidge #####\n",
      "Train MSE: 11.206\n",
      "Train inference error (RMSE): ±3.347588640882133\n",
      "Test MSE: 11.913\n",
      "Test inference error (RMSE): ±3.451510391797372\n",
      "##### ElasticNetCV - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293155414660654e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534598371314901e-05\n",
      "##### ElasticNetCV - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293155414660654e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534598371314901e-05\n",
      "##### ElasticNetCV - Lasso #####\n",
      "Train MSE: 3.416\n",
      "Train inference error (RMSE): ±1.8482561023830153\n",
      "Test MSE: 4.573\n",
      "Test inference error (RMSE): ±2.138409275334163\n",
      "##### ElasticNetCV - LassoCV #####\n",
      "Train MSE: 11.092\n",
      "Train inference error (RMSE): ±3.330454214195521\n",
      "Test MSE: 12.323\n",
      "Test inference error (RMSE): ±3.510389157516197\n",
      "##### ElasticNetCV - LassoLars #####\n",
      "Train MSE: 3.416\n",
      "Train inference error (RMSE): ±1.8482560638745056\n",
      "Test MSE: 4.573\n",
      "Test inference error (RMSE): ±2.138409221511303\n",
      "##### ElasticNetCV - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2931510128416816e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5345938791351596e-05\n",
      "##### ElasticNetCV - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2931510128416816e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5345938791351596e-05\n",
      "##### ElasticNetCV - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293173941706956e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534634398462252e-05\n",
      "##### ElasticNetCV - LinearSVR #####\n",
      "Train MSE: 11.095\n",
      "Train inference error (RMSE): ±3.3308927732623057\n",
      "Test MSE: 12.281\n",
      "Test inference error (RMSE): ±3.504368918909032\n",
      "##### ElasticNetCV - MLPRegressor #####\n",
      "Train MSE: 12.187\n",
      "Train inference error (RMSE): ±3.4910032264293913\n",
      "Test MSE: 15.275\n",
      "Test inference error (RMSE): ±3.908267649539602\n",
      "##### ElasticNetCV - MultiTaskElasticNet #####\n",
      "Error (ElasticNetCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNetCV - MultiTaskElasticNetCV #####\n",
      "Error (ElasticNetCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ElasticNetCV - MultiTaskLasso #####\n",
      "Error (ElasticNetCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNetCV - MultiTaskLassoCV #####\n",
      "Error (ElasticNetCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ElasticNetCV - NuSVR #####\n",
      "Train MSE: 11.091\n",
      "Train inference error (RMSE): ±3.3303287661511773\n",
      "Test MSE: 12.579\n",
      "Test inference error (RMSE): ±3.546737586473526\n",
      "##### ElasticNetCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.077\n",
      "Train inference error (RMSE): ±3.3281791341776334\n",
      "Test MSE: 12.651\n",
      "Test inference error (RMSE): ±3.556819854116902\n",
      "##### ElasticNetCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0487669839514941\n",
      "Test MSE: 1.380\n",
      "Test inference error (RMSE): ±1.1747553294655264\n",
      "##### ElasticNetCV - PLSCanonical #####\n",
      "Error (ElasticNetCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ElasticNetCV - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07634735525623226\n",
      "Test MSE: 0.006\n",
      "Test inference error (RMSE): ±0.07950422158959805\n",
      "##### ElasticNetCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.096\n",
      "Train inference error (RMSE): ±3.3311043987624855\n",
      "Test MSE: 12.227\n",
      "Test inference error (RMSE): ±3.49672985567393\n",
      "##### ElasticNetCV - PoissonRegressor #####\n",
      "Error (ElasticNetCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ElasticNetCV - QuantileRegressor #####\n",
      "Train MSE: 11.071\n",
      "Train inference error (RMSE): ±3.3273292919478914\n",
      "Test MSE: 12.977\n",
      "Test inference error (RMSE): ±3.602408434431557\n",
      "##### ElasticNetCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293173941706956e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534634398462252e-05\n",
      "##### ElasticNetCV - RadiusNeighborsRegressor #####\n",
      "Error (ElasticNetCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ElasticNetCV - RandomForestRegressor #####\n",
      "Train MSE: 0.205\n",
      "Train inference error (RMSE): ±0.45245151074868395\n",
      "Test MSE: 1.335\n",
      "Test inference error (RMSE): ±1.1553888519216042\n",
      "##### ElasticNetCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015799841662656588\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016218501626864216\n",
      "##### ElasticNetCV - RidgeCV #####\n",
      "Train MSE: 11.079\n",
      "Train inference error (RMSE): ±3.3284906375800722\n",
      "Test MSE: 12.676\n",
      "Test inference error (RMSE): ±3.560382987160953\n",
      "##### ElasticNetCV - SGDRegressor #####\n",
      "Train MSE: 50445359413608072689465400180102105566864164917284533117912197736644737914372096.000\n",
      "Train inference error (RMSE): ±7.102489663041269e+39\n",
      "Test MSE: 52297322809750737251250853638733386584022783553565088890604119829362759887224832.000\n",
      "Test inference error (RMSE): ±7.231688793757011e+39\n",
      "##### ElasticNetCV - SVR #####\n",
      "Train MSE: 11.093\n",
      "Train inference error (RMSE): ±3.330602071725022\n",
      "Test MSE: 12.297\n",
      "Test inference error (RMSE): ±3.506742367083882\n",
      "##### ElasticNetCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293077486096508e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534366077636017e-05\n",
      "##### ElasticNetCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293173941706956e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534634398462252e-05\n",
      "##### ElasticNetCV - TweedieRegressor #####\n",
      "Train MSE: 11.083\n",
      "Train inference error (RMSE): ±3.3290787909437363\n",
      "Test MSE: 12.489\n",
      "Test inference error (RMSE): ±3.533969897469793\n",
      "##### ExtraTreeRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.313\n",
      "Train inference error (RMSE): ±0.5594825749639141\n",
      "Test MSE: 0.985\n",
      "Test inference error (RMSE): ±0.9927065343695233\n",
      "##### ExtraTreeRegressor - GammaRegressor #####\n",
      "Error (ExtraTreeRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ExtraTreeRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.576\n",
      "Train inference error (RMSE): ±0.7586891119035328\n",
      "Test MSE: 4.722\n",
      "Test inference error (RMSE): ±2.1731165929579115\n",
      "##### ExtraTreeRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.151\n",
      "Train inference error (RMSE): ±0.38908514967330493\n",
      "Test MSE: 0.515\n",
      "Test inference error (RMSE): ±0.7178612265586579\n",
      "##### ExtraTreeRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.100\n",
      "Train inference error (RMSE): ±0.3157389279119003\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.771957212228424\n",
      "##### ExtraTreeRegressor - HuberRegressor #####\n",
      "Train MSE: 0.591\n",
      "Train inference error (RMSE): ±0.7689020169790208\n",
      "Test MSE: 4.355\n",
      "Test inference error (RMSE): ±2.0867712932139377\n",
      "##### ExtraTreeRegressor - IsotonicRegression #####\n",
      "Error (ExtraTreeRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ExtraTreeRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.309\n",
      "Train inference error (RMSE): ±0.5555466977836298\n",
      "Test MSE: 5.217\n",
      "Test inference error (RMSE): ±2.2840691246783726\n",
      "##### ExtraTreeRegressor - KernelRidge #####\n",
      "Train MSE: 0.559\n",
      "Train inference error (RMSE): ±0.7474086413049611\n",
      "Test MSE: 4.425\n",
      "Test inference error (RMSE): ±2.1035237312235795\n",
      "##### ExtraTreeRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.4925032464584836e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.048898402490441e-05\n",
      "##### ExtraTreeRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.445617285826615e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.565145732885591e-05\n",
      "##### ExtraTreeRegressor - Lasso #####\n",
      "Train MSE: 1.198\n",
      "Train inference error (RMSE): ±1.0947511407852482\n",
      "Test MSE: 3.922\n",
      "Test inference error (RMSE): ±1.980282365045709\n",
      "##### ExtraTreeRegressor - LassoCV #####\n",
      "Train MSE: 0.467\n",
      "Train inference error (RMSE): ±0.6834086162353116\n",
      "Test MSE: 4.293\n",
      "Test inference error (RMSE): ±2.0718427626367117\n",
      "##### ExtraTreeRegressor - LassoLars #####\n",
      "Train MSE: 1.264\n",
      "Train inference error (RMSE): ±1.1244885938657239\n",
      "Test MSE: 4.604\n",
      "Test inference error (RMSE): ±2.145697502515263\n",
      "##### ExtraTreeRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.564498367951823e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.096477016193402e-05\n",
      "##### ExtraTreeRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.4421465493114183e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.175585197465134e-05\n",
      "##### ExtraTreeRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.287967082508288e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.82168414714223e-05\n",
      "##### ExtraTreeRegressor - LinearSVR #####\n",
      "Train MSE: 0.540\n",
      "Train inference error (RMSE): ±0.7351031173788204\n",
      "Test MSE: 4.631\n",
      "Test inference error (RMSE): ±2.1520076953342517\n",
      "##### ExtraTreeRegressor - MLPRegressor #####\n",
      "Train MSE: 1.613\n",
      "Train inference error (RMSE): ±1.2700290838948467\n",
      "Test MSE: 5.274\n",
      "Test inference error (RMSE): ±2.2964979869334092\n",
      "##### ExtraTreeRegressor - MultiTaskElasticNet #####\n",
      "Error (ExtraTreeRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreeRegressor - MultiTaskElasticNetCV #####\n",
      "Error (ExtraTreeRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ExtraTreeRegressor - MultiTaskLasso #####\n",
      "Error (ExtraTreeRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreeRegressor - MultiTaskLassoCV #####\n",
      "Error (ExtraTreeRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ExtraTreeRegressor - NuSVR #####\n",
      "Train MSE: 0.557\n",
      "Train inference error (RMSE): ±0.7461179184058591\n",
      "Test MSE: 3.904\n",
      "Test inference error (RMSE): ±1.9759636992018816\n",
      "##### ExtraTreeRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.442\n",
      "Train inference error (RMSE): ±0.6644816699298748\n",
      "Test MSE: 4.302\n",
      "Test inference error (RMSE): ±2.074092193125726\n",
      "##### ExtraTreeRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.920\n",
      "Train inference error (RMSE): ±0.959041456841454\n",
      "Test MSE: 1.336\n",
      "Test inference error (RMSE): ±1.155709171502516\n",
      "##### ExtraTreeRegressor - PLSCanonical #####\n",
      "Error (ExtraTreeRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ExtraTreeRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07645102861269953\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08550078099813864\n",
      "##### ExtraTreeRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.633\n",
      "Train inference error (RMSE): ±0.7954153819927734\n",
      "Test MSE: 4.175\n",
      "Test inference error (RMSE): ±2.043284413318772\n",
      "##### ExtraTreeRegressor - PoissonRegressor #####\n",
      "Error (ExtraTreeRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ExtraTreeRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.521\n",
      "Train inference error (RMSE): ±0.7216478240791442\n",
      "Test MSE: 4.272\n",
      "Test inference error (RMSE): ±2.06686879817151\n",
      "##### ExtraTreeRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.4171780383409053e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.23519480135905e-05\n",
      "##### ExtraTreeRegressor - RadiusNeighborsRegressor #####\n",
      "Error (ExtraTreeRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ExtraTreeRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.201\n",
      "Train inference error (RMSE): ±0.44820295169398167\n",
      "Test MSE: 1.326\n",
      "Test inference error (RMSE): ±1.1515249984013747\n",
      "##### ExtraTreeRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016468797508217734\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018191055105190163\n",
      "##### ExtraTreeRegressor - RidgeCV #####\n",
      "Train MSE: 0.563\n",
      "Train inference error (RMSE): ±0.7504802624093942\n",
      "Test MSE: 4.635\n",
      "Test inference error (RMSE): ±2.153017101809075\n",
      "##### ExtraTreeRegressor - SGDRegressor #####\n",
      "Train MSE: 116881678760184702033890001906294715628877875274688208904622127635648631535566848.000\n",
      "Train inference error (RMSE): ±1.0811183041655743e+40\n",
      "Test MSE: 127643819553375387537782747930588005126899176580325795275899332903443632461185024.000\n",
      "Test inference error (RMSE): ±1.1297956432619813e+40\n",
      "##### ExtraTreeRegressor - SVR #####\n",
      "Train MSE: 0.711\n",
      "Train inference error (RMSE): ±0.8431028448772392\n",
      "Test MSE: 4.654\n",
      "Test inference error (RMSE): ±2.157249652696456\n",
      "##### ExtraTreeRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.20082953811312e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.695566315058928e-05\n",
      "##### ExtraTreeRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.2719792959656457e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.9998371041118e-05\n",
      "##### ExtraTreeRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.637\n",
      "Train inference error (RMSE): ±0.7978572496475052\n",
      "Test MSE: 4.676\n",
      "Test inference error (RMSE): ±2.1623650118720428\n",
      "##### ExtraTreesRegressor - GammaRegressor #####\n",
      "Error (ExtraTreesRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ExtraTreesRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.278\n",
      "Train inference error (RMSE): ±0.5267947956076126\n",
      "Test MSE: 0.991\n",
      "Test inference error (RMSE): ±0.9957079865464292\n",
      "##### ExtraTreesRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.160\n",
      "Train inference error (RMSE): ±0.39963898296583644\n",
      "Test MSE: 0.514\n",
      "Test inference error (RMSE): ±0.7170616445290716\n",
      "##### ExtraTreesRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.125\n",
      "Train inference error (RMSE): ±0.3534168364537432\n",
      "Test MSE: 0.579\n",
      "Test inference error (RMSE): ±0.7611249554771532\n",
      "##### ExtraTreesRegressor - HuberRegressor #####\n",
      "Train MSE: 0.294\n",
      "Train inference error (RMSE): ±0.5423320846793415\n",
      "Test MSE: 0.965\n",
      "Test inference error (RMSE): ±0.9821494574987282\n",
      "##### ExtraTreesRegressor - IsotonicRegression #####\n",
      "Error (ExtraTreesRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ExtraTreesRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.377\n",
      "Train inference error (RMSE): ±0.6139956468818447\n",
      "Test MSE: 1.189\n",
      "Test inference error (RMSE): ±1.0905532762669594\n",
      "##### ExtraTreesRegressor - KernelRidge #####\n",
      "Train MSE: 0.290\n",
      "Train inference error (RMSE): ±0.5382820178808577\n",
      "Test MSE: 1.056\n",
      "Test inference error (RMSE): ±1.027640607555887\n",
      "##### ExtraTreesRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.775786794727237e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00014508570049410203\n",
      "##### ExtraTreesRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.592728710463338e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00014594358432847682\n",
      "##### ExtraTreesRegressor - Lasso #####\n",
      "Train MSE: 0.679\n",
      "Train inference error (RMSE): ±0.8239232882182944\n",
      "Test MSE: 0.856\n",
      "Test inference error (RMSE): ±0.9250451334772535\n",
      "##### ExtraTreesRegressor - LassoCV #####\n",
      "Train MSE: 0.279\n",
      "Train inference error (RMSE): ±0.5278968330591003\n",
      "Test MSE: 1.045\n",
      "Test inference error (RMSE): ±1.0223149990214027\n",
      "##### ExtraTreesRegressor - LassoLars #####\n",
      "Train MSE: 0.777\n",
      "Train inference error (RMSE): ±0.8814553928838147\n",
      "Test MSE: 0.901\n",
      "Test inference error (RMSE): ±0.9494473801041893\n",
      "##### ExtraTreesRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.813558224890493e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00014242045569551586\n",
      "##### ExtraTreesRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.651974041474677e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001418107091798996\n",
      "##### ExtraTreesRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.754469701399711e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001437165591886218\n",
      "##### ExtraTreesRegressor - LinearSVR #####\n",
      "Train MSE: 0.293\n",
      "Train inference error (RMSE): ±0.5411425763190642\n",
      "Test MSE: 0.967\n",
      "Test inference error (RMSE): ±0.9832558071645319\n",
      "##### ExtraTreesRegressor - MLPRegressor #####\n",
      "Train MSE: 0.291\n",
      "Train inference error (RMSE): ±0.5393699548244483\n",
      "Test MSE: 0.971\n",
      "Test inference error (RMSE): ±0.985300118406224\n",
      "##### ExtraTreesRegressor - MultiTaskElasticNet #####\n",
      "Error (ExtraTreesRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreesRegressor - MultiTaskElasticNetCV #####\n",
      "Error (ExtraTreesRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ExtraTreesRegressor - MultiTaskLasso #####\n",
      "Error (ExtraTreesRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreesRegressor - MultiTaskLassoCV #####\n",
      "Error (ExtraTreesRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ExtraTreesRegressor - NuSVR #####\n",
      "Train MSE: 0.300\n",
      "Train inference error (RMSE): ±0.5473448230717104\n",
      "Test MSE: 0.983\n",
      "Test inference error (RMSE): ±0.9914151371199436\n",
      "##### ExtraTreesRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.305\n",
      "Train inference error (RMSE): ±0.5519246349943883\n",
      "Test MSE: 1.058\n",
      "Test inference error (RMSE): ±1.028711788734001\n",
      "##### ExtraTreesRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.227\n",
      "Train inference error (RMSE): ±0.47663670359003374\n",
      "Test MSE: 1.009\n",
      "Test inference error (RMSE): ±1.0045122916053455\n",
      "##### ExtraTreesRegressor - PLSCanonical #####\n",
      "Error (ExtraTreesRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ExtraTreesRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07789144159616769\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08452423994152831\n",
      "##### ExtraTreesRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.291\n",
      "Train inference error (RMSE): ±0.5389944941018215\n",
      "Test MSE: 0.968\n",
      "Test inference error (RMSE): ±0.983744142134416\n",
      "##### ExtraTreesRegressor - PoissonRegressor #####\n",
      "Error (ExtraTreesRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ExtraTreesRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.258\n",
      "Train inference error (RMSE): ±0.5081018442802252\n",
      "Test MSE: 1.047\n",
      "Test inference error (RMSE): ±1.0234494541694465\n",
      "##### ExtraTreesRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.405495164873935e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001419075588429395\n",
      "##### ExtraTreesRegressor - RadiusNeighborsRegressor #####\n",
      "Error (ExtraTreesRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ExtraTreesRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.316\n",
      "Train inference error (RMSE): ±0.5622795740097856\n",
      "Test MSE: 1.020\n",
      "Test inference error (RMSE): ±1.009992995605704\n",
      "##### ExtraTreesRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014752376435620141\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0017931800821938946\n",
      "##### ExtraTreesRegressor - RidgeCV #####\n",
      "Train MSE: 0.303\n",
      "Train inference error (RMSE): ±0.5508159044425618\n",
      "Test MSE: 1.101\n",
      "Test inference error (RMSE): ±1.0492827048752245\n",
      "##### ExtraTreesRegressor - SGDRegressor #####\n",
      "Train MSE: 383555889301954942318447865554022654986793982863367279099774570423625627615834931200.000\n",
      "Train inference error (RMSE): ±6.193188914460425e+41\n",
      "Test MSE: 411213307830929261804316803382824629736497715279941293163535312444216143172283138048.000\n",
      "Test inference error (RMSE): ±6.412591580873752e+41\n",
      "##### ExtraTreesRegressor - SVR #####\n",
      "Train MSE: 0.284\n",
      "Train inference error (RMSE): ±0.5325152770837907\n",
      "Test MSE: 1.019\n",
      "Test inference error (RMSE): ±1.0095223140234526\n",
      "##### ExtraTreesRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.541899965235372e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00014310895899371435\n",
      "##### ExtraTreesRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.76684436867583e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00014451658940299087\n",
      "##### ExtraTreesRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.296\n",
      "Train inference error (RMSE): ±0.5436334609511347\n",
      "Test MSE: 0.997\n",
      "Test inference error (RMSE): ±0.998509635447771\n",
      "##### GammaRegressor - GaussianProcessRegressor #####\n",
      "Error (GammaRegressor-GaussianProcessRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - GradientBoostingRegressor #####\n",
      "Error (GammaRegressor-GradientBoostingRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - HistGradientBoostingRegressor #####\n",
      "Error (GammaRegressor-HistGradientBoostingRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - HuberRegressor #####\n",
      "Error (GammaRegressor-HuberRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - IsotonicRegression #####\n",
      "Error (GammaRegressor-IsotonicRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - KNeighborsRegressor #####\n",
      "Error (GammaRegressor-KNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - KernelRidge #####\n",
      "Error (GammaRegressor-KernelRidge): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Lars #####\n",
      "Error (GammaRegressor-Lars): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LarsCV #####\n",
      "Error (GammaRegressor-LarsCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Lasso #####\n",
      "Error (GammaRegressor-Lasso): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoCV #####\n",
      "Error (GammaRegressor-LassoCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLars #####\n",
      "Error (GammaRegressor-LassoLars): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLarsCV #####\n",
      "Error (GammaRegressor-LassoLarsCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLarsIC #####\n",
      "Error (GammaRegressor-LassoLarsIC): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LinearRegression #####\n",
      "Error (GammaRegressor-LinearRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LinearSVR #####\n",
      "Error (GammaRegressor-LinearSVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MLPRegressor #####\n",
      "Error (GammaRegressor-MLPRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskElasticNet #####\n",
      "Error (GammaRegressor-MultiTaskElasticNet): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GammaRegressor-MultiTaskElasticNetCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskLasso #####\n",
      "Error (GammaRegressor-MultiTaskLasso): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskLassoCV #####\n",
      "Error (GammaRegressor-MultiTaskLassoCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - NuSVR #####\n",
      "Error (GammaRegressor-NuSVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - OrthogonalMatchingPursuit #####\n",
      "Error (GammaRegressor-OrthogonalMatchingPursuit): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Error (GammaRegressor-OrthogonalMatchingPursuitCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PLSCanonical #####\n",
      "Error (GammaRegressor-PLSCanonical): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PLSRegression #####\n",
      "Error (GammaRegressor-PLSRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PassiveAggressiveRegressor #####\n",
      "Error (GammaRegressor-PassiveAggressiveRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PoissonRegressor #####\n",
      "Error (GammaRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - QuantileRegressor #####\n",
      "Error (GammaRegressor-QuantileRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RANSACRegressor #####\n",
      "Error (GammaRegressor-RANSACRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GammaRegressor-RadiusNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RandomForestRegressor #####\n",
      "Error (GammaRegressor-RandomForestRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Ridge #####\n",
      "Error (GammaRegressor-Ridge): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RidgeCV #####\n",
      "Error (GammaRegressor-RidgeCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - SGDRegressor #####\n",
      "Error (GammaRegressor-SGDRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - SVR #####\n",
      "Error (GammaRegressor-SVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TheilSenRegressor #####\n",
      "Error (GammaRegressor-TheilSenRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TransformedTargetRegressor #####\n",
      "Error (GammaRegressor-TransformedTargetRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TweedieRegressor #####\n",
      "Error (GammaRegressor-TweedieRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GaussianProcessRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.151\n",
      "Train inference error (RMSE): ±0.38870110729658025\n",
      "Test MSE: 0.514\n",
      "Test inference error (RMSE): ±0.7168610988460625\n",
      "##### GaussianProcessRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.096\n",
      "Train inference error (RMSE): ±0.3096517603680106\n",
      "Test MSE: 0.595\n",
      "Test inference error (RMSE): ±0.7716234137000082\n",
      "##### GaussianProcessRegressor - HuberRegressor #####\n",
      "Train MSE: 11.072\n",
      "Train inference error (RMSE): ±3.3275195564580065\n",
      "Test MSE: 12.851\n",
      "Test inference error (RMSE): ±3.584897864269498\n",
      "##### GaussianProcessRegressor - IsotonicRegression #####\n",
      "Error (GaussianProcessRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### GaussianProcessRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 6.175\n",
      "Train inference error (RMSE): ±2.4850131589337288\n",
      "Test MSE: 15.312\n",
      "Test inference error (RMSE): ±3.913070997933093\n",
      "##### GaussianProcessRegressor - KernelRidge #####\n",
      "Train MSE: 11.220\n",
      "Train inference error (RMSE): ±3.349595013767605\n",
      "Test MSE: 11.633\n",
      "Test inference error (RMSE): ±3.4107110937033114\n",
      "##### GaussianProcessRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2937550060591184e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409726647165734e-05\n",
      "##### GaussianProcessRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2937550060591184e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409726647165734e-05\n",
      "##### GaussianProcessRegressor - Lasso #####\n",
      "Train MSE: 3.521\n",
      "Train inference error (RMSE): ±1.8763469536603707\n",
      "Test MSE: 6.418\n",
      "Test inference error (RMSE): ±2.5333538141051437\n",
      "##### GaussianProcessRegressor - LassoCV #####\n",
      "Train MSE: 11.095\n",
      "Train inference error (RMSE): ±3.330892773254831\n",
      "Test MSE: 12.281\n",
      "Test inference error (RMSE): ±3.5043689190070713\n",
      "##### GaussianProcessRegressor - LassoLars #####\n",
      "Train MSE: 3.521\n",
      "Train inference error (RMSE): ±1.876346909554898\n",
      "Test MSE: 6.418\n",
      "Test inference error (RMSE): ±2.533353724193224\n",
      "##### GaussianProcessRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293746757739085e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409718176048706e-05\n",
      "##### GaussianProcessRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293746757739085e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409718176048706e-05\n",
      "##### GaussianProcessRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293739828951803e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.40971094630928e-05\n",
      "##### GaussianProcessRegressor - LinearSVR #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.3413737377774635\n",
      "Test MSE: 11.776\n",
      "Test inference error (RMSE): ±3.43162215568848\n",
      "##### GaussianProcessRegressor - MLPRegressor #####\n",
      "Train MSE: 11.173\n",
      "Train inference error (RMSE): ±3.34266903772045\n",
      "Test MSE: 11.871\n",
      "Test inference error (RMSE): ±3.445412008898034\n",
      "##### GaussianProcessRegressor - MultiTaskElasticNet #####\n",
      "Error (GaussianProcessRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### GaussianProcessRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GaussianProcessRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### GaussianProcessRegressor - MultiTaskLasso #####\n",
      "Error (GaussianProcessRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### GaussianProcessRegressor - MultiTaskLassoCV #####\n",
      "Error (GaussianProcessRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### GaussianProcessRegressor - NuSVR #####\n",
      "Train MSE: 11.183\n",
      "Train inference error (RMSE): ±3.3441632361844738\n",
      "Test MSE: 11.764\n",
      "Test inference error (RMSE): ±3.4297971839050962\n",
      "##### GaussianProcessRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.092\n",
      "Train inference error (RMSE): ±3.330443791945397\n",
      "Test MSE: 12.324\n",
      "Test inference error (RMSE): ±3.5105369230027397\n",
      "##### GaussianProcessRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0486118495899746\n",
      "Test MSE: 1.400\n",
      "Test inference error (RMSE): ±1.1833674156303997\n",
      "##### GaussianProcessRegressor - PLSCanonical #####\n",
      "Error (GaussianProcessRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### GaussianProcessRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07625306592035215\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08578467435851106\n",
      "##### GaussianProcessRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.185\n",
      "Train inference error (RMSE): ±3.344453592755776\n",
      "Test MSE: 11.899\n",
      "Test inference error (RMSE): ±3.4494775532540136\n",
      "##### GaussianProcessRegressor - PoissonRegressor #####\n",
      "Error (GaussianProcessRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### GaussianProcessRegressor - QuantileRegressor #####\n",
      "Train MSE: 11.076\n",
      "Train inference error (RMSE): ±3.3280511276924214\n",
      "Test MSE: 12.681\n",
      "Test inference error (RMSE): ±3.561003999346713\n",
      "##### GaussianProcessRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293739828951803e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.40971094630928e-05\n",
      "##### GaussianProcessRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GaussianProcessRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### GaussianProcessRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.217\n",
      "Train inference error (RMSE): ±0.4659687316444425\n",
      "Test MSE: 1.353\n",
      "Test inference error (RMSE): ±1.1633246552488474\n",
      "##### GaussianProcessRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001667273656576586\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018157358080528592\n",
      "##### GaussianProcessRegressor - RidgeCV #####\n",
      "Train MSE: 11.084\n",
      "Train inference error (RMSE): ±3.3292563969579816\n",
      "Test MSE: 13.489\n",
      "Test inference error (RMSE): ±3.6727823637468937\n",
      "##### GaussianProcessRegressor - SGDRegressor #####\n",
      "Train MSE: 1910472011848960799243339432429144513698714922576092911005567902983835374059520.000\n",
      "Train inference error (RMSE): ±1.382198253453158e+39\n",
      "Test MSE: 1956652576033191322725873332890998338392041859001281028253339095429551101050880.000\n",
      "Test inference error (RMSE): ±1.3988039805609617e+39\n",
      "##### GaussianProcessRegressor - SVR #####\n",
      "Train MSE: 11.169\n",
      "Train inference error (RMSE): ±3.341995299634336\n",
      "Test MSE: 11.756\n",
      "Test inference error (RMSE): ±3.4287704616523262\n",
      "##### GaussianProcessRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2940817874916656e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4088725293157424e-05\n",
      "##### GaussianProcessRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293739828951803e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.40971094630928e-05\n",
      "##### GaussianProcessRegressor - TweedieRegressor #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.3413813199683924\n",
      "Test MSE: 11.776\n",
      "Test inference error (RMSE): ±3.43157762955274\n",
      "##### GradientBoostingRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.117\n",
      "Train inference error (RMSE): ±0.342082032205383\n",
      "Test MSE: 0.481\n",
      "Test inference error (RMSE): ±0.6935778482968415\n",
      "##### GradientBoostingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.3841326899877091\n",
      "Test MSE: 0.514\n",
      "Test inference error (RMSE): ±0.7172841123053042\n",
      "##### GradientBoostingRegressor - IsotonicRegression #####\n",
      "Error (GradientBoostingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### GradientBoostingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.170\n",
      "Train inference error (RMSE): ±0.4126936911673356\n",
      "Test MSE: 0.545\n",
      "Test inference error (RMSE): ±0.7385357391496111\n",
      "##### GradientBoostingRegressor - KernelRidge #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.38438547376270304\n",
      "Test MSE: 0.515\n",
      "Test inference error (RMSE): ±0.7173504858263823\n",
      "##### GradientBoostingRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00010308115002009617\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019024509787942778\n",
      "##### GradientBoostingRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.000103146886486646\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019067512818365454\n",
      "##### GradientBoostingRegressor - Lasso #####\n",
      "Train MSE: 0.156\n",
      "Train inference error (RMSE): ±0.39557941979710537\n",
      "Test MSE: 0.503\n",
      "Test inference error (RMSE): ±0.7091298034214021\n",
      "##### GradientBoostingRegressor - LassoCV #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.3845776806349598\n",
      "Test MSE: 0.517\n",
      "Test inference error (RMSE): ±0.7193047342630976\n",
      "##### GradientBoostingRegressor - LassoLars #####\n",
      "Train MSE: 0.157\n",
      "Train inference error (RMSE): ±0.39578275036807\n",
      "Test MSE: 0.504\n",
      "Test inference error (RMSE): ±0.7102596426042064\n",
      "##### GradientBoostingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00010274738648255073\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00018977756230878934\n",
      "##### GradientBoostingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00010289962089303235\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00018972105716051843\n",
      "##### GradientBoostingRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00010293937473005064\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001899681329222819\n",
      "##### GradientBoostingRegressor - LinearSVR #####\n",
      "Train MSE: 0.151\n",
      "Train inference error (RMSE): ±0.38809035776362444\n",
      "Test MSE: 0.516\n",
      "Test inference error (RMSE): ±0.7184887878589001\n",
      "##### GradientBoostingRegressor - MLPRegressor #####\n",
      "Train MSE: 0.154\n",
      "Train inference error (RMSE): ±0.392968218921511\n",
      "Test MSE: 0.521\n",
      "Test inference error (RMSE): ±0.7217892737966691\n",
      "##### GradientBoostingRegressor - MultiTaskElasticNet #####\n",
      "Error (GradientBoostingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### GradientBoostingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GradientBoostingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### GradientBoostingRegressor - MultiTaskLasso #####\n",
      "Error (GradientBoostingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### GradientBoostingRegressor - MultiTaskLassoCV #####\n",
      "Error (GradientBoostingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### GradientBoostingRegressor - NuSVR #####\n",
      "Train MSE: 0.147\n",
      "Train inference error (RMSE): ±0.3838621039419291\n",
      "Test MSE: 0.517\n",
      "Test inference error (RMSE): ±0.7188583429763542\n",
      "##### GradientBoostingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.38492545142614676\n",
      "Test MSE: 0.518\n",
      "Test inference error (RMSE): ±0.7195635406127622\n",
      "##### GradientBoostingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.166\n",
      "Train inference error (RMSE): ±0.40768965137521906\n",
      "Test MSE: 0.522\n",
      "Test inference error (RMSE): ±0.722702530124419\n",
      "##### GradientBoostingRegressor - PLSCanonical #####\n",
      "Error (GradientBoostingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### GradientBoostingRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07650799862871857\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08574372645941107\n",
      "##### GradientBoostingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.151\n",
      "Train inference error (RMSE): ±0.3885834934016256\n",
      "Test MSE: 0.515\n",
      "Test inference error (RMSE): ±0.7176733642278362\n",
      "##### GradientBoostingRegressor - PoissonRegressor #####\n",
      "Error (GradientBoostingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### GradientBoostingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.38486552080908726\n",
      "Test MSE: 0.517\n",
      "Test inference error (RMSE): ±0.7190694278123887\n",
      "##### GradientBoostingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00010291444467355325\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019029649877563655\n",
      "##### GradientBoostingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GradientBoostingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### GradientBoostingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.147\n",
      "Train inference error (RMSE): ±0.38285328413034064\n",
      "Test MSE: 0.508\n",
      "Test inference error (RMSE): ±0.7127566536743615\n",
      "##### GradientBoostingRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016105795860841062\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001806043590053375\n",
      "##### GradientBoostingRegressor - RidgeCV #####\n",
      "Train MSE: 0.165\n",
      "Train inference error (RMSE): ±0.40606014573188254\n",
      "Test MSE: 0.601\n",
      "Test inference error (RMSE): ±0.7749760024203171\n",
      "##### GradientBoostingRegressor - SGDRegressor #####\n",
      "Train MSE: 129423001513048219483389976458578123119764549863289695127224484257925464135454162944.000\n",
      "Train inference error (RMSE): ±3.597540847760429e+41\n",
      "Test MSE: 126742664209383046056324990170725543103392426063877098565215042626446152532918009856.000\n",
      "Test inference error (RMSE): ±3.5600935972159925e+41\n",
      "##### GradientBoostingRegressor - SVR #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.3848335167633287\n",
      "Test MSE: 0.516\n",
      "Test inference error (RMSE): ±0.7184423041211737\n",
      "##### GradientBoostingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00010327968805295875\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001909298341717189\n",
      "##### GradientBoostingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00010297564137839977\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00018985400084172\n",
      "##### GradientBoostingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.148\n",
      "Train inference error (RMSE): ±0.3846544538132761\n",
      "Test MSE: 0.515\n",
      "Test inference error (RMSE): ±0.7173102896737028\n",
      "##### HistGradientBoostingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.093\n",
      "Train inference error (RMSE): ±0.3042948886895157\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.7718485663723043\n",
      "##### HistGradientBoostingRegressor - IsotonicRegression #####\n",
      "Error (HistGradientBoostingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### HistGradientBoostingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.118\n",
      "Train inference error (RMSE): ±0.3439901730005003\n",
      "Test MSE: 0.609\n",
      "Test inference error (RMSE): ±0.7801573077102041\n",
      "##### HistGradientBoostingRegressor - KernelRidge #####\n",
      "Train MSE: 0.096\n",
      "Train inference error (RMSE): ±0.3096087030693956\n",
      "Test MSE: 0.605\n",
      "Test inference error (RMSE): ±0.7776289444038671\n",
      "##### HistGradientBoostingRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.762824762706334e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019344259421445205\n",
      "##### HistGradientBoostingRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.762824762706334e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019344259421445205\n",
      "##### HistGradientBoostingRegressor - Lasso #####\n",
      "Train MSE: 0.100\n",
      "Train inference error (RMSE): ±0.3161918401420064\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.7719060668222643\n",
      "##### HistGradientBoostingRegressor - LassoCV #####\n",
      "Train MSE: 0.094\n",
      "Train inference error (RMSE): ±0.30619971417190184\n",
      "Test MSE: 0.601\n",
      "Test inference error (RMSE): ±0.7750887660938942\n",
      "##### HistGradientBoostingRegressor - LassoLars #####\n",
      "Train MSE: 0.100\n",
      "Train inference error (RMSE): ±0.31619183912136856\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.7719060669979898\n",
      "##### HistGradientBoostingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.762819524272803e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019344260319646608\n",
      "##### HistGradientBoostingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.762819524272803e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019344260319646608\n",
      "##### HistGradientBoostingRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.762875981516047e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019344249232424314\n",
      "##### HistGradientBoostingRegressor - LinearSVR #####\n",
      "Train MSE: 0.096\n",
      "Train inference error (RMSE): ±0.3096517603839059\n",
      "Test MSE: 0.595\n",
      "Test inference error (RMSE): ±0.7716234136993281\n",
      "##### HistGradientBoostingRegressor - MLPRegressor #####\n",
      "Train MSE: 0.096\n",
      "Train inference error (RMSE): ±0.30968585025538653\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.7719080666470555\n",
      "##### HistGradientBoostingRegressor - MultiTaskElasticNet #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### HistGradientBoostingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### HistGradientBoostingRegressor - MultiTaskLasso #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### HistGradientBoostingRegressor - MultiTaskLassoCV #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### HistGradientBoostingRegressor - NuSVR #####\n",
      "Train MSE: 0.093\n",
      "Train inference error (RMSE): ±0.3056189909514946\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.771867373109959\n",
      "##### HistGradientBoostingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.094\n",
      "Train inference error (RMSE): ±0.30633567858735833\n",
      "Test MSE: 0.601\n",
      "Test inference error (RMSE): ±0.7753304885319919\n",
      "##### HistGradientBoostingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.111\n",
      "Train inference error (RMSE): ±0.33306866221389425\n",
      "Test MSE: 0.559\n",
      "Test inference error (RMSE): ±0.7474484893092498\n",
      "##### HistGradientBoostingRegressor - PLSCanonical #####\n",
      "Error (HistGradientBoostingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### HistGradientBoostingRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07586127342452995\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08601756681586183\n",
      "##### HistGradientBoostingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.096\n",
      "Train inference error (RMSE): ±0.3102382040355862\n",
      "Test MSE: 0.595\n",
      "Test inference error (RMSE): ±0.7716019910046333\n",
      "##### HistGradientBoostingRegressor - PoissonRegressor #####\n",
      "Error (HistGradientBoostingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### HistGradientBoostingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.094\n",
      "Train inference error (RMSE): ±0.30643646473254055\n",
      "Test MSE: 0.603\n",
      "Test inference error (RMSE): ±0.7763593157012199\n",
      "##### HistGradientBoostingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.762875981516047e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019344249232424314\n",
      "##### HistGradientBoostingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (HistGradientBoostingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### HistGradientBoostingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.088\n",
      "Train inference error (RMSE): ±0.29650609908517855\n",
      "Test MSE: 0.593\n",
      "Test inference error (RMSE): ±0.7699132483785022\n",
      "##### HistGradientBoostingRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016555748355814549\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018148347300612241\n",
      "##### HistGradientBoostingRegressor - RidgeCV #####\n",
      "Train MSE: 0.101\n",
      "Train inference error (RMSE): ±0.31712440096366734\n",
      "Test MSE: 0.612\n",
      "Test inference error (RMSE): ±0.7823116087458243\n",
      "##### HistGradientBoostingRegressor - SGDRegressor #####\n",
      "Train MSE: 187937242478824349071190185940453672742588858312771165643601404065503965192835301376.000\n",
      "Train inference error (RMSE): ±4.335172920182358e+41\n",
      "Test MSE: 191331195280428008728126079653613483315317748654741469947279424172958994389115338752.000\n",
      "Test inference error (RMSE): ±4.37414214767225e+41\n",
      "##### HistGradientBoostingRegressor - SVR #####\n",
      "Train MSE: 0.093\n",
      "Train inference error (RMSE): ±0.30570280173485337\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.7719455682370275\n",
      "##### HistGradientBoostingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.761655639077638e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019344522409124577\n",
      "##### HistGradientBoostingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.762875981516047e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019344249232424314\n",
      "##### HistGradientBoostingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.093\n",
      "Train inference error (RMSE): ±0.3048214184911018\n",
      "Test MSE: 0.596\n",
      "Test inference error (RMSE): ±0.7718448589824131\n",
      "##### HuberRegressor - IsotonicRegression #####\n",
      "Error (HuberRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### HuberRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 6.195\n",
      "Train inference error (RMSE): ±2.488889956489033\n",
      "Test MSE: 15.809\n",
      "Test inference error (RMSE): ±3.9761011835160387\n",
      "##### HuberRegressor - KernelRidge #####\n",
      "Train MSE: 11.079\n",
      "Train inference error (RMSE): ±3.328514994624186\n",
      "Test MSE: 12.637\n",
      "Test inference error (RMSE): ±3.5547855480951966\n",
      "##### HuberRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.325140564590481e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.697847858032103e-05\n",
      "##### HuberRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.325140564590481e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.697847858032103e-05\n",
      "##### HuberRegressor - Lasso #####\n",
      "Train MSE: 3.425\n",
      "Train inference error (RMSE): ±1.8507550664633172\n",
      "Test MSE: 5.049\n",
      "Test inference error (RMSE): ±2.2469386107220717\n",
      "##### HuberRegressor - LassoCV #####\n",
      "Train MSE: 11.075\n",
      "Train inference error (RMSE): ±3.327870958121547\n",
      "Test MSE: 12.725\n",
      "Test inference error (RMSE): ±3.5671877431871817\n",
      "##### HuberRegressor - LassoLars #####\n",
      "Train MSE: 3.425\n",
      "Train inference error (RMSE): ±1.85075502674119\n",
      "Test MSE: 5.049\n",
      "Test inference error (RMSE): ±2.2469385476682775\n",
      "##### HuberRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3251459858174004e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.697853326472212e-05\n",
      "##### HuberRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3251459858174004e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.697853326472212e-05\n",
      "##### HuberRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.32512643390617e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.697846513377392e-05\n",
      "##### HuberRegressor - LinearSVR #####\n",
      "Train MSE: 11.072\n",
      "Train inference error (RMSE): ±3.3275195564580065\n",
      "Test MSE: 12.851\n",
      "Test inference error (RMSE): ±3.5848978642695\n",
      "##### HuberRegressor - MLPRegressor #####\n",
      "Train MSE: 18.799\n",
      "Train inference error (RMSE): ±4.335737096294472\n",
      "Test MSE: 26.885\n",
      "Test inference error (RMSE): ±5.185091158178697\n",
      "##### HuberRegressor - MultiTaskElasticNet #####\n",
      "Error (HuberRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### HuberRegressor - MultiTaskElasticNetCV #####\n",
      "Error (HuberRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### HuberRegressor - MultiTaskLasso #####\n",
      "Error (HuberRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### HuberRegressor - MultiTaskLassoCV #####\n",
      "Error (HuberRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### HuberRegressor - NuSVR #####\n",
      "Train MSE: 11.077\n",
      "Train inference error (RMSE): ±3.32815504857138\n",
      "Test MSE: 12.741\n",
      "Test inference error (RMSE): ±3.569521010045594\n",
      "##### HuberRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.075\n",
      "Train inference error (RMSE): ±3.327865583649643\n",
      "Test MSE: 12.726\n",
      "Test inference error (RMSE): ±3.567410702502993\n",
      "##### HuberRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.048629514247504\n",
      "Test MSE: 1.401\n",
      "Test inference error (RMSE): ±1.1837871981257542\n",
      "##### HuberRegressor - PLSCanonical #####\n",
      "Error (HuberRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### HuberRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07614926230267867\n",
      "Test MSE: 0.006\n",
      "Test inference error (RMSE): ±0.08055321641588843\n",
      "##### HuberRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.076\n",
      "Train inference error (RMSE): ±3.328105232385263\n",
      "Test MSE: 13.033\n",
      "Test inference error (RMSE): ±3.6100559992808474\n",
      "##### HuberRegressor - PoissonRegressor #####\n",
      "Error (HuberRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### HuberRegressor - QuantileRegressor #####\n",
      "Train MSE: 11.072\n",
      "Train inference error (RMSE): ±3.3274334471667792\n",
      "Test MSE: 12.897\n",
      "Test inference error (RMSE): ±3.591231517192919\n",
      "##### HuberRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.32512643390617e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.697846513377392e-05\n",
      "##### HuberRegressor - RadiusNeighborsRegressor #####\n",
      "Error (HuberRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### HuberRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.202\n",
      "Train inference error (RMSE): ±0.44948217078367636\n",
      "Test MSE: 1.321\n",
      "Test inference error (RMSE): ±1.1495175414634276\n",
      "##### HuberRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00160719651872724\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001555336758775627\n",
      "##### HuberRegressor - RidgeCV #####\n",
      "Train MSE: 11.088\n",
      "Train inference error (RMSE): ±3.3298128359718535\n",
      "Test MSE: 12.331\n",
      "Test inference error (RMSE): ±3.5115810215812777\n",
      "##### HuberRegressor - SGDRegressor #####\n",
      "Train MSE: 5139675798014594730928326813412963023382832891475819015215072668377844714349527040.000\n",
      "Train inference error (RMSE): ±7.169153226158997e+40\n",
      "Test MSE: 5370999907681954513554402649355423017193688727834211981640481875842149616623550464.000\n",
      "Test inference error (RMSE): ±7.328710601246275e+40\n",
      "##### HuberRegressor - SVR #####\n",
      "Train MSE: 11.072\n",
      "Train inference error (RMSE): ±3.327454245190315\n",
      "Test MSE: 12.887\n",
      "Test inference error (RMSE): ±3.5898606221480276\n",
      "##### HuberRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.325068620829342e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.693494464872791e-05\n",
      "##### HuberRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.32512643390617e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.697846513377392e-05\n",
      "##### HuberRegressor - TweedieRegressor #####\n",
      "Train MSE: 11.075\n",
      "Train inference error (RMSE): ±3.3278740006553247\n",
      "Test MSE: 12.725\n",
      "Test inference error (RMSE): ±3.56715889916598\n",
      "##### IsotonicRegression - KNeighborsRegressor #####\n",
      "Error (IsotonicRegression-KNeighborsRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - KernelRidge #####\n",
      "Error (IsotonicRegression-KernelRidge): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Lars #####\n",
      "Error (IsotonicRegression-Lars): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LarsCV #####\n",
      "Error (IsotonicRegression-LarsCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Lasso #####\n",
      "Error (IsotonicRegression-Lasso): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoCV #####\n",
      "Error (IsotonicRegression-LassoCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLars #####\n",
      "Error (IsotonicRegression-LassoLars): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLarsCV #####\n",
      "Error (IsotonicRegression-LassoLarsCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLarsIC #####\n",
      "Error (IsotonicRegression-LassoLarsIC): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LinearRegression #####\n",
      "Error (IsotonicRegression-LinearRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LinearSVR #####\n",
      "Error (IsotonicRegression-LinearSVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MLPRegressor #####\n",
      "Error (IsotonicRegression-MLPRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskElasticNet #####\n",
      "Error (IsotonicRegression-MultiTaskElasticNet): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskElasticNetCV #####\n",
      "Error (IsotonicRegression-MultiTaskElasticNetCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskLasso #####\n",
      "Error (IsotonicRegression-MultiTaskLasso): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskLassoCV #####\n",
      "Error (IsotonicRegression-MultiTaskLassoCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - NuSVR #####\n",
      "Error (IsotonicRegression-NuSVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - OrthogonalMatchingPursuit #####\n",
      "Error (IsotonicRegression-OrthogonalMatchingPursuit): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - OrthogonalMatchingPursuitCV #####\n",
      "Error (IsotonicRegression-OrthogonalMatchingPursuitCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PLSCanonical #####\n",
      "Error (IsotonicRegression-PLSCanonical): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PLSRegression #####\n",
      "Error (IsotonicRegression-PLSRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PassiveAggressiveRegressor #####\n",
      "Error (IsotonicRegression-PassiveAggressiveRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PoissonRegressor #####\n",
      "Error (IsotonicRegression-PoissonRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - QuantileRegressor #####\n",
      "Error (IsotonicRegression-QuantileRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RANSACRegressor #####\n",
      "Error (IsotonicRegression-RANSACRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RadiusNeighborsRegressor #####\n",
      "Error (IsotonicRegression-RadiusNeighborsRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RandomForestRegressor #####\n",
      "Error (IsotonicRegression-RandomForestRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Ridge #####\n",
      "Error (IsotonicRegression-Ridge): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RidgeCV #####\n",
      "Error (IsotonicRegression-RidgeCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - SGDRegressor #####\n",
      "Error (IsotonicRegression-SGDRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - SVR #####\n",
      "Error (IsotonicRegression-SVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TheilSenRegressor #####\n",
      "Error (IsotonicRegression-TheilSenRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TransformedTargetRegressor #####\n",
      "Error (IsotonicRegression-TransformedTargetRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TweedieRegressor #####\n",
      "Error (IsotonicRegression-TweedieRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### KNeighborsRegressor - KernelRidge #####\n",
      "Train MSE: 6.239\n",
      "Train inference error (RMSE): ±2.4978374107286534\n",
      "Test MSE: 14.234\n",
      "Test inference error (RMSE): ±3.772810332015913\n",
      "##### KNeighborsRegressor - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.6659780696823183e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.782046420555894e-05\n",
      "##### KNeighborsRegressor - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.6659780696823183e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.782046420555894e-05\n",
      "##### KNeighborsRegressor - Lasso #####\n",
      "Train MSE: 2.613\n",
      "Train inference error (RMSE): ±1.6165112143080285\n",
      "Test MSE: 8.772\n",
      "Test inference error (RMSE): ±2.961678619093771\n",
      "##### KNeighborsRegressor - LassoCV #####\n",
      "Train MSE: 6.174\n",
      "Train inference error (RMSE): ±2.48468427182482\n",
      "Test MSE: 15.254\n",
      "Test inference error (RMSE): ±3.9056614654147843\n",
      "##### KNeighborsRegressor - LassoLars #####\n",
      "Train MSE: 2.613\n",
      "Train inference error (RMSE): ±1.616511180513484\n",
      "Test MSE: 8.772\n",
      "Test inference error (RMSE): ±2.9616785182390353\n",
      "##### KNeighborsRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.665974822765779e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.7820452386008345e-05\n",
      "##### KNeighborsRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.665974822765779e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.7820452386008345e-05\n",
      "##### KNeighborsRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.6659507695895e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.7820379756368386e-05\n",
      "##### KNeighborsRegressor - LinearSVR #####\n",
      "Train MSE: 6.175\n",
      "Train inference error (RMSE): ±2.485013158933845\n",
      "Test MSE: 15.312\n",
      "Test inference error (RMSE): ±3.913070997932964\n",
      "##### KNeighborsRegressor - MLPRegressor #####\n",
      "Train MSE: 6.185\n",
      "Train inference error (RMSE): ±2.487032160099692\n",
      "Test MSE: 15.785\n",
      "Test inference error (RMSE): ±3.9730155108412775\n",
      "##### KNeighborsRegressor - MultiTaskElasticNet #####\n",
      "Error (KNeighborsRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### KNeighborsRegressor - MultiTaskElasticNetCV #####\n",
      "Error (KNeighborsRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### KNeighborsRegressor - MultiTaskLasso #####\n",
      "Error (KNeighborsRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### KNeighborsRegressor - MultiTaskLassoCV #####\n",
      "Error (KNeighborsRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### KNeighborsRegressor - NuSVR #####\n",
      "Train MSE: 6.158\n",
      "Train inference error (RMSE): ±2.481508035850666\n",
      "Test MSE: 15.341\n",
      "Test inference error (RMSE): ±3.916734731210372\n",
      "##### KNeighborsRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 6.174\n",
      "Train inference error (RMSE): ±2.4848317930445023\n",
      "Test MSE: 15.278\n",
      "Test inference error (RMSE): ±3.908745270348582\n",
      "##### KNeighborsRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.019\n",
      "Train inference error (RMSE): ±1.0094141314316638\n",
      "Test MSE: 1.538\n",
      "Test inference error (RMSE): ±1.2400815886591152\n",
      "##### KNeighborsRegressor - PLSCanonical #####\n",
      "Error (KNeighborsRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### KNeighborsRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07598643189388174\n",
      "Test MSE: 0.008\n",
      "Test inference error (RMSE): ±0.08799169109448156\n",
      "##### KNeighborsRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 6.191\n",
      "Train inference error (RMSE): ±2.488098542244311\n",
      "Test MSE: 14.977\n",
      "Test inference error (RMSE): ±3.8700025748358877\n",
      "##### KNeighborsRegressor - PoissonRegressor #####\n",
      "Error (KNeighborsRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### KNeighborsRegressor - QuantileRegressor #####\n",
      "Train MSE: 6.187\n",
      "Train inference error (RMSE): ±2.4874466758508205\n",
      "Test MSE: 15.740\n",
      "Test inference error (RMSE): ±3.9673974755913326\n",
      "##### KNeighborsRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.6659507695895e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.7820379756368386e-05\n",
      "##### KNeighborsRegressor - RadiusNeighborsRegressor #####\n",
      "Error (KNeighborsRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### KNeighborsRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.285\n",
      "Train inference error (RMSE): ±0.5334801521813214\n",
      "Test MSE: 1.537\n",
      "Test inference error (RMSE): ±1.239896709374988\n",
      "##### KNeighborsRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016511583638966077\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0017970040933031513\n",
      "##### KNeighborsRegressor - RidgeCV #####\n",
      "Train MSE: 6.217\n",
      "Train inference error (RMSE): ±2.4933474477791773\n",
      "Test MSE: 13.901\n",
      "Test inference error (RMSE): ±3.728457578567405\n",
      "##### KNeighborsRegressor - SGDRegressor #####\n",
      "Train MSE: 20172955933282134369002842942626619899736446618999841450645723544689425057316864.000\n",
      "Train inference error (RMSE): ±4.491431390245445e+39\n",
      "Test MSE: 20693811523843590136351166989540307949032750953123374833395518379966282948673536.000\n",
      "Test inference error (RMSE): ±4.549045122203515e+39\n",
      "##### KNeighborsRegressor - SVR #####\n",
      "Train MSE: 6.179\n",
      "Train inference error (RMSE): ±2.4857236989277918\n",
      "Test MSE: 15.234\n",
      "Test inference error (RMSE): ±3.9030911410715285\n",
      "##### KNeighborsRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.6662448106527323e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.778442510769533e-05\n",
      "##### KNeighborsRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.6659507695895e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.7820379756368386e-05\n",
      "##### KNeighborsRegressor - TweedieRegressor #####\n",
      "Train MSE: 6.165\n",
      "Train inference error (RMSE): ±2.482969261733321\n",
      "Test MSE: 15.329\n",
      "Test inference error (RMSE): ±3.915174148438923\n",
      "##### KernelRidge - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3110759047660066e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.386947871285284e-05\n",
      "##### KernelRidge - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3110759047660066e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.386947871285284e-05\n",
      "##### KernelRidge - Lasso #####\n",
      "Train MSE: 3.555\n",
      "Train inference error (RMSE): ±1.8855029845174573\n",
      "Test MSE: 5.635\n",
      "Test inference error (RMSE): ±2.373871295430154\n",
      "##### KernelRidge - LassoCV #####\n",
      "Train MSE: 11.206\n",
      "Train inference error (RMSE): ±3.3475886408781506\n",
      "Test MSE: 11.913\n",
      "Test inference error (RMSE): ±3.451510391870265\n",
      "##### KernelRidge - LassoLars #####\n",
      "Train MSE: 3.555\n",
      "Train inference error (RMSE): ±1.8855029399094607\n",
      "Test MSE: 5.635\n",
      "Test inference error (RMSE): ±2.3738712181863644\n",
      "##### KernelRidge - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.311092224262216e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.386964614543269e-05\n",
      "##### KernelRidge - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.311092224262216e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.386964614543269e-05\n",
      "##### KernelRidge - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.31108364739225e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.386956734610399e-05\n",
      "##### KernelRidge - LinearSVR #####\n",
      "Train MSE: 11.220\n",
      "Train inference error (RMSE): ±3.3495950137676056\n",
      "Test MSE: 11.633\n",
      "Test inference error (RMSE): ±3.4107110937033114\n",
      "##### KernelRidge - MLPRegressor #####\n",
      "Train MSE: 603.802\n",
      "Train inference error (RMSE): ±24.572390718106202\n",
      "Test MSE: 649.024\n",
      "Test inference error (RMSE): ±25.475939941107406\n",
      "##### KernelRidge - MultiTaskElasticNet #####\n",
      "Error (KernelRidge-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### KernelRidge - MultiTaskElasticNetCV #####\n",
      "Error (KernelRidge-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### KernelRidge - MultiTaskLasso #####\n",
      "Error (KernelRidge-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### KernelRidge - MultiTaskLassoCV #####\n",
      "Error (KernelRidge-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### KernelRidge - NuSVR #####\n",
      "Train MSE: 11.201\n",
      "Train inference error (RMSE): ±3.3467372604716004\n",
      "Test MSE: 11.650\n",
      "Test inference error (RMSE): ±3.4132242125430934\n",
      "##### KernelRidge - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.205\n",
      "Train inference error (RMSE): ±3.347393262650983\n",
      "Test MSE: 11.944\n",
      "Test inference error (RMSE): ±3.456059140995538\n",
      "##### KernelRidge - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0489395510550277\n",
      "Test MSE: 1.384\n",
      "Test inference error (RMSE): ±1.1764674252343956\n",
      "##### KernelRidge - PLSCanonical #####\n",
      "Error (KernelRidge-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### KernelRidge - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07620895927768144\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08389722164575077\n",
      "##### KernelRidge - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.209\n",
      "Train inference error (RMSE): ±3.3479553517482357\n",
      "Test MSE: 11.642\n",
      "Test inference error (RMSE): ±3.41202527473299\n",
      "##### KernelRidge - PoissonRegressor #####\n",
      "Error (KernelRidge-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### KernelRidge - QuantileRegressor #####\n",
      "Train MSE: 11.204\n",
      "Train inference error (RMSE): ±3.3471810360347702\n",
      "Test MSE: 12.172\n",
      "Test inference error (RMSE): ±3.4888385094891876\n",
      "##### KernelRidge - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.31108364739225e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.386956734610399e-05\n",
      "##### KernelRidge - RadiusNeighborsRegressor #####\n",
      "Error (KernelRidge-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### KernelRidge - RandomForestRegressor #####\n",
      "Train MSE: 0.215\n",
      "Train inference error (RMSE): ±0.463760597081576\n",
      "Test MSE: 1.314\n",
      "Test inference error (RMSE): ±1.1461496470082089\n",
      "##### KernelRidge - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016902786232078795\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015708086808477338\n",
      "##### KernelRidge - RidgeCV #####\n",
      "Train MSE: 11.141\n",
      "Train inference error (RMSE): ±3.337851426268246\n",
      "Test MSE: 13.088\n",
      "Test inference error (RMSE): ±3.6177676108074004\n",
      "##### KernelRidge - SGDRegressor #####\n",
      "Train MSE: 483665267275115810963871550342585136595114864070659785091694752237152427680202752.000\n",
      "Train inference error (RMSE): ±2.19923911222749e+40\n",
      "Test MSE: 506049091060752422071426924295989915897430987744509067398858348693870701480771584.000\n",
      "Test inference error (RMSE): ±2.249553491386129e+40\n",
      "##### KernelRidge - SVR #####\n",
      "Train MSE: 11.211\n",
      "Train inference error (RMSE): ±3.34822333026255\n",
      "Test MSE: 11.641\n",
      "Test inference error (RMSE): ±3.411824608840676\n",
      "##### KernelRidge - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3106717797637996e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.3864605574891975e-05\n",
      "##### KernelRidge - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.31108364739225e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.386956734610399e-05\n",
      "##### KernelRidge - TweedieRegressor #####\n",
      "Train MSE: 11.164\n",
      "Train inference error (RMSE): ±3.341297633969844\n",
      "Test MSE: 11.785\n",
      "Test inference error (RMSE): ±3.432868109345718\n",
      "##### Lars - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.14687040990597e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048560388342897e-05\n",
      "##### Lars - Lasso #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.38308216800698e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969872807723149e-05\n",
      "##### Lars - LassoCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2931673622250515e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534610567421723e-05\n",
      "##### Lars - LassoLars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383059737647556e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969850357817317e-05\n",
      "##### Lars - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468773753796148e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048631924404097e-05\n",
      "##### Lars - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468773753796148e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048631924404097e-05\n",
      "##### Lars - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468830154743886e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048689279461263e-05\n",
      "##### Lars - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293744940017599e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4097163092218904e-05\n",
      "##### Lars - MLPRegressor #####\n",
      "Train MSE: 4.827\n",
      "Train inference error (RMSE): ±2.197151440033851\n",
      "Test MSE: 4.829\n",
      "Test inference error (RMSE): ±2.1974118144290626\n",
      "##### Lars - MultiTaskElasticNet #####\n",
      "Error (Lars-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### Lars - MultiTaskElasticNetCV #####\n",
      "Error (Lars-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### Lars - MultiTaskLasso #####\n",
      "Error (Lars-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### Lars - MultiTaskLassoCV #####\n",
      "Error (Lars-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### Lars - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312086909619533e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.420861032516907e-05\n",
      "##### Lars - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2933035781932454e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.544331892404941e-05\n",
      "##### Lars - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.000134893717358065\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00015222815544925803\n",
      "##### Lars - PLSCanonical #####\n",
      "Error (Lars-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### Lars - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014941389617111076\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809058414688004\n",
      "##### Lars - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.307321621111944e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.39031953815261e-05\n",
      "##### Lars - PoissonRegressor #####\n",
      "Error (Lars-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### Lars - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2999106939553885e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.609901127055715e-05\n",
      "##### Lars - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468830154743886e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048689279461263e-05\n",
      "##### Lars - RadiusNeighborsRegressor #####\n",
      "Error (Lars-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### Lars - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.040820536430864e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012280088308469996\n",
      "##### Lars - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281267442822453\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0009018671699100927\n",
      "##### Lars - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.283318421661866e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.703045761825821e-05\n",
      "##### Lars - SGDRegressor #####\n",
      "Train MSE: 2643925195863488277158300118443676646506690000345925311055980301352915441609458319360.000\n",
      "Train inference error (RMSE): ±1.6260151278089292e+42\n",
      "Test MSE: 2764745061237065596585793729410885826901527826835196979363486583272302956516718149632.000\n",
      "Test inference error (RMSE): ±1.662752254918653e+42\n",
      "##### Lars - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299984027543196e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.408013274320359e-05\n",
      "##### Lars - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468240627885e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2047851063437647e-05\n",
      "##### Lars - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468830154743886e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048689279461263e-05\n",
      "##### Lars - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312914626923688e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4293101343590635e-05\n",
      "##### LarsCV - Lasso #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.38308216800698e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969872807723149e-05\n",
      "##### LarsCV - LassoCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2931673622250515e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534610567421723e-05\n",
      "##### LarsCV - LassoLars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383059737647556e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969850357817317e-05\n",
      "##### LarsCV - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468773753796148e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048631924404097e-05\n",
      "##### LarsCV - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468773753796148e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048631924404097e-05\n",
      "##### LarsCV - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468830154743886e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048689279461263e-05\n",
      "##### LarsCV - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293744940017599e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4097163092218904e-05\n",
      "##### LarsCV - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293714320754063e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.408582914395696e-05\n",
      "##### LarsCV - MultiTaskElasticNet #####\n",
      "Error (LarsCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LarsCV - MultiTaskElasticNetCV #####\n",
      "Error (LarsCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LarsCV - MultiTaskLasso #####\n",
      "Error (LarsCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LarsCV - MultiTaskLassoCV #####\n",
      "Error (LarsCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LarsCV - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312086909619533e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.420861032516907e-05\n",
      "##### LarsCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2933035781932454e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.544331892404941e-05\n",
      "##### LarsCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.000134893717358065\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00015222815544925803\n",
      "##### LarsCV - PLSCanonical #####\n",
      "Error (LarsCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LarsCV - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014941389617111076\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809058414688004\n",
      "##### LarsCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3043444675435764e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4388755292457805e-05\n",
      "##### LarsCV - PoissonRegressor #####\n",
      "Error (LarsCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LarsCV - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2999106939553885e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.609901127055715e-05\n",
      "##### LarsCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468830154743886e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048689279461263e-05\n",
      "##### LarsCV - RadiusNeighborsRegressor #####\n",
      "Error (LarsCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LarsCV - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.69645699851299e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012073126492089903\n",
      "##### LarsCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281267442822453\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0009018671699100927\n",
      "##### LarsCV - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.283318421661866e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.703045761825821e-05\n",
      "##### LarsCV - SGDRegressor #####\n",
      "Train MSE: 8665027971580789723529301918081700240571273959427462142654963647895315238965802434560.000\n",
      "Train inference error (RMSE): ±2.943641957096819e+42\n",
      "Test MSE: 8989412518880359774383813720877241149249681760397486954935214894328552632117635317760.000\n",
      "Test inference error (RMSE): ±2.998234900550716e+42\n",
      "##### LarsCV - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299984027543196e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.408013274320359e-05\n",
      "##### LarsCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1467915540604568e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.204492435178246e-05\n",
      "##### LarsCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468830154743886e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048689279461263e-05\n",
      "##### LarsCV - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312914626923688e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4293101343590635e-05\n",
      "##### Lasso - LassoCV #####\n",
      "Train MSE: 3.416\n",
      "Train inference error (RMSE): ±1.8482561023854356\n",
      "Test MSE: 4.573\n",
      "Test inference error (RMSE): ±2.138409275161691\n",
      "##### Lasso - LassoLars #####\n",
      "Train MSE: 3.521\n",
      "Train inference error (RMSE): ±1.876339040223053\n",
      "Test MSE: 6.419\n",
      "Test inference error (RMSE): ±2.53356775027627\n",
      "##### Lasso - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383083182240771e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969873798492387e-05\n",
      "##### Lasso - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383083182240771e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969873798492387e-05\n",
      "##### Lasso - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383082812056793e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969875506264879e-05\n",
      "##### Lasso - LinearSVR #####\n",
      "Train MSE: 3.521\n",
      "Train inference error (RMSE): ±1.8763469536603683\n",
      "Test MSE: 6.418\n",
      "Test inference error (RMSE): ±2.5333538141052125\n",
      "##### Lasso - MLPRegressor #####\n",
      "Train MSE: 3.543\n",
      "Train inference error (RMSE): ±1.8822169025891742\n",
      "Test MSE: 5.978\n",
      "Test inference error (RMSE): ±2.444921424229067\n",
      "##### Lasso - MultiTaskElasticNet #####\n",
      "Error (Lasso-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### Lasso - MultiTaskElasticNetCV #####\n",
      "Error (Lasso-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### Lasso - MultiTaskLasso #####\n",
      "Error (Lasso-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### Lasso - MultiTaskLassoCV #####\n",
      "Error (Lasso-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### Lasso - NuSVR #####\n",
      "Train MSE: 3.520\n",
      "Train inference error (RMSE): ±1.8761078522517423\n",
      "Test MSE: 6.396\n",
      "Test inference error (RMSE): ±2.5290605123253793\n",
      "##### Lasso - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 3.417\n",
      "Train inference error (RMSE): ±1.8484398908565571\n",
      "Test MSE: 4.532\n",
      "Test inference error (RMSE): ±2.128741650145519\n",
      "##### Lasso - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.048631869672329\n",
      "Test MSE: 1.399\n",
      "Test inference error (RMSE): ±1.1828862050704279\n",
      "##### Lasso - PLSCanonical #####\n",
      "Error (Lasso-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### Lasso - PLSRegression #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.07183735068861069\n",
      "Test MSE: 0.006\n",
      "Test inference error (RMSE): ±0.07485408368096981\n",
      "##### Lasso - PassiveAggressiveRegressor #####\n",
      "Train MSE: 3.548\n",
      "Train inference error (RMSE): ±1.8835904821111804\n",
      "Test MSE: 5.917\n",
      "Test inference error (RMSE): ±2.4324426218985544\n",
      "##### Lasso - PoissonRegressor #####\n",
      "Error (Lasso-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### Lasso - QuantileRegressor #####\n",
      "Train MSE: 3.417\n",
      "Train inference error (RMSE): ±1.8486351623377941\n",
      "Test MSE: 4.501\n",
      "Test inference error (RMSE): ±2.1216032999042325\n",
      "##### Lasso - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383082812056793e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969875506264879e-05\n",
      "##### Lasso - RadiusNeighborsRegressor #####\n",
      "Error (Lasso-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### Lasso - RandomForestRegressor #####\n",
      "Train MSE: 0.197\n",
      "Train inference error (RMSE): ±0.44375558795467634\n",
      "Test MSE: 1.270\n",
      "Test inference error (RMSE): ±1.1270319673327116\n",
      "##### Lasso - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015660109220727682\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015653033779865467\n",
      "##### Lasso - RidgeCV #####\n",
      "Train MSE: 3.456\n",
      "Train inference error (RMSE): ±1.8590659711956605\n",
      "Test MSE: 4.182\n",
      "Test inference error (RMSE): ±2.044990975678875\n",
      "##### Lasso - SGDRegressor #####\n",
      "Train MSE: 75346478000612804894333802402524971928191969671874701726108784261260276244099891200.000\n",
      "Train inference error (RMSE): ±2.7449312924117575e+41\n",
      "Test MSE: 79274762547393930336310964318032117532634954261971621484122991431190696753148985344.000\n",
      "Test inference error (RMSE): ±2.8155774282976827e+41\n",
      "##### Lasso - SVR #####\n",
      "Train MSE: 3.519\n",
      "Train inference error (RMSE): ±1.8757991561318168\n",
      "Test MSE: 6.350\n",
      "Test inference error (RMSE): ±2.5199482723273117\n",
      "##### Lasso - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.382978371672205e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.973221018257057e-05\n",
      "##### Lasso - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383082812056793e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969875506264879e-05\n",
      "##### Lasso - TweedieRegressor #####\n",
      "Train MSE: 3.522\n",
      "Train inference error (RMSE): ±1.8766004670698757\n",
      "Test MSE: 6.398\n",
      "Test inference error (RMSE): ±2.529487962178191\n",
      "##### LassoCV - LassoLars #####\n",
      "Train MSE: 3.416\n",
      "Train inference error (RMSE): ±1.8482560638769454\n",
      "Test MSE: 4.573\n",
      "Test inference error (RMSE): ±2.1384092213384633\n",
      "##### LassoCV - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293173498154716e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5346168306203897e-05\n",
      "##### LassoCV - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293173498154716e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5346168306203897e-05\n",
      "##### LassoCV - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293171761841777e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534632158593818e-05\n",
      "##### LassoCV - LinearSVR #####\n",
      "Train MSE: 11.095\n",
      "Train inference error (RMSE): ±3.330892773254831\n",
      "Test MSE: 12.281\n",
      "Test inference error (RMSE): ±3.5043689190070704\n",
      "##### LassoCV - MLPRegressor #####\n",
      "Train MSE: 11.526\n",
      "Train inference error (RMSE): ±3.395011258115732\n",
      "Test MSE: 14.070\n",
      "Test inference error (RMSE): ±3.7509974704371087\n",
      "##### LassoCV - MultiTaskElasticNet #####\n",
      "Error (LassoCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoCV - MultiTaskElasticNetCV #####\n",
      "Error (LassoCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoCV - MultiTaskLasso #####\n",
      "Error (LassoCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoCV - MultiTaskLassoCV #####\n",
      "Error (LassoCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoCV - NuSVR #####\n",
      "Train MSE: 11.091\n",
      "Train inference error (RMSE): ±3.330328766144181\n",
      "Test MSE: 12.579\n",
      "Test inference error (RMSE): ±3.5467375866143778\n",
      "##### LassoCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.077\n",
      "Train inference error (RMSE): ±3.328179134210827\n",
      "Test MSE: 12.651\n",
      "Test inference error (RMSE): ±3.556819853064975\n",
      "##### LassoCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0487669839516267\n",
      "Test MSE: 1.380\n",
      "Test inference error (RMSE): ±1.1747553294620185\n",
      "##### LassoCV - PLSCanonical #####\n",
      "Error (LassoCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoCV - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07634735525390673\n",
      "Test MSE: 0.006\n",
      "Test inference error (RMSE): ±0.07950422159392746\n",
      "##### LassoCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.102\n",
      "Train inference error (RMSE): ±3.3320349245127416\n",
      "Test MSE: 12.187\n",
      "Test inference error (RMSE): ±3.490946832749173\n",
      "##### LassoCV - PoissonRegressor #####\n",
      "Error (LassoCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoCV - QuantileRegressor #####\n",
      "Train MSE: 11.071\n",
      "Train inference error (RMSE): ±3.327329291950447\n",
      "Test MSE: 12.977\n",
      "Test inference error (RMSE): ±3.602408434063963\n",
      "##### LassoCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293171761841777e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534632158593818e-05\n",
      "##### LassoCV - RadiusNeighborsRegressor #####\n",
      "Error (LassoCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoCV - RandomForestRegressor #####\n",
      "Train MSE: 0.203\n",
      "Train inference error (RMSE): ±0.45098268819489734\n",
      "Test MSE: 1.368\n",
      "Test inference error (RMSE): ±1.1696217368069395\n",
      "##### LassoCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001579984003412006\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001621850000576396\n",
      "##### LassoCV - RidgeCV #####\n",
      "Train MSE: 11.079\n",
      "Train inference error (RMSE): ±3.328490637577025\n",
      "Test MSE: 12.676\n",
      "Test inference error (RMSE): ±3.560382987256881\n",
      "##### LassoCV - SGDRegressor #####\n",
      "Train MSE: 1603842161274356283932126932323430319298292285791625581560762792471056699359232.000\n",
      "Train inference error (RMSE): ±1.2664289009945866e+39\n",
      "Test MSE: 1437458794204693648546433138226674639375859839110607265543902011000930577678336.000\n",
      "Test inference error (RMSE): ±1.1989406967005056e+39\n",
      "##### LassoCV - SVR #####\n",
      "Train MSE: 11.093\n",
      "Train inference error (RMSE): ±3.330602071717365\n",
      "Test MSE: 12.297\n",
      "Test inference error (RMSE): ±3.5067423671896503\n",
      "##### LassoCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.29275247669742e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5356324449611706e-05\n",
      "##### LassoCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293171761841777e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.534632158593818e-05\n",
      "##### LassoCV - TweedieRegressor #####\n",
      "Train MSE: 11.083\n",
      "Train inference error (RMSE): ±3.3290787909377757\n",
      "Test MSE: 12.489\n",
      "Test inference error (RMSE): ±3.5339698975941753\n",
      "##### LassoLars - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383070910228031e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969861490774692e-05\n",
      "##### LassoLars - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.383070910228031e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969861490774692e-05\n",
      "##### LassoLars - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.38307100900813e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969863567557334e-05\n",
      "##### LassoLars - LinearSVR #####\n",
      "Train MSE: 3.521\n",
      "Train inference error (RMSE): ±1.8763469095549097\n",
      "Test MSE: 6.418\n",
      "Test inference error (RMSE): ±2.533353724192912\n",
      "##### LassoLars - MLPRegressor #####\n",
      "Train MSE: 3.520\n",
      "Train inference error (RMSE): ±1.8762963313800232\n",
      "Test MSE: 6.399\n",
      "Test inference error (RMSE): ±2.529696886734381\n",
      "##### LassoLars - MultiTaskElasticNet #####\n",
      "Error (LassoLars-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLars - MultiTaskElasticNetCV #####\n",
      "Error (LassoLars-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLars - MultiTaskLasso #####\n",
      "Error (LassoLars-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLars - MultiTaskLassoCV #####\n",
      "Error (LassoLars-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLars - NuSVR #####\n",
      "Train MSE: 3.520\n",
      "Train inference error (RMSE): ±1.8761078082072675\n",
      "Test MSE: 6.396\n",
      "Test inference error (RMSE): ±2.529060422946579\n",
      "##### LassoLars - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 3.417\n",
      "Train inference error (RMSE): ±1.848439852446206\n",
      "Test MSE: 4.532\n",
      "Test inference error (RMSE): ±2.128741597451723\n",
      "##### LassoLars - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0486318696747896\n",
      "Test MSE: 1.399\n",
      "Test inference error (RMSE): ±1.1828862048603561\n",
      "##### LassoLars - PLSCanonical #####\n",
      "Error (LassoLars-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLars - PLSRegression #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.07183735098048334\n",
      "Test MSE: 0.006\n",
      "Test inference error (RMSE): ±0.07485408404029252\n",
      "##### LassoLars - PassiveAggressiveRegressor #####\n",
      "Train MSE: 3.544\n",
      "Train inference error (RMSE): ±1.8825200001483333\n",
      "Test MSE: 6.001\n",
      "Test inference error (RMSE): ±2.4497831356165123\n",
      "##### LassoLars - PoissonRegressor #####\n",
      "Error (LassoLars-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLars - QuantileRegressor #####\n",
      "Train MSE: 3.417\n",
      "Train inference error (RMSE): ±1.8486351239786865\n",
      "Test MSE: 4.501\n",
      "Test inference error (RMSE): ±2.1216032490040697\n",
      "##### LassoLars - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.38307100900813e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969863567557334e-05\n",
      "##### LassoLars - RadiusNeighborsRegressor #####\n",
      "Error (LassoLars-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLars - RandomForestRegressor #####\n",
      "Train MSE: 0.206\n",
      "Train inference error (RMSE): ±0.4533219240068782\n",
      "Test MSE: 1.236\n",
      "Test inference error (RMSE): ±1.1118575976536127\n",
      "##### LassoLars - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015660107033149658\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001565303175334503\n",
      "##### LassoLars - RidgeCV #####\n",
      "Train MSE: 3.456\n",
      "Train inference error (RMSE): ±1.8590659357080943\n",
      "Test MSE: 4.182\n",
      "Test inference error (RMSE): ±2.0449909266451103\n",
      "##### LassoLars - SGDRegressor #####\n",
      "Train MSE: 1872873933206833724861615731988921771887222437644350625515049366836966729210396672.000\n",
      "Train inference error (RMSE): ±4.3276713521324994e+40\n",
      "Test MSE: 2117062297787484082429475137747926111323637553055282291238542275808964228216258560.000\n",
      "Test inference error (RMSE): ±4.601154526624252e+40\n",
      "##### LassoLars - SVR #####\n",
      "Train MSE: 3.519\n",
      "Train inference error (RMSE): ±1.8757991121026083\n",
      "Test MSE: 6.350\n",
      "Test inference error (RMSE): ±2.5199481835765387\n",
      "##### LassoLars - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.382927771287711e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.968821712705329e-05\n",
      "##### LassoLars - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.38307100900813e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.969863567557334e-05\n",
      "##### LassoLars - TweedieRegressor #####\n",
      "Train MSE: 3.522\n",
      "Train inference error (RMSE): ±1.8766004229432\n",
      "Test MSE: 6.398\n",
      "Test inference error (RMSE): ±2.529487872756466\n",
      "##### LassoLarsCV - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146867229920677e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.204852772958113e-05\n",
      "##### LassoLarsCV - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146880139305497e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048659741139364e-05\n",
      "##### LassoLarsCV - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293740032295152e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409711268962173e-05\n",
      "##### LassoLarsCV - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.314308712081635e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.44864812449419e-05\n",
      "##### LassoLarsCV - MultiTaskElasticNet #####\n",
      "Error (LassoLarsCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsCV - MultiTaskElasticNetCV #####\n",
      "Error (LassoLarsCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLarsCV - MultiTaskLasso #####\n",
      "Error (LassoLarsCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsCV - MultiTaskLassoCV #####\n",
      "Error (LassoLarsCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLarsCV - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312088729527467e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4208629020717506e-05\n",
      "##### LassoLarsCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2932851456251325e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5443130987530716e-05\n",
      "##### LassoLarsCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00013489365650508434\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001522280830550577\n",
      "##### LassoLarsCV - PLSCanonical #####\n",
      "Error (LassoLarsCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLarsCV - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014941389618765505\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809058289617735\n",
      "##### LassoLarsCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3040800083707295e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.441922858681604e-05\n",
      "##### LassoLarsCV - PoissonRegressor #####\n",
      "Error (LassoLarsCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLarsCV - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2999126000482095e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.609903064332981e-05\n",
      "##### LassoLarsCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146880139305497e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048659741139364e-05\n",
      "##### LassoLarsCV - RadiusNeighborsRegressor #####\n",
      "Error (LassoLarsCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLarsCV - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.937613894821073e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012229655135269016\n",
      "##### LassoLarsCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281267748114536\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.000901867193358001\n",
      "##### LassoLarsCV - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.283034522117329e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.683811626118214e-05\n",
      "##### LassoLarsCV - SGDRegressor #####\n",
      "Train MSE: 266650395642439182174212397338533964197057853710335206685244108113054252435419168768.000\n",
      "Train inference error (RMSE): ±5.16382024902532e+41\n",
      "Test MSE: 279983005410855337452498802796537610036132902179659141923388333984353615439013609472.000\n",
      "Test inference error (RMSE): ±5.291342035919199e+41\n",
      "##### LassoLarsCV - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299979152662459e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4080082680937805e-05\n",
      "##### LassoLarsCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146934170130845e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.204886384517714e-05\n",
      "##### LassoLarsCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146880139305497e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048659741139364e-05\n",
      "##### LassoLarsCV - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312913333088215e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4293088055773296e-05\n",
      "##### LassoLarsIC - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146880139305497e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048659741139364e-05\n",
      "##### LassoLarsIC - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293740032295152e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409711268962173e-05\n",
      "##### LassoLarsIC - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.308039725743941e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4621393419077527e-05\n",
      "##### LassoLarsIC - MultiTaskElasticNet #####\n",
      "Error (LassoLarsIC-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsIC - MultiTaskElasticNetCV #####\n",
      "Error (LassoLarsIC-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLarsIC - MultiTaskLasso #####\n",
      "Error (LassoLarsIC-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsIC - MultiTaskLassoCV #####\n",
      "Error (LassoLarsIC-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLarsIC - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312088729527467e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4208629020717506e-05\n",
      "##### LassoLarsIC - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2932851456251325e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5443130987530716e-05\n",
      "##### LassoLarsIC - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00013489365650508434\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001522280830550577\n",
      "##### LassoLarsIC - PLSCanonical #####\n",
      "Error (LassoLarsIC-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLarsIC - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014941389618765505\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809058289617735\n",
      "##### LassoLarsIC - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.294306877863219e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.403330995298875e-05\n",
      "##### LassoLarsIC - PoissonRegressor #####\n",
      "Error (LassoLarsIC-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLarsIC - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2999126000482095e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.609903064332981e-05\n",
      "##### LassoLarsIC - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146880139305497e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048659741139364e-05\n",
      "##### LassoLarsIC - RadiusNeighborsRegressor #####\n",
      "Error (LassoLarsIC-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLarsIC - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.997628009110724e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001226886113163385\n",
      "##### LassoLarsIC - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281267748114536\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.000901867193358001\n",
      "##### LassoLarsIC - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.283034522117329e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.683811626118214e-05\n",
      "##### LassoLarsIC - SGDRegressor #####\n",
      "Train MSE: 16878394469548293557319874315090694605446809010217376310801318223244597120292880384.000\n",
      "Train inference error (RMSE): ±1.2991687523008045e+41\n",
      "Test MSE: 17484748513385016345817817108594460598802957279512927902929887326935736647965212672.000\n",
      "Test inference error (RMSE): ±1.3222990778710018e+41\n",
      "##### LassoLarsIC - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299979152662459e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4080082680937805e-05\n",
      "##### LassoLarsIC - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1469137463933662e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2045278396240455e-05\n",
      "##### LassoLarsIC - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146880139305497e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048659741139364e-05\n",
      "##### LassoLarsIC - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312913333088215e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4293088055773296e-05\n",
      "##### LinearRegression - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293740172204779e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.409711298835748e-05\n",
      "##### LinearRegression - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.9266554267094365e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.298332020719083e-05\n",
      "##### LinearRegression - MultiTaskElasticNet #####\n",
      "Error (LinearRegression-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LinearRegression - MultiTaskElasticNetCV #####\n",
      "Error (LinearRegression-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LinearRegression - MultiTaskLasso #####\n",
      "Error (LinearRegression-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LinearRegression - MultiTaskLassoCV #####\n",
      "Error (LinearRegression-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LinearRegression - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.31207507033158e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.420849038763081e-05\n",
      "##### LinearRegression - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2933042789380956e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5443510811206395e-05\n",
      "##### LinearRegression - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00013489380945251795\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00015222825719256262\n",
      "##### LinearRegression - PLSCanonical #####\n",
      "Error (LinearRegression-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LinearRegression - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014941389652489458\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809058439795418\n",
      "##### LinearRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.294427530048733e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.41290687858744e-05\n",
      "##### LinearRegression - PoissonRegressor #####\n",
      "Error (LinearRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LinearRegression - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299947718635543e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.609953129608829e-05\n",
      "##### LinearRegression - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468703453911517e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048558587599454e-05\n",
      "##### LinearRegression - RadiusNeighborsRegressor #####\n",
      "Error (LinearRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LinearRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.194576152758947e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012740002410570214\n",
      "##### LinearRegression - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281268646852262\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0009018672637239101\n",
      "##### LinearRegression - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2835872190163624e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.71808814346871e-05\n",
      "##### LinearRegression - SGDRegressor #####\n",
      "Train MSE: 3581100557340448843057250723805153322787336913777263005541063435543951156295548010496.000\n",
      "Train inference error (RMSE): ±1.8923796018083814e+42\n",
      "Test MSE: 3704762555262064091653333279092700453709948681801044632454646169281096253376414351360.000\n",
      "Test inference error (RMSE): ±1.9247759753441605e+42\n",
      "##### LinearRegression - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299938733416554e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.407966826427694e-05\n",
      "##### LinearRegression - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1473757017536177e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.205156692669248e-05\n",
      "##### LinearRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468703453911517e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048558587599454e-05\n",
      "##### LinearRegression - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312951125857467e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429347506270429e-05\n",
      "##### LinearSVR - MLPRegressor #####\n",
      "Train MSE: 11.184\n",
      "Train inference error (RMSE): ±3.3442576549138137\n",
      "Test MSE: 11.688\n",
      "Test inference error (RMSE): ±3.4187753788045994\n",
      "##### LinearSVR - MultiTaskElasticNet #####\n",
      "Error (LinearSVR-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LinearSVR - MultiTaskElasticNetCV #####\n",
      "Error (LinearSVR-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LinearSVR - MultiTaskLasso #####\n",
      "Error (LinearSVR-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LinearSVR - MultiTaskLassoCV #####\n",
      "Error (LinearSVR-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LinearSVR - NuSVR #####\n",
      "Train MSE: 11.183\n",
      "Train inference error (RMSE): ±3.3441632361844738\n",
      "Test MSE: 11.764\n",
      "Test inference error (RMSE): ±3.4297971839050962\n",
      "##### LinearSVR - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.092\n",
      "Train inference error (RMSE): ±3.330443791945397\n",
      "Test MSE: 12.324\n",
      "Test inference error (RMSE): ±3.5105369230027397\n",
      "##### LinearSVR - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0486118495899746\n",
      "Test MSE: 1.400\n",
      "Test inference error (RMSE): ±1.1833674156303997\n",
      "##### LinearSVR - PLSCanonical #####\n",
      "Error (LinearSVR-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LinearSVR - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07625306592035215\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08578467435851106\n",
      "##### LinearSVR - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.164\n",
      "Train inference error (RMSE): ±3.3412041756892084\n",
      "Test MSE: 11.799\n",
      "Test inference error (RMSE): ±3.435021139334708\n",
      "##### LinearSVR - PoissonRegressor #####\n",
      "Error (LinearSVR-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LinearSVR - QuantileRegressor #####\n",
      "Train MSE: 11.076\n",
      "Train inference error (RMSE): ±3.3280511276924214\n",
      "Test MSE: 12.681\n",
      "Test inference error (RMSE): ±3.561003999346713\n",
      "##### LinearSVR - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293739828951803e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.40971094630928e-05\n",
      "##### LinearSVR - RadiusNeighborsRegressor #####\n",
      "Error (LinearSVR-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LinearSVR - RandomForestRegressor #####\n",
      "Train MSE: 0.215\n",
      "Train inference error (RMSE): ±0.46412398751199996\n",
      "Test MSE: 1.381\n",
      "Test inference error (RMSE): ±1.1752390138929403\n",
      "##### LinearSVR - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001667273656576586\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018157358080528592\n",
      "##### LinearSVR - RidgeCV #####\n",
      "Train MSE: 11.084\n",
      "Train inference error (RMSE): ±3.3292563969579816\n",
      "Test MSE: 13.489\n",
      "Test inference error (RMSE): ±3.6727823637468937\n",
      "##### LinearSVR - SGDRegressor #####\n",
      "Train MSE: 70535025340218896104933036687858767811170303273217401240809946737628791556800512.000\n",
      "Train inference error (RMSE): ±8.3985132815409e+39\n",
      "Test MSE: 80802869751253505039445543097799115930817447803123053903131358155192051796279296.000\n",
      "Test inference error (RMSE): ±8.989041648098729e+39\n",
      "##### LinearSVR - SVR #####\n",
      "Train MSE: 11.169\n",
      "Train inference error (RMSE): ±3.341995299634336\n",
      "Test MSE: 11.756\n",
      "Test inference error (RMSE): ±3.4287704616523262\n",
      "##### LinearSVR - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293505538660359e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4088508304195666e-05\n",
      "##### LinearSVR - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293739828951803e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.40971094630928e-05\n",
      "##### LinearSVR - TweedieRegressor #####\n",
      "Train MSE: 11.165\n",
      "Train inference error (RMSE): ±3.3413813199683924\n",
      "Test MSE: 11.776\n",
      "Test inference error (RMSE): ±3.43157762955274\n",
      "##### MLPRegressor - MultiTaskElasticNet #####\n",
      "Error (MLPRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### MLPRegressor - MultiTaskElasticNetCV #####\n",
      "Error (MLPRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MLPRegressor - MultiTaskLasso #####\n",
      "Error (MLPRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### MLPRegressor - MultiTaskLassoCV #####\n",
      "Error (MLPRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### MLPRegressor - NuSVR #####\n",
      "Train MSE: 19978432.720\n",
      "Train inference error (RMSE): ±4469.72400941431\n",
      "Test MSE: 20967241.017\n",
      "Test inference error (RMSE): ±4579.000001876487\n",
      "##### MLPRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.279\n",
      "Train inference error (RMSE): ±3.358489170133451\n",
      "Test MSE: 13.219\n",
      "Test inference error (RMSE): ±3.635773238596834\n",
      "##### MLPRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.102\n",
      "Train inference error (RMSE): ±1.0498572336177514\n",
      "Test MSE: 1.377\n",
      "Test inference error (RMSE): ±1.1732768889725096\n",
      "##### MLPRegressor - PLSCanonical #####\n",
      "Error (MLPRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### MLPRegressor - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.0766421957634117\n",
      "Test MSE: 0.008\n",
      "Test inference error (RMSE): ±0.08816528219259533\n",
      "##### MLPRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 98.832\n",
      "Train inference error (RMSE): ±9.941443023836065\n",
      "Test MSE: 96.417\n",
      "Test inference error (RMSE): ±9.819213494889055\n",
      "##### MLPRegressor - PoissonRegressor #####\n",
      "Error (MLPRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### MLPRegressor - QuantileRegressor #####\n",
      "Train MSE: 11.081\n",
      "Train inference error (RMSE): ±3.3287647282445287\n",
      "Test MSE: 12.862\n",
      "Test inference error (RMSE): ±3.586408198328074\n",
      "##### MLPRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.298804472941315e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.396063235937909e-05\n",
      "##### MLPRegressor - RadiusNeighborsRegressor #####\n",
      "Error (MLPRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### MLPRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.210\n",
      "Train inference error (RMSE): ±0.45832086113490705\n",
      "Test MSE: 1.277\n",
      "Test inference error (RMSE): ±1.1301717162334015\n",
      "##### MLPRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016688432248335191\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001852196328161928\n",
      "##### MLPRegressor - RidgeCV #####\n",
      "Train MSE: 11.084\n",
      "Train inference error (RMSE): ±3.329314373765348\n",
      "Test MSE: 13.445\n",
      "Test inference error (RMSE): ±3.666778746567901\n",
      "##### MLPRegressor - SGDRegressor #####\n",
      "Train MSE: 29543872356036543556709055643094886468556614491623515900029823928022406203965440.000\n",
      "Train inference error (RMSE): ±5.435427522839077e+39\n",
      "Test MSE: 30336931770230854136125947536393617264122586309937099591847112444354982295109632.000\n",
      "Test inference error (RMSE): ±5.507897218560896e+39\n",
      "##### MLPRegressor - SVR #####\n",
      "Train MSE: 11.182\n",
      "Train inference error (RMSE): ±3.3439520236776485\n",
      "Test MSE: 11.864\n",
      "Test inference error (RMSE): ±3.44439263323981\n",
      "##### MLPRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2959456011224597e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.419601767831623e-05\n",
      "##### MLPRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.302197759599462e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.39395785375376e-05\n",
      "##### MLPRegressor - TweedieRegressor #####\n",
      "Train MSE: 11.173\n",
      "Train inference error (RMSE): ±3.3425497985802517\n",
      "Test MSE: 11.716\n",
      "Test inference error (RMSE): ±3.4228336405186575\n",
      "##### MultiTaskElasticNet - MultiTaskElasticNetCV #####\n",
      "Error (MultiTaskElasticNet-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - MultiTaskLasso #####\n",
      "Error (MultiTaskElasticNet-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - MultiTaskLassoCV #####\n",
      "Error (MultiTaskElasticNet-MultiTaskLassoCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - NuSVR #####\n",
      "Error (MultiTaskElasticNet-NuSVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskElasticNet-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskElasticNet-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PLSCanonical #####\n",
      "Error (MultiTaskElasticNet-PLSCanonical): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PLSRegression #####\n",
      "Error (MultiTaskElasticNet-PLSRegression): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskElasticNet-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PoissonRegressor #####\n",
      "Error (MultiTaskElasticNet-PoissonRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - QuantileRegressor #####\n",
      "Error (MultiTaskElasticNet-QuantileRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RANSACRegressor #####\n",
      "Error (MultiTaskElasticNet-RANSACRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskElasticNet-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RandomForestRegressor #####\n",
      "Error (MultiTaskElasticNet-RandomForestRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - Ridge #####\n",
      "Error (MultiTaskElasticNet-Ridge): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RidgeCV #####\n",
      "Error (MultiTaskElasticNet-RidgeCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - SGDRegressor #####\n",
      "Error (MultiTaskElasticNet-SGDRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - SVR #####\n",
      "Error (MultiTaskElasticNet-SVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TheilSenRegressor #####\n",
      "Error (MultiTaskElasticNet-TheilSenRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TransformedTargetRegressor #####\n",
      "Error (MultiTaskElasticNet-TransformedTargetRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TweedieRegressor #####\n",
      "Error (MultiTaskElasticNet-TweedieRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNetCV - MultiTaskLasso #####\n",
      "Error (MultiTaskElasticNetCV-MultiTaskLasso): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - MultiTaskLassoCV #####\n",
      "Error (MultiTaskElasticNetCV-MultiTaskLassoCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - NuSVR #####\n",
      "Error (MultiTaskElasticNetCV-NuSVR): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskElasticNetCV-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskElasticNetCV-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PLSCanonical #####\n",
      "Error (MultiTaskElasticNetCV-PLSCanonical): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PLSRegression #####\n",
      "Error (MultiTaskElasticNetCV-PLSRegression): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskElasticNetCV-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PoissonRegressor #####\n",
      "Error (MultiTaskElasticNetCV-PoissonRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - QuantileRegressor #####\n",
      "Error (MultiTaskElasticNetCV-QuantileRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RANSACRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RANSACRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RandomForestRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RandomForestRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - Ridge #####\n",
      "Error (MultiTaskElasticNetCV-Ridge): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RidgeCV #####\n",
      "Error (MultiTaskElasticNetCV-RidgeCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - SGDRegressor #####\n",
      "Error (MultiTaskElasticNetCV-SGDRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - SVR #####\n",
      "Error (MultiTaskElasticNetCV-SVR): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TheilSenRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TheilSenRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TransformedTargetRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TransformedTargetRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TweedieRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TweedieRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskLasso - MultiTaskLassoCV #####\n",
      "Error (MultiTaskLasso-MultiTaskLassoCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - NuSVR #####\n",
      "Error (MultiTaskLasso-NuSVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskLasso-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskLasso-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PLSCanonical #####\n",
      "Error (MultiTaskLasso-PLSCanonical): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PLSRegression #####\n",
      "Error (MultiTaskLasso-PLSRegression): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskLasso-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PoissonRegressor #####\n",
      "Error (MultiTaskLasso-PoissonRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - QuantileRegressor #####\n",
      "Error (MultiTaskLasso-QuantileRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RANSACRegressor #####\n",
      "Error (MultiTaskLasso-RANSACRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskLasso-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RandomForestRegressor #####\n",
      "Error (MultiTaskLasso-RandomForestRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - Ridge #####\n",
      "Error (MultiTaskLasso-Ridge): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RidgeCV #####\n",
      "Error (MultiTaskLasso-RidgeCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - SGDRegressor #####\n",
      "Error (MultiTaskLasso-SGDRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - SVR #####\n",
      "Error (MultiTaskLasso-SVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TheilSenRegressor #####\n",
      "Error (MultiTaskLasso-TheilSenRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TransformedTargetRegressor #####\n",
      "Error (MultiTaskLasso-TransformedTargetRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TweedieRegressor #####\n",
      "Error (MultiTaskLasso-TweedieRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLassoCV - NuSVR #####\n",
      "Error (MultiTaskLassoCV-NuSVR): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskLassoCV-OrthogonalMatchingPursuit): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskLassoCV-OrthogonalMatchingPursuitCV): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PLSCanonical #####\n",
      "Error (MultiTaskLassoCV-PLSCanonical): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PLSRegression #####\n",
      "Error (MultiTaskLassoCV-PLSRegression): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskLassoCV-PassiveAggressiveRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PoissonRegressor #####\n",
      "Error (MultiTaskLassoCV-PoissonRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - QuantileRegressor #####\n",
      "Error (MultiTaskLassoCV-QuantileRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RANSACRegressor #####\n",
      "Error (MultiTaskLassoCV-RANSACRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskLassoCV-RadiusNeighborsRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RandomForestRegressor #####\n",
      "Error (MultiTaskLassoCV-RandomForestRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - Ridge #####\n",
      "Error (MultiTaskLassoCV-Ridge): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RidgeCV #####\n",
      "Error (MultiTaskLassoCV-RidgeCV): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - SGDRegressor #####\n",
      "Error (MultiTaskLassoCV-SGDRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - SVR #####\n",
      "Error (MultiTaskLassoCV-SVR): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TheilSenRegressor #####\n",
      "Error (MultiTaskLassoCV-TheilSenRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TransformedTargetRegressor #####\n",
      "Error (MultiTaskLassoCV-TransformedTargetRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TweedieRegressor #####\n",
      "Error (MultiTaskLassoCV-TweedieRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### NuSVR - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 11.088\n",
      "Train inference error (RMSE): ±3.3299246985301663\n",
      "Test MSE: 12.641\n",
      "Test inference error (RMSE): ±3.555429693933911\n",
      "##### NuSVR - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0486254099153391\n",
      "Test MSE: 1.401\n",
      "Test inference error (RMSE): ±1.18345121376485\n",
      "##### NuSVR - PLSCanonical #####\n",
      "Error (NuSVR-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### NuSVR - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07625870142260935\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08580897301461508\n",
      "##### NuSVR - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.182\n",
      "Train inference error (RMSE): ±3.3440016410856392\n",
      "Test MSE: 11.754\n",
      "Test inference error (RMSE): ±3.428442367192591\n",
      "##### NuSVR - PoissonRegressor #####\n",
      "Error (NuSVR-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### NuSVR - QuantileRegressor #####\n",
      "Train MSE: 11.080\n",
      "Train inference error (RMSE): ±3.3286842671222616\n",
      "Test MSE: 12.831\n",
      "Test inference error (RMSE): ±3.5820176334752403\n",
      "##### NuSVR - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312078233757606e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.420852288498411e-05\n",
      "##### NuSVR - RadiusNeighborsRegressor #####\n",
      "Error (NuSVR-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### NuSVR - RandomForestRegressor #####\n",
      "Train MSE: 0.205\n",
      "Train inference error (RMSE): ±0.45263067348899144\n",
      "Test MSE: 1.304\n",
      "Test inference error (RMSE): ±1.1417152172245961\n",
      "##### NuSVR - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016513050581903866\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018086751579221437\n",
      "##### NuSVR - RidgeCV #####\n",
      "Train MSE: 11.095\n",
      "Train inference error (RMSE): ±3.3309780665218374\n",
      "Test MSE: 13.931\n",
      "Test inference error (RMSE): ±3.7324515173233785\n",
      "##### NuSVR - SGDRegressor #####\n",
      "Train MSE: 192302054501017385257446322367603451428950757674260187814436404291242884595712.000\n",
      "Train inference error (RMSE): ±4.385225815177793e+38\n",
      "Test MSE: 198302306550784399304673602529250045683584518989492753979154249668309693759488.000\n",
      "Test inference error (RMSE): ±4.453114713891664e+38\n",
      "##### NuSVR - SVR #####\n",
      "Train MSE: 11.173\n",
      "Train inference error (RMSE): ±3.3425705954508507\n",
      "Test MSE: 11.757\n",
      "Test inference error (RMSE): ±3.428792232171704\n",
      "##### NuSVR - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.311691642348223e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.419522114129345e-05\n",
      "##### NuSVR - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312078233757606e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.420852288498411e-05\n",
      "##### NuSVR - TweedieRegressor #####\n",
      "Train MSE: 11.152\n",
      "Train inference error (RMSE): ±3.3394869698032217\n",
      "Test MSE: 11.792\n",
      "Test inference error (RMSE): ±3.43401953580699\n",
      "##### OrthogonalMatchingPursuit - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0487712254184858\n",
      "Test MSE: 1.380\n",
      "Test inference error (RMSE): ±1.1746379983348667\n",
      "##### OrthogonalMatchingPursuit - PLSCanonical #####\n",
      "Error (OrthogonalMatchingPursuit-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### OrthogonalMatchingPursuit - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07639087933782056\n",
      "Test MSE: 0.006\n",
      "Test inference error (RMSE): ±0.07943295678823982\n",
      "##### OrthogonalMatchingPursuit - PassiveAggressiveRegressor #####\n",
      "Train MSE: 11.107\n",
      "Train inference error (RMSE): ±3.3326894888880996\n",
      "Test MSE: 12.156\n",
      "Test inference error (RMSE): ±3.48660834269654\n",
      "##### OrthogonalMatchingPursuit - PoissonRegressor #####\n",
      "Error (OrthogonalMatchingPursuit-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### OrthogonalMatchingPursuit - QuantileRegressor #####\n",
      "Train MSE: 11.073\n",
      "Train inference error (RMSE): ±3.3275675613124074\n",
      "Test MSE: 12.832\n",
      "Test inference error (RMSE): ±3.5821225690839444\n",
      "##### OrthogonalMatchingPursuit - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293317553849491e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.544364628043433e-05\n",
      "##### OrthogonalMatchingPursuit - RadiusNeighborsRegressor #####\n",
      "Error (OrthogonalMatchingPursuit-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### OrthogonalMatchingPursuit - RandomForestRegressor #####\n",
      "Train MSE: 0.211\n",
      "Train inference error (RMSE): ±0.4596881493159253\n",
      "Test MSE: 1.353\n",
      "Test inference error (RMSE): ±1.1633169092788516\n",
      "##### OrthogonalMatchingPursuit - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015806769181440302\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016422384512819205\n",
      "##### OrthogonalMatchingPursuit - RidgeCV #####\n",
      "Train MSE: 11.078\n",
      "Train inference error (RMSE): ±3.3284241326182524\n",
      "Test MSE: 12.682\n",
      "Test inference error (RMSE): ±3.561189178248422\n",
      "##### OrthogonalMatchingPursuit - SGDRegressor #####\n",
      "Train MSE: 2865025231099765632595269488822179742690876074692849132630945466932288924709552128.000\n",
      "Train inference error (RMSE): ±5.352593045524539e+40\n",
      "Test MSE: 2941939312723210127026545030499473718044742722856845904545174357371551633589141504.000\n",
      "Test inference error (RMSE): ±5.423964705566593e+40\n",
      "##### OrthogonalMatchingPursuit - SVR #####\n",
      "Train MSE: 11.090\n",
      "Train inference error (RMSE): ±3.3301455430894564\n",
      "Test MSE: 12.344\n",
      "Test inference error (RMSE): ±3.5133763179493167\n",
      "##### OrthogonalMatchingPursuit - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293368306278372e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.5471767839800746e-05\n",
      "##### OrthogonalMatchingPursuit - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.293317553849491e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.544364628043433e-05\n",
      "##### OrthogonalMatchingPursuit - TweedieRegressor #####\n",
      "Train MSE: 11.080\n",
      "Train inference error (RMSE): ±3.328732537878118\n",
      "Test MSE: 12.544\n",
      "Test inference error (RMSE): ±3.541682731953778\n",
      "##### OrthogonalMatchingPursuitCV - PLSCanonical #####\n",
      "Error (OrthogonalMatchingPursuitCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### OrthogonalMatchingPursuitCV - PLSRegression #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07572726002805297\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08476891042381439\n",
      "##### OrthogonalMatchingPursuitCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 1.108\n",
      "Train inference error (RMSE): ±1.0526663093844506\n",
      "Test MSE: 1.363\n",
      "Test inference error (RMSE): ±1.1674108869206403\n",
      "##### OrthogonalMatchingPursuitCV - PoissonRegressor #####\n",
      "Error (OrthogonalMatchingPursuitCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### OrthogonalMatchingPursuitCV - QuantileRegressor #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.048679618089301\n",
      "Test MSE: 1.388\n",
      "Test inference error (RMSE): ±1.1780106591782804\n",
      "##### OrthogonalMatchingPursuitCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00013489381029311318\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00015222825822915523\n",
      "##### OrthogonalMatchingPursuitCV - RadiusNeighborsRegressor #####\n",
      "Error (OrthogonalMatchingPursuitCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### OrthogonalMatchingPursuitCV - RandomForestRegressor #####\n",
      "Train MSE: 0.532\n",
      "Train inference error (RMSE): ±0.7292154917355664\n",
      "Test MSE: 1.107\n",
      "Test inference error (RMSE): ±1.0519898308351503\n",
      "##### OrthogonalMatchingPursuitCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016601554645311628\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018018335079975853\n",
      "##### OrthogonalMatchingPursuitCV - RidgeCV #####\n",
      "Train MSE: 1.131\n",
      "Train inference error (RMSE): ±1.0634421953207354\n",
      "Test MSE: 1.367\n",
      "Test inference error (RMSE): ±1.1693037711058412\n",
      "##### OrthogonalMatchingPursuitCV - SGDRegressor #####\n",
      "Train MSE: 144728884186084117613992479285597028473001924740753386722252304779539098015629312.000\n",
      "Train inference error (RMSE): ±1.2030331840231347e+40\n",
      "Test MSE: 148584155058657284645812632329630595747060512228466294847168811911736516558192640.000\n",
      "Test inference error (RMSE): ±1.2189510041780075e+40\n",
      "##### OrthogonalMatchingPursuitCV - SVR #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.0486309271040377\n",
      "Test MSE: 1.398\n",
      "Test inference error (RMSE): ±1.1824344378189182\n",
      "##### OrthogonalMatchingPursuitCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00013489546596826\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00015224205414505774\n",
      "##### OrthogonalMatchingPursuitCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00013489381029311318\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00015222825822915523\n",
      "##### OrthogonalMatchingPursuitCV - TweedieRegressor #####\n",
      "Train MSE: 1.100\n",
      "Train inference error (RMSE): ±1.048628342621207\n",
      "Test MSE: 1.400\n",
      "Test inference error (RMSE): ±1.1834269591913948\n",
      "##### PLSCanonical - PLSRegression #####\n",
      "Error (PLSCanonical-PLSRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - PassiveAggressiveRegressor #####\n",
      "Error (PLSCanonical-PassiveAggressiveRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - PoissonRegressor #####\n",
      "Error (PLSCanonical-PoissonRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - QuantileRegressor #####\n",
      "Error (PLSCanonical-QuantileRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RANSACRegressor #####\n",
      "Error (PLSCanonical-RANSACRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RadiusNeighborsRegressor #####\n",
      "Error (PLSCanonical-RadiusNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RandomForestRegressor #####\n",
      "Error (PLSCanonical-RandomForestRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - Ridge #####\n",
      "Error (PLSCanonical-Ridge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RidgeCV #####\n",
      "Error (PLSCanonical-RidgeCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - SGDRegressor #####\n",
      "Error (PLSCanonical-SGDRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - SVR #####\n",
      "Error (PLSCanonical-SVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TheilSenRegressor #####\n",
      "Error (PLSCanonical-TheilSenRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TransformedTargetRegressor #####\n",
      "Error (PLSCanonical-TransformedTargetRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TweedieRegressor #####\n",
      "Error (PLSCanonical-TweedieRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07627782636988253\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.0860360797760517\n",
      "##### PLSRegression - PoissonRegressor #####\n",
      "Error (PLSRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PLSRegression - QuantileRegressor #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07642681148465584\n",
      "Test MSE: 0.006\n",
      "Test inference error (RMSE): ±0.07939354819629459\n",
      "##### PLSRegression - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001494138965251023\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809058438001334\n",
      "##### PLSRegression - RadiusNeighborsRegressor #####\n",
      "Error (PLSRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### PLSRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.0765018412702298\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.084815001063567\n",
      "##### PLSRegression - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0021635324602140085\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002564601517424809\n",
      "##### PLSRegression - RidgeCV #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07632762760122574\n",
      "Test MSE: 0.008\n",
      "Test inference error (RMSE): ±0.08683096161924495\n",
      "##### PLSRegression - SGDRegressor #####\n",
      "Train MSE: 181117182599679873645604823479968886733570347391465598934974697186335373177393250304.000\n",
      "Train inference error (RMSE): ±4.255786444356435e+41\n",
      "Test MSE: 195175066589930593440989039124763280601920007639208041157753390614748490643397410816.000\n",
      "Test inference error (RMSE): ±4.4178622272534776e+41\n",
      "##### PLSRegression - SVR #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07624670955910041\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08577635452637097\n",
      "##### PLSRegression - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014941422591474823\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809007634186039\n",
      "##### PLSRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001494138965251023\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016809058438001334\n",
      "##### PLSRegression - TweedieRegressor #####\n",
      "Train MSE: 0.006\n",
      "Train inference error (RMSE): ±0.07624849523925978\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.08581711218614126\n",
      "##### PassiveAggressiveRegressor - PoissonRegressor #####\n",
      "Error (PassiveAggressiveRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PassiveAggressiveRegressor - QuantileRegressor #####\n",
      "Train MSE: 11.077\n",
      "Train inference error (RMSE): ±3.3282468624265027\n",
      "Test MSE: 12.686\n",
      "Test inference error (RMSE): ±3.561694878757521\n",
      "##### PassiveAggressiveRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.302750178290861e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4408329113109736e-05\n",
      "##### PassiveAggressiveRegressor - RadiusNeighborsRegressor #####\n",
      "Error (PassiveAggressiveRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### PassiveAggressiveRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.210\n",
      "Train inference error (RMSE): ±0.4586753647384796\n",
      "Test MSE: 1.346\n",
      "Test inference error (RMSE): ±1.1599759949123476\n",
      "##### PassiveAggressiveRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001666698556775675\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0018074438104374012\n",
      "##### PassiveAggressiveRegressor - RidgeCV #####\n",
      "Train MSE: 11.107\n",
      "Train inference error (RMSE): ±3.3327150941471335\n",
      "Test MSE: 13.991\n",
      "Test inference error (RMSE): ±3.740467545780702\n",
      "##### PassiveAggressiveRegressor - SGDRegressor #####\n",
      "Train MSE: 8025603985263654766256466068671715751009697433609495082260167801054390260858880.000\n",
      "Train inference error (RMSE): ±2.8329496969172706e+39\n",
      "Test MSE: 7761931461789076699105737050857209443901683918708077617480010814061960438480896.000\n",
      "Test inference error (RMSE): ±2.7860243110549265e+39\n",
      "##### PassiveAggressiveRegressor - SVR #####\n",
      "Train MSE: 11.203\n",
      "Train inference error (RMSE): ±3.347110219808852\n",
      "Test MSE: 11.664\n",
      "Test inference error (RMSE): ±3.415261933577936\n",
      "##### PassiveAggressiveRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2944309473367737e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4146464164370534e-05\n",
      "##### PassiveAggressiveRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.298549305509982e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.433341787177939e-05\n",
      "##### PassiveAggressiveRegressor - TweedieRegressor #####\n",
      "Train MSE: 11.364\n",
      "Train inference error (RMSE): ±3.3710834820049347\n",
      "Test MSE: 11.629\n",
      "Test inference error (RMSE): ±3.4100913132682917\n",
      "##### PoissonRegressor - QuantileRegressor #####\n",
      "Error (PoissonRegressor-QuantileRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RANSACRegressor #####\n",
      "Error (PoissonRegressor-RANSACRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RadiusNeighborsRegressor #####\n",
      "Error (PoissonRegressor-RadiusNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RandomForestRegressor #####\n",
      "Error (PoissonRegressor-RandomForestRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - Ridge #####\n",
      "Error (PoissonRegressor-Ridge): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RidgeCV #####\n",
      "Error (PoissonRegressor-RidgeCV): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - SGDRegressor #####\n",
      "Error (PoissonRegressor-SGDRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - SVR #####\n",
      "Error (PoissonRegressor-SVR): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TheilSenRegressor #####\n",
      "Error (PoissonRegressor-TheilSenRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TransformedTargetRegressor #####\n",
      "Error (PoissonRegressor-TransformedTargetRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TweedieRegressor #####\n",
      "Error (PoissonRegressor-TweedieRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### QuantileRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299966489579585e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.609972094706182e-05\n",
      "##### QuantileRegressor - RadiusNeighborsRegressor #####\n",
      "Error (QuantileRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### QuantileRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.216\n",
      "Train inference error (RMSE): ±0.4646130829649662\n",
      "Test MSE: 1.384\n",
      "Test inference error (RMSE): ±1.1766177773900321\n",
      "##### QuantileRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015897757805535865\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016753093833963486\n",
      "##### QuantileRegressor - RidgeCV #####\n",
      "Train MSE: 11.078\n",
      "Train inference error (RMSE): ±3.3283367014890417\n",
      "Test MSE: 12.601\n",
      "Test inference error (RMSE): ±3.5497553377787874\n",
      "##### QuantileRegressor - SGDRegressor #####\n",
      "Train MSE: 1033054520427206527442118471233238179135199627564200897964813357365063279706112.000\n",
      "Train inference error (RMSE): ±1.0163928966827771e+39\n",
      "Test MSE: 1121204327427586951659301802005225327851326667081646197750332966084474885373952.000\n",
      "Test inference error (RMSE): ±1.0588693627769135e+39\n",
      "##### QuantileRegressor - SVR #####\n",
      "Train MSE: 11.074\n",
      "Train inference error (RMSE): ±3.327826048992589\n",
      "Test MSE: 12.729\n",
      "Test inference error (RMSE): ±3.56771757911113\n",
      "##### QuantileRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.3002397575003036e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.609346519383432e-05\n",
      "##### QuantileRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299966489579585e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.609972094706182e-05\n",
      "##### QuantileRegressor - TweedieRegressor #####\n",
      "Train MSE: 11.074\n",
      "Train inference error (RMSE): ±3.327788420986408\n",
      "Test MSE: 12.753\n",
      "Test inference error (RMSE): ±3.5711404566976737\n",
      "##### RANSACRegressor - RadiusNeighborsRegressor #####\n",
      "Error (RANSACRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RANSACRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.926210796669738e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.000122914206644613\n",
      "##### RANSACRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281268646852262\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0009018672637239101\n",
      "##### RANSACRegressor - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.2835872190163624e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.71808814346871e-05\n",
      "##### RANSACRegressor - SGDRegressor #####\n",
      "Train MSE: 2318073323968692229039270815744293458943420393868240394056541231482377462395340587008.000\n",
      "Train inference error (RMSE): ±1.5225220274165797e+42\n",
      "Test MSE: 2404213559400779755366707879738996325351366017854944623550757793302758092138887512064.000\n",
      "Test inference error (RMSE): ±1.550552662569311e+42\n",
      "##### RANSACRegressor - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299938733416554e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.407966826427694e-05\n",
      "##### RANSACRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.146917344204393e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.204748235677308e-05\n",
      "##### RANSACRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1468703453911517e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2048558587599454e-05\n",
      "##### RANSACRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312951125857467e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429347506270429e-05\n",
      "##### RadiusNeighborsRegressor - RandomForestRegressor #####\n",
      "Error (RadiusNeighborsRegressor-RandomForestRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - Ridge #####\n",
      "Error (RadiusNeighborsRegressor-Ridge): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - RidgeCV #####\n",
      "Error (RadiusNeighborsRegressor-RidgeCV): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - SGDRegressor #####\n",
      "Error (RadiusNeighborsRegressor-SGDRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - SVR #####\n",
      "Error (RadiusNeighborsRegressor-SVR): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TheilSenRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TheilSenRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TransformedTargetRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TransformedTargetRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TweedieRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TweedieRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RandomForestRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015461897717116788\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0017957443482209845\n",
      "##### RandomForestRegressor - RidgeCV #####\n",
      "Train MSE: 0.235\n",
      "Train inference error (RMSE): ±0.48433157495022794\n",
      "Test MSE: 1.412\n",
      "Test inference error (RMSE): ±1.1882894230717445\n",
      "##### RandomForestRegressor - SGDRegressor #####\n",
      "Train MSE: 7172799608534800237114068033863445573923892511765569092428877912266891575070556160.000\n",
      "Train inference error (RMSE): ±8.469238223438281e+40\n",
      "Test MSE: 7017063720047510626713765969221416155884801142803752347632538576350852938819698688.000\n",
      "Test inference error (RMSE): ±8.376791581534968e+40\n",
      "##### RandomForestRegressor - SVR #####\n",
      "Train MSE: 0.228\n",
      "Train inference error (RMSE): ±0.4779906755720178\n",
      "Test MSE: 1.327\n",
      "Test inference error (RMSE): ±1.152038169278708\n",
      "##### RandomForestRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.1183624252991273e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001261271113402379\n",
      "##### RandomForestRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.0437541903304576e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012320592074583988\n",
      "##### RandomForestRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.208\n",
      "Train inference error (RMSE): ±0.45599741326372223\n",
      "Test MSE: 1.344\n",
      "Test inference error (RMSE): ±1.1592132619978068\n",
      "##### Ridge - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016138093229798702\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0022148942859049076\n",
      "##### Ridge - SGDRegressor #####\n",
      "Train MSE: 3648812978632471620902635954361248385592795690020419374855705377177572216335451029504.000\n",
      "Train inference error (RMSE): ±1.9101866345026266e+42\n",
      "Test MSE: 3718159741870168924925258574870702684164462601781383806215787931710480213545263824896.000\n",
      "Test inference error (RMSE): ±1.9282530284872285e+42\n",
      "##### Ridge - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016574851796943026\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0017843188645510725\n",
      "##### Ridge - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281268177506479\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0009018491299560713\n",
      "##### Ridge - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0008281268734398828\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0009018672704470672\n",
      "##### Ridge - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001661496910894742\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001811196810027911\n",
      "##### RidgeCV - SGDRegressor #####\n",
      "Train MSE: 52433095824931663890316695660324835953022017961972985922910566971130704667082752.000\n",
      "Train inference error (RMSE): ±7.2410700745768e+39\n",
      "Test MSE: 56787510503728901377780986128061928439499239839239432575094212891889909784117248.000\n",
      "Test inference error (RMSE): ±7.535748834968486e+39\n",
      "##### RidgeCV - SVR #####\n",
      "Train MSE: 11.085\n",
      "Train inference error (RMSE): ±3.3294117082944408\n",
      "Test MSE: 13.515\n",
      "Test inference error (RMSE): ±3.6762403450252896\n",
      "##### RidgeCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.284164113172803e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.720366901313405e-05\n",
      "##### RidgeCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.284093247711402e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.740250467427346e-05\n",
      "##### RidgeCV - TweedieRegressor #####\n",
      "Train MSE: 11.088\n",
      "Train inference error (RMSE): ±3.329860277524723\n",
      "Test MSE: 13.664\n",
      "Test inference error (RMSE): ±3.696525626709664\n",
      "##### SGDRegressor - SVR #####\n",
      "Train MSE: 71512528702439134171354643800456921445234381022938524975178002471037749235286016.000\n",
      "Train inference error (RMSE): ±8.456508067898897e+39\n",
      "Test MSE: 71940991163165009889805555275819920745586329782796934444695998306213564740796416.000\n",
      "Test inference error (RMSE): ±8.481803532454935e+39\n",
      "##### SGDRegressor - TheilSenRegressor #####\n",
      "Train MSE: 407373335784552836731607164233898292432288816874457420986442781427564993975938973696.000\n",
      "Train inference error (RMSE): ±6.382580479590938e+41\n",
      "Test MSE: 425658527874731315464852698574297175591723290764970768332486899363275748601292128256.000\n",
      "Test inference error (RMSE): ±6.5242511284800445e+41\n",
      "##### SGDRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 252039666878194716391060240799848620202790136413317068149457826214013448467383320576.000\n",
      "Train inference error (RMSE): ±5.020355235221853e+41\n",
      "Test MSE: 260450351050104308375208637620862451926824102867425899763849160931654064248402739200.000\n",
      "Test inference error (RMSE): ±5.1034336583334196e+41\n",
      "##### SGDRegressor - TweedieRegressor #####\n",
      "Train MSE: 2335724607838550191768637586768367752357969421826513409249550461966020405375270912.000\n",
      "Train inference error (RMSE): ±4.832933485822612e+40\n",
      "Test MSE: 2852635535682660446649328084791609112088190980458955366487759196083831899324153856.000\n",
      "Test inference error (RMSE): ±5.341006960941598e+40\n",
      "##### SVR - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299687915233197e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.408662913191878e-05\n",
      "##### SVR - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.299947288105769e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.4079756117294945e-05\n",
      "##### SVR - TweedieRegressor #####\n",
      "Train MSE: 11.168\n",
      "Train inference error (RMSE): ±3.3418754259497017\n",
      "Test MSE: 11.760\n",
      "Test inference error (RMSE): ±3.4293000930912116\n",
      "##### TheilSenRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1470002280246087e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±2.2049393041302885e-05\n",
      "##### TheilSenRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.31297830628397e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.42942114652155e-05\n",
      "##### TransformedTargetRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.312951125857467e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.429347506270429e-05\n",
      "########## Best Estimator ##########\n",
      "['LarsCV-TheilSenRegressor', 4.859786896758113e-10, 2.204492435178246e-05]\n",
      "Total time: 380.63429403305054\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimators_stacked_trained, best_staked_estimator_name = run_sklearn_estimators_with_stacking(\n",
    "    all_estimators,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    model_type\n",
    ")\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62b0d684-33bf-419b-b59d-4c171e29b1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;LarsCV&#x27;, LarsCV()),\n",
       "                              (&#x27;TheilSenRegressor&#x27;, TheilSenRegressor())],\n",
       "                  final_estimator=RidgeCV())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingRegressor.html\">?<span>Documentation for StackingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingRegressor(estimators=[(&#x27;LarsCV&#x27;, LarsCV()),\n",
       "                              (&#x27;TheilSenRegressor&#x27;, TheilSenRegressor())],\n",
       "                  final_estimator=RidgeCV())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>LarsCV</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LarsCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LarsCV.html\">?<span>Documentation for LarsCV</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LarsCV()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>TheilSenRegressor</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TheilSenRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.TheilSenRegressor.html\">?<span>Documentation for TheilSenRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TheilSenRegressor()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RidgeCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.RidgeCV.html\">?<span>Documentation for RidgeCV</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RidgeCV()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('LarsCV', LarsCV()),\n",
       "                              ('TheilSenRegressor', TheilSenRegressor())],\n",
       "                  final_estimator=RidgeCV())"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_stacked_trained[best_staked_estimator_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a42d4-3bad-4a1c-a8c9-dee86bc52bb5",
   "metadata": {},
   "source": [
    "### Save Estimator staked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32120e1f-2db5-41c8-b53f-2dc4588c3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(estimators_trained[best_estimator_name], open('results/estimator_sklearn_stacked.sav', 'wb'))\n",
    "\n",
    "# Scaler\n",
    "pickle.dump(scaler, open('results/scaler.pkl','wb'))\n",
    "\n",
    "# Save columns names and informations\n",
    "data_to_save = {\n",
    "    'col_names_order': col_names_order,\n",
    "    'num_col_names': num_col_names,\n",
    "    'cat_col_names': cat_col_names,\n",
    "    'date_col_names': date_col_names,\n",
    "    'target_cols': target_cols,\n",
    "    'category_mappings': category_mappings,\n",
    "    'window_size': window_size\n",
    "}\n",
    "with open('results/columns_metadata_sklearn_stacked.json', 'w') as json_file:\n",
    "    json.dump(data_to_save, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538ba71-15e3-42db-a526-cb376135a073",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c843071-fc93-45c4-bca3-a1fd36a7fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43724cc0-8d03-4e8e-a4d4-4a0eefb8a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "#loaded_estimator = pickle.load(open('results/estimator_sklearn.sav', 'rb'))\n",
    "loaded_estimator = pickle.load(open('results/estimator_sklearn_stacked.sav', 'rb'))\n",
    "# Scaler\n",
    "loaded_scaler = pickle.load(open('results/scaler.pkl','rb'))\n",
    "# columns_metadata\n",
    "#columns_metadata = json.load(open('results/columns_metadata_sklearn.json', 'r'))\n",
    "columns_metadata = json.load(open('results/columns_metadata_sklearn_stacked.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1ef45e9-aa23-4ce3-819f-d6e4081582c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inference_data(new_input, columns_metadata, scaler=None):\n",
    "    \"\"\"\n",
    "    Preprocess the input data for inference based on metadata and scaler for numeric normalization.\n",
    "\n",
    "    Args:\n",
    "        new_input (list of list): Data to preprocess (each inner list is a row).\n",
    "        columns_metadata (dict): Metadata defining column names, types, mappings, and order.\n",
    "        scaler (StandardScaler): Trained scaler for numerical columns.\n",
    "    \n",
    "    Returns:\n",
    "        list: Preprocessed data ready for inference.\n",
    "    \"\"\"\n",
    "    # Exclude target columns from col_names_order for inference\n",
    "    target_cols = columns_metadata['target_cols']\n",
    "    col_names_order = [col for col in columns_metadata['col_names_order'] if col not in target_cols]\n",
    "    # Transform the new_input into a DataFrame with the correct column order\n",
    "    df_input = pd.DataFrame(new_input, columns=col_names_order)\n",
    "\n",
    "    # Convert categorical columns based on category_mappings\n",
    "    category_mappings = columns_metadata['category_mappings']\n",
    "    for col in columns_metadata['cat_col_names']:\n",
    "        if col in df_input.columns and col in category_mappings:\n",
    "            # Replace string categories with mapped integer IDs\n",
    "            df_input[col] = df_input[col].map(category_mappings[col])\n",
    "            if df_input[col].isnull().any():\n",
    "                raise ValueError(f'Invalid value found in column \"{col}\" that is not in the category mappings.')\n",
    "\n",
    "    # Normalize numeric columns using the trained scaler\n",
    "    num_col_names = columns_metadata['num_col_names']\n",
    "    if num_col_names and scaler:\n",
    "        df_input[num_col_names] = scaler.transform(df_input[num_col_names])\n",
    "\n",
    "    # Ensure date columns are in the correct datetime format\n",
    "    for col in columns_metadata['date_col_names']:\n",
    "        if col in df_input.columns:\n",
    "            df_input[col] = pd.to_datetime(df_input[col], errors='coerce').astype(int) // 10**9\n",
    "            if df_input[col].isnull().any():\n",
    "                raise ValueError(f'Invalid date value found in column \"{col}\".')\n",
    "\n",
    "    # Drop target columns if they exist in the input (not used in inference)\n",
    "    target_cols = columns_metadata['target_cols']\n",
    "    df_input = df_input.drop(columns=target_cols, errors='ignore')\n",
    "\n",
    "    # Convert DataFrame to list of rows for model inference\n",
    "    processed_data = df_input.values.tolist()\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db28f2-6ac1-4d60-9dd3-eb40e4fb3d43",
   "metadata": {},
   "source": [
    "**ATENÇÃO:** Modifique a variável \"new_input\" conforme o seu dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "297367d2-2bb1-41be-a3bc-f05b8811222e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.35777506968953204,\n",
       "  -1.3790900760388114,\n",
       "  1.1353768019811052,\n",
       "  -0.995928676706269,\n",
       "  0.7628334100284831,\n",
       "  -0.876391059362353,\n",
       "  0.5628335279142523,\n",
       "  -1.0517421247382792,\n",
       "  1736035200.0,\n",
       "  0.9712375087530014,\n",
       "  -0.19348437208231686,\n",
       "  1.5045270774737975,\n",
       "  1.1970465609890275]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "new_input = [\n",
    "    [21.94, 985.30, 79.74, 3.84, 24.25, 992.55, 70.01, 3.53, '2025-01-05', 25.43, 1002.41, 85.90, 16.61]\n",
    "]\n",
    "new_input_preprocessed = preprocess_inference_data(new_input, columns_metadata, loaded_scaler)\n",
    "new_input_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1adcc30-d10d-42f6-b7a6-4332800409c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0627]\n",
      "Total time: 0.00023102760314941406\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "print(loaded_estimator.predict(new_input_preprocessed))\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbf7e0df-f497-4ebd-9cfa-5118cbce826e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Temporal graph result\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test['date'], test['target'], marker='o', linestyle='-', label='Real', color='navy')\n",
    "plt.plot(test['date'], loaded_estimator.predict(x_test), marker='^', linestyle='-', label='Prediction', color='orange')\n",
    "plt.title('Real vs Predict')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Target')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
