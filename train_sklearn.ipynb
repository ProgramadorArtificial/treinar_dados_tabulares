{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3489c1bc-d70b-4089-a6fc-9428e959dfc3",
   "metadata": {},
   "source": [
    "# Sklearn\n",
    "Notebook pensando para facilitar e agiliar o treinamento de Machine Learning, sendo necessário, em grande parte das vezes, somente alterar o caminho do dataset e o tipo (classificador ou regressão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7227abb5-2f27-4fc4-be31-afe3a4a093ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0be3e-6a93-41aa-9ec8-0ceb6ffece8c",
   "metadata": {},
   "source": [
    "## Preparar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a81160e-461d-440f-a3ac-7869034ff805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_cols, max_unique_values=10, window_size=1, no_columns_lags=[]):\n",
    "    \"\"\"\n",
    "    Preprocess dataset, converting string columns to number and identifying numeric, categorical, and date columns.\n",
    "    Adds a window of historical rows to the data.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame with data to analyze.\n",
    "        target_cols (list): All target columns to not add in numeric, categorical, or date feature lists.\n",
    "        max_unique_values (int): Maximum number of unique values to consider a numeric column as categorical.\n",
    "        window_size (int): Number of previous rows to include for each row.\n",
    "        no_columns_lags (list): Columns names to not do lags, keeping only the current one.\n",
    "\n",
    "    Returns:\n",
    "        df_copy (DataFrame): Processed DataFrame with transformations applied.\n",
    "        num_col_names (list): List of numeric feature column names.\n",
    "        cat_col_names (list): List of categorical feature column names.\n",
    "        date_col_names (list): List of date feature column names.\n",
    "        mappings (dict): Mapping of original categorical values (or target columns) to transformed numeric values.\n",
    "    \"\"\"\n",
    "    # Create a copy so as not to alter the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Remove lines with null values\n",
    "    df_copy = df_copy.dropna()\n",
    "    \n",
    "    # Identify categorical and numeric columns\n",
    "    cat_col_names = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_col_names = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    date_col_names = []\n",
    "\n",
    "    # Identify columns that are dates\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['object', 'string']:  # Only check object/string columns\n",
    "            try:\n",
    "                # Attempt to convert the column to datetime\n",
    "                df_copy[col] = pd.to_datetime(df[col], errors='raise').astype(int) // 10**9\n",
    "                if col not in target_cols:  # Avoid considering target columns as date columns\n",
    "                    date_col_names.append(col)\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "    # Identify numeric columns that are categorical\n",
    "    potential_categorical = []\n",
    "    for col in num_col_names:\n",
    "        if col not in target_cols and df_copy[col].nunique() <= max_unique_values:\n",
    "            potential_categorical.append(col)\n",
    "\n",
    "    cat_col_names += potential_categorical\n",
    "\n",
    "    # Remove target columns from the lists\n",
    "    num_col_names = [col for col in num_col_names if col not in potential_categorical + target_cols + date_col_names]\n",
    "    cat_col_names = [col for col in cat_col_names if col not in target_cols + date_col_names]\n",
    "    \n",
    "    mappings = {}\n",
    "    label_encoders = {}\n",
    "\n",
    "    # Convert string columns to category and create a mapping (old value -> new value)\n",
    "    for col in cat_col_names + target_cols:\n",
    "        if df_copy[col].dtype not in ['int64', 'float64']:\n",
    "            le = LabelEncoder()\n",
    "            df_copy[col] = le.fit_transform(df_copy[col])\n",
    "            mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            label_encoders[col] = le\n",
    "            # Convert values to int (otherwise will raise error if save as json)\n",
    "            for key, value in mappings[col].items():\n",
    "                mappings[col][key] = int(value)\n",
    "        #else:\n",
    "        #    mappings[col] = {int(val): int(val) for val in df_copy[col].unique()}\n",
    "\n",
    "    # Add historical data based on window_size\n",
    "    if window_size > 1:\n",
    "        historical_features = []\n",
    "        for i in range(window_size - 1, 0, -1):  # Create features lag, oldest to newest\n",
    "            shifted = df_copy.drop(columns=target_cols + no_columns_lags, errors='ignore').shift(i).add_suffix(f'_lag_{i}')\n",
    "            historical_features.append(shifted)\n",
    "        \n",
    "        # Concatenate the lags to the left and keep the current values\n",
    "        df_copy = pd.concat(historical_features + [df_copy], axis=1)\n",
    "\n",
    "        # Remove NaNs columns created by shifts\n",
    "        df_copy = df_copy.dropna()\n",
    "    \n",
    "        # Add lags\n",
    "        num_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in num_col_names if col not in no_columns_lags]\n",
    "        cat_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in cat_col_names if col not in no_columns_lags]\n",
    "        date_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in date_col_names if col not in no_columns_lags]\n",
    "        mappings_lags = {}\n",
    "        for col, value in mappings.items():\n",
    "            for i in range(window_size - 1, 0, -1):\n",
    "                mappings_lags[f'{col}_lag_{i}'] = value\n",
    "    \n",
    "        # Update main columns + lags columns\n",
    "        num_col_names = num_col_lags + num_col_names\n",
    "        cat_col_names = cat_col_lags + cat_col_names\n",
    "        date_col_names = date_col_lags + date_col_names\n",
    "        mappings = {**mappings_lags, **mappings}\n",
    "    \n",
    "    return df_copy, num_col_names, cat_col_names, date_col_names, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dda78a0-630b-4947-8e10-a24019cf98d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>temperature</th>\n",
       "      <th>atmospheric_pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>29.204468</td>\n",
       "      <td>1018.531025</td>\n",
       "      <td>55.368863</td>\n",
       "      <td>5.636536</td>\n",
       "      <td>12.745888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-04</td>\n",
       "      <td>22.318149</td>\n",
       "      <td>1017.262825</td>\n",
       "      <td>38.066587</td>\n",
       "      <td>2.520635</td>\n",
       "      <td>14.497671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>18.386458</td>\n",
       "      <td>994.651252</td>\n",
       "      <td>57.438279</td>\n",
       "      <td>9.802986</td>\n",
       "      <td>12.170944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>29.625662</td>\n",
       "      <td>1029.142441</td>\n",
       "      <td>88.232424</td>\n",
       "      <td>14.553119</td>\n",
       "      <td>10.076645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>13.901379</td>\n",
       "      <td>1005.326379</td>\n",
       "      <td>37.854832</td>\n",
       "      <td>12.765371</td>\n",
       "      <td>8.582377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2027-09-23</td>\n",
       "      <td>28.789072</td>\n",
       "      <td>1003.400658</td>\n",
       "      <td>67.593622</td>\n",
       "      <td>11.953912</td>\n",
       "      <td>9.325243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2027-09-24</td>\n",
       "      <td>27.887713</td>\n",
       "      <td>1012.916262</td>\n",
       "      <td>50.098965</td>\n",
       "      <td>2.210093</td>\n",
       "      <td>12.846413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2027-09-25</td>\n",
       "      <td>16.830046</td>\n",
       "      <td>988.167754</td>\n",
       "      <td>77.374936</td>\n",
       "      <td>14.168634</td>\n",
       "      <td>10.899380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2027-09-26</td>\n",
       "      <td>12.307704</td>\n",
       "      <td>990.774392</td>\n",
       "      <td>56.353575</td>\n",
       "      <td>18.602596</td>\n",
       "      <td>6.143613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2027-09-27</td>\n",
       "      <td>22.817836</td>\n",
       "      <td>995.903711</td>\n",
       "      <td>61.494547</td>\n",
       "      <td>6.716725</td>\n",
       "      <td>7.138004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           data  temperature  atmospheric_pressure   humidity  wind_speed  \\\n",
       "0    2025-01-03    29.204468           1018.531025  55.368863    5.636536   \n",
       "1    2025-01-04    22.318149           1017.262825  38.066587    2.520635   \n",
       "2    2025-01-05    18.386458            994.651252  57.438279    9.802986   \n",
       "3    2025-01-06    29.625662           1029.142441  88.232424   14.553119   \n",
       "4    2025-01-07    13.901379           1005.326379  37.854832   12.765371   \n",
       "..          ...          ...                   ...        ...         ...   \n",
       "993  2027-09-23    28.789072           1003.400658  67.593622   11.953912   \n",
       "994  2027-09-24    27.887713           1012.916262  50.098965    2.210093   \n",
       "995  2027-09-25    16.830046            988.167754  77.374936   14.168634   \n",
       "996  2027-09-26    12.307704            990.774392  56.353575   18.602596   \n",
       "997  2027-09-27    22.817836            995.903711  61.494547    6.716725   \n",
       "\n",
       "        target  \n",
       "0    12.745888  \n",
       "1    14.497671  \n",
       "2    12.170944  \n",
       "3    10.076645  \n",
       "4     8.582377  \n",
       "..         ...  \n",
       "993   9.325243  \n",
       "994  12.846413  \n",
       "995  10.899380  \n",
       "996   6.143613  \n",
       "997   7.138004  \n",
       "\n",
       "[998 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/time_series_temperature.csv')\n",
    "model_type = 'regressor'  # classifier or regressor\n",
    "window_size = 3  # Greater than 1 for temporal data\n",
    "no_columns_lags = ['data']  # Only for temporal data. Otherwise keep the list empty\n",
    "temporal_test_part = 2  # Which part of the dataset uses to test. 0 == random; 1 == begin; 2 == end\n",
    "target_cols = ['target']  # Target column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502d6196-e3f8-4683-8d12-73fcf834d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "df, num_col_names, cat_col_names, date_col_names, category_mappings = preprocess_data(df, target_cols, max_unique_values=10, window_size=window_size, no_columns_lags=no_columns_lags)\n",
    "col_names_order = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60931f8-4c85-41bc-ad1d-0ac0443fb35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_lag_2</th>\n",
       "      <th>atmospheric_pressure_lag_2</th>\n",
       "      <th>humidity_lag_2</th>\n",
       "      <th>wind_speed_lag_2</th>\n",
       "      <th>temperature_lag_1</th>\n",
       "      <th>atmospheric_pressure_lag_1</th>\n",
       "      <th>humidity_lag_1</th>\n",
       "      <th>wind_speed_lag_1</th>\n",
       "      <th>data</th>\n",
       "      <th>temperature</th>\n",
       "      <th>atmospheric_pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.204468</td>\n",
       "      <td>1018.531025</td>\n",
       "      <td>55.368863</td>\n",
       "      <td>5.636536</td>\n",
       "      <td>22.318149</td>\n",
       "      <td>1017.262825</td>\n",
       "      <td>38.066587</td>\n",
       "      <td>2.520635</td>\n",
       "      <td>1736035200</td>\n",
       "      <td>18.386458</td>\n",
       "      <td>994.651252</td>\n",
       "      <td>57.438279</td>\n",
       "      <td>9.802986</td>\n",
       "      <td>12.170944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.318149</td>\n",
       "      <td>1017.262825</td>\n",
       "      <td>38.066587</td>\n",
       "      <td>2.520635</td>\n",
       "      <td>18.386458</td>\n",
       "      <td>994.651252</td>\n",
       "      <td>57.438279</td>\n",
       "      <td>9.802986</td>\n",
       "      <td>1736121600</td>\n",
       "      <td>29.625662</td>\n",
       "      <td>1029.142441</td>\n",
       "      <td>88.232424</td>\n",
       "      <td>14.553119</td>\n",
       "      <td>10.076645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.386458</td>\n",
       "      <td>994.651252</td>\n",
       "      <td>57.438279</td>\n",
       "      <td>9.802986</td>\n",
       "      <td>29.625662</td>\n",
       "      <td>1029.142441</td>\n",
       "      <td>88.232424</td>\n",
       "      <td>14.553119</td>\n",
       "      <td>1736208000</td>\n",
       "      <td>13.901379</td>\n",
       "      <td>1005.326379</td>\n",
       "      <td>37.854832</td>\n",
       "      <td>12.765371</td>\n",
       "      <td>8.582377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.625662</td>\n",
       "      <td>1029.142441</td>\n",
       "      <td>88.232424</td>\n",
       "      <td>14.553119</td>\n",
       "      <td>13.901379</td>\n",
       "      <td>1005.326379</td>\n",
       "      <td>37.854832</td>\n",
       "      <td>12.765371</td>\n",
       "      <td>1736294400</td>\n",
       "      <td>24.173470</td>\n",
       "      <td>990.590026</td>\n",
       "      <td>41.027570</td>\n",
       "      <td>12.433600</td>\n",
       "      <td>12.463849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.901379</td>\n",
       "      <td>1005.326379</td>\n",
       "      <td>37.854832</td>\n",
       "      <td>12.765371</td>\n",
       "      <td>24.173470</td>\n",
       "      <td>990.590026</td>\n",
       "      <td>41.027570</td>\n",
       "      <td>12.433600</td>\n",
       "      <td>1736380800</td>\n",
       "      <td>19.105578</td>\n",
       "      <td>1022.114411</td>\n",
       "      <td>36.760806</td>\n",
       "      <td>18.049986</td>\n",
       "      <td>10.954051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>26.676370</td>\n",
       "      <td>1022.415136</td>\n",
       "      <td>59.614973</td>\n",
       "      <td>16.943906</td>\n",
       "      <td>10.946224</td>\n",
       "      <td>1017.197600</td>\n",
       "      <td>68.560684</td>\n",
       "      <td>8.132820</td>\n",
       "      <td>1821657600</td>\n",
       "      <td>28.789072</td>\n",
       "      <td>1003.400658</td>\n",
       "      <td>67.593622</td>\n",
       "      <td>11.953912</td>\n",
       "      <td>9.325243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>10.946224</td>\n",
       "      <td>1017.197600</td>\n",
       "      <td>68.560684</td>\n",
       "      <td>8.132820</td>\n",
       "      <td>28.789072</td>\n",
       "      <td>1003.400658</td>\n",
       "      <td>67.593622</td>\n",
       "      <td>11.953912</td>\n",
       "      <td>1821744000</td>\n",
       "      <td>27.887713</td>\n",
       "      <td>1012.916262</td>\n",
       "      <td>50.098965</td>\n",
       "      <td>2.210093</td>\n",
       "      <td>12.846413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>28.789072</td>\n",
       "      <td>1003.400658</td>\n",
       "      <td>67.593622</td>\n",
       "      <td>11.953912</td>\n",
       "      <td>27.887713</td>\n",
       "      <td>1012.916262</td>\n",
       "      <td>50.098965</td>\n",
       "      <td>2.210093</td>\n",
       "      <td>1821830400</td>\n",
       "      <td>16.830046</td>\n",
       "      <td>988.167754</td>\n",
       "      <td>77.374936</td>\n",
       "      <td>14.168634</td>\n",
       "      <td>10.899380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>27.887713</td>\n",
       "      <td>1012.916262</td>\n",
       "      <td>50.098965</td>\n",
       "      <td>2.210093</td>\n",
       "      <td>16.830046</td>\n",
       "      <td>988.167754</td>\n",
       "      <td>77.374936</td>\n",
       "      <td>14.168634</td>\n",
       "      <td>1821916800</td>\n",
       "      <td>12.307704</td>\n",
       "      <td>990.774392</td>\n",
       "      <td>56.353575</td>\n",
       "      <td>18.602596</td>\n",
       "      <td>6.143613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>16.830046</td>\n",
       "      <td>988.167754</td>\n",
       "      <td>77.374936</td>\n",
       "      <td>14.168634</td>\n",
       "      <td>12.307704</td>\n",
       "      <td>990.774392</td>\n",
       "      <td>56.353575</td>\n",
       "      <td>18.602596</td>\n",
       "      <td>1822003200</td>\n",
       "      <td>22.817836</td>\n",
       "      <td>995.903711</td>\n",
       "      <td>61.494547</td>\n",
       "      <td>6.716725</td>\n",
       "      <td>7.138004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     temperature_lag_2  atmospheric_pressure_lag_2  humidity_lag_2  \\\n",
       "2            29.204468                 1018.531025       55.368863   \n",
       "3            22.318149                 1017.262825       38.066587   \n",
       "4            18.386458                  994.651252       57.438279   \n",
       "5            29.625662                 1029.142441       88.232424   \n",
       "6            13.901379                 1005.326379       37.854832   \n",
       "..                 ...                         ...             ...   \n",
       "993          26.676370                 1022.415136       59.614973   \n",
       "994          10.946224                 1017.197600       68.560684   \n",
       "995          28.789072                 1003.400658       67.593622   \n",
       "996          27.887713                 1012.916262       50.098965   \n",
       "997          16.830046                  988.167754       77.374936   \n",
       "\n",
       "     wind_speed_lag_2  temperature_lag_1  atmospheric_pressure_lag_1  \\\n",
       "2            5.636536          22.318149                 1017.262825   \n",
       "3            2.520635          18.386458                  994.651252   \n",
       "4            9.802986          29.625662                 1029.142441   \n",
       "5           14.553119          13.901379                 1005.326379   \n",
       "6           12.765371          24.173470                  990.590026   \n",
       "..                ...                ...                         ...   \n",
       "993         16.943906          10.946224                 1017.197600   \n",
       "994          8.132820          28.789072                 1003.400658   \n",
       "995         11.953912          27.887713                 1012.916262   \n",
       "996          2.210093          16.830046                  988.167754   \n",
       "997         14.168634          12.307704                  990.774392   \n",
       "\n",
       "     humidity_lag_1  wind_speed_lag_1        data  temperature  \\\n",
       "2         38.066587          2.520635  1736035200    18.386458   \n",
       "3         57.438279          9.802986  1736121600    29.625662   \n",
       "4         88.232424         14.553119  1736208000    13.901379   \n",
       "5         37.854832         12.765371  1736294400    24.173470   \n",
       "6         41.027570         12.433600  1736380800    19.105578   \n",
       "..              ...               ...         ...          ...   \n",
       "993       68.560684          8.132820  1821657600    28.789072   \n",
       "994       67.593622         11.953912  1821744000    27.887713   \n",
       "995       50.098965          2.210093  1821830400    16.830046   \n",
       "996       77.374936         14.168634  1821916800    12.307704   \n",
       "997       56.353575         18.602596  1822003200    22.817836   \n",
       "\n",
       "     atmospheric_pressure   humidity  wind_speed     target  \n",
       "2              994.651252  57.438279    9.802986  12.170944  \n",
       "3             1029.142441  88.232424   14.553119  10.076645  \n",
       "4             1005.326379  37.854832   12.765371   8.582377  \n",
       "5              990.590026  41.027570   12.433600  12.463849  \n",
       "6             1022.114411  36.760806   18.049986  10.954051  \n",
       "..                    ...        ...         ...        ...  \n",
       "993           1003.400658  67.593622   11.953912   9.325243  \n",
       "994           1012.916262  50.098965    2.210093  12.846413  \n",
       "995            988.167754  77.374936   14.168634  10.899380  \n",
       "996            990.774392  56.353575   18.602596   6.143613  \n",
       "997            995.903711  61.494547    6.716725   7.138004  \n",
       "\n",
       "[996 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6911e8e8-d77e-497e-a8bc-134fdcd791fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_names_order: ['temperature_lag_2', 'atmospheric_pressure_lag_2', 'humidity_lag_2', 'wind_speed_lag_2', 'temperature_lag_1', 'atmospheric_pressure_lag_1', 'humidity_lag_1', 'wind_speed_lag_1', 'data', 'temperature', 'atmospheric_pressure', 'humidity', 'wind_speed', 'target']\n",
      "num_col_names: ['temperature_lag_2', 'atmospheric_pressure_lag_2', 'humidity_lag_2', 'wind_speed_lag_2', 'temperature_lag_1', 'atmospheric_pressure_lag_1', 'humidity_lag_1', 'wind_speed_lag_1', 'temperature', 'atmospheric_pressure', 'humidity', 'wind_speed']\n",
      "cat_col_names: []\n",
      "date_col_names: ['data']\n",
      "target_cols: ['target']\n",
      "category_mappings: {}\n"
     ]
    }
   ],
   "source": [
    "print(f'''col_names_order: {col_names_order}\n",
    "num_col_names: {num_col_names}\n",
    "cat_col_names: {cat_col_names}\n",
    "date_col_names: {date_col_names}\n",
    "target_cols: {target_cols}\n",
    "category_mappings: {category_mappings}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed57e737-f6d9-4fe3-b38c-038d44e280bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 996 entries, 2 to 997\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   temperature_lag_2           996 non-null    float64\n",
      " 1   atmospheric_pressure_lag_2  996 non-null    float64\n",
      " 2   humidity_lag_2              996 non-null    float64\n",
      " 3   wind_speed_lag_2            996 non-null    float64\n",
      " 4   temperature_lag_1           996 non-null    float64\n",
      " 5   atmospheric_pressure_lag_1  996 non-null    float64\n",
      " 6   humidity_lag_1              996 non-null    float64\n",
      " 7   wind_speed_lag_1            996 non-null    float64\n",
      " 8   data                        996 non-null    int64  \n",
      " 9   temperature                 996 non-null    float64\n",
      " 10  atmospheric_pressure        996 non-null    float64\n",
      " 11  humidity                    996 non-null    float64\n",
      " 12  wind_speed                  996 non-null    float64\n",
      " 13  target                      996 non-null    float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 116.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eacf642-fe7f-465c-8f74-fea497c7453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'classifier':\n",
    "    print(df[target_cols].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fffec-dfee-49f8-815d-3fc5c94a51c1",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8adfa6d0-8dee-468c-8c3b-b00ab8a204a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "train, test = train_test_split(df, random_state=42, test_size=0.3)\n",
    "\n",
    "if window_size > 1:\n",
    "    # Get first part of the dataset for test\n",
    "    if temporal_test_part == 1:\n",
    "        train = df.iloc[:int(len(df)*0.3)]\n",
    "        train = shuffle(train, random_state=42)\n",
    "        test = df.iloc[int(len(df)*0.3):]\n",
    "    # Get last part of the dataset for test\n",
    "    elif temporal_test_part == 2:\n",
    "        train = df.iloc[:int(len(df)*0.7)]\n",
    "        train = shuffle(train, random_state=42)\n",
    "        test = df.iloc[int(len(df)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e972c845-197d-4055-bfb0-641a680b9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[target_cols]\n",
    "x_train = train.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4b2e59-7601-42ad-bf06-f2a4982a7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[target_cols]\n",
    "x_test = test.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee0910a-7f2d-4009-9b66-67bdd31fc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7ec3c7-e375-40d3-8a2c-663157d552e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skelarn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeca4cce-663a-43b1-8539-37ccc4f433ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_lag_2</th>\n",
       "      <th>atmospheric_pressure_lag_2</th>\n",
       "      <th>humidity_lag_2</th>\n",
       "      <th>wind_speed_lag_2</th>\n",
       "      <th>temperature_lag_1</th>\n",
       "      <th>atmospheric_pressure_lag_1</th>\n",
       "      <th>humidity_lag_1</th>\n",
       "      <th>wind_speed_lag_1</th>\n",
       "      <th>data</th>\n",
       "      <th>temperature</th>\n",
       "      <th>atmospheric_pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>19.896108</td>\n",
       "      <td>981.843404</td>\n",
       "      <td>68.426465</td>\n",
       "      <td>1.807610</td>\n",
       "      <td>24.925605</td>\n",
       "      <td>1020.323242</td>\n",
       "      <td>31.711203</td>\n",
       "      <td>10.673051</td>\n",
       "      <td>1749686400</td>\n",
       "      <td>27.863230</td>\n",
       "      <td>982.525893</td>\n",
       "      <td>63.801928</td>\n",
       "      <td>9.083621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>15.265726</td>\n",
       "      <td>1016.268544</td>\n",
       "      <td>52.421635</td>\n",
       "      <td>10.803885</td>\n",
       "      <td>28.956320</td>\n",
       "      <td>1003.066693</td>\n",
       "      <td>57.996864</td>\n",
       "      <td>13.307716</td>\n",
       "      <td>1778976000</td>\n",
       "      <td>25.389537</td>\n",
       "      <td>1029.803245</td>\n",
       "      <td>54.574362</td>\n",
       "      <td>9.752135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>21.193393</td>\n",
       "      <td>987.922220</td>\n",
       "      <td>70.454872</td>\n",
       "      <td>13.339209</td>\n",
       "      <td>23.575029</td>\n",
       "      <td>1015.667173</td>\n",
       "      <td>68.459813</td>\n",
       "      <td>17.584157</td>\n",
       "      <td>1770163200</td>\n",
       "      <td>16.526745</td>\n",
       "      <td>1006.280674</td>\n",
       "      <td>85.923733</td>\n",
       "      <td>6.350102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>14.019939</td>\n",
       "      <td>1015.800780</td>\n",
       "      <td>43.693244</td>\n",
       "      <td>14.098339</td>\n",
       "      <td>13.993246</td>\n",
       "      <td>1009.516868</td>\n",
       "      <td>55.043601</td>\n",
       "      <td>16.018558</td>\n",
       "      <td>1749427200</td>\n",
       "      <td>23.385722</td>\n",
       "      <td>1005.486687</td>\n",
       "      <td>68.897769</td>\n",
       "      <td>18.086136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>16.865377</td>\n",
       "      <td>1005.328230</td>\n",
       "      <td>42.967926</td>\n",
       "      <td>1.789045</td>\n",
       "      <td>11.985979</td>\n",
       "      <td>1011.577320</td>\n",
       "      <td>41.250436</td>\n",
       "      <td>1.161364</td>\n",
       "      <td>1763769600</td>\n",
       "      <td>11.522224</td>\n",
       "      <td>1013.823791</td>\n",
       "      <td>41.428044</td>\n",
       "      <td>11.672949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>22.804534</td>\n",
       "      <td>986.517903</td>\n",
       "      <td>84.836968</td>\n",
       "      <td>8.547070</td>\n",
       "      <td>11.341251</td>\n",
       "      <td>1014.045467</td>\n",
       "      <td>33.255625</td>\n",
       "      <td>15.247649</td>\n",
       "      <td>1742169600</td>\n",
       "      <td>16.213109</td>\n",
       "      <td>1023.135977</td>\n",
       "      <td>75.683038</td>\n",
       "      <td>5.404471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>26.319418</td>\n",
       "      <td>1026.624365</td>\n",
       "      <td>44.655492</td>\n",
       "      <td>9.019665</td>\n",
       "      <td>27.839426</td>\n",
       "      <td>1004.355025</td>\n",
       "      <td>38.214743</td>\n",
       "      <td>17.693443</td>\n",
       "      <td>1745193600</td>\n",
       "      <td>25.764761</td>\n",
       "      <td>989.168588</td>\n",
       "      <td>60.846891</td>\n",
       "      <td>8.526223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>13.686724</td>\n",
       "      <td>985.046995</td>\n",
       "      <td>44.838549</td>\n",
       "      <td>18.886910</td>\n",
       "      <td>28.785689</td>\n",
       "      <td>1028.324998</td>\n",
       "      <td>65.927011</td>\n",
       "      <td>16.656633</td>\n",
       "      <td>1759363200</td>\n",
       "      <td>26.649485</td>\n",
       "      <td>1023.633639</td>\n",
       "      <td>36.592835</td>\n",
       "      <td>7.411725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>10.306918</td>\n",
       "      <td>1015.962999</td>\n",
       "      <td>53.680541</td>\n",
       "      <td>7.409775</td>\n",
       "      <td>23.841495</td>\n",
       "      <td>987.021255</td>\n",
       "      <td>81.811254</td>\n",
       "      <td>17.282881</td>\n",
       "      <td>1773619200</td>\n",
       "      <td>12.585329</td>\n",
       "      <td>994.756855</td>\n",
       "      <td>77.995033</td>\n",
       "      <td>13.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>21.109230</td>\n",
       "      <td>1028.214251</td>\n",
       "      <td>49.202102</td>\n",
       "      <td>12.759224</td>\n",
       "      <td>19.873694</td>\n",
       "      <td>1002.961758</td>\n",
       "      <td>49.871755</td>\n",
       "      <td>4.062832</td>\n",
       "      <td>1744848000</td>\n",
       "      <td>24.556555</td>\n",
       "      <td>1008.547461</td>\n",
       "      <td>42.350670</td>\n",
       "      <td>2.155334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     temperature_lag_2  atmospheric_pressure_lag_2  humidity_lag_2  \\\n",
       "160          19.896108                  981.843404       68.426465   \n",
       "499          15.265726                 1016.268544       52.421635   \n",
       "397          21.193393                  987.922220       70.454872   \n",
       "157          14.019939                 1015.800780       43.693244   \n",
       "323          16.865377                 1005.328230       42.967926   \n",
       "..                 ...                         ...             ...   \n",
       "73           22.804534                  986.517903       84.836968   \n",
       "108          26.319418                 1026.624365       44.655492   \n",
       "272          13.686724                  985.046995       44.838549   \n",
       "437          10.306918                 1015.962999       53.680541   \n",
       "104          21.109230                 1028.214251       49.202102   \n",
       "\n",
       "     wind_speed_lag_2  temperature_lag_1  atmospheric_pressure_lag_1  \\\n",
       "160          1.807610          24.925605                 1020.323242   \n",
       "499         10.803885          28.956320                 1003.066693   \n",
       "397         13.339209          23.575029                 1015.667173   \n",
       "157         14.098339          13.993246                 1009.516868   \n",
       "323          1.789045          11.985979                 1011.577320   \n",
       "..                ...                ...                         ...   \n",
       "73           8.547070          11.341251                 1014.045467   \n",
       "108          9.019665          27.839426                 1004.355025   \n",
       "272         18.886910          28.785689                 1028.324998   \n",
       "437          7.409775          23.841495                  987.021255   \n",
       "104         12.759224          19.873694                 1002.961758   \n",
       "\n",
       "     humidity_lag_1  wind_speed_lag_1        data  temperature  \\\n",
       "160       31.711203         10.673051  1749686400    27.863230   \n",
       "499       57.996864         13.307716  1778976000    25.389537   \n",
       "397       68.459813         17.584157  1770163200    16.526745   \n",
       "157       55.043601         16.018558  1749427200    23.385722   \n",
       "323       41.250436          1.161364  1763769600    11.522224   \n",
       "..              ...               ...         ...          ...   \n",
       "73        33.255625         15.247649  1742169600    16.213109   \n",
       "108       38.214743         17.693443  1745193600    25.764761   \n",
       "272       65.927011         16.656633  1759363200    26.649485   \n",
       "437       81.811254         17.282881  1773619200    12.585329   \n",
       "104       49.871755          4.062832  1744848000    24.556555   \n",
       "\n",
       "     atmospheric_pressure   humidity  wind_speed  \n",
       "160            982.525893  63.801928    9.083621  \n",
       "499           1029.803245  54.574362    9.752135  \n",
       "397           1006.280674  85.923733    6.350102  \n",
       "157           1005.486687  68.897769   18.086136  \n",
       "323           1013.823791  41.428044   11.672949  \n",
       "..                    ...        ...         ...  \n",
       "73            1023.135977  75.683038    5.404471  \n",
       "108            989.168588  60.846891    8.526223  \n",
       "272           1023.633639  36.592835    7.411725  \n",
       "437            994.756855  77.995033   13.001234  \n",
       "104           1008.547461  42.350670    2.155334  \n",
       "\n",
       "[697 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bddd440-aac8-4616-94fa-22e859de77ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.01302354884638623,\n",
       "  -1.6919823116809463,\n",
       "  0.5235174362248355,\n",
       "  -1.4929756774591356,\n",
       "  0.845178117143607,\n",
       "  1.0031663999550586,\n",
       "  -1.6417476723656663,\n",
       "  0.07397616869488374,\n",
       "  1749686400.0,\n",
       "  1.3413561745226181,\n",
       "  -1.6420058658436913,\n",
       "  0.24950183875504459,\n",
       "  -0.21071369628234088],\n",
       " [-0.7989026258623733,\n",
       "  0.7172134638538871,\n",
       "  -0.4219358396823608,\n",
       "  0.09658005864893485,\n",
       "  1.5296581399417235,\n",
       "  -0.2050894079845413,\n",
       "  -0.09090718460557953,\n",
       "  0.5392358578353584,\n",
       "  1778976000.0,\n",
       "  0.921727326951502,\n",
       "  1.6692146892988866,\n",
       "  -0.2954950835696261,\n",
       "  -0.09268005934570933],\n",
       " [0.20715477372498595,\n",
       "  -1.2665647739086283,\n",
       "  0.6433414918035895,\n",
       "  0.5445476697271479,\n",
       "  0.6158286162624164,\n",
       "  0.6771613209489361,\n",
       "  0.5264014374677108,\n",
       "  1.294419510803609,\n",
       "  1770163200.0,\n",
       "  -0.5817266568869617,\n",
       "  0.02173619852406141,\n",
       "  1.5560561969837687,\n",
       "  -0.6933476056837194],\n",
       " [-1.010340431650813,\n",
       "  0.6844776737273773,\n",
       "  -0.9375480708432992,\n",
       "  0.6786786230911152,\n",
       "  -1.0113116572073801,\n",
       "  0.2465340083293369,\n",
       "  -0.26514816089556714,\n",
       "  1.0179478471742125,\n",
       "  1749427200.0,\n",
       "  0.5818069727761647,\n",
       "  -0.033873199239868826,\n",
       "  0.5504715625836039,\n",
       "  1.378782720670466],\n",
       " [-0.5274061621751986,\n",
       "  -0.048429275604990385,\n",
       "  -0.9803947887207358,\n",
       "  -1.4962559193278682,\n",
       "  -1.3521778132934235,\n",
       "  0.39080117176825835,\n",
       "  -1.0789377953016275,\n",
       "  -1.6057078951819956,\n",
       "  1763769600.0,\n",
       "  -1.4306767119873687,\n",
       "  0.5500425440698936,\n",
       "  -1.0719407388478108,\n",
       "  0.2464616297494882],\n",
       " [-0.727074012519722,\n",
       "  1.5981301166789577,\n",
       "  -0.8211638040221216,\n",
       "  1.3910467985803647,\n",
       "  1.041731440618876,\n",
       "  -1.6960302260758096,\n",
       "  -0.7603292379310076,\n",
       "  -1.0728454126334526,\n",
       "  1754352000.0,\n",
       "  -1.2822170079195918,\n",
       "  0.5687781941871433,\n",
       "  -1.1448877713713046,\n",
       "  -0.3700541884147915],\n",
       " [1.4023861913721871,\n",
       "  1.1301285302695883,\n",
       "  -0.10558363864404795,\n",
       "  -0.34419639553757053,\n",
       "  1.052734559437265,\n",
       "  -1.1549276213415507,\n",
       "  -1.526784423368642,\n",
       "  -0.32108530803534235,\n",
       "  1756252800.0,\n",
       "  -0.23661255365810357,\n",
       "  -0.658813239722037,\n",
       "  0.7209675765594993,\n",
       "  1.604979417934855],\n",
       " [1.6753136667047526,\n",
       "  1.2405843953906714,\n",
       "  -1.5711867966691357,\n",
       "  0.7497157985747256,\n",
       "  -1.4256322556900707,\n",
       "  -0.9805044068300173,\n",
       "  1.181143064865889,\n",
       "  0.6250069960747571,\n",
       "  1761004800.0,\n",
       "  -1.5648797956190528,\n",
       "  1.193727076277006,\n",
       "  -0.4102050768034222,\n",
       "  -1.1952362390211244],\n",
       " [-0.018986580956801197,\n",
       "  0.42807551446484937,\n",
       "  1.5412008936380135,\n",
       "  1.1627891344962913,\n",
       "  1.4087343878010083,\n",
       "  -0.5195402833233397,\n",
       "  -1.4086548932900294,\n",
       "  1.447722200404084,\n",
       "  1761955200.0,\n",
       "  -0.5632888947306124,\n",
       "  0.3283894424718842,\n",
       "  1.410968083836029,\n",
       "  0.7712768855258424],\n",
       " [1.22619717528351,\n",
       "  1.2179302958707356,\n",
       "  0.3004107454349127,\n",
       "  -0.97943124260339,\n",
       "  0.7372707553369602,\n",
       "  1.1600883430625428,\n",
       "  -0.9348117013370979,\n",
       "  1.4260550352128654,\n",
       "  1766793600.0,\n",
       "  0.41996247189964714,\n",
       "  -0.3239501626465714,\n",
       "  -1.241383070757257,\n",
       "  -0.7386489297013699],\n",
       " [1.4237846407194739,\n",
       "  0.14980183069546749,\n",
       "  0.4120919980987936,\n",
       "  0.5623270826163234,\n",
       "  -1.626178386389383,\n",
       "  1.0409629659750887,\n",
       "  1.284041925886481,\n",
       "  -0.5345570078715741,\n",
       "  1771372800.0,\n",
       "  -0.2683042285648224,\n",
       "  -0.8456770271135972,\n",
       "  -0.6117531580402658,\n",
       "  -0.6933241827097567],\n",
       " [0.8588895968984221,\n",
       "  -1.402322346184863,\n",
       "  0.12984706113074998,\n",
       "  1.159123045550196,\n",
       "  1.3151822749908157,\n",
       "  0.7865508114427958,\n",
       "  -0.1138899172905249,\n",
       "  1.6440632533886732,\n",
       "  1764374400.0,\n",
       "  1.2698017931394985,\n",
       "  0.25190925552742,\n",
       "  -1.273980301555771,\n",
       "  -1.336295768785534],\n",
       " [-0.3183799101526862,\n",
       "  -0.03917233985962337,\n",
       "  -1.291828176254719,\n",
       "  0.24176807724208602,\n",
       "  -0.28956585305264043,\n",
       "  0.3405473437152992,\n",
       "  -0.34353732365878187,\n",
       "  -1.809133059470821,\n",
       "  1753228800.0,\n",
       "  0.4202956889538081,\n",
       "  -1.1900709644414227,\n",
       "  -0.2676246392004307,\n",
       "  0.7278817148945348],\n",
       " [-0.6531152198413788,\n",
       "  0.1685768235228882,\n",
       "  0.7219357862963972,\n",
       "  0.023731317000902905,\n",
       "  0.7243614221352156,\n",
       "  0.03382611140466977,\n",
       "  0.06026558490173845,\n",
       "  -0.29365028108802876,\n",
       "  1742774400.0,\n",
       "  0.8541117731284514,\n",
       "  -0.3146366150483428,\n",
       "  1.5494764862304364,\n",
       "  1.3008564433165144],\n",
       " [-0.9502514665016256,\n",
       "  0.64980723609613,\n",
       "  -1.1175777665256807,\n",
       "  -0.4878384915761031,\n",
       "  1.1304365353121861,\n",
       "  0.27732516669584534,\n",
       "  -0.5071355095462179,\n",
       "  -1.3552209815298955,\n",
       "  1768608000.0,\n",
       "  1.5619738464612667,\n",
       "  0.14933587476486748,\n",
       "  -0.5090376060521861,\n",
       "  1.2339278903169657],\n",
       " [-1.3108989144814776,\n",
       "  1.3619043903586052,\n",
       "  -0.40525227851243434,\n",
       "  -0.8900123485246301,\n",
       "  -1.1853990746120397,\n",
       "  -1.0716312921957132,\n",
       "  0.41498719852834326,\n",
       "  -0.044715716406788356,\n",
       "  1770508800.0,\n",
       "  -0.7061317183308657,\n",
       "  0.1578058436001703,\n",
       "  0.7335665747958743,\n",
       "  1.1423232620730137],\n",
       " [-1.3513359696081677,\n",
       "  1.5019941854165075,\n",
       "  1.4064490384805661,\n",
       "  -0.7174552147415787,\n",
       "  0.8875610813246658,\n",
       "  0.3428027187656212,\n",
       "  1.4005351566404054,\n",
       "  -0.20621174220806446,\n",
       "  1774483200.0,\n",
       "  1.4655366930828972,\n",
       "  0.4785903013725981,\n",
       "  -0.46502302465802564,\n",
       "  -0.7837395426927152],\n",
       " [0.13919373823120804,\n",
       "  -1.0693470713807511,\n",
       "  -1.297973869093301,\n",
       "  -0.12721221964124463,\n",
       "  1.0459775956586603,\n",
       "  -0.6980388805001273,\n",
       "  -0.6353784757414862,\n",
       "  0.6417749976099482,\n",
       "  1776470400.0,\n",
       "  -1.6077511128381718,\n",
       "  -0.05964376076641454,\n",
       "  1.5475956597316558,\n",
       "  -0.8621449149895737],\n",
       " [-0.5582816848899209,\n",
       "  0.4596773643030026,\n",
       "  -0.7604096202615087,\n",
       "  0.4630766897424801,\n",
       "  -0.0958302329334726,\n",
       "  -0.14613504154918716,\n",
       "  0.2525322201003143,\n",
       "  -0.09836256319257479,\n",
       "  1789948800.0,\n",
       "  1.531768470030326,\n",
       "  0.23093653332340383,\n",
       "  -0.540445839315028,\n",
       "  -0.6965488004157782],\n",
       " [-0.13916601685031252,\n",
       "  -0.2741484706926731,\n",
       "  -0.06565203287395424,\n",
       "  -1.3873567970409983,\n",
       "  -1.408910133944405,\n",
       "  -1.2924631835283673,\n",
       "  1.199940741772325,\n",
       "  -0.4692404280086507,\n",
       "  1782172800.0,\n",
       "  0.7933132725776278,\n",
       "  1.3353470802909442,\n",
       "  0.19360558785223078,\n",
       "  -0.9578954622556365],\n",
       " [0.8974660888517121,\n",
       "  -1.7324065195377127,\n",
       "  1.6186061280853865,\n",
       "  -0.041234594500461456,\n",
       "  -0.025748614329797054,\n",
       "  -1.6890647184255798,\n",
       "  0.637804875350983,\n",
       "  1.2198686479165435,\n",
       "  1767139200.0,\n",
       "  -0.9357340792879866,\n",
       "  -1.0333743863194373,\n",
       "  -0.3201445207232519,\n",
       "  -0.9660197538591835],\n",
       " [1.3537668913446885,\n",
       "  -0.8006241396271964,\n",
       "  0.4882774933976565,\n",
       "  0.46856754933105804,\n",
       "  1.4077555924363672,\n",
       "  1.2165074404086098,\n",
       "  1.184784117474333,\n",
       "  0.8455246865461779,\n",
       "  1765238400.0,\n",
       "  -0.9312918475541552,\n",
       "  -0.8317681425374267,\n",
       "  1.51816647404792,\n",
       "  1.6017213555409906],\n",
       " [-0.05270068382080741,\n",
       "  -0.9039946062930941,\n",
       "  1.0378430742016078,\n",
       "  -0.6964873039307226,\n",
       "  -1.6245249359558067,\n",
       "  0.6873545433377443,\n",
       "  1.0503433658480592,\n",
       "  -1.5361601314456568,\n",
       "  1784160000.0,\n",
       "  -1.2412757034014628,\n",
       "  -0.246480594395239,\n",
       "  -0.303846851228971,\n",
       "  1.5027672525479632],\n",
       " [-1.4289628685086113,\n",
       "  -0.9817425395934923,\n",
       "  1.181044847849314,\n",
       "  0.6248022036805382,\n",
       "  -1.565275917086164,\n",
       "  1.191584653085143,\n",
       "  -0.4074219220446137,\n",
       "  -1.191394929859858,\n",
       "  1761091200.0,\n",
       "  0.005280466695404202,\n",
       "  -0.22355305341430667,\n",
       "  0.7646977046191799,\n",
       "  1.6761369005902325],\n",
       " [-1.0700857687960845,\n",
       "  -0.9084546016964571,\n",
       "  -1.1663785997434246,\n",
       "  -0.30258517726834944,\n",
       "  -1.2720206008957304,\n",
       "  -1.7750331304048503,\n",
       "  0.557382504437269,\n",
       "  1.1455526770774809,\n",
       "  1760572800.0,\n",
       "  0.30255576600144224,\n",
       "  -0.08224008973574734,\n",
       "  0.516998745586308,\n",
       "  1.2854804340070183],\n",
       " [1.418654829251939,\n",
       "  1.397231008323857,\n",
       "  -0.20441613254836746,\n",
       "  -1.236057734198074,\n",
       "  0.3322744202447052,\n",
       "  -1.6968362167879156,\n",
       "  0.7805285099424639,\n",
       "  0.4285261270137385,\n",
       "  1764633600.0,\n",
       "  -1.25381732104169,\n",
       "  0.5389102553434547,\n",
       "  1.6759271053739737,\n",
       "  -0.15692738554536853],\n",
       " [-1.0450338647086344,\n",
       "  -0.07206705621019234,\n",
       "  1.4509143145515904,\n",
       "  1.6343257803685993,\n",
       "  1.302334929358718,\n",
       "  1.465209731691277,\n",
       "  0.28348344944989623,\n",
       "  0.15149996454533513,\n",
       "  1793232000.0,\n",
       "  0.19738564715543375,\n",
       "  0.5934798617735506,\n",
       "  1.1559853818212924,\n",
       "  -0.8327751908953355],\n",
       " [-1.1247361675700378,\n",
       "  -0.9495090638176262,\n",
       "  1.1075558339421643,\n",
       "  0.8994544255673794,\n",
       "  0.41539944837268966,\n",
       "  0.008468388006397447,\n",
       "  -0.44138809076395363,\n",
       "  -1.021871073382452,\n",
       "  1740700800.0,\n",
       "  -1.4951306578014016,\n",
       "  -0.22995131718108813,\n",
       "  1.2891250657897537,\n",
       "  0.576079780375967],\n",
       " [-1.0143831942820944,\n",
       "  -0.1766649330067052,\n",
       "  -1.374866346625512,\n",
       "  1.6082356760245011,\n",
       "  -0.5283167814676297,\n",
       "  1.3711471705082954,\n",
       "  0.15602940796031892,\n",
       "  -0.9179333584978607,\n",
       "  1757462400.0,\n",
       "  -0.586792646947416,\n",
       "  -1.225477616980651,\n",
       "  0.3596865115053205,\n",
       "  -0.27889479263952427],\n",
       " [0.44720863813853623,\n",
       "  -1.7528926666024645,\n",
       "  0.2228043494203761,\n",
       "  0.36745042674446426,\n",
       "  1.3348992869313336,\n",
       "  0.2684272670857982,\n",
       "  -0.533832404707478,\n",
       "  1.533701876999134,\n",
       "  1755302400.0,\n",
       "  -1.2667129166007014,\n",
       "  -0.5460891267074303,\n",
       "  -1.5225599627335993,\n",
       "  -1.8119270834735424],\n",
       " [0.004265903347823544,\n",
       "  0.5146629371768512,\n",
       "  -1.3500720973958917,\n",
       "  1.3840250382380495,\n",
       "  1.220703822394925,\n",
       "  -0.7487879913064502,\n",
       "  0.6014196362387666,\n",
       "  -1.1975308553442916,\n",
       "  1747526400.0,\n",
       "  -0.9390358367848938,\n",
       "  -0.8738469571830674,\n",
       "  0.4946227387042456,\n",
       "  -1.7077697842055173],\n",
       " [-0.8578860526603623,\n",
       "  -0.07109769812110543,\n",
       "  -0.4810395214805601,\n",
       "  0.9091083619483844,\n",
       "  -0.8389927003381197,\n",
       "  1.0229177412671109,\n",
       "  -0.3744190240850923,\n",
       "  1.2010931024948257,\n",
       "  1779753600.0,\n",
       "  0.6253332084186131,\n",
       "  0.12995671270999704,\n",
       "  -0.703112745697746,\n",
       "  -0.26444088125535],\n",
       " [-1.650137285662268,\n",
       "  -0.5571754662203532,\n",
       "  -1.560877341817194,\n",
       "  -1.0429337031164159,\n",
       "  -0.37181522991212906,\n",
       "  -1.6556770698031715,\n",
       "  -0.639084358237349,\n",
       "  -0.3411136423216724,\n",
       "  1747785600.0,\n",
       "  1.6371235644582123,\n",
       "  1.0584171621023513,\n",
       "  -1.5742882060641195,\n",
       "  -0.008075060631032195],\n",
       " [-0.7059276747963461,\n",
       "  -0.34057400163278145,\n",
       "  -1.1959681443930568,\n",
       "  0.3320357625330321,\n",
       "  -0.8056510168710667,\n",
       "  -1.6858601514222396,\n",
       "  -1.2297160877295006,\n",
       "  -0.1435555414895838,\n",
       "  1745452800.0,\n",
       "  0.9048223337587487,\n",
       "  -0.2872933966239342,\n",
       "  0.23036837712655414,\n",
       "  1.0690488713209574],\n",
       " [0.23761450084348346,\n",
       "  0.16048104797354862,\n",
       "  1.5315063834427292,\n",
       "  0.5252490666225053,\n",
       "  0.9801429287588437,\n",
       "  -1.4716801829717487,\n",
       "  0.04869467756422925,\n",
       "  0.8222038068366478,\n",
       "  1751673600.0,\n",
       "  -0.1701238614472286,\n",
       "  1.2230567864626278,\n",
       "  1.7617277259169504,\n",
       "  -1.5302963710882895],\n",
       " [0.9234261101724777,\n",
       "  1.0662337718748105,\n",
       "  -0.4142962151041219,\n",
       "  -1.3843843732523287,\n",
       "  -1.2546217400898283,\n",
       "  -0.06790146074236279,\n",
       "  1.527759475160118,\n",
       "  -1.656144862106036,\n",
       "  1773273600.0,\n",
       "  -1.3072132108162415,\n",
       "  0.20871166721392043,\n",
       "  0.110405458971585,\n",
       "  -0.6565490059464737],\n",
       " [-1.402868519540921,\n",
       "  -1.1355162314612341,\n",
       "  -0.9953775933614472,\n",
       "  1.5754778915490306,\n",
       "  -1.2894615983891382,\n",
       "  0.21101567771165408,\n",
       "  -1.1995454280385411,\n",
       "  1.095580084266389,\n",
       "  1785628800.0,\n",
       "  -0.8814546371304867,\n",
       "  -0.9085310456414507,\n",
       "  0.38097987456694626,\n",
       "  0.8884312203665893],\n",
       " [-1.0865814381726604,\n",
       "  -1.3457298541290226,\n",
       "  -0.4085309945534791,\n",
       "  0.22921100264504585,\n",
       "  0.4035899355253853,\n",
       "  -1.4839758876193474,\n",
       "  1.252100741162304,\n",
       "  -0.0329444065883459,\n",
       "  1780790400.0,\n",
       "  -0.09841901719889264,\n",
       "  0.9425108749542365,\n",
       "  -0.3725090056580616,\n",
       "  0.116898123285259],\n",
       " [-1.5668995294488401,\n",
       "  0.42794200654282155,\n",
       "  0.5738629448320464,\n",
       "  0.4666803435276193,\n",
       "  1.1475758082238308,\n",
       "  -0.9593851391632837,\n",
       "  -0.4636764471636885,\n",
       "  1.3364996043427457,\n",
       "  1780531200.0,\n",
       "  0.22803317447402996,\n",
       "  -1.7995135964226139,\n",
       "  -0.15870505732872212,\n",
       "  0.35180486510562403],\n",
       " [0.47667220215439665,\n",
       "  -1.3340414136221554,\n",
       "  -0.2165661797017558,\n",
       "  -0.9596345011499011,\n",
       "  0.008387843651248006,\n",
       "  0.5166198085928742,\n",
       "  -1.3468240471850133,\n",
       "  1.383805160434854,\n",
       "  1747440000.0,\n",
       "  1.2181563948124574,\n",
       "  -0.7472266373581624,\n",
       "  0.5997025582220278,\n",
       "  -1.2013711140498868],\n",
       " [-0.3926359292007158,\n",
       "  -0.5442646434940579,\n",
       "  0.08721102629382557,\n",
       "  -0.10367007979329344,\n",
       "  1.6379929537506732,\n",
       "  1.5273264665804425,\n",
       "  -0.8915029339233504,\n",
       "  -1.3250869837045829,\n",
       "  1751241600.0,\n",
       "  -0.15286597058144882,\n",
       "  1.400268281526697,\n",
       "  1.113654913515837,\n",
       "  0.5959995684140765],\n",
       " [-1.4649736227852617,\n",
       "  0.5616345127931258,\n",
       "  -1.554129542329144,\n",
       "  0.8817506780054979,\n",
       "  -0.6343432654130243,\n",
       "  1.2001063024395033,\n",
       "  0.9525679482516017,\n",
       "  -0.8564109218562399,\n",
       "  1742256000.0,\n",
       "  0.3070243882599129,\n",
       "  -0.8674192547395936,\n",
       "  0.3101525235010957,\n",
       "  -0.47488152196721883],\n",
       " [1.678395700790962,\n",
       "  1.2253945751403856,\n",
       "  -1.2651083301884933,\n",
       "  0.8987214928267194,\n",
       "  0.1792195018675683,\n",
       "  -1.5361252571588973,\n",
       "  -1.2504328431229956,\n",
       "  0.8804124132123516,\n",
       "  1780185600.0,\n",
       "  0.26694491531887554,\n",
       "  1.6137244497464474,\n",
       "  -0.52439173971904,\n",
       "  -0.2904454658557158],\n",
       " [-1.2928673535183106,\n",
       "  0.20920552057556854,\n",
       "  -1.2026099698955384,\n",
       "  1.095638653561281,\n",
       "  -0.8811279165869036,\n",
       "  -0.9100441093961867,\n",
       "  0.3829278401994638,\n",
       "  0.8926293094605889,\n",
       "  1785715200.0,\n",
       "  1.243792642294007,\n",
       "  -1.1328245961367647,\n",
       "  -0.5871574839689061,\n",
       "  0.10113155542041777],\n",
       " [-0.06333492732194543,\n",
       "  -0.6655889278084668,\n",
       "  1.5370565097059132,\n",
       "  -0.7986025389801159,\n",
       "  0.747883967081499,\n",
       "  -1.480129666635807,\n",
       "  1.2258920839838146,\n",
       "  -0.5924867532547102,\n",
       "  1791936000.0,\n",
       "  -0.04468081150520021,\n",
       "  0.8245342892409937,\n",
       "  0.5829668411525512,\n",
       "  -0.37943088902639777],\n",
       " [1.4356057574511507,\n",
       "  0.9933522243641806,\n",
       "  -0.34648180141137747,\n",
       "  -0.25068030362952265,\n",
       "  -0.636164156918437,\n",
       "  1.4854529711579263,\n",
       "  0.7736632562863901,\n",
       "  0.07525442958450534,\n",
       "  1787270400.0,\n",
       "  0.8714577887067536,\n",
       "  1.4931365416588018,\n",
       "  -0.3585613960736479,\n",
       "  1.6645728532829625],\n",
       " [0.19462638669130017,\n",
       "  0.5895243083361603,\n",
       "  1.1569870820831154,\n",
       "  -0.8298902911931539,\n",
       "  -0.7053772964734443,\n",
       "  -0.3640282693868482,\n",
       "  1.7601356922750424,\n",
       "  1.4734506231972277,\n",
       "  1793404800.0,\n",
       "  -1.631823358834824,\n",
       "  -0.8566674649763767,\n",
       "  1.2153387067756205,\n",
       "  -0.24753022074239678],\n",
       " [0.9113219150674166,\n",
       "  0.10118782319603153,\n",
       "  0.25149798855233624,\n",
       "  0.7802641367407003,\n",
       "  0.0803408055106361,\n",
       "  0.28678734952971496,\n",
       "  -0.5026040751267318,\n",
       "  -1.20860239392482,\n",
       "  1766448000.0,\n",
       "  1.418597568658981,\n",
       "  -0.006368333842475485,\n",
       "  0.1975970476425121,\n",
       "  -0.6280141133285316],\n",
       " [1.5846335218440148,\n",
       "  -1.338675429025649,\n",
       "  -0.9324629075749209,\n",
       "  1.5241025924978306,\n",
       "  -0.2418514522805587,\n",
       "  1.132111917442699,\n",
       "  -0.5968442548874456,\n",
       "  1.6515237364469462,\n",
       "  1742601600.0,\n",
       "  -0.6499278396180723,\n",
       "  0.17220407301499518,\n",
       "  0.721016321795004,\n",
       "  0.020222889061161473],\n",
       " [-1.5310139611839055,\n",
       "  -1.461094386526369,\n",
       "  -1.1193900895599633,\n",
       "  -0.8862760593816927,\n",
       "  -0.4450735307987447,\n",
       "  -1.6966910283730963,\n",
       "  1.225048744760973,\n",
       "  0.8318996504738804,\n",
       "  1748822400.0,\n",
       "  0.43880216443371717,\n",
       "  -0.3822372297371213,\n",
       "  1.023064563879043,\n",
       "  0.004634112122496471],\n",
       " [0.6125308136700182,\n",
       "  0.2850202832683386,\n",
       "  -0.7397277596284254,\n",
       "  1.178615463827133,\n",
       "  -1.4908364013116469,\n",
       "  1.3593712064184766,\n",
       "  -1.1741157290737576,\n",
       "  0.988995739023796,\n",
       "  1765929600.0,\n",
       "  -1.2007802117085595,\n",
       "  0.7511878076156182,\n",
       "  0.3185353512927404,\n",
       "  -0.8104137155034249],\n",
       " [0.223282004217994,\n",
       "  -0.8041270958378528,\n",
       "  -0.1993544953179554,\n",
       "  1.2691465749939062,\n",
       "  -0.6302705293528947,\n",
       "  0.9923239381534346,\n",
       "  1.371310540925858,\n",
       "  -0.7396429779666603,\n",
       "  1743811200.0,\n",
       "  -0.548795779138233,\n",
       "  0.7859634118745826,\n",
       "  1.3629577327375189,\n",
       "  -1.0469003256287337],\n",
       " [0.6045651975168183,\n",
       "  0.31740827744259914,\n",
       "  -0.37919365659615517,\n",
       "  -1.7755519154847834,\n",
       "  0.1934116445092107,\n",
       "  -1.6870312870833817,\n",
       "  -0.5916069561319313,\n",
       "  0.9554803818207905,\n",
       "  1782604800.0,\n",
       "  -1.2625908740602418,\n",
       "  -0.21939898811746567,\n",
       "  1.1313075124353107,\n",
       "  -1.7022988516503168],\n",
       " [1.5512158014508433,\n",
       "  -0.19963833687473495,\n",
       "  0.5168777898058636,\n",
       "  -0.4370550294462157,\n",
       "  -0.02818603915348423,\n",
       "  -0.6550068977476384,\n",
       "  -1.2786195272496788,\n",
       "  -1.6911546160948192,\n",
       "  1736899200.0,\n",
       "  -1.2131686160057096,\n",
       "  0.9767855627151825,\n",
       "  -0.8001801251294494,\n",
       "  -1.4013248446531772],\n",
       " [-1.6081065223599795,\n",
       "  0.1130994870950865,\n",
       "  0.22366641045377741,\n",
       "  0.45157600368119316,\n",
       "  -0.8600135513964599,\n",
       "  0.40061259591428816,\n",
       "  -0.14938652803334093,\n",
       "  -0.5002396436726914,\n",
       "  1741478400.0,\n",
       "  -0.1509755599915955,\n",
       "  1.482406617145453,\n",
       "  1.011347871033794,\n",
       "  -0.5704555043057373],\n",
       " [0.8020765496621782,\n",
       "  -0.09521457508734928,\n",
       "  -1.555074705651132,\n",
       "  0.9180883025442668,\n",
       "  0.44214167622960915,\n",
       "  -0.5334137279238449,\n",
       "  -0.11024082054923799,\n",
       "  0.43697710239856585,\n",
       "  1781740800.0,\n",
       "  -1.2596549607052365,\n",
       "  -1.6199392670738788,\n",
       "  -1.0561226709814573,\n",
       "  -0.0011509341431188882],\n",
       " [1.4345869504791011,\n",
       "  0.20079909689130032,\n",
       "  -1.353947378024607,\n",
       "  0.7362539841237653,\n",
       "  1.2243853806052118,\n",
       "  0.72655370130251,\n",
       "  0.5010540530180759,\n",
       "  1.7066752165049721,\n",
       "  1781222400.0,\n",
       "  -1.32352055470302,\n",
       "  0.523601803037035,\n",
       "  -0.019794282072832667,\n",
       "  -1.4003788939786326],\n",
       " [-0.42691634140060203,\n",
       "  -1.6635333598641158,\n",
       "  -1.2933104846147379,\n",
       "  0.2682837382312992,\n",
       "  0.1472928394451598,\n",
       "  -0.2757375956080926,\n",
       "  -0.424292559241496,\n",
       "  1.2255802737911217,\n",
       "  1751068800.0,\n",
       "  -0.3895800941679713,\n",
       "  -0.5411933509192064,\n",
       "  0.08641154091629148,\n",
       "  -0.1070854473329194],\n",
       " [0.3702193816478764,\n",
       "  0.8823133920736547,\n",
       "  -0.8245421124565593,\n",
       "  -1.373079372475613,\n",
       "  0.006280335744365309,\n",
       "  0.3313973246794097,\n",
       "  -1.574812333794191,\n",
       "  -1.5611903239724763,\n",
       "  1758153600.0,\n",
       "  1.579873421964151,\n",
       "  -0.846828812018177,\n",
       "  0.6485386584573053,\n",
       "  -0.26627691612561377],\n",
       " [-0.8446380100380304,\n",
       "  -1.1654881973027555,\n",
       "  -1.0209741613422434,\n",
       "  1.7183808993541625,\n",
       "  -0.9854875706985221,\n",
       "  -0.6286895855487435,\n",
       "  0.3915074823289455,\n",
       "  1.1794358349274192,\n",
       "  1785110400.0,\n",
       "  -1.3620665050230916,\n",
       "  -0.9030311504813747,\n",
       "  1.77976531008635,\n",
       "  -1.1230993307920292],\n",
       " [-0.985606203243567,\n",
       "  1.6689054710045,\n",
       "  -0.15270313233726662,\n",
       "  0.9767366428966556,\n",
       "  0.6863663139921677,\n",
       "  0.3545018426947533,\n",
       "  -1.3967202181928322,\n",
       "  0.5984294132572554,\n",
       "  1738713600.0,\n",
       "  0.941419474564813,\n",
       "  0.028761908724249143,\n",
       "  0.07687385731117462,\n",
       "  -0.2732943131292202],\n",
       " [-0.016315838165468798,\n",
       "  -0.03127325813508005,\n",
       "  0.28447578630448844,\n",
       "  1.07873734571579,\n",
       "  0.3938393876134353,\n",
       "  1.2975458226370373,\n",
       "  -0.03584414237392956,\n",
       "  -1.2261320703537908,\n",
       "  1767916800.0,\n",
       "  1.4530763123670574,\n",
       "  -0.40518713945913576,\n",
       "  -0.2444256342764502,\n",
       "  0.6356517679779015],\n",
       " [-1.3510193104799995,\n",
       "  0.9721349355663091,\n",
       "  -1.2243365561598825,\n",
       "  1.6132436532703265,\n",
       "  -0.22578342112930244,\n",
       "  -1.1384835280178158,\n",
       "  -1.605997467932308,\n",
       "  1.2231149226750644,\n",
       "  1777680000.0,\n",
       "  -0.9931449438371889,\n",
       "  -0.0879209876465181,\n",
       "  -1.525417170272473,\n",
       "  -0.4191345055777139],\n",
       " [-0.24583530439905482,\n",
       "  1.1298595608796111,\n",
       "  -0.5991578343793126,\n",
       "  1.651893446057685,\n",
       "  -0.6493562388652009,\n",
       "  0.17036746628574556,\n",
       "  0.7226053388115555,\n",
       "  0.02427231752860767,\n",
       "  1742688000.0,\n",
       "  0.7223384090629635,\n",
       "  0.03562182909024691,\n",
       "  0.057976651232077424,\n",
       "  -0.29764528197195234],\n",
       " [-0.8426470352607529,\n",
       "  1.0207178065900913,\n",
       "  -0.37645546295598664,\n",
       "  1.201210723374692,\n",
       "  0.6272536214718131,\n",
       "  0.12813275370208305,\n",
       "  -0.7000203923126945,\n",
       "  -0.26044019488461767,\n",
       "  1779840000.0,\n",
       "  -1.5734630108565477,\n",
       "  -0.7549428716631389,\n",
       "  -1.0162379494722462,\n",
       "  1.6399642251878577],\n",
       " [1.4863041828926564,\n",
       "  1.1769757168552297,\n",
       "  -0.45917383264086115,\n",
       "  -0.3235205758313499,\n",
       "  1.1263064871133361,\n",
       "  -0.6592519367670949,\n",
       "  0.890703711376341,\n",
       "  -0.06373979137660399,\n",
       "  1768435200.0,\n",
       "  -0.946914028881842,\n",
       "  0.6538098051916031,\n",
       "  -1.1181495161775796,\n",
       "  -0.49097324314909263],\n",
       " [1.3820054680994251,\n",
       "  -0.8294714066768485,\n",
       "  -1.1987510409450775,\n",
       "  0.8253887029674242,\n",
       "  -0.7233558663541093,\n",
       "  1.600607388315886,\n",
       "  -0.8185739505422717,\n",
       "  1.39082299316565,\n",
       "  1754265600.0,\n",
       "  1.0393731077296728,\n",
       "  -1.694752535850792,\n",
       "  -0.7634853216978289,\n",
       "  -1.0767070171866744],\n",
       " [0.4110529090768029,\n",
       "  0.00675546967293113,\n",
       "  -0.44350797272562675,\n",
       "  -1.022997560197827,\n",
       "  -1.4954530073179224,\n",
       "  -0.23166752942244284,\n",
       "  1.2901143769540726,\n",
       "  0.5802243864992329,\n",
       "  1740787200.0,\n",
       "  -0.8399070094984742,\n",
       "  -0.32996127002540426,\n",
       "  -0.21399978576125614,\n",
       "  -1.3309239664972556],\n",
       " [-0.942369293812186,\n",
       "  -0.8766590098626688,\n",
       "  0.4954994009694046,\n",
       "  -1.7055244918476675,\n",
       "  -1.6469287897023082,\n",
       "  -0.5557334096067121,\n",
       "  -1.5573669562931807,\n",
       "  -1.041796065048255,\n",
       "  1747699200.0,\n",
       "  -0.3726800688251873,\n",
       "  -1.6543872953127636,\n",
       "  -0.6421123184695329,\n",
       "  -0.3451005175924151],\n",
       " [0.7022569415526007,\n",
       "  1.3545905771592992,\n",
       "  1.4773418692079745,\n",
       "  -1.3124466673577524,\n",
       "  -1.236158505216406,\n",
       "  -0.1842995574556258,\n",
       "  -1.0286787741132442,\n",
       "  0.1623184363883952,\n",
       "  1793836800.0,\n",
       "  -1.1207084126238862,\n",
       "  0.02043014236799888,\n",
       "  1.4152372598119713,\n",
       "  -0.8429482667068087],\n",
       " [-0.9346213917972699,\n",
       "  -0.8346129876091609,\n",
       "  1.5192366486916462,\n",
       "  1.606385834091723,\n",
       "  -1.5108845279145593,\n",
       "  -1.661101199109833,\n",
       "  -1.2995919157859994,\n",
       "  -0.3843881902571125,\n",
       "  1765411200.0,\n",
       "  -1.367487843945216,\n",
       "  0.8345594730381645,\n",
       "  0.7883683167812722,\n",
       "  1.3754626711250724],\n",
       " [-0.26924481716436793,\n",
       "  -0.7956427852375413,\n",
       "  -0.1255876304177356,\n",
       "  -0.08026922231704109,\n",
       "  1.64332310705481,\n",
       "  1.6206622752278912,\n",
       "  1.6929752630005297,\n",
       "  0.7591636010073157,\n",
       "  1736208000.0,\n",
       "  -1.0270848551945326,\n",
       "  -0.045100879824648325,\n",
       "  -1.2829811438369343,\n",
       "  0.4393411068642705],\n",
       " [1.0350163000950081,\n",
       "  0.3842672081326206,\n",
       "  -0.499273956935188,\n",
       "  -1.553809949438689,\n",
       "  0.8416678828186951,\n",
       "  -0.9354745165306965,\n",
       "  -0.01411439374593711,\n",
       "  1.0517669918247872,\n",
       "  1755648000.0,\n",
       "  -0.7667001556348139,\n",
       "  0.3364790745738971,\n",
       "  -0.4088455515667821,\n",
       "  0.14470995066992934],\n",
       " [0.30522086622811073,\n",
       "  -0.9643393243908004,\n",
       "  -0.29267245923172636,\n",
       "  0.004178122318721835,\n",
       "  1.1124685053548005,\n",
       "  -0.5591071152816951,\n",
       "  -0.3385955331593391,\n",
       "  -0.26674622387990304,\n",
       "  1743033600.0,\n",
       "  -0.8580864769331937,\n",
       "  0.719854534971647,\n",
       "  0.21272564812781453,\n",
       "  0.3237104816304325],\n",
       " [-1.2580467207078585,\n",
       "  -0.06957771547663039,\n",
       "  1.5280931402948699,\n",
       "  -1.6576263276070793,\n",
       "  -1.307336804662831,\n",
       "  0.20686413109465138,\n",
       "  0.1126390478447448,\n",
       "  -0.6526154590368494,\n",
       "  1773360000.0,\n",
       "  -0.12172439487104879,\n",
       "  -0.06165539735251486,\n",
       "  0.5483422879488514,\n",
       "  -0.9016862353022211],\n",
       " [1.2997641299176745,\n",
       "  -1.3594914775143148,\n",
       "  1.2773448663749234,\n",
       "  0.4537923802227866,\n",
       "  0.516517418473943,\n",
       "  0.5349617970751571,\n",
       "  -1.1995225629306363,\n",
       "  -0.8269541886267686,\n",
       "  1795824000.0,\n",
       "  1.1540868246229334,\n",
       "  1.0729254591922235,\n",
       "  -1.3392153229604256,\n",
       "  -0.7129553277024585],\n",
       " [0.5579697912552003,\n",
       "  0.3907779707848787,\n",
       "  1.4310215584787906,\n",
       "  -1.3014923388202333,\n",
       "  -1.5647528874747623,\n",
       "  -1.126105957451701,\n",
       "  1.3909106705160559,\n",
       "  -0.5877450941815999,\n",
       "  1791158400.0,\n",
       "  -0.7947457238326203,\n",
       "  -0.375976970119299,\n",
       "  -0.5953028901984024,\n",
       "  -1.4960763602487368],\n",
       " [-1.2070272080531286,\n",
       "  1.4482656488186523,\n",
       "  -0.2729668199547318,\n",
       "  -0.7342630508186809,\n",
       "  1.0158972620883722,\n",
       "  0.6812520990634306,\n",
       "  -1.593554027481489,\n",
       "  1.3198586481049868,\n",
       "  1788048000.0,\n",
       "  0.6700684360134419,\n",
       "  -0.5465412191973651,\n",
       "  -1.6045890900786102,\n",
       "  1.3836165209485682],\n",
       " [1.4808871708433156,\n",
       "  -1.5206230776092136,\n",
       "  1.2099821992169506,\n",
       "  0.07871844823942636,\n",
       "  0.9207881257595959,\n",
       "  -0.3418750844426124,\n",
       "  -0.8270063739288857,\n",
       "  1.172782746928952,\n",
       "  1746403200.0,\n",
       "  1.1750930568057147,\n",
       "  0.4830340327366091,\n",
       "  -1.6905349348976144,\n",
       "  -0.30551812393863415],\n",
       " [-1.4072173911847696,\n",
       "  0.8156274113604687,\n",
       "  -1.3234949547137465,\n",
       "  -1.3781703729044181,\n",
       "  -0.9930963708455288,\n",
       "  -0.371034888786025,\n",
       "  -1.0619466795658978,\n",
       "  -1.3811853372260445,\n",
       "  1762905600.0,\n",
       "  -0.8039932427712392,\n",
       "  1.314725300863247,\n",
       "  0.3272266227730643,\n",
       "  1.1620738269200217],\n",
       " [-1.4348176209202352,\n",
       "  -0.7964711509637399,\n",
       "  0.27246586522158733,\n",
       "  -1.35285678440429,\n",
       "  -0.22793193172881063,\n",
       "  -0.19831191202131843,\n",
       "  0.06692172057087017,\n",
       "  1.3959153682105099,\n",
       "  1753660800.0,\n",
       "  -0.010159366621474594,\n",
       "  -0.10256108195443779,\n",
       "  -0.6226276303218875,\n",
       "  0.014485851748909196],\n",
       " [1.0849081803969047,\n",
       "  -0.3305010410651506,\n",
       "  1.180351359047514,\n",
       "  1.5623684139161993,\n",
       "  -1.5483170102749373,\n",
       "  -0.731783619356609,\n",
       "  1.772719458681673,\n",
       "  -1.6345389404750086,\n",
       "  1757116800.0,\n",
       "  -0.7745357411536442,\n",
       "  0.7298076601729341,\n",
       "  0.6440065734806116,\n",
       "  0.4050663185774436],\n",
       " [-0.2407419009083528,\n",
       "  -0.8146350365484304,\n",
       "  -0.3424159172023667,\n",
       "  0.44503369790583736,\n",
       "  -0.8557467066593804,\n",
       "  -1.5301322512923918,\n",
       "  0.1578871546344383,\n",
       "  1.4841151712373026,\n",
       "  1795132800.0,\n",
       "  0.9934002265339837,\n",
       "  -0.9137397448878409,\n",
       "  -1.3898242637836764,\n",
       "  0.5222146759061383],\n",
       " [1.4957369305626844,\n",
       "  1.560967742425023,\n",
       "  0.3758672127662621,\n",
       "  1.130704780329751,\n",
       "  1.1379206385404068,\n",
       "  1.2349512487481575,\n",
       "  -1.3537338417782745,\n",
       "  -0.5019466620038349,\n",
       "  1759449600.0,\n",
       "  -0.8133023409926368,\n",
       "  -0.8254667843376882,\n",
       "  -1.1142628358840256,\n",
       "  0.6688617193066038],\n",
       " [1.4783343394619757,\n",
       "  -1.386342319508946,\n",
       "  0.05114527222982856,\n",
       "  1.0386964424658858,\n",
       "  0.48105497177943296,\n",
       "  -1.3329724935633545,\n",
       "  -0.21472871408365946,\n",
       "  -0.9585434563702104,\n",
       "  1747353600.0,\n",
       "  0.007121298157206914,\n",
       "  0.5185601049856593,\n",
       "  -1.3505998997057647,\n",
       "  1.3795229832176146],\n",
       " [0.9953020579951456,\n",
       "  1.1975276578527587,\n",
       "  1.7124803589061446,\n",
       "  -0.8412034139268729,\n",
       "  -1.5856009032128189,\n",
       "  0.055756493584573456,\n",
       "  1.769863537157099,\n",
       "  -0.684102866241724,\n",
       "  1794614400.0,\n",
       "  1.662060314574349,\n",
       "  1.477252221365157,\n",
       "  1.5595408215222302,\n",
       "  -0.6508628859724107],\n",
       " [1.5906947025355553,\n",
       "  0.7339533081046343,\n",
       "  -0.056865360181029966,\n",
       "  -1.5578815254717961,\n",
       "  0.8026087900632942,\n",
       "  0.6068761544593441,\n",
       "  0.7518747848802605,\n",
       "  0.6582481224617862,\n",
       "  1741219200.0,\n",
       "  -0.48026927266937053,\n",
       "  0.6333806353580496,\n",
       "  -0.3232637909211672,\n",
       "  1.1432802177320072],\n",
       " [-1.2774528967551755,\n",
       "  1.4393062226765967,\n",
       "  0.8857342907066733,\n",
       "  0.8454518151948786,\n",
       "  -1.4038747720527807,\n",
       "  0.817728839050842,\n",
       "  -1.32027997826755,\n",
       "  -1.3768452206885533,\n",
       "  1762819200.0,\n",
       "  -0.9933047902283229,\n",
       "  -0.3693604118712935,\n",
       "  -1.065421492608778,\n",
       "  -1.3849941547264675],\n",
       " [-1.1157505655638802,\n",
       "  1.0922341179505108,\n",
       "  1.1931276178609784,\n",
       "  1.3167995928628118,\n",
       "  -0.9820308002549433,\n",
       "  1.6714167367583914,\n",
       "  -0.15094514070272363,\n",
       "  0.9767445812699257,\n",
       "  1738627200.0,\n",
       "  0.6843834449535847,\n",
       "  0.3563935908027095,\n",
       "  -1.400548797672533,\n",
       "  0.5942816904772348],\n",
       " [-0.12570705668859905,\n",
       "  -0.1423197701173423,\n",
       "  -0.2387928191920605,\n",
       "  0.9870867203666738,\n",
       "  -0.8309500070358673,\n",
       "  0.5143053117544889,\n",
       "  -0.9345142664012313,\n",
       "  0.9732414481783332,\n",
       "  1741996800.0,\n",
       "  0.4832160995543986,\n",
       "  -1.3624126827913592,\n",
       "  1.4918698529691912,\n",
       "  -0.3054479254282131],\n",
       " [-1.3093282743337755,\n",
       "  0.3543355627084018,\n",
       "  1.689585736569304,\n",
       "  1.1066166684154939,\n",
       "  0.5636070668355381,\n",
       "  -0.3585870876302701,\n",
       "  0.5604814696939548,\n",
       "  1.4043529787687472,\n",
       "  1772064000.0,\n",
       "  0.49264161467884954,\n",
       "  0.7527509725138302,\n",
       "  1.7762011174368162,\n",
       "  -1.5365947689590014],\n",
       " [0.8861991729270825,\n",
       "  0.6745397502531337,\n",
       "  0.05031321578445167,\n",
       "  1.6013570135586639,\n",
       "  1.1903809598290809,\n",
       "  1.5641925408968405,\n",
       "  0.17723269638764122,\n",
       "  0.6095403665906242,\n",
       "  1790553600.0,\n",
       "  1.1467108614941854,\n",
       "  0.7621868313080444,\n",
       "  -1.4020762688733732,\n",
       "  -1.444002704418366],\n",
       " [-0.5188393264253982,\n",
       "  -0.797303223503158,\n",
       "  -0.6799321426231482,\n",
       "  -1.3585676893502685,\n",
       "  -0.0897627862762694,\n",
       "  0.6107584786727525,\n",
       "  0.8693566180169715,\n",
       "  1.2492158300846024,\n",
       "  1739836800.0,\n",
       "  0.8560604294208193,\n",
       "  -1.7085052398773055,\n",
       "  0.6630956736752925,\n",
       "  -0.43135857178260717],\n",
       " [-1.0647387442082867,\n",
       "  1.658443638267898,\n",
       "  -0.5128030276521521,\n",
       "  1.3919562250386408,\n",
       "  -0.5544703435479944,\n",
       "  0.46160782559344765,\n",
       "  -0.7578953719586781,\n",
       "  0.46337194306964913,\n",
       "  1789862400.0,\n",
       "  -0.09698666598989164,\n",
       "  -0.14439321551752612,\n",
       "  0.2504464610385768,\n",
       "  -0.1023909968636703],\n",
       " [-0.8346087801140505,\n",
       "  0.512349551480963,\n",
       "  -0.9372485808804787,\n",
       "  0.9732315492359799,\n",
       "  0.48498619883080896,\n",
       "  -1.363789866613607,\n",
       "  1.4926451430738688,\n",
       "  -0.30145426056678915,\n",
       "  1742083200.0,\n",
       "  -1.4613762442543665,\n",
       "  0.5655683145150641,\n",
       "  -1.5546187725917253,\n",
       "  0.8776155094879362],\n",
       " [0.7106335632570273,\n",
       "  0.8493524349568278,\n",
       "  -0.30362771471709676,\n",
       "  0.1465597529700845,\n",
       "  -1.56364507549141,\n",
       "  0.42985722502065415,\n",
       "  0.5747167657003898,\n",
       "  0.46697358115624144,\n",
       "  1780444800.0,\n",
       "  1.1451056446262946,\n",
       "  -0.9578868512068598,\n",
       "  -0.46651904796768934,\n",
       "  1.3322255257228268],\n",
       " [-0.031245074431254106,\n",
       "  -1.210089518652028,\n",
       "  -0.4189640265060284,\n",
       "  -1.5977724499309223,\n",
       "  -0.20294098796067175,\n",
       "  0.8885393494415564,\n",
       "  0.5931915100082406,\n",
       "  -0.5758635018997846,\n",
       "  1792368000.0,\n",
       "  1.2952776453302843,\n",
       "  1.373366849436222,\n",
       "  0.19365511151257908,\n",
       "  -0.9459453940022471],\n",
       " [-0.5321425549869792,\n",
       "  1.368780058019193,\n",
       "  0.1546539049343405,\n",
       "  -0.9190016753650571,\n",
       "  -0.5861542696513505,\n",
       "  -1.2268957954719373,\n",
       "  0.36165695479652005,\n",
       "  -0.2748965811673215,\n",
       "  1757548800.0,\n",
       "  0.9451822227732135,\n",
       "  1.5724293769264706,\n",
       "  -0.9545239039514469,\n",
       "  0.9994356379833641],\n",
       " [1.2942673595787373,\n",
       "  -0.36892924475952377,\n",
       "  -0.44213694006015036,\n",
       "  1.0546359889065555,\n",
       "  -1.3619879847733518,\n",
       "  1.6525171973451112,\n",
       "  -0.9630317310469646,\n",
       "  1.288951865266112,\n",
       "  1754092800.0,\n",
       "  1.3841650877738862,\n",
       "  -0.826622551600622,\n",
       "  -1.1993074467834695,\n",
       "  0.8212947040765723],\n",
       " [-1.0575004460794766,\n",
       "  1.4950682725456643,\n",
       "  0.7020872843149912,\n",
       "  -1.3227772084914102,\n",
       "  0.3854265225758292,\n",
       "  -1.0552207414319679,\n",
       "  -1.525998557100376,\n",
       "  0.03662579190357542,\n",
       "  1750291200.0,\n",
       "  0.3116428091318913,\n",
       "  -1.324988431982156,\n",
       "  -0.49809729535351954,\n",
       "  -0.12190452151718363],\n",
       " [0.611371475232707,\n",
       "  0.6751273768430989,\n",
       "  0.5254874159646616,\n",
       "  1.2945893628908,\n",
       "  -0.5810829214175894,\n",
       "  0.019944637822132558,\n",
       "  1.55676373082427,\n",
       "  -0.6894203596844825,\n",
       "  1770249600.0,\n",
       "  -0.3803761537087839,\n",
       "  0.15902057768639577,\n",
       "  -1.2943152246830965,\n",
       "  0.1448436506002835],\n",
       " [1.5805322085664517,\n",
       "  0.9109548042584878,\n",
       "  -1.354731795427866,\n",
       "  -1.6140018397510847,\n",
       "  -1.0539647380031223,\n",
       "  1.4974960425387325,\n",
       "  0.7027815371785533,\n",
       "  -1.3214830403621614,\n",
       "  1750204800.0,\n",
       "  0.3837616138671261,\n",
       "  -1.053751152664372,\n",
       "  -1.5299637493407536,\n",
       "  0.032574248551055736],\n",
       " [-1.4831568883164772,\n",
       "  0.5681008274657403,\n",
       "  0.662366744532993,\n",
       "  0.7991061851325341,\n",
       "  0.16045502580055135,\n",
       "  -0.11417940108862638,\n",
       "  -0.026403685149574124,\n",
       "  -0.014262816638282046,\n",
       "  1783900800.0,\n",
       "  -0.9820111242006451,\n",
       "  -0.2462466094233327,\n",
       "  1.124686079427467,\n",
       "  0.04627663344459721],\n",
       " [-1.4342585790498803,\n",
       "  0.5461208417180751,\n",
       "  -1.0713602529102966,\n",
       "  0.25013543466552524,\n",
       "  -1.5472583583214274,\n",
       "  0.5687002212941235,\n",
       "  -1.7412816594873368,\n",
       "  0.8152735852394588,\n",
       "  1763942400.0,\n",
       "  1.1257187148455654,\n",
       "  0.7926025222441185,\n",
       "  0.851650812252448,\n",
       "  -0.9233524807078207],\n",
       " [-0.15391083596644267,\n",
       "  1.4777583152315443,\n",
       "  1.0123222259582598,\n",
       "  -0.5673788530208737,\n",
       "  1.5953392615741402,\n",
       "  -0.12729116543774593,\n",
       "  1.7930147129068514,\n",
       "  -0.2999899382139505,\n",
       "  1741651200.0,\n",
       "  0.9298751894772801,\n",
       "  -0.4344771132140828,\n",
       "  1.5399626209495874,\n",
       "  -0.2677702900353614],\n",
       " [-0.3078650560302163,\n",
       "  0.3749263396933057,\n",
       "  1.242924182100692,\n",
       "  0.15470289305022164,\n",
       "  0.7821906019390135,\n",
       "  0.1330464821333739,\n",
       "  -1.0994781016297392,\n",
       "  1.5709172586440374,\n",
       "  1769731200.0,\n",
       "  0.07944742383793674,\n",
       "  -1.4715695091299994,\n",
       "  -0.6835908384903574,\n",
       "  -0.041977094747221624],\n",
       " [0.26464772339303194,\n",
       "  1.1753041763753862,\n",
       "  0.5364248228312184,\n",
       "  1.68303578527873,\n",
       "  -1.0268116725428724,\n",
       "  -1.515397641589415,\n",
       "  -0.3630580881402385,\n",
       "  0.6996053042106453,\n",
       "  1740268800.0,\n",
       "  -0.3063328046837163,\n",
       "  -0.05195447840006267,\n",
       "  1.0419349487946479,\n",
       "  0.46421615172843267],\n",
       " [1.267101005685101,\n",
       "  -0.37707648780629166,\n",
       "  -1.4075540726165692,\n",
       "  -1.0741298832752892,\n",
       "  0.9508966980289445,\n",
       "  0.15813551625341102,\n",
       "  -0.6940732648854098,\n",
       "  -0.35490940572224355,\n",
       "  1746230400.0,\n",
       "  1.4829968540625655,\n",
       "  -1.5183132632174965,\n",
       "  1.208970481530059,\n",
       "  0.0751698549281661],\n",
       " [-0.9736854109443142,\n",
       "  -0.4095464127874604,\n",
       "  0.08268639411404147,\n",
       "  -1.22621459424153,\n",
       "  -1.4562435605880992,\n",
       "  -1.1045720839772888,\n",
       "  -1.4054835002951045,\n",
       "  -1.5584339829082599,\n",
       "  1752624000.0,\n",
       "  -0.5448892198640587,\n",
       "  1.2282094902521274,\n",
       "  1.420352439223151,\n",
       "  0.5406113187899116],\n",
       " [-1.2121964144461408,\n",
       "  -0.11089858919661066,\n",
       "  0.3701642971309142,\n",
       "  -1.7607127396717033,\n",
       "  -0.8370075461444361,\n",
       "  1.1353276603385065,\n",
       "  1.727438526353931,\n",
       "  0.2025111589578499,\n",
       "  1739404800.0,\n",
       "  -1.1306718455758629,\n",
       "  1.0864141880968794,\n",
       "  1.0900331751730552,\n",
       "  -0.5396816003477962],\n",
       " [-0.9512853653043707,\n",
       "  -1.5102454134466408,\n",
       "  -1.3509677737321597,\n",
       "  1.223358966129741,\n",
       "  0.28706248379920485,\n",
       "  0.11044298609371701,\n",
       "  -0.1915941989539902,\n",
       "  -0.6736852161897848,\n",
       "  1758412800.0,\n",
       "  1.6159706278863375,\n",
       "  0.7235165938819087,\n",
       "  0.23968499543446362,\n",
       "  0.14738886217667263],\n",
       " [-0.12464489119000421,\n",
       "  -0.06510039809258751,\n",
       "  0.5492291064949694,\n",
       "  -0.8988517084942783,\n",
       "  -1.6373092818323367,\n",
       "  0.6978742392220133,\n",
       "  -0.3455679968889826,\n",
       "  -0.502291017588672,\n",
       "  1773532800.0,\n",
       "  0.659122683343905,\n",
       "  -1.327158844707632,\n",
       "  1.3131656067397084,\n",
       "  1.2369589604816427],\n",
       " [-0.14719405434641872,\n",
       "  1.1263283928094816,\n",
       "  -1.3470680039346086,\n",
       "  1.3768969826926174,\n",
       "  1.6379545580159962,\n",
       "  -1.1467648543758169,\n",
       "  1.6875955630930606,\n",
       "  -0.6228680991438696,\n",
       "  1736553600.0,\n",
       "  1.1664659928354442,\n",
       "  1.3143324636137474,\n",
       "  1.0174000202457647,\n",
       "  0.6539110483522871],\n",
       " [-0.6609393425313775,\n",
       "  0.02804163478118453,\n",
       "  -0.19632306036467856,\n",
       "  -1.444296478740461,\n",
       "  0.1970965056407611,\n",
       "  1.5556730143775732,\n",
       "  -0.6097936063728538,\n",
       "  0.44237676133565695,\n",
       "  1744761600.0,\n",
       "  -0.013961608044433941,\n",
       "  -0.21071467011607833,\n",
       "  -0.57323966779958,\n",
       "  -1.097191252160602],\n",
       " [-1.2660878128529018,\n",
       "  -0.22272105788316662,\n",
       "  1.132304547070216,\n",
       "  -1.70004956012645,\n",
       "  -1.4285879030302897,\n",
       "  1.1910124536934075,\n",
       "  -1.4283684487450852,\n",
       "  0.07544886532314073,\n",
       "  1782777600.0,\n",
       "  -0.5568036643442126,\n",
       "  -1.1098076140814324,\n",
       "  -1.4597518685624524,\n",
       "  0.11993792509596951],\n",
       " [-1.568836808832285,\n",
       "  1.2299706758524258,\n",
       "  -0.06505400677938919,\n",
       "  -0.6355623834360957,\n",
       "  -0.014877479029415087,\n",
       "  0.42999079706788434,\n",
       "  1.540850916638786,\n",
       "  1.1626930046767452,\n",
       "  1761868800.0,\n",
       "  1.4059882950293259,\n",
       "  -0.517910278235976,\n",
       "  -1.4124960845415597,\n",
       "  1.4434290807434744],\n",
       " [0.9146840749299692,\n",
       "  -0.346057242906072,\n",
       "  0.48697906273129143,\n",
       "  -1.494086836541666,\n",
       "  -0.29693126515300267,\n",
       "  -0.3169465701221507,\n",
       "  -1.3796968454055378,\n",
       "  0.46673876231070727,\n",
       "  1779494400.0,\n",
       "  0.8221846614759094,\n",
       "  -1.5720437676883428,\n",
       "  -1.1525085592378361,\n",
       "  1.5547307810925775],\n",
       " [0.9193340526192474,\n",
       "  1.6644208062033976,\n",
       "  -0.29476780190625,\n",
       "  -0.08925416169306895,\n",
       "  -1.5165528966194257,\n",
       "  -0.9835282303088376,\n",
       "  -0.7691860515684676,\n",
       "  0.2503827679607882,\n",
       "  1779148800.0,\n",
       "  0.4546724285603374,\n",
       "  -0.7821284586688725,\n",
       "  0.7905372112322221,\n",
       "  1.1560564594564002],\n",
       " [0.33255140601135225,\n",
       "  -1.258282846890091,\n",
       "  1.3017844610843214,\n",
       "  -0.9438075029544003,\n",
       "  -0.7077626552034842,\n",
       "  1.0418373932550637,\n",
       "  1.0194550255780976,\n",
       "  -1.268902205440497,\n",
       "  1763510400.0,\n",
       "  0.407495630486412,\n",
       "  1.5103246544218702,\n",
       "  -0.3943580554557063,\n",
       "  0.979152968450713],\n",
       " [-0.4706451714734827,\n",
       "  0.4234442063872179,\n",
       "  0.4705695402722784,\n",
       "  1.3995208591368964,\n",
       "  0.06296212844854847,\n",
       "  0.9117788526958746,\n",
       "  -0.3500600393768669,\n",
       "  0.2541957037500135,\n",
       "  1748563200.0,\n",
       "  -0.07825160343646716,\n",
       "  1.6413908102361143,\n",
       "  0.4449988304711248,\n",
       "  -1.5304874485778632],\n",
       " [-0.9890610661563781,\n",
       "  -0.6300966173975378,\n",
       "  0.3904253836956276,\n",
       "  1.179541335066191,\n",
       "  -1.3622481158522068,\n",
       "  -0.904545860756529,\n",
       "  1.780236692546075,\n",
       "  -1.11924566985114,\n",
       "  1785196800.0,\n",
       "  1.3098547277301777,\n",
       "  0.05774854320887859,\n",
       "  1.3652172188255332,\n",
       "  0.3929992514394582],\n",
       " [0.07617915979697068,\n",
       "  0.2849408159669156,\n",
       "  -0.5048002318700857,\n",
       "  -1.2098333870904772,\n",
       "  1.4213569979497989,\n",
       "  -0.00815148080468013,\n",
       "  0.19973859549967954,\n",
       "  -0.624075680477524,\n",
       "  1766534400.0,\n",
       "  -0.13752760463226185,\n",
       "  -1.4815139602488767,\n",
       "  1.769235161611521,\n",
       "  -0.030254292385566633],\n",
       " [0.8712765721433465,\n",
       "  1.0346629333899118,\n",
       "  0.4757153485112276,\n",
       "  -1.5390005907573905,\n",
       "  1.299101547380887,\n",
       "  -0.3673967715858926,\n",
       "  -0.4400187642717966,\n",
       "  1.054600354392996,\n",
       "  1754006400.0,\n",
       "  -1.3618066487877964,\n",
       "  1.6547976526441606,\n",
       "  -0.966402017343109,\n",
       "  1.2846859267046575],\n",
       " [0.5121150798004926,\n",
       "  0.5329961200463794,\n",
       "  -1.202587076297834,\n",
       "  -0.8279715879458679,\n",
       "  1.1565664873940462,\n",
       "  1.0708192007495603,\n",
       "  -1.3354514882045325,\n",
       "  -0.7090314390728015,\n",
       "  1795910400.0,\n",
       "  0.43068281065207953,\n",
       "  -0.882803291020765,\n",
       "  -1.3978351202603343,\n",
       "  0.6948973508565168],\n",
       " [-0.029851717297922385,\n",
       "  -1.689962685905267,\n",
       "  0.6370296619221889,\n",
       "  1.2199967767482673,\n",
       "  -0.9354647687777058,\n",
       "  -1.0348500753418326,\n",
       "  -0.31745643551425673,\n",
       "  -0.9621391966683004,\n",
       "  1767225600.0,\n",
       "  0.025617442945464475,\n",
       "  1.2511666724468307,\n",
       "  0.42144575306351784,\n",
       "  0.2504536846320873],\n",
       " [-1.2411193681629684,\n",
       "  1.2848250302370146,\n",
       "  -1.0450836138675401,\n",
       "  1.6602643708821123,\n",
       "  0.7439716755278806,\n",
       "  -0.9028509280750079,\n",
       "  0.3598457359202668,\n",
       "  1.6176854732184172,\n",
       "  1743465600.0,\n",
       "  1.37139990708601,\n",
       "  -0.3174109608705557,\n",
       "  1.786646094169086,\n",
       "  -0.9002861039066041],\n",
       " [0.4842317822041035,\n",
       "  -0.4134708366616451,\n",
       "  -0.9348141581967003,\n",
       "  -1.7823224662075339,\n",
       "  0.02185797639798574,\n",
       "  -1.295979446209164,\n",
       "  -0.11434108903028409,\n",
       "  0.6918158754152679,\n",
       "  1776902400.0,\n",
       "  -1.675524365293003,\n",
       "  1.3289400015606967,\n",
       "  0.6075210249369176,\n",
       "  0.8351285214580204],\n",
       " [-0.11698417602847022,\n",
       "  1.328037443661219,\n",
       "  0.6189007866752646,\n",
       "  0.8684435687202037,\n",
       "  1.2664093026917609,\n",
       "  -0.042154599722852036,\n",
       "  -1.2049811153367798,\n",
       "  0.08095829963564964,\n",
       "  1772496000.0,\n",
       "  0.51485112036717,\n",
       "  0.916362856925873,\n",
       "  -1.5464192788266131,\n",
       "  -1.1446304803958827],\n",
       " [0.6709000760338131,\n",
       "  -0.6013524280520552,\n",
       "  1.39887087544538,\n",
       "  -1.1168642928117338,\n",
       "  1.6193761195829124,\n",
       "  1.1786829814260635,\n",
       "  -1.2311252875710679,\n",
       "  -1.4247700164464976,\n",
       "  1769558400.0,\n",
       "  -0.30485203131317057,\n",
       "  0.37871452460541194,\n",
       "  1.2419062375411565,\n",
       "  0.15109879687153152],\n",
       " [-1.1341021300031826,\n",
       "  1.0820744865825858,\n",
       "  1.0910224064333693,\n",
       "  -0.5365824538210925,\n",
       "  1.31996397308293,\n",
       "  -1.5235674165789255,\n",
       "  0.09007914737083712,\n",
       "  0.5631939004123031,\n",
       "  1739577600.0,\n",
       "  1.0544041536162418,\n",
       "  -0.24943117434295373,\n",
       "  1.6471809454935458,\n",
       "  0.1667176329646918],\n",
       " [0.9830179286973533,\n",
       "  -1.1793394642014012,\n",
       "  0.0757692822809828,\n",
       "  -0.3058610715990125,\n",
       "  -0.7021978531197656,\n",
       "  -0.33902790914970915,\n",
       "  -1.192911867915689,\n",
       "  0.3324043134138236,\n",
       "  1745366400.0,\n",
       "  -0.8060574831332835,\n",
       "  -1.6845794156391416,\n",
       "  -1.2333681883381094,\n",
       "  -0.14757623823159152],\n",
       " [-1.483353565848814,\n",
       "  -1.086867115058904,\n",
       "  -0.47830848984398866,\n",
       "  -1.7064182915737889,\n",
       "  1.6569643752441885,\n",
       "  -0.34474662564397995,\n",
       "  -0.6109944672810002,\n",
       "  0.1288034081707749,\n",
       "  1776211200.0,\n",
       "  0.6634000808878936,\n",
       "  -0.9162325875140186,\n",
       "  -1.0833393225943673,\n",
       "  1.1262816213187594],\n",
       " [-1.4987450913321572,\n",
       "  -0.23326516342349163,\n",
       "  1.2901519375963155,\n",
       "  0.5799945309979291,\n",
       "  -0.839536345049221,\n",
       "  -0.33164754198160895,\n",
       "  -0.21142374885183965,\n",
       "  -1.3271058907257816,\n",
       "  1740873600.0,\n",
       "  -1.612959142095675,\n",
       "  1.200889914381277,\n",
       "  0.7244676015724161,\n",
       "  -0.08338842094260951],\n",
       " [0.452152413891887,\n",
       "  -0.741615974071601,\n",
       "  1.4433329672857196,\n",
       "  0.7786475334662125,\n",
       "  0.0430085828201145,\n",
       "  0.4577965303849197,\n",
       "  1.2110661588312743,\n",
       "  -0.4519200776877698,\n",
       "  1777420800.0,\n",
       "  -1.1510090716953398,\n",
       "  0.5463519060475776,\n",
       "  -0.7026941700260325,\n",
       "  -0.24338928342112462],\n",
       " [0.2642208008751928,\n",
       "  1.6089738106850469,\n",
       "  -0.523707733525825,\n",
       "  -0.28716413161801035,\n",
       "  0.7151455097860421,\n",
       "  0.8514700611163949,\n",
       "  -0.30168190589761124,\n",
       "  0.1470320495892964,\n",
       "  1780358400.0,\n",
       "  -1.5632506771029548,\n",
       "  0.43177153925534584,\n",
       "  0.5729714698639212,\n",
       "  0.4628483632982124],\n",
       " [-1.3012269393262996,\n",
       "  -1.0328996812963573,\n",
       "  1.1779689880801663,\n",
       "  -0.7019566802947089,\n",
       "  -1.3886004569441739,\n",
       "  -1.2187020281188117,\n",
       "  -1.00878106595281,\n",
       "  1.052100073944506,\n",
       "  1738108800.0,\n",
       "  -0.35759843227364363,\n",
       "  -1.2143637958574363,\n",
       "  1.5786035643259873,\n",
       "  0.11308586329620157],\n",
       " [1.4841829602618681,\n",
       "  1.586523303637874,\n",
       "  -0.6963983772580098,\n",
       "  1.5347335661773396,\n",
       "  -0.2589600507995363,\n",
       "  1.3973961303901825,\n",
       "  -1.233482460576319,\n",
       "  -1.8087818517965808,\n",
       "  1754870400.0,\n",
       "  0.3990611925754961,\n",
       "  -0.29465296237729127,\n",
       "  -0.2391996863031662,\n",
       "  0.46104554036181655],\n",
       " [1.3945628104084715,\n",
       "  1.227886120181663,\n",
       "  1.1186822971239545,\n",
       "  -1.7581275890757635,\n",
       "  0.9280555456845908,\n",
       "  1.0684555683293138,\n",
       "  -0.41221268553777884,\n",
       "  -1.3830557452443324,\n",
       "  1773187200.0,\n",
       "  -1.254553842763936,\n",
       "  -0.06613620667085951,\n",
       "  1.5270212915489656,\n",
       "  -1.6599066071977315],\n",
       " [-0.06067289906027626,\n",
       "  -0.42594533850095656,\n",
       "  0.10010702190593793,\n",
       "  -0.08082968982016753,\n",
       "  -0.5242996473633,\n",
       "  -1.7558181664736967,\n",
       "  -0.7623806261157753,\n",
       "  0.6763306896580186,\n",
       "  1760313600.0,\n",
       "  0.15570229413526115,\n",
       "  -1.3320397463885336,\n",
       "  -0.8841200724464455,\n",
       "  0.4768513989114838],\n",
       " [-0.8093237505529167,\n",
       "  -1.686759657348868,\n",
       "  -1.2328182220634472,\n",
       "  -0.14419046882598216,\n",
       "  0.9070383555978104,\n",
       "  -0.28899244219176506,\n",
       "  0.23247533097635104,\n",
       "  1.0732778870165447,\n",
       "  1745539200.0,\n",
       "  -0.9204307264483396,\n",
       "  -0.3483879816502322,\n",
       "  0.8338672270429173,\n",
       "  0.20396163986298366],\n",
       " [1.107737306245634,\n",
       "  -0.560547552248385,\n",
       "  -0.340587336156485,\n",
       "  -0.26745009631114686,\n",
       "  -0.8577350404603045,\n",
       "  0.7178539764503288,\n",
       "  0.21485122596103315,\n",
       "  0.3278118753394408,\n",
       "  1743120000.0,\n",
       "  0.3204535980997327,\n",
       "  -1.4412108595386302,\n",
       "  0.31462451250846113,\n",
       "  0.7800779474135698],\n",
       " [-0.30934657758705764,\n",
       "  -0.055407039152008654,\n",
       "  1.0429150865478944,\n",
       "  0.46804913178976093,\n",
       "  1.4321723751274749,\n",
       "  1.2370965914767416,\n",
       "  -0.4724121910128311,\n",
       "  -0.19749277049712277,\n",
       "  1740441600.0,\n",
       "  -0.3384989357899245,\n",
       "  0.04955766631411156,\n",
       "  -0.9356729282802715,\n",
       "  0.31768680597672183],\n",
       " [0.3964038321604991,\n",
       "  -0.2979163860557804,\n",
       "  -0.23846176136598432,\n",
       "  0.4648762027558911,\n",
       "  1.2771389864667613,\n",
       "  -0.9384061516142986,\n",
       "  -0.5931794412937476,\n",
       "  -0.6652590690233993,\n",
       "  1755043200.0,\n",
       "  1.6538051893988717,\n",
       "  1.1222673008459634,\n",
       "  -0.910502789553759,\n",
       "  -1.532720467332851],\n",
       " [-1.6277457949121044,\n",
       "  0.6853157056747463,\n",
       "  1.050082173121948,\n",
       "  -1.5375744460999405,\n",
       "  -1.241329556765356,\n",
       "  -0.2481918582163711,\n",
       "  -0.30117597013428804,\n",
       "  1.5070705325001537,\n",
       "  1784246400.0,\n",
       "  0.33803344991121403,\n",
       "  -0.22016829587857809,\n",
       "  -0.4927126365320564,\n",
       "  -0.27211975238485164],\n",
       " [-1.0344473229779458,\n",
       "  -1.307967267315496,\n",
       "  -1.6291430354955239,\n",
       "  0.31291712084562817,\n",
       "  -1.6065358425655127,\n",
       "  -0.35730832931701806,\n",
       "  0.28987680914683805,\n",
       "  1.3760161390653092,\n",
       "  1775001600.0,\n",
       "  -1.1162236598568505,\n",
       "  -1.113803138558133,\n",
       "  -0.2550867581627392,\n",
       "  -0.970186995304073],\n",
       " [-0.5664324991321018,\n",
       "  0.32464047634104193,\n",
       "  1.4120179914264266,\n",
       "  0.7753343221746677,\n",
       "  0.39191412706531753,\n",
       "  1.43503037682755,\n",
       "  1.3162755296076134,\n",
       "  -1.4492482914670883,\n",
       "  1762128000.0,\n",
       "  -0.36272859100145105,\n",
       "  -0.21650811990343904,\n",
       "  -1.2328048797191973,\n",
       "  0.766496836793614],\n",
       " [1.0690987864007069,\n",
       "  -1.1421738304796623,\n",
       "  0.4512132949928021,\n",
       "  -0.03927149407154433,\n",
       "  -1.5967661039110113,\n",
       "  -0.3628069954595112,\n",
       "  1.112672800037111,\n",
       "  1.7071900508648523,\n",
       "  1783641600.0,\n",
       "  1.4838322470220806,\n",
       "  -1.4122880983704496,\n",
       "  1.4805913755347722,\n",
       "  -1.712992830824096],\n",
       " [1.3822274090105573,\n",
       "  -0.9814122986414822,\n",
       "  0.8755958900584637,\n",
       "  0.4322833160239545,\n",
       "  -0.8523399616426234,\n",
       "  0.7877896344069013,\n",
       "  -1.5339484705656052,\n",
       "  -0.6988493105967406,\n",
       "  1754611200.0,\n",
       "  1.069636200894897,\n",
       "  1.138769095027029,\n",
       "  1.098328443142082,\n",
       "  1.2516302484880535],\n",
       " [1.0480363229854606,\n",
       "  -1.1560820170945094,\n",
       "  -1.5302567032239098,\n",
       "  -0.3218195919655584,\n",
       "  -0.23560379947497964,\n",
       "  -0.6604010622593104,\n",
       "  0.722556645032402,\n",
       "  1.609300199359906,\n",
       "  1756339200.0,\n",
       "  -0.003277645070618754,\n",
       "  -0.7218413212244158,\n",
       "  1.3244679994094815,\n",
       "  -0.03945936175545499],\n",
       " [0.0370679363668974,\n",
       "  1.222204842132103,\n",
       "  -0.6214526702282883,\n",
       "  0.17434373366505498,\n",
       "  -0.9036427879220756,\n",
       "  -0.3428545275350959,\n",
       "  1.6901786283186453,\n",
       "  1.1909282547521989,\n",
       "  1737590400.0,\n",
       "  0.13229788735341333,\n",
       "  -1.5206741434799353,\n",
       "  1.1238346297568675,\n",
       "  -0.11507670384419369],\n",
       " [-0.5899481270252586,\n",
       "  -1.2280156407794702,\n",
       "  0.36053766256917125,\n",
       "  -0.27560501504059404,\n",
       "  0.9474409322759708,\n",
       "  1.570173580469788,\n",
       "  -0.9511661564063599,\n",
       "  1.0036527340203727,\n",
       "  1757635200.0,\n",
       "  -0.3540299732260927,\n",
       "  -0.5611661629772099,\n",
       "  -1.4396986736248576,\n",
       "  1.6604629633378998],\n",
       " [0.2827867639900465,\n",
       "  0.10868111184565901,\n",
       "  -0.19340283909277464,\n",
       "  -0.67461683675,\n",
       "  1.6189388138160015,\n",
       "  0.7215149390388256,\n",
       "  0.24178211449368328,\n",
       "  0.1514600648802762,\n",
       "  1758499200.0,\n",
       "  0.38110498629060374,\n",
       "  0.14299739084058272,\n",
       "  -0.5712501178404149,\n",
       "  1.1433478978374445],\n",
       " [0.3300278794809358,\n",
       "  0.46415912669249043,\n",
       "  -0.028750160509174623,\n",
       "  -1.762011877344298,\n",
       "  1.3994523742597271,\n",
       "  1.2301855598904894,\n",
       "  1.1188581208401032,\n",
       "  -1.75658990833908,\n",
       "  1773100800.0,\n",
       "  0.9258173179662011,\n",
       "  1.0705611189522153,\n",
       "  -0.4150009028571995,\n",
       "  -1.3868642425354054],\n",
       " [0.9755884793010084,\n",
       "  -0.6021872018211475,\n",
       "  -1.7096118172908434,\n",
       "  1.4983565935234977,\n",
       "  -1.1175766373304354,\n",
       "  0.6364550811150509,\n",
       "  -0.26437144948975805,\n",
       "  0.6047645384883111,\n",
       "  1758844800.0,\n",
       "  -0.07357420088133108,\n",
       "  0.6606922884215286,\n",
       "  1.4584415319616246,\n",
       "  0.9859837544466323],\n",
       " [0.7980485791496774,\n",
       "  0.6048759528214573,\n",
       "  0.7512417019348077,\n",
       "  0.6580619338496638,\n",
       "  -0.4795182282156906,\n",
       "  0.6314059647922681,\n",
       "  -0.3205724129542059,\n",
       "  1.1475219438313875,\n",
       "  1741305600.0,\n",
       "  -1.6044368599845458,\n",
       "  0.11668346888972492,\n",
       "  0.22284113153789561,\n",
       "  0.4477550564227345],\n",
       " [1.0370392759580769,\n",
       "  -1.6969248495580307,\n",
       "  -0.7628465188175271,\n",
       "  -1.0740004278292712,\n",
       "  -1.2823141638960838,\n",
       "  0.5668228638515592,\n",
       "  -1.1413290722891183,\n",
       "  -0.36607158588390337,\n",
       "  1754438400.0,\n",
       "  1.3843869166021754,\n",
       "  -0.978681944794225,\n",
       "  0.8746473798891161,\n",
       "  0.4284764611167405],\n",
       " [-1.4557494866323626,\n",
       "  -0.9167635195428177,\n",
       "  1.3432320292409379,\n",
       "  0.018698667223481374,\n",
       "  1.6220278444649905,\n",
       "  -1.615405156819563,\n",
       "  -1.7028239442742896,\n",
       "  1.130338364085655,\n",
       "  1783296000.0,\n",
       "  0.2989286770148656,\n",
       "  -1.2721422554259034,\n",
       "  -0.6102032718259283,\n",
       "  -0.9531170299969123],\n",
       " [-1.4033878413211884,\n",
       "  -0.3004839200618685,\n",
       "  0.9766916866775982,\n",
       "  1.5490512523928428,\n",
       "  -1.1122470190806022,\n",
       "  1.0944684026336355,\n",
       "  1.1932107985473932,\n",
       "  1.3166173175155216,\n",
       "  1738540800.0,\n",
       "  -0.982250911054345,\n",
       "  1.6737028517646637,\n",
       "  -0.1534572678366049,\n",
       "  0.9725320918438898],\n",
       " [0.975484750150409,\n",
       "  -1.4726825123116525,\n",
       "  0.0471854360512699,\n",
       "  0.8221093779257491,\n",
       "  -0.16904478380678203,\n",
       "  1.2209055827458135,\n",
       "  1.762218149176348,\n",
       "  -1.5265124332368458,\n",
       "  1751760000.0,\n",
       "  -1.6654545313451254,\n",
       "  -1.56241274401168,\n",
       "  -0.6086941838764183,\n",
       "  1.4587891090250096],\n",
       " [1.0621388781786856,\n",
       "  -0.4550363941534073,\n",
       "  1.004767683622512,\n",
       "  -0.07669242924888672,\n",
       "  -0.893631133303954,\n",
       "  -1.5986885269684084,\n",
       "  0.8021737821989946,\n",
       "  -1.4763721935562022,\n",
       "  1762473600.0,\n",
       "  1.6102667783050946,\n",
       "  0.9606710782420718,\n",
       "  -0.7326635328590206,\n",
       "  1.4825845642833677],\n",
       " [1.1444312639747396,\n",
       "  0.7580998030383164,\n",
       "  -1.4015581987462038,\n",
       "  -1.4415646024560744,\n",
       "  1.2145276428074445,\n",
       "  0.14189935721338015,\n",
       "  1.7561175041734498,\n",
       "  1.0476354014173335,\n",
       "  1790726400.0,\n",
       "  0.23364890527702803,\n",
       "  0.9522668564785606,\n",
       "  1.184915372832599,\n",
       "  1.1938143998596151],\n",
       " [1.310339213448514,\n",
       "  0.7844643516844892,\n",
       "  -0.11560173831937855,\n",
       "  1.6444287876535006,\n",
       "  1.2724038447917798,\n",
       "  0.2500487872141531,\n",
       "  -1.2702853300668497,\n",
       "  -1.3324786128111468,\n",
       "  1764460800.0,\n",
       "  1.4207959405559845,\n",
       "  1.4018165056516485,\n",
       "  -0.20516049297534614,\n",
       "  -1.238645948732659],\n",
       " [0.6565967234843527,\n",
       "  -1.3296176274270566,\n",
       "  1.3141970236791263,\n",
       "  1.2413568034341669,\n",
       "  -1.2503984951679636,\n",
       "  -0.7869212887069417,\n",
       "  1.0889744861251325,\n",
       "  0.4851136687531527,\n",
       "  1773705600.0,\n",
       "  0.585253105643672,\n",
       "  0.09054440859558116,\n",
       "  -0.9066937834409791,\n",
       "  -1.295094547024833],\n",
       " [1.5762185053395388,\n",
       "  -0.38503761723827346,\n",
       "  -0.885701113849761,\n",
       "  -1.3329253468513012,\n",
       "  -0.4947092879054253,\n",
       "  0.5209917430191555,\n",
       "  -0.7976480234068005,\n",
       "  0.9339056339123804,\n",
       "  1761609600.0,\n",
       "  0.8666184838167392,\n",
       "  -0.6245658854165316,\n",
       "  -1.6883016971722888,\n",
       "  -0.024058087301663596],\n",
       " [-1.4678927082448503,\n",
       "  -0.3108834541591026,\n",
       "  1.6807959640703223,\n",
       "  -0.9245623914948344,\n",
       "  -1.4590561146247556,\n",
       "  -0.75930190338253,\n",
       "  0.10260420947401752,\n",
       "  -1.773807891836349,\n",
       "  1786579200.0,\n",
       "  -1.39143239936836,\n",
       "  -0.98422537967552,\n",
       "  0.7043116983869675,\n",
       "  1.0266342321503095],\n",
       " [-1.3710377837418564,\n",
       "  0.8304160441291293,\n",
       "  0.7893005149297985,\n",
       "  1.3799617581209567,\n",
       "  1.2056903713295517,\n",
       "  -1.3549182869765606,\n",
       "  -1.1468619010873509,\n",
       "  -0.6269165964205895,\n",
       "  1765584000.0,\n",
       "  -0.4166161863328898,\n",
       "  -1.687519020730187,\n",
       "  0.14611187349993945,\n",
       "  0.129407547950908],\n",
       " [-0.6859709310369582,\n",
       "  0.5409276350715128,\n",
       "  -1.3796646925774232,\n",
       "  -0.4448536419499623,\n",
       "  0.0717658777389458,\n",
       "  -1.203869022591682,\n",
       "  -0.11327696088090615,\n",
       "  -0.5301259791388112,\n",
       "  1787702400.0,\n",
       "  -0.5525122355462594,\n",
       "  1.1718112223034718,\n",
       "  -1.5532062454349997,\n",
       "  -0.007327706700163131],\n",
       " [1.516259068851558,\n",
       "  1.452619006648635,\n",
       "  -0.5343944462913123,\n",
       "  -1.1502668472929922,\n",
       "  1.4286903387971264,\n",
       "  0.15158345563978845,\n",
       "  0.41314713384468604,\n",
       "  0.5625668203793961,\n",
       "  1771286400.0,\n",
       "  -1.6257179179339953,\n",
       "  1.0430602835888825,\n",
       "  1.283046197759263,\n",
       "  -0.5385107661038264],\n",
       " [0.36566883162391245,\n",
       "  1.408424839967636,\n",
       "  0.5170228655847349,\n",
       "  -1.1352320339173196,\n",
       "  0.6995082026354837,\n",
       "  -0.3783778277438349,\n",
       "  0.6328469196587415,\n",
       "  1.4278607177206473,\n",
       "  1764201600.0,\n",
       "  0.8613133964114948,\n",
       "  -1.3999202670849396,\n",
       "  0.12903951645818454,\n",
       "  1.1547852702782797],\n",
       " [-0.9390658680453333,\n",
       "  -1.0360621178636593,\n",
       "  -0.3194218993113621,\n",
       "  -0.963232253845772,\n",
       "  0.026903551357731186,\n",
       "  1.2490070533875632,\n",
       "  0.42335100218373617,\n",
       "  0.2545425348063835,\n",
       "  1767312000.0,\n",
       "  0.05985950012198253,\n",
       "  -0.9215650980816515,\n",
       "  -1.2089381789281772,\n",
       "  0.853093822785038],\n",
       " [-1.402442149298945,\n",
       "  0.4173902719373016,\n",
       "  -1.3187171696684135,\n",
       "  1.1747795658724043,\n",
       "  -1.3830202829498586,\n",
       "  1.1221002698561333,\n",
       "  1.0521492093929705,\n",
       "  1.40927206948134,\n",
       "  1789171200.0,\n",
       "  -0.1095487380493618,\n",
       "  -0.45981906088827706,\n",
       "  -1.2937623689104427,\n",
       "  -0.6473641109294486],\n",
       " [-0.8847590002631182,\n",
       "  -0.9113160687043894,\n",
       "  0.38183505137898094,\n",
       "  0.8925742949994174,\n",
       "  1.2463671847060154,\n",
       "  -1.13427051244599,\n",
       "  -0.5841875350527016,\n",
       "  0.10519483762849381,\n",
       "  1785801600.0,\n",
       "  1.3644647085928592,\n",
       "  -0.897871579933355,\n",
       "  1.487152580774777,\n",
       "  -0.3717826637347546],\n",
       " [1.4382287124442614,\n",
       "  0.8820002177898534,\n",
       "  -0.07639985119365872,\n",
       "  -1.1610411540581043,\n",
       "  1.506081623234553,\n",
       "  0.7981477246730904,\n",
       "  -1.410887721908532,\n",
       "  -1.391588449663889,\n",
       "  1755993600.0,\n",
       "  0.36952640611390747,\n",
       "  -1.6041751050775974,\n",
       "  1.718666694205976,\n",
       "  1.5907247146665213],\n",
       " [1.0245580946761772,\n",
       "  0.7237065787798664,\n",
       "  1.285178139875816,\n",
       "  1.602495888197696,\n",
       "  -0.5389784415459615,\n",
       "  -1.6343295461259872,\n",
       "  -1.56524271140125,\n",
       "  0.5628617740811971,\n",
       "  1765065600.0,\n",
       "  1.355940771841771,\n",
       "  -0.7977527860875637,\n",
       "  0.48740219625671777,\n",
       "  0.464734190591434],\n",
       " [-0.2069463118283296,\n",
       "  0.8864039270763925,\n",
       "  0.5923607085702527,\n",
       "  -0.5767403754025211,\n",
       "  1.2979066421659455,\n",
       "  1.371170646936603,\n",
       "  0.19580082054873071,\n",
       "  -0.9420613995408307,\n",
       "  1792454400.0,\n",
       "  1.1755586189409375,\n",
       "  -1.3181046624188073,\n",
       "  -1.4092645923383997,\n",
       "  -0.07362238140572173],\n",
       " [-1.4220598012051686,\n",
       "  0.3556629489171239,\n",
       "  -1.024529783650787,\n",
       "  0.703725487260554,\n",
       "  1.5855244515565854,\n",
       "  0.9131020186577352,\n",
       "  -1.3514779464839166,\n",
       "  -1.6125447755444002,\n",
       "  1750118400.0,\n",
       "  -1.054108846428533,\n",
       "  1.4997300747832094,\n",
       "  0.7011715716853189,\n",
       "  -1.3253020787520813],\n",
       " [0.2998496445545147,\n",
       "  -0.08566904864312466,\n",
       "  0.5178796382855609,\n",
       "  1.2899137453967902,\n",
       "  0.3609645918436375,\n",
       "  -1.6484021338904533,\n",
       "  -0.845438800586005,\n",
       "  0.4264548149448987,\n",
       "  1760745600.0,\n",
       "  0.7473619556174721,\n",
       "  0.47006001840544837,\n",
       "  0.191089918832432,\n",
       "  -0.9941830942281273],\n",
       " [1.165472191784865,\n",
       "  -0.9158099412594354,\n",
       "  -0.23625911320276968,\n",
       "  -1.6065085158718306,\n",
       "  -0.2637145905555658,\n",
       "  -0.5159061858297036,\n",
       "  -1.08070800038224,\n",
       "  0.24227915217955312,\n",
       "  1788739200.0,\n",
       "  1.2622556055141994,\n",
       "  -0.9709225536834606,\n",
       "  0.5238054114807441,\n",
       "  0.06050964077133293],\n",
       " [-1.2538258062761896,\n",
       "  -0.7882523567579784,\n",
       "  1.0887614275635846,\n",
       "  0.48483058343504304,\n",
       "  0.5871311269562127,\n",
       "  0.08873224856956892,\n",
       "  -0.9033865262350855,\n",
       "  -1.2912703362927098,\n",
       "  1773792000.0,\n",
       "  1.06697974675613,\n",
       "  0.9265728986526199,\n",
       "  1.3730898188985319,\n",
       "  1.4053223927068346],\n",
       " [0.09186866397695373,\n",
       "  -1.3251116051484957,\n",
       "  -0.06626373391247663,\n",
       "  -0.3957388743670912,\n",
       "  -1.035814170658139,\n",
       "  0.6817639626067405,\n",
       "  -0.011151948802445542,\n",
       "  -0.14013474083586033,\n",
       "  1778803200.0,\n",
       "  -0.7956416212366839,\n",
       "  0.7212686041875976,\n",
       "  -0.42263908335207934,\n",
       "  0.0930184183173652],\n",
       " [0.23490967813270505,\n",
       "  -0.5958905463307587,\n",
       "  -1.6845336086387213,\n",
       "  -1.7613387276707533,\n",
       "  1.2422810037608503,\n",
       "  0.9687468246284768,\n",
       "  0.4688385099145882,\n",
       "  -0.7217674264657872,\n",
       "  1759968000.0,\n",
       "  0.32072232074732215,\n",
       "  -0.3069166675237563,\n",
       "  0.8250364528688364,\n",
       "  -0.4341831813025042],\n",
       " [1.0646598637152414,\n",
       "  0.9223577628678176,\n",
       "  1.3741325651797534,\n",
       "  1.409843306691559,\n",
       "  -0.5743749873178138,\n",
       "  -0.07623408729254297,\n",
       "  0.8944312230238207,\n",
       "  -0.7761209839375706,\n",
       "  1773964800.0,\n",
       "  0.009856996187118834,\n",
       "  0.37147538826580484,\n",
       "  -0.8653724233579018,\n",
       "  1.2573219689150885],\n",
       " [0.7779584687431316,\n",
       "  0.1768641933221136,\n",
       "  -1.016857972023718,\n",
       "  -1.431536277868031,\n",
       "  -1.2831936055819295,\n",
       "  -1.628487030414365,\n",
       "  1.054071585836922,\n",
       "  -0.5584139556127214,\n",
       "  1745020800.0,\n",
       "  1.0794691688817073,\n",
       "  1.4465716774405242,\n",
       "  -0.8813217566253256,\n",
       "  -0.22200586293809546],\n",
       " [-0.3916493670426188,\n",
       "  -0.30547943484868467,\n",
       "  -1.485443928479724,\n",
       "  0.029348633057544902,\n",
       "  -1.2582913902348658,\n",
       "  0.4053077364909103,\n",
       "  1.4198813688767444,\n",
       "  1.3566177055062623,\n",
       "  1745884800.0,\n",
       "  1.4286200484730784,\n",
       "  0.844615991310832,\n",
       "  0.8591993841499495,\n",
       "  0.08950355427744876],\n",
       " [-0.09989466314449243,\n",
       "  -0.14777373794469179,\n",
       "  0.25127695905041747,\n",
       "  -0.09897219775427157,\n",
       "  1.5346475974049552,\n",
       "  0.2290823436780625,\n",
       "  -0.5375252000546991,\n",
       "  -0.6926221025472116,\n",
       "  1790035200.0,\n",
       "  -1.0529140972830244,\n",
       "  -1.7633197200305595,\n",
       "  0.31991143902894786,\n",
       "  -1.4980390894408173],\n",
       " [1.3083938043635206,\n",
       "  1.6231966079529776,\n",
       "  1.638627122704365,\n",
       "  -1.3104464269713005,\n",
       "  -0.7077406924858344,\n",
       "  0.9271668708986259,\n",
       "  -0.043947247066066564,\n",
       "  0.6195851008059068,\n",
       "  1783036800.0,\n",
       "  1.4416581966932096,\n",
       "  0.056267129705353726,\n",
       "  1.4337182451141643,\n",
       "  0.38695583125870586],\n",
       " [-1.588340645754465,\n",
       "  -0.3334874145252161,\n",
       "  0.4643860342590113,\n",
       "  1.0638028744848553,\n",
       "  0.17035462602158186,\n",
       "  0.8945378641801094,\n",
       "  -0.3942718384287455,\n",
       "  -1.7831518335157464,\n",
       "  1795478400.0,\n",
       "  -0.48206853173483605,\n",
       "  -0.22306888630181387,\n",
       "  -0.7079771953522275,\n",
       "  0.6154618234965599],\n",
       " [-0.5519320606429977,\n",
       "  0.781857854305489,\n",
       "  1.3639985634346523,\n",
       "  -1.0441719480466072,\n",
       "  1.1538643186938211,\n",
       "  1.422242116434523,\n",
       "  -0.36315806033040504,\n",
       "  0.3259828972534891,\n",
       "  1743984000.0,\n",
       "  1.381099620935751,\n",
       "  1.6568320850736185,\n",
       "  0.8253430060417031,\n",
       "  0.516478639718234],\n",
       " [1.6329333828063657,\n",
       "  -1.1479231689059015,\n",
       "  1.6881283831191158,\n",
       "  -0.6237712793148725,\n",
       "  1.1689587487488422,\n",
       "  1.3121539344185837,\n",
       "  1.018676169276484,\n",
       "  0.6580689812827785,\n",
       "  1736640000.0,\n",
       "  -1.0513745125335505,\n",
       "  0.2618633891949801,\n",
       "  -1.4227721402416769,\n",
       "  0.19681302395321634],\n",
       " [0.881716202826064,\n",
       "  1.374089596149378,\n",
       "  0.8648704593700518,\n",
       "  0.014263779309812258,\n",
       "  0.22752486971051172,\n",
       "  -0.8028036525842075,\n",
       "  -0.19753844867653014,\n",
       "  1.2689909542934268,\n",
       "  1743724800.0,\n",
       "  -0.6308622952639328,\n",
       "  0.9944066901923185,\n",
       "  1.3704070324738131,\n",
       "  -0.7435616259745522],\n",
       " [0.5134031995096076,\n",
       "  1.6141358038567692,\n",
       "  -1.6278361828878058,\n",
       "  0.14848121432018857,\n",
       "  -1.0340494688233126,\n",
       "  -0.10095347240221007,\n",
       "  -1.4579426982047456,\n",
       "  -0.1283472177656394,\n",
       "  1781568000.0,\n",
       "  0.8045290404508865,\n",
       "  -0.0917930608948224,\n",
       "  -1.5555637572538055,\n",
       "  0.9139265911946489],\n",
       " [0.9011929209042077,\n",
       "  -0.035853202266121,\n",
       "  -0.015037496419215262,\n",
       "  -0.9071567295355454,\n",
       "  1.0131116164989098,\n",
       "  0.25775574610710233,\n",
       "  0.2874391807768948,\n",
       "  -1.1608860695699261,\n",
       "  1788998400.0,\n",
       "  -1.3988763499180685,\n",
       "  0.42121157517649355,\n",
       "  -1.3192508988571392,\n",
       "  1.1704303542890955],\n",
       " [-0.6109113040502504,\n",
       "  -0.9335042764389817,\n",
       "  -0.4057243851062898,\n",
       "  0.38665878439448126,\n",
       "  1.0268388302198685,\n",
       "  0.9861395296042701,\n",
       "  0.8716476254980786,\n",
       "  -0.32946846685843834,\n",
       "  1788480000.0,\n",
       "  -0.07878854059063117,\n",
       "  1.181941530117835,\n",
       "  0.052634660820677755,\n",
       "  1.285816973853763],\n",
       " [-1.2596775347218274,\n",
       "  0.6027739781876618,\n",
       "  -1.5840881330435346,\n",
       "  -0.9248496629973078,\n",
       "  -0.2367552365729567,\n",
       "  -0.8133166403647569,\n",
       "  -0.3404218386385831,\n",
       "  0.4453390435544652,\n",
       "  1795046400.0,\n",
       "  -0.8561002439221594,\n",
       "  -1.528804880810854,\n",
       "  0.15570138095472996,\n",
       "  1.4798158211876982],\n",
       " [0.022771393632377318,\n",
       "  1.246698577865452,\n",
       "  0.4223085804019817,\n",
       "  0.2541304076777235,\n",
       "  0.06118182551741465,\n",
       "  -0.9230742597922847,\n",
       "  -1.2053118670787948,\n",
       "  0.8572858611657747,\n",
       "  1767398400.0,\n",
       "  -0.5709675002160589,\n",
       "  -0.2112411779149294,\n",
       "  -0.19383959950182442,\n",
       "  1.1587577683240784],\n",
       " [-0.5766266782066444,\n",
       "  1.2663525030471579,\n",
       "  1.0009297420153478,\n",
       "  0.7081918717865602,\n",
       "  -1.5364078569892174,\n",
       "  -0.7226945050426272,\n",
       "  0.9513070328692407,\n",
       "  1.2643084852655044,\n",
       "  1790985600.0,\n",
       "  0.560545558907774,\n",
       "  0.3945785186477431,\n",
       "  1.4299680587308645,\n",
       "  -1.3040327566222805],\n",
       " [0.5612253576393813,\n",
       "  -1.3382952553097212,\n",
       "  0.1544715759960068,\n",
       "  -0.36716376394716693,\n",
       "  -1.6809649716630486,\n",
       "  -0.7261264309875359,\n",
       "  -0.7099647989758147,\n",
       "  -1.7257663225845856,\n",
       "  1748131200.0,\n",
       "  0.63174073593071,\n",
       "  0.9089718438400713,\n",
       "  -1.568664875192276,\n",
       "  -1.4030028699976391],\n",
       " [-0.5646413260527673,\n",
       "  0.8967536322406371,\n",
       "  -0.8220294375269849,\n",
       "  0.6149313187124268,\n",
       "  -1.4000431077828175,\n",
       "  -0.29891857190801974,\n",
       "  0.9770442097512789,\n",
       "  1.5487390674147918,\n",
       "  1738454400.0,\n",
       "  -1.112329548898444,\n",
       "  1.0965817431302998,\n",
       "  1.1921190861186592,\n",
       "  1.3123466426952433],\n",
       " [1.0520779165399334,\n",
       "  -0.25272983976051405,\n",
       "  1.6482755117644954,\n",
       "  0.17033314626795787,\n",
       "  -0.5150062078048303,\n",
       "  -0.7959765026747624,\n",
       "  -0.6775180440312724,\n",
       "  -1.357253501867175,\n",
       "  1739750400.0,\n",
       "  -0.09092562994170618,\n",
       "  0.6127269660864596,\n",
       "  0.8679226780036869,\n",
       "  1.2449566942367112],\n",
       " [1.3151182728822672,\n",
       "  -1.5245448359213933,\n",
       "  0.0886214706808947,\n",
       "  0.5629545136018471,\n",
       "  1.0567783844736374,\n",
       "  -0.25114155483995176,\n",
       "  1.6477922864034822,\n",
       "  0.1707921452739191,\n",
       "  1739664000.0,\n",
       "  -0.5157197571514529,\n",
       "  -0.7944292799258014,\n",
       "  -0.6805866184294772,\n",
       "  -1.3610664164401984],\n",
       " [-0.6381105309164051,\n",
       "  1.1978213031657106,\n",
       "  0.952184927889971,\n",
       "  -0.8574448069778928,\n",
       "  0.3086081338891419,\n",
       "  -0.8689446262567835,\n",
       "  0.3121752557647931,\n",
       "  -0.47091686869634575,\n",
       "  1742342400.0,\n",
       "  -1.074022832623333,\n",
       "  -0.7441592835383428,\n",
       "  -1.6516245657351216,\n",
       "  -1.1324393313379346],\n",
       " [0.3089412790702979,\n",
       "  -1.3274489061233992,\n",
       "  -0.4974083179018263,\n",
       "  -0.11849998648870336,\n",
       "  -0.5243009954850884,\n",
       "  -0.20531901431682284,\n",
       "  1.3328668792778258,\n",
       "  1.3112365866988414,\n",
       "  1750464000.0,\n",
       "  0.06835753998348192,\n",
       "  1.4821790709756226,\n",
       "  -0.5185498561618044,\n",
       "  0.25214900626184167],\n",
       " [-1.3653537180625572,\n",
       "  1.6500150048727495,\n",
       "  -0.9658015781311776,\n",
       "  1.2891186573220341,\n",
       "  1.3868880986750576,\n",
       "  -0.8281601365514796,\n",
       "  -1.1956913013089046,\n",
       "  0.8254812975925909,\n",
       "  1754179200.0,\n",
       "  -0.7238492822120666,\n",
       "  1.602872298563033,\n",
       "  -0.8217915834522203,\n",
       "  1.3865396145123416],\n",
       " [1.0221548836669858,\n",
       "  0.9839572513929072,\n",
       "  0.8711637788569098,\n",
       "  -0.3302074425207639,\n",
       "  -0.07761285982377729,\n",
       "  1.179802635200935,\n",
       "  0.05492923359191248,\n",
       "  1.2900831060809217,\n",
       "  1788566400.0,\n",
       "  1.1677411633814145,\n",
       "  -0.9130284230424517,\n",
       "  -0.23699745449647874,\n",
       "  -1.6088261344880572],\n",
       " [1.5903416025309614,\n",
       "  -0.12893890839197,\n",
       "  1.7936788846169598,\n",
       "  -0.3007124158756655,\n",
       "  0.9321177091067382,\n",
       "  -0.4361320959429779,\n",
       "  1.5406871434596578,\n",
       "  -0.2637701737489942,\n",
       "  1741737600.0,\n",
       "  -1.6425273643282285,\n",
       "  0.40367682289492773,\n",
       "  -1.6836867962734199,\n",
       "  -0.532500838142539],\n",
       " [-0.03228779709077198,\n",
       "  -0.6564012951942143,\n",
       "  -1.2817825950017787,\n",
       "  -1.6926556752109188,\n",
       "  -1.213192741193349,\n",
       "  0.9747080859670703,\n",
       "  -0.7969853056652864,\n",
       "  -1.3975188234062672,\n",
       "  1736985600.0,\n",
       "  -0.14130106323958846,\n",
       "  -0.20205878928163098,\n",
       "  1.7344999369282383,\n",
       "  -0.6219609840947353],\n",
       " [0.6376976493240193,\n",
       "  -1.6946763399071918,\n",
       "  1.0975865507336624,\n",
       "  -1.5738755089438405,\n",
       "  -0.05442242327821648,\n",
       "  -1.1584076010604416,\n",
       "  0.7236697540905005,\n",
       "  0.26182532147524146,\n",
       "  1786060800.0,\n",
       "  -1.3918750473481811,\n",
       "  -1.5706960315478602,\n",
       "  1.150732809724628,\n",
       "  -0.3416479092340157],\n",
       " [-1.6369189885378255,\n",
       "  -1.4091263224014428,\n",
       "  1.4562955635046437,\n",
       "  0.07399269824747,\n",
       "  1.4074289269510356,\n",
       "  0.23894599612419024,\n",
       "  0.9938183029041936,\n",
       "  -0.8406127706584158,\n",
       "  1792972800.0,\n",
       "  1.1456196080494623,\n",
       "  1.4577486206381773,\n",
       "  1.021155877355001,\n",
       "  0.660874407891477],\n",
       " [-0.1558022017188646,\n",
       "  1.395683990743649,\n",
       "  1.1146486107296953,\n",
       "  0.5999288800891287,\n",
       "  0.9108598801905793,\n",
       "  1.6513648333036097,\n",
       "  -0.3506603167809232,\n",
       "  0.22283575641829495,\n",
       "  1751414400.0,\n",
       "  -0.23753355757691877,\n",
       "  0.27978756737429067,\n",
       "  1.0805245109531896,\n",
       "  0.41640057110400763],\n",
       " [-1.4376546679474644,\n",
       "  -0.8584615719922866,\n",
       "  -0.48951692975394273,\n",
       "  1.4739771723336474,\n",
       "  -0.35619126218114006,\n",
       "  -0.9328944467256571,\n",
       "  -0.8837625188244934,\n",
       "  0.5534931373503836,\n",
       "  1782000000.0,\n",
       "  -0.13623818718736086,\n",
       "  -0.270866510021646,\n",
       "  -0.06642262324523504,\n",
       "  -1.3898344951159562],\n",
       " [0.7327465995544472,\n",
       "  1.1578225555908863,\n",
       "  -0.9375463864186485,\n",
       "  1.4262985586487278,\n",
       "  0.42166566936708866,\n",
       "  -0.3256382341663582,\n",
       "  -1.2377225094939892,\n",
       "  -0.7347294405076937,\n",
       "  1766880000.0,\n",
       "  1.3683892356611214,\n",
       "  -0.0904932356977429,\n",
       "  -1.4262082962744167,\n",
       "  -1.7998124436855862],\n",
       " [1.293073113741819,\n",
       "  1.3688035231769484,\n",
       "  0.19447487248529835,\n",
       "  -0.9431432199461669,\n",
       "  1.1780609919017253,\n",
       "  -1.3194951108684914,\n",
       "  -1.4054268123084113,\n",
       "  -0.06958902177360415,\n",
       "  1792540800.0,\n",
       "  0.17537696579410253,\n",
       "  0.4163715942801027,\n",
       "  -0.7467869411252989,\n",
       "  -1.6144529252994837],\n",
       " [-1.568529471105178,\n",
       "  1.1893037448805557,\n",
       "  -0.4094994823458485,\n",
       "  -1.1926162926685842,\n",
       "  0.006545065187204197,\n",
       "  -0.22527118112343428,\n",
       "  0.7662406107789804,\n",
       "  1.6804698660908954,\n",
       "  1761177600.0,\n",
       "  1.370109928824858,\n",
       "  -1.3637823361339534,\n",
       "  -0.7658169510993893,\n",
       "  -1.163413713177473],\n",
       " [0.42804142760523134,\n",
       "  -0.8856083639502536,\n",
       "  -1.397316248296636,\n",
       "  0.6988989552616863,\n",
       "  0.6965464475848349,\n",
       "  0.9604600312397052,\n",
       "  -0.8463782573134826,\n",
       "  -0.8949613815520652,\n",
       "  1796083200.0,\n",
       "  -1.2994377534025072,\n",
       "  -0.31227066387199404,\n",
       "  -1.3425941929351484,\n",
       "  -1.2055990835712533],\n",
       " [1.6329717573533342,\n",
       "  1.5248843756121608,\n",
       "  -0.894183656517591,\n",
       "  -1.3263831688225418,\n",
       "  -0.15176863969354887,\n",
       "  1.3980640254631593,\n",
       "  1.1148294541425134,\n",
       "  0.6001475853410215,\n",
       "  1751328000.0,\n",
       "  0.9086398206893179,\n",
       "  1.6536449435126044,\n",
       "  -0.35338348964592753,\n",
       "  0.21875233436812852],\n",
       " [-0.5599439919711497,\n",
       "  -1.1124357805357663,\n",
       "  -1.459244702651777,\n",
       "  0.12351924316540522,\n",
       "  1.3132357917886204,\n",
       "  1.6256859192786413,\n",
       "  1.6381559042228402,\n",
       "  -1.3091591560469091,\n",
       "  1782950400.0,\n",
       "  -0.7082506066799237,\n",
       "  0.9292301108258068,\n",
       "  -0.04634630593375685,\n",
       "  0.6154337562231077],\n",
       " [1.583539487220318,\n",
       "  1.384373173131619,\n",
       "  1.752329233238774,\n",
       "  -0.4926515703380315,\n",
       "  0.14439542533406483,\n",
       "  0.5359515227756424,\n",
       "  -0.21526784920748962,\n",
       "  -0.055797224158206184,\n",
       "  1774310400.0,\n",
       "  -1.3477959794658292,\n",
       "  1.5066613892887035,\n",
       "  1.4054001835639214,\n",
       "  -0.7204222426893281],\n",
       " [-0.8613790328996793,\n",
       "  0.7158004966345735,\n",
       "  0.2135490145985438,\n",
       "  0.32744075424739244,\n",
       "  0.32205154747449555,\n",
       "  -1.4425644533099478,\n",
       "  0.31664252405978227,\n",
       "  0.7842574835118591,\n",
       "  1743206400.0,\n",
       "  -1.687920338141504,\n",
       "  -0.1975528915136882,\n",
       "  -1.5769669115585867,\n",
       "  1.696871825636914],\n",
       " [-0.7980062757906881,\n",
       "  -0.3791770172798386,\n",
       "  -0.5946322905504307,\n",
       "  -1.4936763233133266,\n",
       "  -0.6140250927303862,\n",
       "  1.4578324211556812,\n",
       "  0.21615322101166154,\n",
       "  -1.3772084857836453,\n",
       "  1791331200.0,\n",
       "  -1.1460055784836056,\n",
       "  -1.1542623550300912,\n",
       "  -0.3418849269488748,\n",
       "  -1.3649593034275351],\n",
       " [1.4164553465896026,\n",
       "  -0.009856420279751307,\n",
       "  0.19841755388229745,\n",
       "  -0.6249795364854325,\n",
       "  -0.13641405073128468,\n",
       "  -1.482855488357794,\n",
       "  1.7697176598861883,\n",
       "  -0.02621350696973598,\n",
       "  1766620800.0,\n",
       "  1.2284354800293222,\n",
       "  1.2223759535904661,\n",
       "  0.29957095988772797,\n",
       "  -0.9822069100591279],\n",
       " [-1.142771865169347,\n",
       "  0.2137233671404603,\n",
       "  0.23517777297825962,\n",
       "  -0.695557400478932,\n",
       "  -0.17953891401004787,\n",
       "  0.6894278505363168,\n",
       "  0.6910672874847074,\n",
       "  -0.7570885112645201,\n",
       "  1778630400.0,\n",
       "  0.09467981833323864,\n",
       "  -1.3226493081073447,\n",
       "  -0.06703420865670254,\n",
       "  -0.3989409001414916],\n",
       " [-1.2395936743005682,\n",
       "  -0.18591993184921826,\n",
       "  -1.0315304170540458,\n",
       "  0.1618546949729313,\n",
       "  -1.1206347449244891,\n",
       "  0.01863897266409195,\n",
       "  1.416093444666244,\n",
       "  -0.8390466363659322,\n",
       "  1793923200.0,\n",
       "  -0.5864620531845908,\n",
       "  1.6102064661139341,\n",
       "  1.7132692205766191,\n",
       "  0.9878082340595662],\n",
       " [0.7198443900395873,\n",
       "  0.032101019347901674,\n",
       "  0.05877076067603183,\n",
       "  -0.2943692106870709,\n",
       "  0.856274159652579,\n",
       "  -0.31632747479333034,\n",
       "  1.550190965732462,\n",
       "  1.3051251507055008,\n",
       "  1742860800.0,\n",
       "  0.3079242751431634,\n",
       "  -0.9615956550469399,\n",
       "  -0.293400136968163,\n",
       "  0.0006839770176833274],\n",
       " [-1.4681736897670326,\n",
       "  0.6790121929043864,\n",
       "  1.4166183697366583,\n",
       "  -0.33053168672280797,\n",
       "  -1.2978257997687248,\n",
       "  -1.0316861198243312,\n",
       "  1.1780710328318522,\n",
       "  -0.7010097672324418,\n",
       "  1738022400.0,\n",
       "  -1.3883910033395077,\n",
       "  -1.2172813958997777,\n",
       "  -1.0121996971069827,\n",
       "  1.0478746838395336],\n",
       " [-1.352036697560816,\n",
       "  1.6727179955566518,\n",
       "  -0.19459604190432697,\n",
       "  1.0833266649451063,\n",
       "  0.07465396407830849,\n",
       "  -0.11938316980478478,\n",
       "  -0.35403119045156284,\n",
       "  -0.8870068074786258,\n",
       "  1737331200.0,\n",
       "  -1.081744169588653,\n",
       "  -0.5862154768977776,\n",
       "  -1.3080683711168848,\n",
       "  -0.6547537591180397],\n",
       " [1.0968211455343937,\n",
       "  0.9999898520693719,\n",
       "  0.3130747300104821,\n",
       "  -0.968208821395864,\n",
       "  -1.3905304827383747,\n",
       "  -0.825695026765198,\n",
       "  0.041232897381860936,\n",
       "  0.02203832873209964,\n",
       "  1768867200.0,\n",
       "  0.37370490005892093,\n",
       "  0.9840610925179064,\n",
       "  -0.6032521301901357,\n",
       "  1.6062595833770639],\n",
       " [0.0024241417741621076,\n",
       "  -0.22687188588020948,\n",
       "  0.7656254275740202,\n",
       "  1.6808557757389664,\n",
       "  1.3728180739294908,\n",
       "  -1.3651591099188953,\n",
       "  -0.7626584060224542,\n",
       "  -1.1595669551435572,\n",
       "  1761264000.0,\n",
       "  -1.576365240139692,\n",
       "  1.6378829059842361,\n",
       "  1.7012635588635365,\n",
       "  1.700070920776137],\n",
       " [-1.0054651465726612,\n",
       "  0.03605700198474241,\n",
       "  1.7301443756016874,\n",
       "  -0.14524185503860143,\n",
       "  -0.417755412536478,\n",
       "  -0.7597560768027465,\n",
       "  0.10745644980836802,\n",
       "  0.29850913204561785,\n",
       "  1759795200.0,\n",
       "  0.23764859504769853,\n",
       "  -0.5928595176562548,\n",
       "  -1.6849981892159438,\n",
       "  -1.763543250498217],\n",
       " [0.3587327264921748,\n",
       "  -1.098637596034281,\n",
       "  -0.5366256832725557,\n",
       "  -1.6957315828346038,\n",
       "  -0.027142740776316954,\n",
       "  -1.2089610632471228,\n",
       "  -0.4168746881099803,\n",
       "  -1.5963244636100242,\n",
       "  1792281600.0,\n",
       "  -0.203984252297056,\n",
       "  0.890591021866619,\n",
       "  0.5914657370542906,\n",
       "  -0.5798101885596998],\n",
       " [0.6554987106220688,\n",
       "  0.6317109181887466,\n",
       "  -1.198559463592008,\n",
       "  0.8127602764609084,\n",
       "  0.46983745738574706,\n",
       "  -1.2188754163487683,\n",
       "  -0.46603697888253065,\n",
       "  0.5307671086736198,\n",
       "  1763164800.0,\n",
       "  -1.0734871399365558,\n",
       "  -0.25922052734322626,\n",
       "  0.09506751651468992,\n",
       "  0.8683911205695243],\n",
       " [-0.7448085143128181,\n",
       "  -0.7125348118187439,\n",
       "  1.6398319589058754,\n",
       "  -0.03687895165891552,\n",
       "  0.5428468343791977,\n",
       "  -0.8529216933415369,\n",
       "  -0.29229212689545886,\n",
       "  -0.2147259243304673,\n",
       "  1792800000.0,\n",
       "  -1.633234775518674,\n",
       "  -1.4067295498357455,\n",
       "  1.4552372863269236,\n",
       "  0.0704475568621396],\n",
       " [-0.3757273648285257,\n",
       "  -1.6565910660086889,\n",
       "  -0.6414505686669476,\n",
       "  -0.34185913534157103,\n",
       "  1.6401141233295418,\n",
       "  1.0563152470529162,\n",
       "  -1.5702762241265666,\n",
       "  -0.004030477533965122,\n",
       "  1747872000.0,\n",
       "  -0.31367543973127165,\n",
       "  -0.10510025474244261,\n",
       "  1.064566710394493,\n",
       "  -1.678533767854225],\n",
       " [-0.2297761399817333,\n",
       "  -1.1396458182429607,\n",
       "  -1.6095684468078275,\n",
       "  1.2232448683221253,\n",
       "  -0.9929363553887915,\n",
       "  -0.08967971994158021,\n",
       "  -1.5214567774830872,\n",
       "  -0.4151603069176915,\n",
       "  1777766400.0,\n",
       "  1.6393289963193929,\n",
       "  1.4677374264151961,\n",
       "  0.5663274029470644,\n",
       "  -0.9278808343719782],\n",
       " [-1.1544496318570654,\n",
       "  0.5424330798425866,\n",
       "  -0.7020438738993264,\n",
       "  -0.24007355185101112,\n",
       "  -1.3476456627455065,\n",
       "  0.9743115354000671,\n",
       "  -1.2212449767838396,\n",
       "  1.6128955623654353,\n",
       "  1777593600.0,\n",
       "  -0.2268025511112652,\n",
       "  -1.137038873349636,\n",
       "  -1.6100471977073745,\n",
       "  1.218860255239687],\n",
       " [0.9390361500299185,\n",
       "  0.02524644497847096,\n",
       "  0.0776715394830647,\n",
       "  -0.2700004416674776,\n",
       "  1.5720230593816995,\n",
       "  -0.0408245321741335,\n",
       "  -0.9044082617560774,\n",
       "  -1.3107514952171957,\n",
       "  1738886400.0,\n",
       "  -1.2011712631580647,\n",
       "  -1.4661787039194647,\n",
       "  0.9433163392762021,\n",
       "  -1.4643488254191965],\n",
       " [1.2097401249614717,\n",
       "  0.14012238140623995,\n",
       "  1.756735702163294,\n",
       "  1.047667137914142,\n",
       "  0.23515504345941915,\n",
       "  0.950196719970448,\n",
       "  1.1860146896312025,\n",
       "  1.1980647787706613,\n",
       "  1790812800.0,\n",
       "  -0.5734779256214906,\n",
       "  1.2708359260517015,\n",
       "  0.9999575405601149,\n",
       "  0.7041834793668805],\n",
       " [0.0021595584155268324,\n",
       "  0.32952937478181393,\n",
       "  -1.5783444561631488,\n",
       "  -1.562618647064446,\n",
       "  1.5828034287653687,\n",
       "  -0.8483603477591157,\n",
       "  0.6502041842044815,\n",
       "  -0.2622765441334521,\n",
       "  1758240000.0,\n",
       "  -0.9479474055531933,\n",
       "  -1.5079275053420254,\n",
       "  -1.3514954067364238,\n",
       "  1.2189742697045147],\n",
       " [-1.0547647306151138,\n",
       "  0.258166267405393,\n",
       "  -1.4222579829002113,\n",
       "  0.2004505365159681,\n",
       "  1.5561918579959628,\n",
       "  -0.19802455156952545,\n",
       "  0.5178025255061832,\n",
       "  -0.43625628874025923,\n",
       "  1736812800.0,\n",
       "  -0.029413942220789892,\n",
       "  -0.6534174598592614,\n",
       "  -1.2823233057645471,\n",
       "  -1.6949103676009138],\n",
       " [1.204944692625745,\n",
       "  1.5272253170058587,\n",
       "  1.652011192467846,\n",
       "  0.6595951177786681,\n",
       "  -1.4648647263886763,\n",
       "  0.6810480029265844,\n",
       "  1.4164234287068085,\n",
       "  -0.3297925296949557,\n",
       "  1737936000.0,\n",
       "  -1.2977122548499933,\n",
       "  -1.0302094833152537,\n",
       "  1.1769633217044355,\n",
       "  -0.7049350291530065],\n",
       " [0.3710347279396195,\n",
       "  0.9798011556755621,\n",
       "  -0.6025830334347961,\n",
       "  1.6109273793012706,\n",
       "  1.081333141904276,\n",
       "  0.33975776791973405,\n",
       "  -1.1891600288167874,\n",
       "  -0.5944706999409232,\n",
       "  1769040000.0,\n",
       "  1.5537597985407363,\n",
       "  -0.5402931039168661,\n",
       "  -0.959988284238691,\n",
       "  -1.2994959977197094],\n",
       " [1.2723169181447345,\n",
       "  -0.939664494887307,\n",
       "  -0.5954884544479222,\n",
       "  -0.6661859737925798,\n",
       "  1.656813392015334,\n",
       "  1.120146270785407,\n",
       "  -0.9071915114922087,\n",
       "  -1.5289369445519079,\n",
       "  1755129600.0,\n",
       "  0.4498403415123634,\n",
       "  -1.7507640031266858,\n",
       "  0.22197923345595613,\n",
       "  0.3636909290465809],\n",
       " [-1.4319168848500898,\n",
       "  1.188731820190021,\n",
       "  -1.4317181028342811,\n",
       "  0.07493650634423732,\n",
       "  -0.5561335684375366,\n",
       "  -1.1112604210549009,\n",
       "  -1.4558607932517014,\n",
       "  0.12400442746054295,\n",
       "  1782864000.0,\n",
       "  1.3105905988180186,\n",
       "  1.627958339610544,\n",
       "  1.6375343802243545,\n",
       "  -1.3129803042561556],\n",
       " [-1.1246202235760532,\n",
       "  -0.4698092921361749,\n",
       "  0.3081915426170742,\n",
       "  -0.10618976846154768,\n",
       "  -1.256253454523868,\n",
       "  0.6047731702259183,\n",
       "  -1.5805488629905753,\n",
       "  -0.9237780750666644,\n",
       "  1794960000.0,\n",
       "  -0.23776277419605782,\n",
       "  -0.8117746103403585,\n",
       "  -0.34313419216002244,\n",
       "  0.441217529477191],\n",
       " [1.644877467640702,\n",
       "  0.1781487574497884,\n",
       "  -0.16314914692968854,\n",
       "  1.5519232957692257,\n",
       "  0.7457441599732076,\n",
       "  0.36003337460799556,\n",
       "  -1.6639674644027573,\n",
       "  -0.15867652050106423,\n",
       "  1764892800.0,\n",
       "  1.0268982295951985,\n",
       "  0.7277667832019118,\n",
       "  1.284152208243532,\n",
       "  1.5978342510594634],\n",
       " [0.3177565198412911,\n",
       "  -1.4435807605149409,\n",
       "  0.3154671440979525,\n",
       "  0.7841418175008007,\n",
       "  -1.6884465965695528,\n",
       "  -0.199278802970724,\n",
       "  -1.572952101931127,\n",
       "  1.7012083415146442,\n",
       "  1743292800.0,\n",
       "  -1.2376350387367065,\n",
       "  1.2893228602727784,\n",
       "  -1.0456690667581794,\n",
       "  1.6555605367331092],\n",
       " [0.7412153283580601,\n",
       "  0.35815167712971946,\n",
       "  -1.6676106735767986,\n",
       "  -0.159319910468823,\n",
       "  1.0292433681120818,\n",
       "  0.7257638559666659,\n",
       "  1.285146768846104,\n",
       "  1.6021538090396956,\n",
       "  1764979200.0,\n",
       "  -0.5396666628383829,\n",
       "  -1.6330333788483633,\n",
       "  -1.5692493742569278,\n",
       "  0.5587201403953787],\n",
       " [-0.4125818658884019,\n",
       "  0.90825025848115,\n",
       "  1.1912635472366153,\n",
       "  -1.75630510403375,\n",
       "  -1.0108236799111068,\n",
       "  -0.17504011334376518,\n",
       "  -1.3715874413609395,\n",
       "  1.6078903863244587,\n",
       "  1757376000.0,\n",
       "  -0.5290162674217951,\n",
       "  1.3733433659775993,\n",
       "  0.15384167113733432,\n",
       "  -0.9218214836218185],\n",
       " [-0.05850970333484454,\n",
       "  -1.1595603261464589,\n",
       "  0.7230015278309577,\n",
       "  0.26141727024264666,\n",
       "  -1.392088185940655,\n",
       "  -1.5720108609476091,\n",
       "  1.1518682102543076,\n",
       "  -0.33766044278382523,\n",
       "  1786147200.0,\n",
       "  1.1955358839422432,\n",
       "  -0.8069893426576747,\n",
       "  -1.0077899025116295,\n",
       "  0.6881558768457052],\n",
       " [0.4078781977193365,\n",
       "  -1.465732008104498,\n",
       "  1.4138814094822576,\n",
       "  0.24722706278212764,\n",
       "  0.5478502568743018,\n",
       "  1.146376300853965,\n",
       "  -0.886632931198644,\n",
       "  -0.6869961254184849,\n",
       "  1789430400.0,\n",
       "  0.7957203546536501,\n",
       "  -1.53500776698762,\n",
       "  -0.24792405483258823,\n",
       "  -0.9422801020703635],\n",
       " [0.7978453563119328,\n",
       "  -1.6548276302691955,\n",
       "  -0.3787544387045565,\n",
       "  -0.9139744433554625,\n",
       "  -1.431490240681581,\n",
       "  -0.7951440304825061,\n",
       "  0.27369475786518266,\n",
       "  -1.3515457913076407,\n",
       "  1753574400.0,\n",
       "  -0.22894879168481322,\n",
       "  -0.1965857110165021,\n",
       "  0.06463982066322128,\n",
       "  1.391631117754853],\n",
       " [-0.3976063407392764,\n",
       "  0.26032299502201184,\n",
       "  -1.0322106891959848,\n",
       "  -1.4552427143344258,\n",
       "  0.2779508352999105,\n",
       "  -1.4102765090657559,\n",
       "  -1.0161971418814115,\n",
       "  0.7307654419616133,\n",
       "  1752969600.0,\n",
       "  -0.66993552035329,\n",
       "  1.266705822369395,\n",
       "  0.12916765393725294,\n",
       "  -0.07658751105712445],\n",
       " [0.538429966487868,\n",
       "  -0.8542210759509744,\n",
       "  -0.29422623610166737,\n",
       "  -0.21540068299744963,\n",
       "  -1.6337031943697755,\n",
       "  -1.408093466382102,\n",
       "  1.4560512464306636,\n",
       "  0.074505585144071,\n",
       "  1792886400.0,\n",
       "  1.4046842134743958,\n",
       "  0.24080313956558838,\n",
       "  0.9925158857315848,\n",
       "  -0.8445141328808715],\n",
       " [0.6950048851563292,\n",
       "  -0.37990502913745927,\n",
       "  0.6320655286442737,\n",
       "  1.4281052517276773,\n",
       "  0.8634833999157548,\n",
       "  -1.401286222147078,\n",
       "  0.13125343488366387,\n",
       "  1.159028966352214,\n",
       "  1764288000.0,\n",
       "  1.312535025447907,\n",
       "  0.7885719421042442,\n",
       "  -0.11636288692585985,\n",
       "  1.6397365206124603],\n",
       " [-0.3834273382918019,\n",
       "  0.15540360220870997,\n",
       "  -1.2937767811265777,\n",
       "  0.14844317436501184,\n",
       "  -1.3075031151040077,\n",
       "  1.3642682003951396,\n",
       "  -0.4031800036183565,\n",
       "  -0.888960246795588,\n",
       "  1770422400.0,\n",
       "  -1.1854043150438593,\n",
       "  -1.070166617776063,\n",
       "  0.41307311109602424,\n",
       "  -0.048753334288905235],\n",
       " [1.1491102763589083,\n",
       "  1.4198504743090625,\n",
       "  -0.36518046810205557,\n",
       "  0.3256107525526324,\n",
       "  1.3838193895679107,\n",
       "  1.6545510207203167,\n",
       "  0.8268218939258515,\n",
       "  0.5206130405225761,\n",
       "  1744070400.0,\n",
       "  0.1823209533403438,\n",
       "  0.2639482883698257,\n",
       "  -0.641354416812175,\n",
       "  0.5692973070844773],\n",
       " [1.4850167098234424,\n",
       "  0.3611540220395738,\n",
       "  0.7725080528033783,\n",
       "  -0.3876463268831907,\n",
       "  -0.7595967207625921,\n",
       "  1.6610410580100006,\n",
       "  0.8091831454188279,\n",
       "  -1.7042086280422581,\n",
       "  1785456000.0,\n",
       "  -1.3993025048379182,\n",
       "  -1.132906065834488,\n",
       "  -0.9959724419542344,\n",
       "  1.5708359897170168],\n",
       " [-1.580020718844837,\n",
       "  1.6331134400243845,\n",
       "  1.7023683500567743,\n",
       "  1.7048072913187942,\n",
       "  -1.565638961031655,\n",
       "  0.2826373529006883,\n",
       "  1.3621931731146872,\n",
       "  -1.0525844592245013,\n",
       "  1761436800.0,\n",
       "  1.578280045082461,\n",
       "  -0.3818421408571243,\n",
       "  -0.8863166940867963,\n",
       "  -1.3354428044003384],\n",
       " [-1.1210772427995623,\n",
       "  0.6344406792406913,\n",
       "  -0.26627076968463775,\n",
       "  0.6045484171678202,\n",
       "  -0.07239300503538902,\n",
       "  0.6587094414827224,\n",
       "  1.4592521096057927,\n",
       "  0.9901985471592397,\n",
       "  1758931200.0,\n",
       "  0.09961365025115584,\n",
       "  1.6092120850197302,\n",
       "  -0.8623900095071351,\n",
       "  0.6737771587584251],\n",
       " [0.46331878235862145,\n",
       "  1.41247976454028,\n",
       "  -0.29855176941940215,\n",
       "  0.14465586370722072,\n",
       "  -1.0581908335206365,\n",
       "  1.2844944088740107,\n",
       "  0.7637917018309184,\n",
       "  -0.35511180586824403,\n",
       "  1771027200.0,\n",
       "  -1.607502462875099,\n",
       "  0.6813936303397866,\n",
       "  -0.5036464882850541,\n",
       "  0.615194380298433],\n",
       " [-1.6691550239518445,\n",
       "  -1.5646881912882766,\n",
       "  -0.6080261160021287,\n",
       "  1.463349106342015,\n",
       "  -1.13945310837728,\n",
       "  0.9792380801471579,\n",
       "  1.5136609725796717,\n",
       "  -0.26776871847901296,\n",
       "  1751932800.0,\n",
       "  0.6885788527256776,\n",
       "  -1.6479284991173944,\n",
       "  -0.492373897314763,\n",
       "  -0.352231389573791],\n",
       " [-1.6355068587113426,\n",
       "  -0.8594929057860818,\n",
       "  1.2163516284466427,\n",
       "  -0.2442175161326135,\n",
       "  -0.005273949938827972,\n",
       "  0.2792205329736418,\n",
       "  -0.4204074554249531,\n",
       "  -1.384203493627596,\n",
       "  1793577600.0,\n",
       "  1.0348792411114902,\n",
       "  -1.7925864429792018,\n",
       "  0.6043501794235071,\n",
       "  -0.3755956515483013],\n",
       " [-1.3762509033271615,\n",
       "  0.541144384312909,\n",
       "  1.1133838053706333,\n",
       "  0.8889745887508183,\n",
       "  -1.1211215742901415,\n",
       "  -0.4683252726674025,\n",
       "  0.30937597665722144,\n",
       "  -0.10557609676208633,\n",
       "  1794873600.0,\n",
       "  -1.256183833197114,\n",
       "  0.6067398652629592,\n",
       "  -1.5845717003704745,\n",
       "  -0.927665199589216],\n",
       " [-0.345219702198389,\n",
       "  0.5216506792908508,\n",
       "  0.34446202272865434,\n",
       "  0.6796727008436712,\n",
       "  1.677065405821115,\n",
       "  -1.1940703089726712,\n",
       "  -1.1344942356271606,\n",
       "  0.7889580117300545,\n",
       "  1749254400.0,\n",
       "  -1.0069726483772472,\n",
       "  0.6885072828738539,\n",
       "  -0.9381538506867356,\n",
       "  0.6746917886354878],\n",
       " [-1.0774244941594076,\n",
       "  -0.7470724029681548,\n",
       "  -1.6511536755015177,\n",
       "  -1.1297734814293465,\n",
       "  1.5896280292890523,\n",
       "  -1.337608734731214,\n",
       "  -0.9297345485979127,\n",
       "  1.5238043625167061,\n",
       "  1742515200.0,\n",
       "  -0.24285360545642573,\n",
       "  1.1342365307681876,\n",
       "  -0.5998275785843935,\n",
       "  1.647195726453994],\n",
       " [0.327973751379414,\n",
       "  -1.6977304533305144,\n",
       "  0.7799311293817103,\n",
       "  0.4282113718212796,\n",
       "  -1.2538844393666397,\n",
       "  0.5369638666639798,\n",
       "  1.6765081013182819,\n",
       "  -0.15290828997138525,\n",
       "  1764720000.0,\n",
       "  1.6469043337776823,\n",
       "  0.1817834722523808,\n",
       "  -0.16390130786657456,\n",
       "  1.5472985994009114],\n",
       " [-1.646216272588215,\n",
       "  0.39986918464315546,\n",
       "  -1.6832219677627103,\n",
       "  -0.5293964425911218,\n",
       "  -0.12165687825431101,\n",
       "  -0.14067845412604754,\n",
       "  -0.23692769376670164,\n",
       "  0.9870888694390398,\n",
       "  1741910400.0,\n",
       "  -0.8313297434488323,\n",
       "  0.5162449150417868,\n",
       "  -0.9378544173351356,\n",
       "  0.9690295584802493],\n",
       " [-1.0426295052589416,\n",
       "  -0.4994382292075234,\n",
       "  0.4190804529326737,\n",
       "  -1.491322569523317,\n",
       "  -1.2444320151516421,\n",
       "  0.4843887796175141,\n",
       "  -0.11107465200167617,\n",
       "  0.19611938969666493,\n",
       "  1787529600.0,\n",
       "  -0.6827669582823237,\n",
       "  0.5448452871550857,\n",
       "  -1.3801869011341197,\n",
       "  -0.4480197918231728],\n",
       " [0.49575823038755634,\n",
       "  -1.438666411198179,\n",
       "  -0.08771076004361984,\n",
       "  -1.0902133856143985,\n",
       "  -1.539477714472547,\n",
       "  -0.8213476753143515,\n",
       "  -0.31983688692744167,\n",
       "  -1.3961142735646734,\n",
       "  1752278400.0,\n",
       "  -0.07899530943505925,\n",
       "  1.166157551066808,\n",
       "  0.447829526653485,\n",
       "  1.428845142189258],\n",
       " [-0.23959109920162525,\n",
       "  -0.6617928700780565,\n",
       "  0.7218870318450612,\n",
       "  1.6096462780781726,\n",
       "  -0.0020220982835151198,\n",
       "  -0.7234102748523561,\n",
       "  1.3254200019346518,\n",
       "  -0.03542015249517439,\n",
       "  1756425600.0,\n",
       "  0.17913102194594727,\n",
       "  0.34629346601945904,\n",
       "  -0.26869850580287946,\n",
       "  -1.3868569266548607],\n",
       " [1.3692338375837492,\n",
       "  -0.320656649039691,\n",
       "  1.7877670278845477,\n",
       "  -0.8974505536245386,\n",
       "  0.8863226090795386,\n",
       "  1.3764592588632294,\n",
       "  0.8653621376946437,\n",
       "  0.014810075491068657,\n",
       "  1743638400.0,\n",
       "  0.22602679324887484,\n",
       "  -0.8012584743120357,\n",
       "  -0.20009981252311332,\n",
       "  1.2647284329918773],\n",
       " [0.3331260830642312,\n",
       "  -1.671437192391114,\n",
       "  1.0282134207663107,\n",
       "  -0.8438869945398471,\n",
       "  1.619446175428893,\n",
       "  -0.30316911297608407,\n",
       "  0.053523359656945456,\n",
       "  -0.7361924454991867,\n",
       "  1786838400.0,\n",
       "  1.6104024713412206,\n",
       "  -0.2503760728158778,\n",
       "  -0.5132047732721126,\n",
       "  -0.26340022516980455],\n",
       " [0.4070221048843134,\n",
       "  -1.3154521160191153,\n",
       "  -0.016996461606036448,\n",
       "  -0.8574328945057071,\n",
       "  1.2719201941494462,\n",
       "  -0.3755479278357196,\n",
       "  -1.4042344893088243,\n",
       "  -1.0729747956687539,\n",
       "  1746144000.0,\n",
       "  0.9486343373093986,\n",
       "  0.15996845996979905,\n",
       "  -0.6971593337412602,\n",
       "  -0.35889391919150376],\n",
       " [1.6268594038049564,\n",
       "  -1.1996921748701743,\n",
       "  -1.6698625333886938,\n",
       "  1.177070164910758,\n",
       "  1.3426838796660054,\n",
       "  -0.9204897124379713,\n",
       "  1.2681250890043825,\n",
       "  -0.19692292454167976,\n",
       "  1746835200.0,\n",
       "  -0.02656880873782516,\n",
       "  1.6714593587396331,\n",
       "  0.9905469799576537,\n",
       "  -0.6387257630543896],\n",
       " [-1.3656137055946989,\n",
       "  -0.905820459661218,\n",
       "  1.7808849429127063,\n",
       "  -1.1204266534893168,\n",
       "  1.3124991423879973,\n",
       "  0.05594620138129055,\n",
       "  1.3661262057386117,\n",
       "  0.39711250925015906,\n",
       "  1785283200.0,\n",
       "  1.4871243075755876,\n",
       "  0.36493146569205853,\n",
       "  0.77157902885731,\n",
       "  -0.3908542638620657],\n",
       " [0.17636253801745197,\n",
       "  0.342530547124836,\n",
       "  -0.2679661579470955,\n",
       "  -1.3843770520239898,\n",
       "  -0.4102708233111803,\n",
       "  -1.109925439285291,\n",
       "  0.6263828560353817,\n",
       "  0.42289436263876107,\n",
       "  1756598400.0,\n",
       "  -1.5337154924973695,\n",
       "  1.6104170217741596,\n",
       "  1.727717970973102,\n",
       "  -0.17054709630868128],\n",
       " [1.5668129350357434,\n",
       "  0.8755500673418255,\n",
       "  -0.24783425110167698,\n",
       "  -0.8164410984336151,\n",
       "  0.4023902881919224,\n",
       "  0.7888844770205561,\n",
       "  -1.266783254235608,\n",
       "  -1.3656720587967233,\n",
       "  1736035200.0,\n",
       "  -0.26625129613480786,\n",
       "  -0.7927675466567623,\n",
       "  -0.12634689143661923,\n",
       "  -0.08370168302216274],\n",
       " [0.1661433084726176,\n",
       "  0.8923995620509578,\n",
       "  -0.39633301379772246,\n",
       "  -1.784704379942067,\n",
       "  -0.48131939031329435,\n",
       "  -0.22478715895752924,\n",
       "  -0.7048797069662515,\n",
       "  0.6196131728852314,\n",
       "  1795564800.0,\n",
       "  1.0041272372288033,\n",
       "  -0.8856476313091426,\n",
       "  -0.6518405512578491,\n",
       "  0.4317536271462731],\n",
       " [0.4377803799160767,\n",
       "  -0.5348664997592243,\n",
       "  -0.11194809482351159,\n",
       "  0.4366670768925422,\n",
       "  -1.2597282533583327,\n",
       "  -1.621239354375752,\n",
       "  -1.052657673942657,\n",
       "  0.0028948345507052225,\n",
       "  1781827200.0,\n",
       "  -1.434071085819006,\n",
       "  -0.8556353268282009,\n",
       "  -0.4902073988787133,\n",
       "  1.4694094117416818],\n",
       " [-0.7091053636551516,\n",
       "  -0.36556235970934825,\n",
       "  1.760758896905283,\n",
       "  1.4737206721238612,\n",
       "  -1.6322902848651522,\n",
       "  -0.8581960552897187,\n",
       "  1.2164059081533596,\n",
       "  -0.24352663881158215,\n",
       "  1793491200.0,\n",
       "  -0.006526060956204454,\n",
       "  0.28108973713684515,\n",
       "  -0.42320433243281697,\n",
       "  -1.3880117944269088],\n",
       " [0.5541195253065734,\n",
       "  -0.3568757616399214,\n",
       "  1.6878240530120587,\n",
       "  1.0247597727493336,\n",
       "  -0.6071290210589364,\n",
       "  -0.9322429743508822,\n",
       "  -0.4036515227020128,\n",
       "  0.3869967819667822,\n",
       "  1788393600.0,\n",
       "  1.0244962322366176,\n",
       "  0.9882204296434324,\n",
       "  0.8702161064693099,\n",
       "  -0.333457335755186],\n",
       " [1.2374781709291736,\n",
       "  0.9665728962983126,\n",
       "  0.4678527653186617,\n",
       "  -0.7227259567929062,\n",
       "  0.32232055434343176,\n",
       "  -0.3086098384130216,\n",
       "  0.8265156643560516,\n",
       "  -0.4302115593806694,\n",
       "  1760054400.0,\n",
       "  1.3896098514631752,\n",
       "  0.5940197859139511,\n",
       "  0.09444541107672447,\n",
       "  -0.21863077591641586],\n",
       " [1.4264828904345592,\n",
       "  0.8404647252682306,\n",
       "  0.860144973703112,\n",
       "  0.09306262529845187,\n",
       "  0.4113664186554226,\n",
       "  -1.3143742673330683,\n",
       "  -0.01540734931820272,\n",
       "  -0.8563990160472783,\n",
       "  1746057600.0,\n",
       "  1.2693186535020973,\n",
       "  -0.37387480240787624,\n",
       "  -1.408071009371072,\n",
       "  -1.0768363780719115],\n",
       " [0.8370861181390983,\n",
       "  -0.9367342672216252,\n",
       "  -0.01570189501819992,\n",
       "  1.051801040614108,\n",
       "  -0.7662520620936021,\n",
       "  0.3345932883355105,\n",
       "  -0.4060638319473712,\n",
       "  0.14878069467180347,\n",
       "  1755734400.0,\n",
       "  0.8681625331147396,\n",
       "  -0.6715022298105204,\n",
       "  -1.368363579554401,\n",
       "  -0.8867677788841453],\n",
       " [1.0864594279761892,\n",
       "  -0.39417869131282474,\n",
       "  0.6442335545480669,\n",
       "  -1.152165451950394,\n",
       "  0.5684089124810844,\n",
       "  0.6630885390757685,\n",
       "  -0.7928527980000245,\n",
       "  -0.35649735290818846,\n",
       "  1772323200.0,\n",
       "  -0.11406754846327746,\n",
       "  1.332568975776991,\n",
       "  0.6180007984094941,\n",
       "  0.8643181203858239],\n",
       " [-0.7114894060857023,\n",
       "  1.039628375640879,\n",
       "  1.019155346148961,\n",
       "  -1.270166946095359,\n",
       "  0.4091856420817763,\n",
       "  1.5080874504457167,\n",
       "  -0.3915916290988862,\n",
       "  0.983366591548967,\n",
       "  1763596800.0,\n",
       "  -0.5242822665456401,\n",
       "  -0.04497127277918866,\n",
       "  -0.9809924694446877,\n",
       "  -1.4986540719963608],\n",
       " [-0.1399977868686962,\n",
       "  1.567508577107186,\n",
       "  -1.1603826876508796,\n",
       "  -0.43013194128074334,\n",
       "  -1.0019007082869418,\n",
       "  0.03778399413989564,\n",
       "  1.7295592690275683,\n",
       "  -0.14460633961084154,\n",
       "  1759708800.0,\n",
       "  -0.4185717129842398,\n",
       "  -0.7581980073870258,\n",
       "  0.10521738430988019,\n",
       "  0.2944127548957186],\n",
       " [-0.36011201878637783,\n",
       "  -0.9341554360552212,\n",
       "  -0.8864335969038588,\n",
       "  0.553248321395317,\n",
       "  -0.13512326950120995,\n",
       "  -0.27257047335670914,\n",
       "  -0.0640023714543408,\n",
       "  -1.3860265064120434,\n",
       "  1782086400.0,\n",
       "  -1.4086792219889892,\n",
       "  -1.291064640024562,\n",
       "  1.1988561411005252,\n",
       "  -0.47320536828213366],\n",
       " [1.481583866639627,\n",
       "  -0.743053179216089,\n",
       "  1.279960545764621,\n",
       "  -1.2135900142773648,\n",
       "  -0.46678544345169914,\n",
       "  0.425357264526243,\n",
       "  0.4715519039940234,\n",
       "  1.3992923137686322,\n",
       "  1748476800.0,\n",
       "  0.061637922059896384,\n",
       "  0.9138374844854777,\n",
       "  -0.3527825779085868,\n",
       "  0.2501069129523592],\n",
       " [-1.393880465576706,\n",
       "  -0.8270074803392534,\n",
       "  0.03971435853160832,\n",
       "  0.021496077926642772,\n",
       "  0.37535917202834135,\n",
       "  0.9819814376722078,\n",
       "  -0.6002651914746532,\n",
       "  1.610580584000883,\n",
       "  1768953600.0,\n",
       "  1.0789329675226424,\n",
       "  0.34164510072715426,\n",
       "  -1.1927692724764514,\n",
       "  -0.5984142010933282],\n",
       " [-0.45330017218984053,\n",
       "  -0.10967922063678871,\n",
       "  0.38008546532399967,\n",
       "  1.5371836632114146,\n",
       "  0.6090185806017165,\n",
       "  0.3192704054548141,\n",
       "  -0.3771538101967243,\n",
       "  -1.7740044884762554,\n",
       "  1782518400.0,\n",
       "  0.19194961064694965,\n",
       "  -1.6857509020117385,\n",
       "  -0.5945847453994648,\n",
       "  0.9512715327745093],\n",
       " [-0.8283580466015288,\n",
       "  -1.6934615996674887,\n",
       "  -0.6155169006921228,\n",
       "  -1.6364562882993248,\n",
       "  0.22439470864554992,\n",
       "  -0.4790911026086109,\n",
       "  0.25294768549597946,\n",
       "  -0.4306125949122579,\n",
       "  1790380800.0,\n",
       "  0.8886091807741306,\n",
       "  0.6785616086477891,\n",
       "  0.049520705031599346,\n",
       "  1.5966962083118568],\n",
       " [-0.10181924948037921,\n",
       "  0.940725129893999,\n",
       "  0.4336153413232341,\n",
       "  0.7762257522003905,\n",
       "  -1.203574058071336,\n",
       "  1.4506709390392019,\n",
       "  -0.27105916690053833,\n",
       "  -0.7332980672346596,\n",
       "  1787961600.0,\n",
       "  1.0135662245059445,\n",
       "  0.6832416966874861,\n",
       "  -1.597590607855297,\n",
       "  1.3155874183767147],\n",
       " [-1.0810053722740018,\n",
       "  0.1105384770391235,\n",
       "  1.5733367288995384,\n",
       "  -0.9936769879302536,\n",
       "  0.9309548331580709,\n",
       "  1.5248483532934116,\n",
       "  1.2245515044782438,\n",
       "  -0.9933581562191116,\n",
       "  1759190400.0,\n",
       "  -1.0634982019194343,\n",
       "  -1.4654324564243835,\n",
       "  -0.8705100555921587,\n",
       "  1.5201685713676212],\n",
       " [-0.8861465823596075,\n",
       "  -0.028091502609537074,\n",
       "  -1.5256288080930804,\n",
       "  0.12023118151230291,\n",
       "  -1.480052983723609,\n",
       "  -1.0856794746899654,\n",
       "  -0.4761453005889863,\n",
       "  -1.7049095343580778,\n",
       "  1776124800.0,\n",
       "  1.6539560131051947,\n",
       "  -0.34306427637482056,\n",
       "  -0.6139927439824155,\n",
       "  0.12473608423225684],\n",
       " [0.8536339757555371,\n",
       "  -1.7106668359807542,\n",
       "  0.6640041876310484,\n",
       "  -0.4281802428184801,\n",
       "  -0.193192395452228,\n",
       "  0.07312416035808517,\n",
       "  -1.7293458043974876,\n",
       "  1.3697880483142908,\n",
       "  1740009600.0,\n",
       "  -1.4422463366188023,\n",
       "  0.20067968254625304,\n",
       "  -0.589767797238938,\n",
       "  1.2342651984412532],\n",
       " [1.6139281319607095,\n",
       "  0.7194597016699623,\n",
       "  0.2405134588710008,\n",
       "  0.15099024645120246,\n",
       "  0.38276708514954466,\n",
       "  0.14116952780501274,\n",
       "  -0.5682969610272395,\n",
       "  1.14758963552548,\n",
       "  1758585600.0,\n",
       "  0.18703675834125238,\n",
       "  -0.6930742011689242,\n",
       "  0.31865158460837245,\n",
       "  -1.756563636719698],\n",
       " [-1.1136302030486724,\n",
       "  -0.945383108863858,\n",
       "  -1.2960757285917852,\n",
       "  1.0610023741555894,\n",
       "  -0.39370628584479905,\n",
       "  0.26215770439696284,\n",
       "  -1.029358199694625,\n",
       "  -1.4538744518155504,\n",
       "  1752883200.0,\n",
       "  0.27639948088331173,\n",
       "  -1.4089132462592695,\n",
       "  -1.0196236098519802,\n",
       "  0.7265950635720616],\n",
       " [0.6920447644748053,\n",
       "  0.9582900812292107,\n",
       "  -0.8490027548074873,\n",
       "  -0.896016841885808,\n",
       "  -1.2995531233386932,\n",
       "  -0.3139622319190141,\n",
       "  -1.3388267913830754,\n",
       "  -1.2017595488077992,\n",
       "  1796169600.0,\n",
       "  1.2773126823164602,\n",
       "  -0.4536485480945017,\n",
       "  0.36930045549253815,\n",
       "  1.4500718221341233],\n",
       " [-1.39543730920013,\n",
       "  -1.5729650235852748,\n",
       "  1.1517335169290126,\n",
       "  -0.33840400318053326,\n",
       "  1.1980593863657416,\n",
       "  -0.8085328052622801,\n",
       "  -1.0043759264162881,\n",
       "  0.6923196734122348,\n",
       "  1786233600.0,\n",
       "  -1.4655349196403398,\n",
       "  -0.17338525312282418,\n",
       "  0.7265321275313511,\n",
       "  -0.6441609949435855],\n",
       " [1.3351349227024751,\n",
       "  -0.11653768960029491,\n",
       "  -1.261179563840722,\n",
       "  1.313899085592685,\n",
       "  0.9876802665937884,\n",
       "  -1.1781962392350072,\n",
       "  0.07724295279915096,\n",
       "  -0.305135714044145,\n",
       "  1745280000.0,\n",
       "  -0.7027136236448672,\n",
       "  -0.3373438473382311,\n",
       "  -1.19652507626968,\n",
       "  0.3283021334904727],\n",
       " [1.1932809561078412,\n",
       "  -0.8098534980671425,\n",
       "  -1.0071972881417897,\n",
       "  0.6921525533389518,\n",
       "  -1.4658259664712416,\n",
       "  -0.17511839971960605,\n",
       "  0.7281153219637322,\n",
       "  -0.6402253268731625,\n",
       "  1786320000.0,\n",
       "  -1.2401831773164675,\n",
       "  -1.190411598165577,\n",
       "  -0.9570702926211602,\n",
       "  1.6613880579176985],\n",
       " [0.3992499130085196,\n",
       "  -1.4849723140434479,\n",
       "  1.2520909370222748,\n",
       "  -0.033517429119618185,\n",
       "  -0.0972640991051803,\n",
       "  0.940443659124121,\n",
       "  -0.3697656435528797,\n",
       "  0.12096410515397278,\n",
       "  1780876800.0,\n",
       "  -0.09286453153698566,\n",
       "  -0.22675496684074942,\n",
       "  0.8789014652930276,\n",
       "  0.5662233433380875],\n",
       " [-0.8593917963101447,\n",
       "  -1.531106518992259,\n",
       "  0.15651396635065445,\n",
       "  1.4843911887019932,\n",
       "  0.9957099350354714,\n",
       "  -0.915251249298369,\n",
       "  -1.3860070053156723,\n",
       "  0.5263500588742109,\n",
       "  1795219200.0,\n",
       "  -1.1387920221255294,\n",
       "  0.2921278813800066,\n",
       "  -0.017059971651095743,\n",
       "  -1.5184233807772352],\n",
       " [1.3532944126517492,\n",
       "  0.2701188796213749,\n",
       "  -1.05446804529865,\n",
       "  -0.8224574781188595,\n",
       "  -0.6571846814819631,\n",
       "  0.029764777074577028,\n",
       "  -0.19451078617417072,\n",
       "  -1.4429343389826765,\n",
       "  1744675200.0,\n",
       "  0.19563057850916724,\n",
       "  1.557924468455489,\n",
       "  -0.612790614084234,\n",
       "  0.4382557543939673],\n",
       " [-0.21653161713219227,\n",
       "  1.0480005624483462,\n",
       "  -0.11065801231946858,\n",
       "  1.4595557473509635,\n",
       "  -1.4638206138420495,\n",
       "  -0.842016294084552,\n",
       "  -0.43507571103580317,\n",
       "  1.1232751272599464,\n",
       "  1766275200.0,\n",
       "  0.913719235625989,\n",
       "  0.10476251488586107,\n",
       "  0.2506674487602979,\n",
       "  0.7762030991068972],\n",
       " [-0.35117787562358155,\n",
       "  1.0666490646479125,\n",
       "  0.20615316287829324,\n",
       "  -1.2267057729532984,\n",
       "  -1.0612070326078376,\n",
       "  1.660949879097943,\n",
       "  -0.5105969118779249,\n",
       "  1.3917319109375481,\n",
       "  1789776000.0,\n",
       "  -0.5551421967481545,\n",
       "  0.46353164794891766,\n",
       "  -0.76104888377762,\n",
       "  0.45924734180339],\n",
       " [-1.257309826845304,\n",
       "  0.5349972284826245,\n",
       "  1.6770271064276112,\n",
       "  -0.1535484516819963,\n",
       "  1.649905237528584,\n",
       "  0.1799439977091129,\n",
       "  -0.16137815581538104,\n",
       "  1.5516095043178548,\n",
       "  1764806400.0,\n",
       "  0.7436985547992441,\n",
       "  0.36192677920346916,\n",
       "  -1.6680784530191826,\n",
       "  -0.16269462856786715],\n",
       " [0.9062399336687059,\n",
       "  1.648863194057607,\n",
       "  -0.3526671524324704,\n",
       "  0.22240588422319982,\n",
       "  -0.2365257775170273,\n",
       "  0.2779187530456277,\n",
       "  1.0817340246312646,\n",
       "  0.4205178358502769,\n",
       "  1751500800.0,\n",
       "  0.2403520517903109,\n",
       "  0.16410198343564267,\n",
       "  1.5304338895070542,\n",
       "  0.5213743048464073],\n",
       " [-0.36577085884891114,\n",
       "  -0.21983244254828777,\n",
       "  -1.2322548069447472,\n",
       "  0.7705507793016769,\n",
       "  -0.35003328111894705,\n",
       "  -0.7698246903914917,\n",
       "  -1.3806635877923612,\n",
       "  0.5995834516383078,\n",
       "  1762300800.0,\n",
       "  1.064460034347745,\n",
       "  -0.45189551098270686,\n",
       "  1.003794756698697,\n",
       "  -0.0801275026239039],\n",
       " [-0.674365708361966,\n",
       "  -1.4262899451856597,\n",
       "  0.22424623541313518,\n",
       "  1.0802483137530536,\n",
       "  -0.212531585591682,\n",
       "  1.0502136013083483,\n",
       "  -0.10895234348057492,\n",
       "  1.4592936215545704,\n",
       "  1766188800.0,\n",
       "  -1.4635316857824159,\n",
       "  -0.8404828585361301,\n",
       "  -0.43788808848179345,\n",
       "  1.1190375521571918],\n",
       " [-0.4489452399867892,\n",
       "  -1.6975853346176772,\n",
       "  1.2250052339813953,\n",
       "  0.8318106479543791,\n",
       "  0.44052528818140024,\n",
       "  -0.3839078516795449,\n",
       "  1.024334733315181,\n",
       "  0.00868087137189518,\n",
       "  1748908800.0,\n",
       "  -1.6717238478482914,\n",
       "  0.2274482207337471,\n",
       "  0.8428877662067984,\n",
       "  0.03800088514965611],\n",
       " [0.028626863066527005,\n",
       "  0.09713356868112355,\n",
       "  -0.02855474962750161,\n",
       "  -0.36145359331318133,\n",
       "  1.6318772253932943,\n",
       "  -1.1985587255161185,\n",
       "  -1.6662165219013112,\n",
       "  1.1769660470174483,\n",
       "  1746748800.0,\n",
       "  1.3400075730839673,\n",
       "  -0.9189797767517924,\n",
       "  1.2671125410212933,\n",
       "  -0.20093448491618457],\n",
       " [1.2563380901934655,\n",
       "  0.08486866060715896,\n",
       "  -0.8995907739580897,\n",
       "  0.22926572632599115,\n",
       "  1.0738086520540226,\n",
       "  -1.1410127544843078,\n",
       "  0.45221974647707147,\n",
       "  -0.038695253012340794,\n",
       "  1783555200.0,\n",
       "  -1.5963367112365805,\n",
       "  -0.36113005459757597,\n",
       "  1.111495980401641,\n",
       "  1.7028525109328816],\n",
       " [1.0112193533613147,\n",
       "  0.6792161910588603,\n",
       "  -1.5971095018982693,\n",
       "  1.3200427375005521,\n",
       "  0.6720361644185306,\n",
       "  -0.5481626529524551,\n",
       "  -1.6005451219805495,\n",
       "  1.387899399089609,\n",
       "  1788134400.0,\n",
       "  0.1303107511136055,\n",
       "  1.5946542838080022,\n",
       "  -1.6364620142017594,\n",
       "  -1.6887519214271964],\n",
       " [-1.1429416418727856,\n",
       "  0.9770591151802354,\n",
       "  1.5139770710573233,\n",
       "  -0.26847316316122366,\n",
       "  0.6905661591440557,\n",
       "  -1.6492202071973532,\n",
       "  -0.4895040036647605,\n",
       "  -0.34824573530019654,\n",
       "  1752019200.0,\n",
       "  1.2348013565233638,\n",
       "  1.4016496663504403,\n",
       "  1.519548367952588,\n",
       "  1.0572325832436988],\n",
       " [-1.5680067301143519,\n",
       "  -1.1272741898947987,\n",
       "  1.391073822788748,\n",
       "  -0.5886286173553252,\n",
       "  -0.7943272934003173,\n",
       "  -0.37764946621477175,\n",
       "  -0.592324342844247,\n",
       "  -1.4922865630107056,\n",
       "  1791244800.0,\n",
       "  -0.6146340228866815,\n",
       "  1.460054575624752,\n",
       "  0.2140290190403217,\n",
       "  -1.3810179841114616],\n",
       " [-1.4728459623878745,\n",
       "  -1.1361341663639926,\n",
       "  -0.9889615061131911,\n",
       "  0.22948302268181872,\n",
       "  -1.435392479099559,\n",
       "  -1.453817354990031,\n",
       "  0.7337861778188877,\n",
       "  1.458113551943723,\n",
       "  1769990400.0,\n",
       "  0.20990770720221885,\n",
       "  -1.2640568152199478,\n",
       "  0.6424368836229005,\n",
       "  0.5406588112788643],\n",
       " [-1.1422264094121606,\n",
       "  0.2884071742041916,\n",
       "  -0.016280048719033678,\n",
       "  -1.5160396791638524,\n",
       "  -1.5850980300638715,\n",
       "  -0.3319379182828366,\n",
       "  0.4653760930074656,\n",
       "  1.06376211248707,\n",
       "  1795392000.0,\n",
       "  0.16891695323556757,\n",
       "  0.8965913329366301,\n",
       "  -0.3970410970527408,\n",
       "  -1.7868918353196908],\n",
       " [-0.4196856818176952,\n",
       "  -1.6896969715796866,\n",
       "  0.1469226458923422,\n",
       "  0.13299578816634597,\n",
       "  0.10331942186012773,\n",
       "  1.1502732607330517,\n",
       "  1.5490349420042262,\n",
       "  -0.2327706693686835,\n",
       "  1765756800.0,\n",
       "  0.6150790273467147,\n",
       "  0.2887383489515765,\n",
       "  -0.7403709325422394,\n",
       "  1.1742634503106628],\n",
       " [-1.149443610544053,\n",
       "  -1.1568558775119269,\n",
       "  -0.34116641580367363,\n",
       "  -1.362463421977026,\n",
       "  0.3452448768691234,\n",
       "  -1.1109041335316545,\n",
       "  1.179728627695008,\n",
       "  -0.2761033520103514,\n",
       "  1791504000.0,\n",
       "  -0.5739584502772471,\n",
       "  0.7197045729433046,\n",
       "  -1.5978370167828118,\n",
       "  -1.6157246240850274],\n",
       " [0.6292009408697652,\n",
       "  0.904770424712837,\n",
       "  -1.5681783005023193,\n",
       "  -1.4005347977984886,\n",
       "  0.019501004892758973,\n",
       "  -0.1772285558402009,\n",
       "  -0.19488128328261076,\n",
       "  -1.4100204027953078,\n",
       "  1748304000.0,\n",
       "  1.483693198019078,\n",
       "  -0.7401369251268186,\n",
       "  1.2789356003903336,\n",
       "  -1.2161946403667532],\n",
       " [-1.6841546856224783,\n",
       "  -0.7274866854037847,\n",
       "  -0.7124193260468762,\n",
       "  -1.7272867525438398,\n",
       "  0.6336679260684421,\n",
       "  0.9069146686921745,\n",
       "  -1.564658829344369,\n",
       "  -1.3991971360738173,\n",
       "  1748217600.0,\n",
       "  0.018222717699829447,\n",
       "  -0.1754960411564819,\n",
       "  -0.1974398392133195,\n",
       "  -1.4138242838019224],\n",
       " [1.241562097019409,\n",
       "  -1.135434825253566,\n",
       "  -0.5864853443408833,\n",
       "  0.1046991263281491,\n",
       "  1.3671668828866541,\n",
       "  -0.8993878348449086,\n",
       "  1.4879328505171938,\n",
       "  -0.36780035716534804,\n",
       "  1785888000.0,\n",
       "  0.6402331534444828,\n",
       "  -1.6925022725498757,\n",
       "  1.0965960786831166,\n",
       "  -1.5762169643527406],\n",
       " [0.4048425317167016,\n",
       "  1.5056545957347813,\n",
       "  -0.3936494649416981,\n",
       "  0.9833623592605882,\n",
       "  -0.5235777735549771,\n",
       "  -0.04674286306161771,\n",
       "  -0.9776067812037491,\n",
       "  -1.4948647161319368,\n",
       "  1763683200.0,\n",
       "  -1.3520068423225617,\n",
       "  0.3927037901715405,\n",
       "  -1.0824305634269078,\n",
       "  -1.609478274961008],\n",
       " [-0.9072614473397221,\n",
       "  -0.34439878293710724,\n",
       "  1.6907146668298427,\n",
       "  1.191040186757078,\n",
       "  0.1336968290525145,\n",
       "  -1.5220039480851504,\n",
       "  1.1249984244911981,\n",
       "  -0.1110504423074581,\n",
       "  1737676800.0,\n",
       "  1.6006858504954335,\n",
       "  1.680782839870809,\n",
       "  0.10593337379802309,\n",
       "  0.8442841658764941],\n",
       " [-0.9082312930051172,\n",
       "  -1.4638746251837882,\n",
       "  0.08351935241056449,\n",
       "  -0.43924498779182103,\n",
       "  -1.2170719706929178,\n",
       "  -0.050410115177181726,\n",
       "  1.1857489226212712,\n",
       "  0.7413381542789882,\n",
       "  1750896000.0,\n",
       "  -0.4238431943452998,\n",
       "  -1.6613350035786438,\n",
       "  -1.2938490163131577,\n",
       "  0.26459667687982463],\n",
       " [-0.5771074456557743,\n",
       "  0.715650651472965,\n",
       "  -1.5973559574121445,\n",
       "  -1.613412048156658,\n",
       "  1.5197577705319771,\n",
       "  -1.361387039872582,\n",
       "  1.0842077459674606,\n",
       "  0.014473225639921072,\n",
       "  1791676800.0,\n",
       "  1.0651028402755232,\n",
       "  0.7723869405474694,\n",
       "  -1.1570045393388708,\n",
       "  1.686474325359747],\n",
       " [-0.9966656675807267,\n",
       "  -0.37256561537415084,\n",
       "  -1.064839774134927,\n",
       "  -1.3825129184384901,\n",
       "  -0.8035845932126726,\n",
       "  1.3125466540631956,\n",
       "  0.32923133130915105,\n",
       "  1.1663187709909608,\n",
       "  1762992000.0,\n",
       "  0.6580252249913896,\n",
       "  0.6356993736648767,\n",
       "  -1.1991159056433927,\n",
       "  0.8086755020091373],\n",
       " [0.7433539546682734,\n",
       "  -1.4811279395517742,\n",
       "  1.2258496240002954,\n",
       "  -0.5933729301529557,\n",
       "  -0.043469055830704845,\n",
       "  0.8225023924218049,\n",
       "  0.5847015856945352,\n",
       "  -0.37544989203894624,\n",
       "  1792022400.0,\n",
       "  -0.5139523483798447,\n",
       "  -0.7978473018191353,\n",
       "  0.9709084701614975,\n",
       "  1.1714239585329846],\n",
       " [-1.2166405833497307,\n",
       "  0.9725312957575122,\n",
       "  -0.7995482598117039,\n",
       "  -1.3988555458437795,\n",
       "  -0.1401915004331344,\n",
       "  -0.20378335179428483,\n",
       "  1.7350191023335235,\n",
       "  -0.6180215147851358,\n",
       "  1737072000.0,\n",
       "  0.4748373226147296,\n",
       "  -1.1364878283456932,\n",
       "  -1.5593658715675796,\n",
       "  0.20892216805053937],\n",
       " [-0.3539574358492656,\n",
       "  -0.7711639661689881,\n",
       "  -1.3839538018857431,\n",
       "  0.5993644306624424,\n",
       "  1.0668449010632985,\n",
       "  -0.4535452791126424,\n",
       "  1.0050852676913764,\n",
       "  -0.07609525684356731,\n",
       "  1762387200.0,\n",
       "  -0.8939446434744814,\n",
       "  -1.5973816865347275,\n",
       "  0.8006688478277322,\n",
       "  -1.4801647152959725],\n",
       " [-1.391951504818106,\n",
       "  -1.219825807086121,\n",
       "  -1.011607916458079,\n",
       "  1.0521343091471003,\n",
       "  -0.3567176418838888,\n",
       "  -1.215785301527309,\n",
       "  1.579287296758236,\n",
       "  0.11715119240343158,\n",
       "  1738195200.0,\n",
       "  -0.6736172171911982,\n",
       "  1.581077303720702,\n",
       "  1.3972351954748097,\n",
       "  -0.5951640849930621],\n",
       " [0.22528939920188223,\n",
       "  -1.8016042689095033,\n",
       "  -0.15795191398261751,\n",
       "  0.3555556742769155,\n",
       "  -1.0830617865618077,\n",
       "  -1.3446665481461593,\n",
       "  -0.4064546394810277,\n",
       "  0.22963706840696735,\n",
       "  1780704000.0,\n",
       "  0.4019058361182836,\n",
       "  -1.482634695028225,\n",
       "  1.2510712597129028,\n",
       "  -0.036984039690365685],\n",
       " [0.06553308584188272,\n",
       "  1.4775309463904551,\n",
       "  -0.5178647454952354,\n",
       "  0.25582696856103865,\n",
       "  -1.244904283826496,\n",
       "  1.1508248720298286,\n",
       "  -0.07161088475718638,\n",
       "  1.7105269011430981,\n",
       "  1750636800.0,\n",
       "  -1.1315043694353357,\n",
       "  -1.5173959200539817,\n",
       "  0.9369307542803643,\n",
       "  -1.6673818455997558],\n",
       " [-0.2048847738237857,\n",
       "  1.669831469150486,\n",
       "  -1.2067013417492551,\n",
       "  -1.3689981121266142,\n",
       "  -1.1493670457019376,\n",
       "  1.6625607196719379,\n",
       "  1.4855498955362338,\n",
       "  -0.28609006178733154,\n",
       "  1777248000.0,\n",
       "  0.4547816205991962,\n",
       "  -0.7386985990821325,\n",
       "  1.4422771403683885,\n",
       "  0.7745876766809034],\n",
       " [1.1170014298006663,\n",
       "  -0.6288398787500185,\n",
       "  0.6983623719425293,\n",
       "  -1.7018858935992864,\n",
       "  -0.32129725125439224,\n",
       "  1.0758416811518532,\n",
       "  -0.6545587080568034,\n",
       "  1.2941353843189025,\n",
       "  1778198400.0,\n",
       "  -1.0411535956572757,\n",
       "  0.5749768049375928,\n",
       "  -0.8763876909812984,\n",
       "  0.23592812608829028],\n",
       " [-1.551579922634939,\n",
       "  -0.7331411578726647,\n",
       "  1.7733583426160262,\n",
       "  -1.6360083139713062,\n",
       "  -0.7740959351188567,\n",
       "  0.7278041219541138,\n",
       "  0.6456768833785548,\n",
       "  0.409181642594718,\n",
       "  1757203200.0,\n",
       "  -0.40951595791651485,\n",
       "  0.9124543915886225,\n",
       "  1.1902553678510568,\n",
       "  -1.758513303673568],\n",
       " [0.8641973647906147,\n",
       "  -0.6275722050384289,\n",
       "  -1.6878377411601535,\n",
       "  -0.020582028062154582,\n",
       "  -1.565583424503411,\n",
       "  1.2322711167943785,\n",
       "  -0.06340508956973699,\n",
       "  -0.6346526079280099,\n",
       "  1761782400.0,\n",
       "  -0.016119443361757718,\n",
       "  0.43190515130242274,\n",
       "  1.540126567193332,\n",
       "  1.1584486813282706],\n",
       " [1.1449392735315735,\n",
       "  1.6047018832726625,\n",
       "  1.642898825176931,\n",
       "  -0.9483410135396275,\n",
       "  -0.4494308674871195,\n",
       "  -0.1080222270601628,\n",
       "  0.381180431406281,\n",
       "  1.5368781163522547,\n",
       "  1782432000.0,\n",
       "  0.6071174339259641,\n",
       "  0.3211516030612229,\n",
       "  -0.37990497962562403,\n",
       "  -1.7777460562836493],\n",
       " [1.133175394319496,\n",
       "  1.2326495211297825,\n",
       "  -1.3569905015554216,\n",
       "  -0.5027821670894279,\n",
       "  -0.8129035374387021,\n",
       "  -0.8270047152941223,\n",
       "  -1.1107364650369351,\n",
       "  0.6730222121942292,\n",
       "  1759536000.0,\n",
       "  -0.13706953715183048,\n",
       "  1.5722268767432024,\n",
       "  -1.1609463460839429,\n",
       "  -0.43330884462596536],\n",
       " [1.6720226482857978,\n",
       "  -1.1952059131235202,\n",
       "  -1.1374777240542258,\n",
       "  0.7888449764241561,\n",
       "  -1.0067786851524445,\n",
       "  0.6865161088751734,\n",
       "  -0.9348133836655764,\n",
       "  0.6788532797878476,\n",
       "  1749340800.0,\n",
       "  -1.0115008310845093,\n",
       "  0.24839342409740645,\n",
       "  -0.26778097019475183,\n",
       "  1.0137283038482456],\n",
       " [1.3378256420632928,\n",
       "  -0.9217566570262342,\n",
       "  1.2681352511141157,\n",
       "  -0.1975877195532528,\n",
       "  -0.025337896442688218,\n",
       "  1.6691739153747225,\n",
       "  0.991851475542763,\n",
       "  -0.6347891643260254,\n",
       "  1746921600.0,\n",
       "  -0.36365506732284303,\n",
       "  -1.3545972022603243,\n",
       "  -0.11079351872263014,\n",
       "  -0.1329828876829527],\n",
       " [-1.6114224497970457,\n",
       "  -0.06309032919265696,\n",
       "  1.5486713982917293,\n",
       "  -0.8592814840957428,\n",
       "  0.6191189196211916,\n",
       "  0.6876055643626745,\n",
       "  -0.3466670399417287,\n",
       "  -0.2950899054657448,\n",
       "  1776643200.0,\n",
       "  1.6129774292012173,\n",
       "  -0.824460930943888,\n",
       "  0.23258731052932047,\n",
       "  -0.7614657286150059],\n",
       " [-1.5141680964370046,\n",
       "  -1.6620125913020367,\n",
       "  -1.3027811150195021,\n",
       "  -0.38515790237990033,\n",
       "  -1.3676751887914047,\n",
       "  0.8325245749490716,\n",
       "  0.7898862358152988,\n",
       "  1.3797441531076338,\n",
       "  1765497600.0,\n",
       "  1.2031588063282033,\n",
       "  -1.3535384464470643,\n",
       "  -1.1504264468954688,\n",
       "  -0.6308545429136269],\n",
       " [0.3566480910375368,\n",
       "  -1.6493196226436038,\n",
       "  -0.8480621275220658,\n",
       "  0.426138900518606,\n",
       "  0.7494114354805375,\n",
       "  0.4681342416317682,\n",
       "  0.19323833573231333,\n",
       "  -0.9903073593588854,\n",
       "  1760832000.0,\n",
       "  1.6773251621932794,\n",
       "  1.245047721419437,\n",
       "  -1.5716728026767957,\n",
       "  0.7456770749864834],\n",
       " [0.26222700036803887,\n",
       "  -0.4346504285843301,\n",
       "  -1.0523582123326476,\n",
       "  -0.8659865433171248,\n",
       "  -0.3877460231288966,\n",
       "  -0.3039164860910038,\n",
       "  -1.4820274156113131,\n",
       "  0.029886491547615746,\n",
       "  1745798400.0,\n",
       "  -1.2582196157109296,\n",
       "  0.40721469906932534,\n",
       "  1.419029186849148,\n",
       "  1.352340182715856],\n",
       " [1.0913164459961877,\n",
       "  1.1389823288101717,\n",
       "  0.5707592258467741,\n",
       "  0.2153235448187767,\n",
       "  -0.08489691765851112,\n",
       "  1.5364594244810672,\n",
       "  -1.4074517298494267,\n",
       "  1.7054976169959042,\n",
       "  1767744000.0,\n",
       "  -0.013450049327820058,\n",
       "  -0.027801875045886985,\n",
       "  0.2836390128698849,\n",
       "  1.074458288209757],\n",
       " [-1.2205176721952569,\n",
       "  -0.052094767147973356,\n",
       "  1.1856564444782667,\n",
       "  0.7411984679673093,\n",
       "  -0.42303246941394834,\n",
       "  -1.6626226981124006,\n",
       "  -1.290133071050039,\n",
       "  0.2686879487149286,\n",
       "  1750982400.0,\n",
       "  0.14587953277315438,\n",
       "  -0.27403458070803044,\n",
       "  -0.4270935417689881,\n",
       "  1.2213251842935682],\n",
       " [-0.14045608579562582,\n",
       "  -1.4838524526626178,\n",
       "  1.7703528035956615,\n",
       "  -0.026782762474934566,\n",
       "  1.2309937795478518,\n",
       "  1.220224953696669,\n",
       "  0.3016048622411165,\n",
       "  -0.9783291245449219,\n",
       "  1766707200.0,\n",
       "  0.7352341028060508,\n",
       "  1.1622213342841636,\n",
       "  -0.9381521665804841,\n",
       "  1.4217656249187756],\n",
       " [-0.8431903799753605,\n",
       "  -0.33319717762769946,\n",
       "  -0.21325709650133443,\n",
       "  -1.3284032057484811,\n",
       "  -1.6134061159071118,\n",
       "  1.1987453468286857,\n",
       "  0.7260529753556921,\n",
       "  -0.07935673351922819,\n",
       "  1740960000.0,\n",
       "  -0.5141838132013797,\n",
       "  -0.5651726222042937,\n",
       "  -0.22581218542053688,\n",
       "  1.2567337883923644],\n",
       " [-1.0445386494442304,\n",
       "  0.571035671095919,\n",
       "  -0.8757702335552957,\n",
       "  0.23959423117811723,\n",
       "  -0.9280400184929352,\n",
       "  0.36608625464914174,\n",
       "  0.16370063909877594,\n",
       "  -0.40106567476731814,\n",
       "  1778371200.0,\n",
       "  -1.391803315014102,\n",
       "  1.4381644959826139,\n",
       "  -0.32427215193269604,\n",
       "  0.09550089761142272],\n",
       " [1.6517818100382649,\n",
       "  1.1178996586840457,\n",
       "  -0.9098917819682876,\n",
       "  -1.5303472166658323,\n",
       "  0.4515751400689335,\n",
       "  -1.7520249250276094,\n",
       "  0.2240950430373496,\n",
       "  0.3677991684839109,\n",
       "  1755216000.0,\n",
       "  1.3322312052226573,\n",
       "  0.2702932390683876,\n",
       "  -0.536749141666994,\n",
       "  1.5293940378248772],\n",
       " [1.3874529828495146,\n",
       "  0.5900638117089065,\n",
       "  0.09524641534716968,\n",
       "  -0.21529694626506188,\n",
       "  -0.0565868133672183,\n",
       "  -0.4244402507325684,\n",
       "  0.10155040547103227,\n",
       "  -0.08023020324411512,\n",
       "  1760227200.0,\n",
       "  -0.5250033776524501,\n",
       "  -1.7545583805071228,\n",
       "  -0.7655388776533579,\n",
       "  0.6721696303670162],\n",
       " [-1.085149732463457,\n",
       "  -0.5892516833319625,\n",
       "  -1.3075325277463543,\n",
       "  -0.6517387285372404,\n",
       "  0.041207987631249915,\n",
       "  1.2245015530657453,\n",
       "  -0.6191113460626122,\n",
       "  0.17480048935474046,\n",
       "  1737504000.0,\n",
       "  -0.9039457201992975,\n",
       "  -0.341171611653116,\n",
       "  1.6896120784791464,\n",
       "  1.1866790975968844],\n",
       " [1.2822430495704,\n",
       "  -0.9290491069268447,\n",
       "  -1.0207998608720046,\n",
       "  -1.4633334681902694,\n",
       "  0.4676941791703923,\n",
       "  1.4148678664394516,\n",
       "  -0.2966122773293831,\n",
       "  0.14512922526414562,\n",
       "  1770940800.0,\n",
       "  -1.0583304768312196,\n",
       "  1.2866646550727963,\n",
       "  0.7622462078268208,\n",
       "  -0.35909628468708654],\n",
       " [-1.355548960076015,\n",
       "  0.3889047033011458,\n",
       "  -1.0818520607079263,\n",
       "  -1.6071611330492535,\n",
       "  -1.430930890147874,\n",
       "  0.5480928226831293,\n",
       "  -1.06845904397084,\n",
       "  0.25054979637657726,\n",
       "  1763856000.0,\n",
       "  -1.5468812734493156,\n",
       "  0.5706561138282482,\n",
       "  -1.745474348609193,\n",
       "  0.8110887392592212],\n",
       " [-0.4159812521862315,\n",
       "  0.33074492886265533,\n",
       "  0.12603713797282892,\n",
       "  -0.5580879040306971,\n",
       "  0.3745433755600856,\n",
       "  0.8844468497135742,\n",
       "  -0.8219480548611834,\n",
       "  -1.371757067903495,\n",
       "  1758067200.0,\n",
       "  0.005016016954563438,\n",
       "  0.3332821538458702,\n",
       "  -1.5788291091911095,\n",
       "  -1.5649683250525088],\n",
       " [0.038867537943146124,\n",
       "  0.45586789881919243,\n",
       "  1.211005225826109,\n",
       "  -0.4527275848149659,\n",
       "  -1.1509674522591018,\n",
       "  0.5444032895383943,\n",
       "  -0.6996022584970211,\n",
       "  -0.23938499245042347,\n",
       "  1777507200.0,\n",
       "  -1.3474794802543486,\n",
       "  0.9763888933960733,\n",
       "  -1.2248881256851316,\n",
       "  1.608574165422893],\n",
       " [-0.009388351329258394,\n",
       "  0.27737763208439054,\n",
       "  -0.42250119562975236,\n",
       "  -1.3855327639862929,\n",
       "  1.0372328209483046,\n",
       "  -1.793834844368524,\n",
       "  0.606062351327353,\n",
       "  -0.37161399786500166,\n",
       "  1793664000.0,\n",
       "  0.7047598424500676,\n",
       "  1.3591428185055607,\n",
       "  1.4762796137431637,\n",
       "  -1.314979083566235],\n",
       " [-0.08189421614632864,\n",
       "  1.161755704845005,\n",
       "  0.4486973421391151,\n",
       "  1.433383250935462,\n",
       "  1.2618994626506286,\n",
       "  0.10351999608338326,\n",
       "  -0.15797275943495043,\n",
       "  1.000080456093605,\n",
       "  1752451200.0,\n",
       "  -0.970336138899307,\n",
       "  -0.4063700512236299,\n",
       "  0.08188776400707334,\n",
       "  -1.2288099987015457],\n",
       " [1.142825236043329,\n",
       "  -0.9606334108543302,\n",
       "  -0.46582410029552423,\n",
       "  1.3366930070425633,\n",
       "  0.22953337303582808,\n",
       "  -1.8007599240088448,\n",
       "  -0.15618739053345918,\n",
       "  0.3559110693289979,\n",
       "  1780617600.0,\n",
       "  -1.0831751522691662,\n",
       "  -1.3432836376032071,\n",
       "  -0.409236772079879,\n",
       "  0.2255524819885618],\n",
       " [-0.48517109814650405,\n",
       "  -0.22638809608342636,\n",
       "  -0.7073278980404831,\n",
       "  0.619405361775277,\n",
       "  1.0064482914261335,\n",
       "  -0.8871675457415444,\n",
       "  -0.6488023217274073,\n",
       "  0.43587352074883,\n",
       "  1795651200.0,\n",
       "  1.301965282462087,\n",
       "  -1.357055993907483,\n",
       "  1.2763204154305703,\n",
       "  0.44996981401121633],\n",
       " [1.4750291098543453,\n",
       "  1.6288951292944494,\n",
       "  1.292627213253717,\n",
       "  0.21883542054537614,\n",
       "  1.0056856210483565,\n",
       "  -0.20560212372393183,\n",
       "  -0.9645319200822223,\n",
       "  -1.2180408875680615,\n",
       "  1772755200.0,\n",
       "  -0.26252347409253923,\n",
       "  1.235667276441159,\n",
       "  0.8708429377983109,\n",
       "  0.5816000938440614],\n",
       " [1.3789384523812767,\n",
       "  1.6520478518510355,\n",
       "  0.8262821946683286,\n",
       "  0.5203498228397948,\n",
       "  0.18377280320817418,\n",
       "  0.2620842158945131,\n",
       "  -0.638327256634671,\n",
       "  0.5734407518658249,\n",
       "  1744156800.0,\n",
       "  0.15669359136027294,\n",
       "  -1.3316787282336757,\n",
       "  1.1938200228018552,\n",
       "  0.5116747260899467],\n",
       " [-0.24051256847356192,\n",
       "  0.27607647711424016,\n",
       "  1.0815119444942987,\n",
       "  0.420198598724744,\n",
       "  0.24186527972619365,\n",
       "  0.16226780225370527,\n",
       "  1.5311684707181583,\n",
       "  0.5255095439203432,\n",
       "  1751587200.0,\n",
       "  0.977849667701636,\n",
       "  -1.4703353082756352,\n",
       "  0.0463935165283422,\n",
       "  0.8180177744191566],\n",
       " [1.4038397019068793,\n",
       "  -0.5209997155151381,\n",
       "  -1.4119799843969565,\n",
       "  1.447977850120361,\n",
       "  -0.5626256580928909,\n",
       "  0.3265060780513767,\n",
       "  1.4118287753095782,\n",
       "  0.775454914645533,\n",
       "  1762041600.0,\n",
       "  0.3902423638264976,\n",
       "  1.437245702934714,\n",
       "  1.3153138638115496,\n",
       "  -1.4530454567535989],\n",
       " [1.0010133473554415,\n",
       "  -0.20721227119205093,\n",
       "  -0.9673036363937676,\n",
       "  -1.2192771630962058,\n",
       "  -0.26154212525379444,\n",
       "  1.23351229748343,\n",
       "  0.8722737951326058,\n",
       "  0.5857456451935241,\n",
       "  1772841600.0,\n",
       "  0.937310389397129,\n",
       "  0.859898519228945,\n",
       "  0.023382446184525237,\n",
       "  -0.3584473262695593],\n",
       " [-1.263150416077016,\n",
       "  -1.6221698834226514,\n",
       "  -1.0555391944614878,\n",
       "  0.0023418698665978004,\n",
       "  -1.4343288541253745,\n",
       "  -0.8571642261358938,\n",
       "  -0.4873397922235945,\n",
       "  1.4737069799339915,\n",
       "  1781913600.0,\n",
       "  -0.3570726087215559,\n",
       "  -0.9313882257947806,\n",
       "  -0.887049038682966,\n",
       "  0.5493531075526197],\n",
       " [-1.1196466440890394,\n",
       "  -1.1164281912649312,\n",
       "  -0.25435183685398843,\n",
       "  -0.9674025414788943,\n",
       "  0.18013617398853107,\n",
       "  1.6601528507936738,\n",
       "  -0.845082046106257,\n",
       "  -1.1561846407078016,\n",
       "  1775174400.0,\n",
       "  1.522274590355895,\n",
       "  -1.375149717852877,\n",
       "  0.12646377144544949,\n",
       "  -1.5024410864660205],\n",
       " [1.68028319476068,\n",
       "  1.5383717522071239,\n",
       "  0.6669572593475857,\n",
       "  0.9239589804595224,\n",
       "  1.3299115450351708,\n",
       "  -1.191160591443778,\n",
       "  -1.221715543839536,\n",
       "  -0.9083934799832267,\n",
       "  1778025600.0,\n",
       "  1.119294879717954,\n",
       "  -0.6258345478079348,\n",
       "  0.6974473634160384,\n",
       "  -1.7041338437726496],\n",
       " [0.9349249886760532,\n",
       "  0.8557353433772749,\n",
       "  0.02417001520751644,\n",
       "  -0.3552157003268325,\n",
       "  0.334329682490375,\n",
       "  0.4660917406186421,\n",
       "  -0.027146421401734434,\n",
       "  -1.7604720239365739,\n",
       "  1773014400.0,\n",
       "  1.396716088473268,\n",
       "  1.2323395426143748,\n",
       "  1.1176878374407706,\n",
       "  -1.7603344574806696],\n",
       " [0.712940321909125,\n",
       "  -1.0798620624716262,\n",
       "  -1.0950174451652885,\n",
       "  0.3845352262807684,\n",
       "  -0.14315573951140262,\n",
       "  1.128579053316908,\n",
       "  -1.3438236921496929,\n",
       "  1.3766810919570096,\n",
       "  1736467200.0,\n",
       "  1.6349662808505727,\n",
       "  -1.145322679656041,\n",
       "  1.6870262836418228,\n",
       "  -0.6268067387298946],\n",
       " [-0.0938305646532634,\n",
       "  0.6087564132105784,\n",
       "  0.8688699167930124,\n",
       "  1.2493603834073572,\n",
       "  0.8582248769908639,\n",
       "  -1.7097788129132991,\n",
       "  0.6647458327742529,\n",
       "  -0.4273864662116229,\n",
       "  1739923200.0,\n",
       "  -0.19424595974155381,\n",
       "  0.07493164634375937,\n",
       "  -1.7335258805005764,\n",
       "  1.365508270792902],\n",
       " [-0.23457381961342993,\n",
       "  0.45742175712342475,\n",
       "  1.7295512431876556,\n",
       "  1.6786439876891333,\n",
       "  -1.6206384183997864,\n",
       "  1.6414831538766037,\n",
       "  1.1012863153714976,\n",
       "  -0.982632501661812,\n",
       "  1794355200.0,\n",
       "  0.051484418145521106,\n",
       "  -0.7556103417664429,\n",
       "  -0.5538161034468774,\n",
       "  1.449559810758768],\n",
       " [1.3076575614641155,\n",
       "  0.05421048992267172,\n",
       "  1.3662584767037556,\n",
       "  0.39678017306201024,\n",
       "  1.4899562159156907,\n",
       "  0.3630371615744104,\n",
       "  0.7731146709669436,\n",
       "  -0.3868752228637462,\n",
       "  1785369600.0,\n",
       "  -0.7600518460576144,\n",
       "  1.663324065887434,\n",
       "  0.8076856180769885,\n",
       "  -1.7079621447329332],\n",
       " [-1.1349350745097002,\n",
       "  -1.519706449339333,\n",
       "  0.937891039817493,\n",
       "  -1.6651070302913047,\n",
       "  -0.9046131690676021,\n",
       "  -1.4628680653268058,\n",
       "  0.08498337840077111,\n",
       "  -0.4384450221358227,\n",
       "  1750809600.0,\n",
       "  -1.217043746874501,\n",
       "  -0.048639623099996365,\n",
       "  1.1846493249777463,\n",
       "  0.7371659658665404],\n",
       " [0.07049545650331325,\n",
       "  -0.12103470922563936,\n",
       "  -0.35604222619326586,\n",
       "  -0.8880578159426873,\n",
       "  -1.0816292903660467,\n",
       "  -0.5878250332491205,\n",
       "  -1.3043374156459828,\n",
       "  -0.6508199048138549,\n",
       "  1737417600.0,\n",
       "  0.03990676575308071,\n",
       "  1.2266538336415638,\n",
       "  -0.6221182001423248,\n",
       "  0.17072529082665616],\n",
       " [-1.4458340494337873,\n",
       "  0.1970302417599798,\n",
       "  -0.5890961511198022,\n",
       "  1.2386610722959133,\n",
       "  0.2689134281078413,\n",
       "  1.1775783604459338,\n",
       "  0.5373252333443557,\n",
       "  1.6826486562454674,\n",
       "  1740182400.0,\n",
       "  -1.0269844697555333,\n",
       "  -1.5140658586417775,\n",
       "  -0.36579436214643907,\n",
       "  0.6954402603616623],\n",
       " [1.2520682070753812,\n",
       "  0.046583957087330215,\n",
       "  0.2627265313130313,\n",
       "  -0.8583414058213276,\n",
       "  0.254717812424129,\n",
       "  -1.1874870190927307,\n",
       "  -0.5862884235057536,\n",
       "  -0.11488887722245135,\n",
       "  1794182400.0,\n",
       "  -0.23159780785675138,\n",
       "  0.4612742815837816,\n",
       "  1.7284413137362196,\n",
       "  1.6739267281418453],\n",
       " [-1.5396773411122797,\n",
       "  -0.7240564070561853,\n",
       "  0.9509224414139404,\n",
       "  1.2644614853678593,\n",
       "  0.5623974476547513,\n",
       "  0.39267533900126905,\n",
       "  1.4308086934877076,\n",
       "  -1.300210076352134,\n",
       "  1791072000.0,\n",
       "  -1.5643573186187463,\n",
       "  -1.1246575961627403,\n",
       "  1.3900278741789376,\n",
       "  -0.59168974674152],\n",
       " [1.6382989693480638,\n",
       "  1.6181753756507777,\n",
       "  1.693514786103244,\n",
       "  0.7590338909137363,\n",
       "  -1.026912164157086,\n",
       "  -0.04687243130622018,\n",
       "  -1.279276670896314,\n",
       "  0.44346229964750583,\n",
       "  1736294400.0,\n",
       "  0.7154378275703666,\n",
       "  -1.0772084912327553,\n",
       "  -1.095593459291746,\n",
       "  0.3807632489843818],\n",
       " [-0.29677206234070486,\n",
       "  1.5912106428268729,\n",
       "  0.373853434250183,\n",
       "  1.3091041490221715,\n",
       "  -0.7548934127206243,\n",
       "  -1.0600392366949891,\n",
       "  1.6717523128790588,\n",
       "  -1.7972925259775128,\n",
       "  1774742400.0,\n",
       "  1.224975584971508,\n",
       "  1.5962339928255576,\n",
       "  0.9092829089587479,\n",
       "  0.606512998404648],\n",
       " [-0.27129878687391507,\n",
       "  -0.8485110328686588,\n",
       "  -0.611085668499218,\n",
       "  -0.6903373465045477,\n",
       "  -0.5972514055133058,\n",
       "  1.3243175944033825,\n",
       "  -0.910129290404556,\n",
       "  1.7008097558600663,\n",
       "  1771545600.0,\n",
       "  -0.7086020057081935,\n",
       "  -1.572314692489679,\n",
       "  -0.2587766031220135,\n",
       "  0.9402861562389705],\n",
       " [-1.076888530804657,\n",
       "  -0.2625115638314783,\n",
       "  0.09586863840111857,\n",
       "  0.8725195462032508,\n",
       "  0.3585156381443338,\n",
       "  0.37091564481295375,\n",
       "  -1.447117685943818,\n",
       "  0.4468827837605441,\n",
       "  1763337600.0,\n",
       "  0.33524101267343076,\n",
       "  -1.2557684289887705,\n",
       "  1.3007553904349474,\n",
       "  -0.9466091917846975],\n",
       " [-0.6178035703001068,\n",
       "  1.455423692854341,\n",
       "  0.21485263192788373,\n",
       "  -1.3785338413050359,\n",
       "  -1.145958666975443,\n",
       "  -1.1557018534519365,\n",
       "  -0.3391738921743585,\n",
       "  -1.361147055421507,\n",
       "  1791417600.0,\n",
       "  0.34362242239774093,\n",
       "  -1.1094512198633601,\n",
       "  1.1786226682037295,\n",
       "  -0.28010135688629095],\n",
       " [0.15292197243778827,\n",
       "  -1.3344947253781425,\n",
       "  -0.8835040769135478,\n",
       "  0.48069361514062103,\n",
       "  -1.066557009444154,\n",
       "  -0.9071812679967719,\n",
       "  -1.163359145796172,\n",
       "  -0.30186165208025073,\n",
       "  1760486400.0,\n",
       "  -1.2719343206650873,\n",
       "  -1.773779098603379,\n",
       "  0.5556188909050019,\n",
       "  1.141311288111828],\n",
       " [-1.5198333371969053,\n",
       "  -0.9847649113966332,\n",
       "  -0.7717143679963351,\n",
       "  0.24996831277034512,\n",
       "  0.45641233789674085,\n",
       "  -0.7836793639522767,\n",
       "  0.7920528407420883,\n",
       "  1.1603003731921246,\n",
       "  1779235200.0,\n",
       "  -1.0489907536493794,\n",
       "  1.4910317188956435,\n",
       "  0.8785586239773227,\n",
       "  -1.3058300394595703],\n",
       " [-1.275435980395361,\n",
       "  -1.7758898262118525,\n",
       "  0.5565070851742056,\n",
       "  1.1456392141137979,\n",
       "  0.3041347852786219,\n",
       "  -0.08400052273857422,\n",
       "  0.5188031272415912,\n",
       "  1.2897465086095001,\n",
       "  1760659200.0,\n",
       "  0.3593255285823858,\n",
       "  -1.6471101808280477,\n",
       "  -0.8486848224848642,\n",
       "  0.42233653380210096],\n",
       " [-0.6010391392152966,\n",
       "  1.3219729638340048,\n",
       "  -0.9128332213370909,\n",
       "  1.7012070489634612,\n",
       "  -0.7080924631802289,\n",
       "  -1.573629037305956,\n",
       "  -0.2561532989953618,\n",
       "  0.9444931242932135,\n",
       "  1771632000.0,\n",
       "  0.9406494673145874,\n",
       "  1.6003554166377452,\n",
       "  1.3965576709489216,\n",
       "  0.6347754405598122],\n",
       " [-1.2702119381264787,\n",
       "  -0.5491566039609427,\n",
       "  -1.5220646713948416,\n",
       "  -1.8097579284702396,\n",
       "  -0.39608353169342037,\n",
       "  0.21619229961896533,\n",
       "  -0.009456746876878823,\n",
       "  1.422749739092247,\n",
       "  1755475200.0,\n",
       "  1.0373511534938695,\n",
       "  0.3880626781433951,\n",
       "  -0.4999625817336514,\n",
       "  -1.5561660617433777],\n",
       " [-0.36063810801988805,\n",
       "  -1.2169104807552773,\n",
       "  1.5796851652768558,\n",
       "  0.11666217261577248,\n",
       "  -0.6730706721113647,\n",
       "  1.5788189183077523,\n",
       "  1.3981103836333781,\n",
       "  -0.5912200273333322,\n",
       "  1738281600.0,\n",
       "  -0.5614986262153355,\n",
       "  0.9009487989380741,\n",
       "  -0.8226570533303337,\n",
       "  0.6109910485002147],\n",
       " [-1.4691343994137296,\n",
       "  -0.17674318179886148,\n",
       "  0.7274526348574434,\n",
       "  -0.6411382212180691,\n",
       "  -1.2402358751423441,\n",
       "  -1.1918402744780554,\n",
       "  -0.9537098570621966,\n",
       "  1.66571849801966,\n",
       "  1786406400.0,\n",
       "  -1.4642938555405112,\n",
       "  -0.3076301437127164,\n",
       "  1.6796952506067295,\n",
       "  -0.9273781379243241],\n",
       " [0.18427226892248041,\n",
       "  -0.6960271316549006,\n",
       "  0.3194949775608362,\n",
       "  -1.7543540119038707,\n",
       "  0.9802467151813381,\n",
       "  -0.600766764798384,\n",
       "  -1.7059163400471986,\n",
       "  1.4980727645297638,\n",
       "  1758758400.0,\n",
       "  -1.1176535360977309,\n",
       "  0.6384312637028715,\n",
       "  -0.26700343801192555,\n",
       "  0.600615731150102],\n",
       " [-1.0303623643471447,\n",
       "  -1.5163789830734173,\n",
       "  -0.3650803713470869,\n",
       "  0.6994422616251775,\n",
       "  -0.3053977918983322,\n",
       "  -0.05372397809888875,\n",
       "  1.0431851983116027,\n",
       "  0.468341603788643,\n",
       "  1740355200.0,\n",
       "  1.4294015187638893,\n",
       "  1.23925264379685,\n",
       "  -0.47526402317062166,\n",
       "  -0.20150423331537184],\n",
       " [0.05703075219911379,\n",
       "  -0.9243399635923327,\n",
       "  -1.2083835938872953,\n",
       "  0.8572110663336565,\n",
       "  -0.5703123850508344,\n",
       "  -0.21296299146784253,\n",
       "  -0.1912848440491883,\n",
       "  1.163002144596563,\n",
       "  1767484800.0,\n",
       "  -1.6134121709985896,\n",
       "  -1.4540777430728162,\n",
       "  -0.5650438096859252,\n",
       "  -0.8172950516213828],\n",
       " [-0.769946537085637,\n",
       "  0.3327238041212641,\n",
       "  -0.4081397000757732,\n",
       "  0.14830937670210245,\n",
       "  0.8703397807827307,\n",
       "  -0.6730862536060616,\n",
       "  -1.3645689753723256,\n",
       "  -0.8828736516227726,\n",
       "  1755820800.0,\n",
       "  1.4403599387006771,\n",
       "  0.8861838780539577,\n",
       "  -0.07716840995390643,\n",
       "  -1.1636841644829918],\n",
       " [0.188702265553985,\n",
       "  0.11662847656611174,\n",
       "  1.3361078916897227,\n",
       "  -0.7857120540602048,\n",
       "  0.017574234652594146,\n",
       "  1.1478003320904921,\n",
       "  0.5735890198340121,\n",
       "  -1.0613562915612942,\n",
       "  1739232000.0,\n",
       "  -1.2087266914611392,\n",
       "  -0.10748930722756941,\n",
       "  0.36931132638827796,\n",
       "  -1.7629177197523456],\n",
       " [0.5792419478198033,\n",
       "  -0.03733985089246105,\n",
       "  0.5513587836928805,\n",
       "  1.3832842345705723,\n",
       "  -0.008911154554728013,\n",
       "  -1.6910853142479016,\n",
       "  0.5244339092572731,\n",
       "  -1.491586309061762,\n",
       "  1749600000.0,\n",
       "  0.8430274542314349,\n",
       "  1.0052523989068982,\n",
       "  -1.6458351805819138,\n",
       "  0.06991823104777395],\n",
       " [-0.006138294125496672,\n",
       "  -0.7247718332394981,\n",
       "  1.325501553192508,\n",
       "  -0.035994560606370796,\n",
       "  0.18057949790166092,\n",
       "  0.3444047416167188,\n",
       "  -0.2660647279365329,\n",
       "  -1.383048428111112,\n",
       "  1756512000.0,\n",
       "  -0.41109503166121014,\n",
       "  -1.1084722325345688,\n",
       "  0.6246921574910326,\n",
       "  0.4187766910368268],\n",
       " [1.032543138736246,\n",
       "  -1.7946825138579898,\n",
       "  0.6052475868872487,\n",
       "  -0.37237656076279163,\n",
       "  0.7067642631040018,\n",
       "  1.3569508742975414,\n",
       "  1.4770713611859838,\n",
       "  -1.311158277601786,\n",
       "  1793750400.0,\n",
       "  -1.2361101153681502,\n",
       "  -0.18256916027318773,\n",
       "  -1.0321184318436083,\n",
       "  0.15824537475772968],\n",
       " [-0.7279640400200736,\n",
       "  -0.5363578396317628,\n",
       "  1.6553480379824057,\n",
       "  0.8175283370193879,\n",
       "  1.4912443998364073,\n",
       "  1.1792507037835394,\n",
       "  -0.45703445539443993,\n",
       "  -0.322785340458262,\n",
       "  1768348800.0,\n",
       "  1.123858795786166,\n",
       "  -0.6576637701095915,\n",
       "  0.8892923295532443,\n",
       "  -0.06777415238288421],\n",
       " [0.3895047456882077,\n",
       "  1.2952140446466023,\n",
       "  -0.03745871879412687,\n",
       "  -1.2273728742062673,\n",
       "  1.455872208978574,\n",
       "  -0.4068508908169655,\n",
       "  -0.24181747929174163,\n",
       "  0.6398065744283039,\n",
       "  1768003200.0,\n",
       "  -1.529201264114831,\n",
       "  0.588584166434073,\n",
       "  -0.16758978850232434,\n",
       "  -0.25119447341719314],\n",
       " [0.14309424795601633,\n",
       "  -0.27731407247357326,\n",
       "  -0.42639114026440017,\n",
       "  1.2257115992005412,\n",
       "  -0.3887331299967891,\n",
       "  -0.5428163856819626,\n",
       "  0.08867045820276626,\n",
       "  -0.1030578174780543,\n",
       "  1751155200.0,\n",
       "  1.6350046360179311,\n",
       "  1.529569431924437,\n",
       "  -0.8947976333383085,\n",
       "  -1.3289054051080789],\n",
       " [1.6144352135990112,\n",
       "  -0.3047324205322801,\n",
       "  0.05202013465546201,\n",
       "  -0.7371590489555888,\n",
       "  1.613364767968416,\n",
       "  -0.252086170435733,\n",
       "  -0.5103128901731695,\n",
       "  -0.25939936061075025,\n",
       "  1786924800.0,\n",
       "  -0.996068095434979,\n",
       "  0.26803943050166756,\n",
       "  0.7219114729060664,\n",
       "  1.2979745637419402],\n",
       " [-1.152850108443517,\n",
       "  1.6600537055103475,\n",
       "  1.4858309677656496,\n",
       "  -0.28680476022191687,\n",
       "  0.4565216454253383,\n",
       "  -0.7402625060952953,\n",
       "  1.443104781436309,\n",
       "  0.7787662726971207,\n",
       "  1777334400.0,\n",
       "  0.041705458508779054,\n",
       "  0.4597192113996115,\n",
       "  1.2099933147611677,\n",
       "  -0.4558879831635311],\n",
       " [0.17500329246254828,\n",
       "  -1.5370966477394732,\n",
       "  -1.2535607904208472,\n",
       "  0.8803505614234358,\n",
       "  0.2684862698736051,\n",
       "  1.611456290657643,\n",
       "  -0.5214880474562389,\n",
       "  -0.28644923216955304,\n",
       "  1780272000.0,\n",
       "  0.7131322338592732,\n",
       "  0.8535106326720501,\n",
       "  -0.30435332163159984,\n",
       "  0.14296160495125074],\n",
       " [-0.5480235275123443,\n",
       "  1.2237592864057216,\n",
       "  1.42140412103078,\n",
       "  0.5445001425219295,\n",
       "  -1.1101254858512914,\n",
       "  -0.944127512298856,\n",
       "  -1.2928948738359214,\n",
       "  1.0609631786136238,\n",
       "  1752796800.0,\n",
       "  -0.3945479955886204,\n",
       "  0.2640217988793413,\n",
       "  -1.0327985753968099,\n",
       "  -1.457670825114546],\n",
       " [-0.999430368995018,\n",
       "  0.2643374956685082,\n",
       "  0.7228311066457781,\n",
       "  1.3024170081448763,\n",
       "  -1.4295387289713561,\n",
       "  -1.5600579516851778,\n",
       "  -0.38539798887953597,\n",
       "  -1.3176517951653872,\n",
       "  1787097600.0,\n",
       "  1.4377383083315454,\n",
       "  0.9976227299103985,\n",
       "  -0.347199307813502,\n",
       "  -0.2539882874936512],\n",
       " [0.06760896388087274,\n",
       "  -1.2049999225809451,\n",
       "  -0.11498801816942611,\n",
       "  -0.5309772551062182,\n",
       "  -0.5518376007007069,\n",
       "  1.1696753601277738,\n",
       "  -1.5492165179959025,\n",
       "  -0.0032829956359945976,\n",
       "  1787788800.0,\n",
       "  -0.09891028038641356,\n",
       "  0.9449545906938609,\n",
       "  0.4327503767193687,\n",
       "  0.7721676644061543],\n",
       " [0.5122522648110883,\n",
       "  0.9121556779168215,\n",
       "  -1.5459284983581278,\n",
       "  -1.141973542026329,\n",
       "  1.4799631015008063,\n",
       "  1.6313871776774242,\n",
       "  1.2925865722696332,\n",
       "  0.21926728987417946,\n",
       "  1772668800.0,\n",
       "  1.0033653726564788,\n",
       "  -0.20387810586564242,\n",
       "  -0.9679037916784825,\n",
       "  -1.2218776350055152],\n",
       " [0.1401984327091369,\n",
       "  0.5339853705998401,\n",
       "  -0.21710598658500133,\n",
       "  -0.05638303653400458,\n",
       "  -1.3479624967104322,\n",
       "  1.5044252819954254,\n",
       "  1.4062667526135741,\n",
       "  -0.7164996325964236,\n",
       "  1774396800.0,\n",
       "  0.8853656383546327,\n",
       "  0.34469096342226263,\n",
       "  1.3996625308208748,\n",
       "  -0.2102217123593465],\n",
       " [1.4634181878160457,\n",
       "  0.47472428238498626,\n",
       "  -0.4643277941459397,\n",
       "  -0.7808187986996497,\n",
       "  -0.2928163338946759,\n",
       "  1.5936845909706772,\n",
       "  0.3749561557458921,\n",
       "  1.3089261781102939,\n",
       "  1774656000.0,\n",
       "  -0.755353507333162,\n",
       "  -1.0585710908870256,\n",
       "  1.6711662913334522,\n",
       "  -1.8010301069289496],\n",
       " [-0.5896173662242306,\n",
       "  1.6054585686482692,\n",
       "  1.7143762815743353,\n",
       "  0.9920239517330505,\n",
       "  1.2568790954923452,\n",
       "  0.04831600544525957,\n",
       "  0.26396754401188255,\n",
       "  -0.8573070191884048,\n",
       "  1794096000.0,\n",
       "  0.253191005042613,\n",
       "  -1.1860570391426126,\n",
       "  -0.5892605925013147,\n",
       "  -0.11891448162837007],\n",
       " [1.3622951349618964,\n",
       "  -0.900664910012125,\n",
       "  1.4882168918954815,\n",
       "  -0.3685607857148688,\n",
       "  0.6421693258037136,\n",
       "  -1.693780636443093,\n",
       "  1.097788626923986,\n",
       "  -1.5724408893424155,\n",
       "  1785974400.0,\n",
       "  -0.05562260608522724,\n",
       "  -1.156968912909098,\n",
       "  0.7220818618773073,\n",
       "  0.2577352245054],\n",
       " [-1.2478626187099717,\n",
       "  0.4824473816579333,\n",
       "  -0.11278296522537866,\n",
       "  0.19567456537693012,\n",
       "  -0.6822300906589981,\n",
       "  0.5428971216870037,\n",
       "  -1.3763798160402134,\n",
       "  -0.4440505391013505,\n",
       "  1787616000.0,\n",
       "  0.07043236967896811,\n",
       "  -1.2024439484406684,\n",
       "  -0.11574928278462572,\n",
       "  -0.5340804959525154],\n",
       " [0.927486031993154,\n",
       "  -0.43763157069610265,\n",
       "  1.5410369163984,\n",
       "  -0.26447238059924955,\n",
       "  -1.6430056117223624,\n",
       "  0.4017709194613125,\n",
       "  -1.6795593312079131,\n",
       "  -0.528546050848915,\n",
       "  1741824000.0,\n",
       "  -0.1227860239632269,\n",
       "  -0.13893499404994888,\n",
       "  -0.2395306815508928,\n",
       "  0.982874609095772],\n",
       " [-1.6000022808720953,\n",
       "  -0.36434167209059404,\n",
       "  1.1124892694450739,\n",
       "  1.7075909147743802,\n",
       "  1.486660673430563,\n",
       "  -1.4136503508371479,\n",
       "  1.4813785714039591,\n",
       "  -1.7092401755222366,\n",
       "  1783728000.0,\n",
       "  -1.4795503270166817,\n",
       "  0.57203967237405,\n",
       "  0.6614585400956311,\n",
       "  0.795031384317114],\n",
       " [-0.5281289850136994,\n",
       "  -0.206929297699966,\n",
       "  1.3329577093041192,\n",
       "  1.3114158506576947,\n",
       "  0.06968885354703186,\n",
       "  1.4799502930287802,\n",
       "  -0.5156523306968117,\n",
       "  0.25623814672081563,\n",
       "  1750550400.0,\n",
       "  -1.244846653556298,\n",
       "  1.1529550891873432,\n",
       "  -0.0740391767195102,\n",
       "  1.706188789950393],\n",
       " [0.8829539916518114,\n",
       "  0.340929293372076,\n",
       "  1.4007103009701651,\n",
       "  -0.20688173581422747,\n",
       "  1.46834576873317,\n",
       "  0.4766619708620429,\n",
       "  -0.46218200308325397,\n",
       "  -0.7798277742252027,\n",
       "  1774569600.0,\n",
       "  -0.2937646397195693,\n",
       "  1.5959474280981951,\n",
       "  0.3729997661667981,\n",
       "  1.3046568199945663],\n",
       " [-0.31342553614363594,\n",
       "  -1.0691499318904787,\n",
       "  1.6020421945622372,\n",
       "  1.6684313955351313,\n",
       "  -1.4187253770014574,\n",
       "  0.35754345103412266,\n",
       "  -1.0216868526059395,\n",
       "  0.7038861340299405,\n",
       "  1750032000.0,\n",
       "  1.5825915698370983,\n",
       "  0.9151610466861984,\n",
       "  -1.3552587169362917,\n",
       "  -1.6163139848659533],\n",
       " [-0.3827299221613228,\n",
       "  -0.7466803213595335,\n",
       "  0.7647346747213313,\n",
       "  0.910427800138416,\n",
       "  -1.274038630854003,\n",
       "  1.4417072095943497,\n",
       "  0.8862000051623781,\n",
       "  0.8455331875471597,\n",
       "  1762732800.0,\n",
       "  -1.4036491802490156,\n",
       "  0.8197593063688192,\n",
       "  -1.3240277807795757,\n",
       "  -1.3806547812064793],\n",
       " [-1.459557281337327,\n",
       "  -1.105750654391709,\n",
       "  -1.4088046398637064,\n",
       "  -1.5598607633819699,\n",
       "  -0.5442065223419792,\n",
       "  1.2260567439546364,\n",
       "  1.4212032244016388,\n",
       "  0.5447498517582307,\n",
       "  1752710400.0,\n",
       "  -1.1102102571919383,\n",
       "  -0.9426246552521977,\n",
       "  -1.2966137375887594,\n",
       "  1.0567362711664687],\n",
       " [1.5103719741233625,\n",
       "  0.7066557328613079,\n",
       "  0.3922098566055175,\n",
       "  0.16190455747430338,\n",
       "  -0.8246958223107226,\n",
       "  -1.6925653127513933,\n",
       "  -0.6131829632589935,\n",
       "  -1.6349866642292328,\n",
       "  1790294400.0,\n",
       "  0.2228999393804792,\n",
       "  -0.47744898450011747,\n",
       "  0.250862365470473,\n",
       "  -0.43458414817777513],\n",
       " [-0.5741149843654604,\n",
       "  -0.21456960513421738,\n",
       "  -0.19309309873345346,\n",
       "  1.1630984474298522,\n",
       "  -1.6138596239675742,\n",
       "  -1.4554274848458975,\n",
       "  -0.5620972043637456,\n",
       "  -0.8133890287598519,\n",
       "  1767571200.0,\n",
       "  1.093622867140788,\n",
       "  1.1433664136972015,\n",
       "  0.5698683375604803,\n",
       "  0.2116751682612933],\n",
       " [1.076619124052793,\n",
       "  0.3378858043446843,\n",
       "  -1.1922116305231596,\n",
       "  -0.5953579871779524,\n",
       "  1.5566621856036003,\n",
       "  -0.541916408189318,\n",
       "  -0.9566247683950665,\n",
       "  -1.2956725406343717,\n",
       "  1769126400.0,\n",
       "  0.9982767834803403,\n",
       "  1.170676435157366,\n",
       "  -1.460914609443201,\n",
       "  1.458023503560349],\n",
       " [-1.0563050932663474,\n",
       "  -1.7654385987251915,\n",
       "  0.32075507017096544,\n",
       "  -1.495640487229708,\n",
       "  1.5153254795979296,\n",
       "  0.7087048203547318,\n",
       "  0.3932897345623011,\n",
       "  0.162368270999249,\n",
       "  1790208000.0,\n",
       "  -0.825082166632296,\n",
       "  -1.6912865849140541,\n",
       "  -0.616183552617578,\n",
       "  -1.6387520315534692],\n",
       " [-0.18355715171645098,\n",
       "  0.6873880175210249,\n",
       "  0.6903584387301006,\n",
       "  -0.7580668094465957,\n",
       "  0.09603897232433516,\n",
       "  -1.3240383960125632,\n",
       "  -0.06461331126520055,\n",
       "  -0.3949632437928843,\n",
       "  1778716800.0,\n",
       "  -1.0359774562098227,\n",
       "  0.6837537135148382,\n",
       "  -0.013516351777502322,\n",
       "  -0.14415602321070484],\n",
       " [1.0332691325579424,\n",
       "  1.5847916049237283,\n",
       "  -0.5773139982449987,\n",
       "  -0.28542398262826135,\n",
       "  -0.34129072310999914,\n",
       "  0.5236109069899331,\n",
       "  0.3456013201889042,\n",
       "  0.6798468015044465,\n",
       "  1749168000.0,\n",
       "  1.6740358057784095,\n",
       "  -1.1926423004723579,\n",
       "  -1.1380457121079965,\n",
       "  0.7847776709126502],\n",
       " [-0.7585941556941499,\n",
       "  -1.0612391864166975,\n",
       "  1.6722653923020057,\n",
       "  -1.7988529864064515,\n",
       "  1.2275302250439823,\n",
       "  1.5939710699082814,\n",
       "  0.9106731883651227,\n",
       "  0.6106628155136844,\n",
       "  1774828800.0,\n",
       "  -1.031067365432845,\n",
       "  -1.3054915991200966,\n",
       "  -1.6296180862999292,\n",
       "  0.30919745702236673],\n",
       " [-0.24271038306396323,\n",
       "  -0.1615911098378893,\n",
       "  0.281683991070732,\n",
       "  0.8961770151207803,\n",
       "  1.1345842599105822,\n",
       "  -0.07958890629164647,\n",
       "  -0.1963939949849303,\n",
       "  -1.055798885430741,\n",
       "  1775952000.0,\n",
       "  -0.8828415184812437,\n",
       "  -0.024617638016285553,\n",
       "  -1.5261234257193483,\n",
       "  0.11665226520878769],\n",
       " [-0.3999822747652955,\n",
       "  0.21437965729279598,\n",
       "  -0.011038444746618883,\n",
       "  1.4229914126807823,\n",
       "  1.0397073478117205,\n",
       "  0.3861614491640011,\n",
       "  -0.4970846773312976,\n",
       "  -1.5523865534790307,\n",
       "  1755561600.0,\n",
       "  0.8395209286725145,\n",
       "  -0.9339690682345066,\n",
       "  -0.01648192723601678,\n",
       "  1.0475416587426716],\n",
       " [-0.23029785189423177,\n",
       "  0.4727190504324625,\n",
       "  -1.1538393528245339,\n",
       "  -1.3497259638165116,\n",
       "  0.02288117036153661,\n",
       "  0.9822264019464224,\n",
       "  0.8535104707868306,\n",
       "  0.6600559504475474,\n",
       "  1775433600.0,\n",
       "  -0.6371474942765474,\n",
       "  -1.4956771349352536,\n",
       "  0.9817200219129925,\n",
       "  -0.8688046133845161],\n",
       " [-1.2447618723363645,\n",
       "  -0.2497815592258289,\n",
       "  -0.30312114856057987,\n",
       "  1.5073593971991377,\n",
       "  0.3396499930636178,\n",
       "  -0.22188743689291085,\n",
       "  -0.48984238530281726,\n",
       "  -0.26812038084346634,\n",
       "  1784332800.0,\n",
       "  -1.5476036490700193,\n",
       "  -0.3467456374892963,\n",
       "  0.29581547479311976,\n",
       "  0.17501156084356018],\n",
       " [-0.016827655355950946,\n",
       "  -0.21404350764754707,\n",
       "  -0.5725648968529156,\n",
       "  -1.094499636458159,\n",
       "  0.7825075873197458,\n",
       "  0.17865881659232347,\n",
       "  -1.0140245881185115,\n",
       "  -1.4301812755101992,\n",
       "  1744934400.0,\n",
       "  -1.2830955204243306,\n",
       "  -1.6271891135211738,\n",
       "  1.052832840331128,\n",
       "  -0.5623636295929532],\n",
       " [0.5639779388077073,\n",
       "  0.6610613510240896,\n",
       "  -0.7954106030644948,\n",
       "  -0.35725145560022203,\n",
       "  -0.11292918143688109,\n",
       "  1.330384987061462,\n",
       "  0.6196985604733595,\n",
       "  0.8685120806683135,\n",
       "  1772409600.0,\n",
       "  1.2638135846206076,\n",
       "  -0.040381635426665737,\n",
       "  -1.2086070776696929,\n",
       "  0.07689916666453142],\n",
       " [0.8690391148229246,\n",
       "  1.4884798778198922,\n",
       "  -0.3578460378012503,\n",
       "  1.6692832752942206,\n",
       "  -1.039085586501621,\n",
       "  -0.49796844081624814,\n",
       "  0.42012689193815916,\n",
       "  -1.4899341257894831,\n",
       "  1787443200.0,\n",
       "  -1.2443748838606683,\n",
       "  0.4863194240191312,\n",
       "  -0.11354464665167019,\n",
       "  0.1920405414241648],\n",
       " [0.08293844233448336,\n",
       "  0.412626885385828,\n",
       "  -0.5882859778886937,\n",
       "  -1.3088570517145264,\n",
       "  0.5178062493915889,\n",
       "  1.616620763186782,\n",
       "  -1.6242424708384606,\n",
       "  0.14895243617276577,\n",
       "  1781481600.0,\n",
       "  -1.0342146188847539,\n",
       "  -0.09919811617557145,\n",
       "  -1.4618359735343514,\n",
       "  -0.13237051813605646],\n",
       " [0.30432052466148535,\n",
       "  -0.8702363165845153,\n",
       "  0.3109943096111026,\n",
       "  -0.4717350075980594,\n",
       "  -1.0738997867321929,\n",
       "  -0.7457215557697155,\n",
       "  -1.6475309461393293,\n",
       "  -1.1285872696564432,\n",
       "  1742428800.0,\n",
       "  1.5866908119018779,\n",
       "  -1.3362237106363553,\n",
       "  -0.9330696486435562,\n",
       "  1.5194982177731018],\n",
       " [-1.2617143458498845,\n",
       "  0.4034043037193837,\n",
       "  1.4200806184811319,\n",
       "  1.3568223675348368,\n",
       "  1.4313900782947242,\n",
       "  0.8425780825711375,\n",
       "  0.8606425326297997,\n",
       "  0.09356484545886316,\n",
       "  1745971200.0,\n",
       "  0.40967410294322654,\n",
       "  -1.31298228538172,\n",
       "  -0.017776249117840915,\n",
       "  -0.860297675702527],\n",
       " [-1.6111736741992886,\n",
       "  0.6773695649255982,\n",
       "  -0.5029585599702823,\n",
       "  0.6191377230803607,\n",
       "  1.5212158247631495,\n",
       "  1.4550263878308856,\n",
       "  -0.5321614612065739,\n",
       "  -1.1490691725854525,\n",
       "  1771200000.0,\n",
       "  1.425923161406717,\n",
       "  0.15341443725837242,\n",
       "  0.41123110195424367,\n",
       "  0.5584252371889413],\n",
       " [-1.1241336628547927,\n",
       "  0.016921171641375674,\n",
       "  1.416287974537784,\n",
       "  -0.8400708033637238,\n",
       "  -0.5858233262276191,\n",
       "  1.6079393602146386,\n",
       "  1.7138107975095875,\n",
       "  0.9920233391721731,\n",
       "  1794009600.0,\n",
       "  1.2542934466373985,\n",
       "  0.05011606231372201,\n",
       "  0.2618938690408133,\n",
       "  -0.8612055233957016],\n",
       " [0.9462546582083947,\n",
       "  0.1563507457990727,\n",
       "  -0.6965079911919172,\n",
       "  -0.35566261970120877,\n",
       "  1.485824396896425,\n",
       "  -1.519643774606649,\n",
       "  1.2100444053214003,\n",
       "  0.07922869179458573,\n",
       "  1746316800.0,\n",
       "  0.9185575764915231,\n",
       "  -0.3401918752539532,\n",
       "  -0.8302329176637084,\n",
       "  1.1685366962408936],\n",
       " [-0.34152896118601805,\n",
       "  0.046025996250657196,\n",
       "  -0.9350666793907362,\n",
       "  0.32141267538111634,\n",
       "  -1.1212375823001932,\n",
       "  -0.9482554489904286,\n",
       "  1.1077455039182147,\n",
       "  0.8995055916374415,\n",
       "  1740614400.0,\n",
       "  0.41370287153087265,\n",
       "  0.010256511999496795,\n",
       "  -0.4442071387135131,\n",
       "  -1.025741404619839],\n",
       " [-1.6754275081353474,\n",
       "  0.22377791898909236,\n",
       "  0.8438302718663495,\n",
       "  0.041522308526115256,\n",
       "  1.037959215612404,\n",
       "  1.5872624699388453,\n",
       "  -0.5750276021830701,\n",
       "  -0.28471005652963144,\n",
       "  1749081600.0,\n",
       "  -0.34218781293346884,\n",
       "  0.5255532969559651,\n",
       "  0.34361391036961725,\n",
       "  0.6756851402635606],\n",
       " [-1.3128824068859815,\n",
       "  1.0809162822527276,\n",
       "  1.2397202502491325,\n",
       "  0.4691231028253358,\n",
       "  1.2870705983996353,\n",
       "  -0.927785664975866,\n",
       "  -1.01796157150703,\n",
       "  -1.461960680119895,\n",
       "  1770854400.0,\n",
       "  0.465942349914871,\n",
       "  1.4170771546266865,\n",
       "  -0.2992783358166731,\n",
       "  0.14105910638504363],\n",
       " [0.1726065850639621,\n",
       "  0.4125540628807975,\n",
       "  -0.7461449812295895,\n",
       "  -1.6121394197792185,\n",
       "  -0.7411001598838598,\n",
       "  -0.7111673758667146,\n",
       "  1.6393592410732172,\n",
       "  -0.03630404886485951,\n",
       "  1792713600.0,\n",
       "  0.5410156019881552,\n",
       "  -0.8513915235534912,\n",
       "  -0.2949536201347553,\n",
       "  -0.21873443687426686],\n",
       " [-1.5799280063132806,\n",
       "  0.25866955498290783,\n",
       "  -1.4690810329224049,\n",
       "  1.371676740118407,\n",
       "  0.875877214371668,\n",
       "  1.0368695660520708,\n",
       "  0.47669130856299086,\n",
       "  -1.5375854783911496,\n",
       "  1753920000.0,\n",
       "  1.2964712880586182,\n",
       "  -0.3657212051907381,\n",
       "  -0.4428363652080826,\n",
       "  1.05037453624603],\n",
       " [0.018751232284734687,\n",
       "  0.9800460023474492,\n",
       "  0.853004025350097,\n",
       "  0.6598707736073345,\n",
       "  -0.6365623760661909,\n",
       "  -1.4970144229712914,\n",
       "  0.9830338353944601,\n",
       "  -0.8649074103458885,\n",
       "  1775520000.0,\n",
       "  1.504395542181198,\n",
       "  -0.647268832143989,\n",
       "  -0.09494903568947521,\n",
       "  -0.8186242573979513],\n",
       " [1.637298302612453,\n",
       "  1.4631005563312653,\n",
       "  0.5672176217801089,\n",
       "  -0.925065455405719,\n",
       "  1.6853305131850849,\n",
       "  1.5408203212985017,\n",
       "  0.6676952295585294,\n",
       "  0.9239964399421507,\n",
       "  1777939200.0,\n",
       "  1.3272487331648606,\n",
       "  -1.1897317115915784,\n",
       "  -1.225359190004833,\n",
       "  -0.9122832383114201],\n",
       " [0.6608762822572549,\n",
       "  -0.9190116086973121,\n",
       "  -1.0827609916864596,\n",
       "  1.1305985608696847,\n",
       "  0.14339017613495683,\n",
       "  -1.0681510159580176,\n",
       "  -1.2947906522079549,\n",
       "  -0.12658678906403847,\n",
       "  1776384000.0,\n",
       "  1.0436147764605817,\n",
       "  -0.6964623290857684,\n",
       "  -0.638402519843228,\n",
       "  0.6376198541702358],\n",
       " [0.7908551148286791,\n",
       "  1.3308133831737725,\n",
       "  0.19442533946194876,\n",
       "  -0.9551020235122981,\n",
       "  1.149691012933946,\n",
       "  1.6071823113954093,\n",
       "  1.6424222908010657,\n",
       "  -0.947256285755942,\n",
       "  1782345600.0,\n",
       "  -0.45021370098105046,\n",
       "  -0.10626898766192515,\n",
       "  0.3792306192282301,\n",
       "  1.5325697334134671],\n",
       " [1.1641963769369736,\n",
       "  1.309815143373073,\n",
       "  1.018375519396656,\n",
       "  0.6578826924122165,\n",
       "  -1.0512275120703123,\n",
       "  0.2599999408823036,\n",
       "  -1.4189201014001271,\n",
       "  0.2008926894031351,\n",
       "  1736726400.0,\n",
       "  1.553289967861473,\n",
       "  -0.1962982645109705,\n",
       "  0.5159970864814555,\n",
       "  -0.4402268758189796],\n",
       " [1.4025349614422424,\n",
       "  0.2371224302146614,\n",
       "  0.9934866802588316,\n",
       "  -0.8416378141614366,\n",
       "  1.1480903152534923,\n",
       "  1.4555271565098964,\n",
       "  1.0224280616351116,\n",
       "  0.6650335331364794,\n",
       "  1793059200.0,\n",
       "  -1.0416485608319848,\n",
       "  -0.0686274888826663,\n",
       "  1.4498570545667944,\n",
       "  1.6296408930731816],\n",
       " [0.49331783005523244,\n",
       "  1.328110208671417,\n",
       "  0.24351487142854766,\n",
       "  1.7170450920373763,\n",
       "  0.19292603856234233,\n",
       "  0.11839416801365153,\n",
       "  1.3360131414379868,\n",
       "  -0.7847182925504298,\n",
       "  1739145600.0,\n",
       "  0.016297983204084734,\n",
       "  1.1499296435110908,\n",
       "  0.5718425322706274,\n",
       "  -1.065219863024385],\n",
       " [-1.6097666283450358,\n",
       "  -0.3588456457450218,\n",
       "  0.28866807925062815,\n",
       "  1.3762316576523153,\n",
       "  -1.1161452487445613,\n",
       "  -1.1152547493792313,\n",
       "  -0.2524673491030783,\n",
       "  -0.9663071516570502,\n",
       "  1775088000.0,\n",
       "  0.1786881664302234,\n",
       "  1.6624355926861702,\n",
       "  -0.8483276910106811,\n",
       "  -1.1600319777858064],\n",
       " [-0.3166929226276643,\n",
       "  -0.1085113985211992,\n",
       "  1.06555112693512,\n",
       "  -1.6762671044262905,\n",
       "  0.5656548115322629,\n",
       "  -1.3372283784140133,\n",
       "  0.15584730592013124,\n",
       "  -0.3664041168197569,\n",
       "  1748044800.0,\n",
       "  -1.6804466180052933,\n",
       "  -0.7245582907470631,\n",
       "  -0.7130676609492269,\n",
       "  -1.7295161486498527],\n",
       " [0.6726113765276794,\n",
       "  0.8926237892657418,\n",
       "  1.359100359809123,\n",
       "  -0.9268700454080206,\n",
       "  0.19941266738696928,\n",
       "  0.6721454674552089,\n",
       "  -1.1873595828720092,\n",
       "  0.7641317959217427,\n",
       "  1757894400.0,\n",
       "  -0.41291362748317073,\n",
       "  0.3344986559575583,\n",
       "  0.12523031347264568,\n",
       "  -0.5611713418928844],\n",
       " [0.38758054754611054,\n",
       "  1.432632595320368,\n",
       "  1.3163456869029682,\n",
       "  -1.450613964901645,\n",
       "  -0.36185322665462716,\n",
       "  -0.21822835667583665,\n",
       "  -1.229153373749342,\n",
       "  0.7706740474403485,\n",
       "  1762214400.0,\n",
       "  -0.3509211339232262,\n",
       "  -0.7682696361500463,\n",
       "  -1.3844751996916869,\n",
       "  0.5954355312896946],\n",
       " [-0.12366570494825162,\n",
       "  1.4964688667221069,\n",
       "  -0.5021203860735055,\n",
       "  0.32284293649611734,\n",
       "  1.4394986128276228,\n",
       "  0.20260521633725082,\n",
       "  -1.3506945052441572,\n",
       "  0.7363964361253502,\n",
       "  1781136000.0,\n",
       "  1.2218340632431393,\n",
       "  0.7285568650669777,\n",
       "  0.49923091532021346,\n",
       "  1.7023377647114046],\n",
       " [-1.3270482792681364,\n",
       "  0.5197007061883785,\n",
       "  -0.019014876092704535,\n",
       "  -1.3979089036941066,\n",
       "  0.08710382004554869,\n",
       "  0.4145347478564053,\n",
       "  -0.5859859278129694,\n",
       "  -1.3075706698048923,\n",
       "  1781395200.0,\n",
       "  0.5160014738297534,\n",
       "  1.618890468842507,\n",
       "  -1.6283114807205938,\n",
       "  0.14488166276916012],\n",
       " [-0.08896738114122774,\n",
       "  1.5340129489668757,\n",
       "  -1.4107753218212877,\n",
       "  1.7058975337151794,\n",
       "  -0.01220526164294663,\n",
       "  -0.02957860538337425,\n",
       "  0.2856897332743333,\n",
       "  1.078688230143063,\n",
       "  1767830400.0,\n",
       "  0.39216559022527236,\n",
       "  1.299719977247511,\n",
       "  -0.03823463841886546,\n",
       "  -1.2299674326002301],\n",
       " [-0.5173026064131423,\n",
       "  -0.5682252275211114,\n",
       "  -0.22507172942674314,\n",
       "  1.261146086434396,\n",
       "  1.5956925565355649,\n",
       "  0.7360155068989408,\n",
       "  -0.05522663328317683,\n",
       "  -1.5564558520819562,\n",
       "  1741132800.0,\n",
       "  0.8005031041121864,\n",
       "  0.6088434792617351,\n",
       "  0.750316697869963,\n",
       "  0.6540901588627562],\n",
       " [0.9024205178869962,\n",
       "  -0.2905625556770565,\n",
       "  0.2311950791523116,\n",
       "  1.0733239746279621,\n",
       "  -0.9201452299574878,\n",
       "  -0.3500687371454774,\n",
       "  0.835337116605399,\n",
       "  0.20804252934828862,\n",
       "  1745625600.0,\n",
       "  0.2649521217050797,\n",
       "  -0.4314936460599901,\n",
       "  -1.0529422901391476,\n",
       "  -0.8688450764978249],\n",
       " [1.3250603555201692,\n",
       "  -1.1922975924903787,\n",
       "  -1.2248077095395564,\n",
       "  -0.9094564577467161,\n",
       "  1.1217377439031517,\n",
       "  -0.6274322432769686,\n",
       "  0.6990612602507944,\n",
       "  -1.7003796715738448,\n",
       "  1778112000.0,\n",
       "  -0.3222154653395514,\n",
       "  1.0779494436400907,\n",
       "  -0.6576030205539249,\n",
       "  1.2898685583514649],\n",
       " [0.45204316668186645,\n",
       "  -0.7850119883849455,\n",
       "  0.7914698194344759,\n",
       "  1.1603951639476973,\n",
       "  -1.0488412319428952,\n",
       "  1.4888002907045452,\n",
       "  0.8799813364939143,\n",
       "  -1.3020076669326037,\n",
       "  1779321600.0,\n",
       "  0.9170796975571678,\n",
       "  -0.34283136508259676,\n",
       "  0.4861040110267742,\n",
       "  -1.496486573617528],\n",
       " [-1.6238614220318555,\n",
       "  1.638986258622371,\n",
       "  1.1010885972818483,\n",
       "  -0.9837370281552179,\n",
       "  0.052797885422371536,\n",
       "  -0.7571691858595267,\n",
       "  -0.5508813502942163,\n",
       "  1.453853980165311,\n",
       "  1794441600.0,\n",
       "  0.9976569675663506,\n",
       "  1.2019574032157294,\n",
       "  1.7113736562860355,\n",
       "  -0.844080049954129],\n",
       " [0.37843855319255576,\n",
       "  0.13939290237401378,\n",
       "  -0.5705749707471026,\n",
       "  1.1476773125692281,\n",
       "  0.1884935960002499,\n",
       "  -0.6946517668974895,\n",
       "  0.3206653451096417,\n",
       "  -1.7528184419121349,\n",
       "  1758672000.0,\n",
       "  0.9779533444677604,\n",
       "  -0.5991610840129967,\n",
       "  -1.7100716574487669,\n",
       "  1.493771024973789],\n",
       " [-1.2436687942337137,\n",
       "  -1.1929769492227613,\n",
       "  -0.9564680891424127,\n",
       "  1.666096151893422,\n",
       "  -1.4645835897283852,\n",
       "  -0.30932310100643506,\n",
       "  1.680272268828864,\n",
       "  -0.9234909642490917,\n",
       "  1786492800.0,\n",
       "  -1.45877222053466,\n",
       "  -0.7577436979588077,\n",
       "  0.10036001645027569,\n",
       "  -1.7775494933006144],\n",
       " [-0.4985536068645256,\n",
       "  0.5190327727270164,\n",
       "  -0.800211803295899,\n",
       "  0.9338737202251389,\n",
       "  0.8687940983816973,\n",
       "  -0.6261639606889017,\n",
       "  -1.6841693605340318,\n",
       "  -0.02001624092880591,\n",
       "  1761696000.0,\n",
       "  -1.5651869781368923,\n",
       "  1.2344257240647791,\n",
       "  -0.06582471019281265,\n",
       "  -0.6385892300345007],\n",
       " [0.9382657537202437,\n",
       "  1.5956151961819975,\n",
       "  1.3976048540897648,\n",
       "  0.6387330967901301,\n",
       "  -0.2727847270035389,\n",
       "  -1.5735854158275506,\n",
       "  -0.9290722202870876,\n",
       "  0.5657459044902408,\n",
       "  1771804800.0,\n",
       "  -0.8645140451476512,\n",
       "  -1.299520402109194,\n",
       "  -1.3534059256319162,\n",
       "  1.1059725824429993],\n",
       " [0.43616488383046265,\n",
       "  -0.3854323982220146,\n",
       "  1.0240411339751945,\n",
       "  0.008131144910433137,\n",
       "  -1.6722329756462129,\n",
       "  0.2255950753952038,\n",
       "  0.8443481335251956,\n",
       "  0.042053357688371935,\n",
       "  1748995200.0,\n",
       "  1.0356048682975305,\n",
       "  1.5895233838806182,\n",
       "  -0.5779878714907069,\n",
       "  -0.2887065879584769],\n",
       " [-1.310732695814484,\n",
       "  0.2050559670310115,\n",
       "  0.11120948066739617,\n",
       "  -0.6535352876629905,\n",
       "  -0.1205941263031072,\n",
       "  -0.06342199285759428,\n",
       "  0.5501135827946405,\n",
       "  -0.897794662481987,\n",
       "  1773446400.0,\n",
       "  -1.6368370529408487,\n",
       "  0.6998688145571474,\n",
       "  -0.34828578852860487,\n",
       "  -0.5062502996807843],\n",
       " [-0.5781753447888035,\n",
       "  -0.07790634170357942,\n",
       "  0.8939757646205487,\n",
       "  -0.7771099338638214,\n",
       "  0.011126435161799368,\n",
       "  0.3695791250740617,\n",
       "  -0.8621087857261233,\n",
       "  1.2615832220307077,\n",
       "  1774051200.0,\n",
       "  0.2999954387100234,\n",
       "  0.3807371748934754,\n",
       "  0.7752228069655543,\n",
       "  -0.9772956980321558],\n",
       " [-0.07647036848396511,\n",
       "  0.6566843557460491,\n",
       "  1.459500414937781,\n",
       "  0.990198138454093,\n",
       "  0.10097802263513661,\n",
       "  1.6069452768113412,\n",
       "  -0.8591295201652905,\n",
       "  0.6779384933015407,\n",
       "  1759017600.0,\n",
       "  -1.0776019023511925,\n",
       "  0.11412046145942042,\n",
       "  1.5722563279646176,\n",
       "  -0.996442249575746],\n",
       " [0.1275175999009022,\n",
       "  1.5899185062954537,\n",
       "  -1.6359882573183866,\n",
       "  -1.6864927273094965,\n",
       "  0.5585450558617867,\n",
       "  -0.3553374990567015,\n",
       "  1.6872916117077672,\n",
       "  1.0247408494541885,\n",
       "  1788307200.0,\n",
       "  -0.607745237314598,\n",
       "  -0.9307365583283252,\n",
       "  -0.40643069315326136,\n",
       "  0.3828852559442399],\n",
       " [1.3662216449651754,\n",
       "  -0.0939157628555333,\n",
       "  -1.4256947885766393,\n",
       "  -1.797634433070327,\n",
       "  0.9020811910774842,\n",
       "  -1.731528938259672,\n",
       "  1.6181598246096867,\n",
       "  -0.04065725538386457,\n",
       "  1767052800.0,\n",
       "  -0.02697909267768409,\n",
       "  -1.6877849422907896,\n",
       "  0.6361262468378889,\n",
       "  1.2156145362355897],\n",
       " [-0.11246308240762305,\n",
       "  -0.4629537691665102,\n",
       "  -1.2932238208303635,\n",
       "  -0.6443436786315534,\n",
       "  0.4122229841643155,\n",
       "  -1.4647263403672777,\n",
       "  1.4136898744460649,\n",
       "  0.24764305128679764,\n",
       "  1789344000.0,\n",
       "  0.5460137380774318,\n",
       "  1.1485051858303152,\n",
       "  -0.8899224843182338,\n",
       "  -0.6909237864407921],\n",
       " [0.013447225073160518,\n",
       "  1.145540443841063,\n",
       "  0.5727337938004876,\n",
       "  -1.0625048767371905,\n",
       "  -1.2087461185342456,\n",
       "  -0.10924218129501018,\n",
       "  0.3712716095510285,\n",
       "  -1.7591736129347624,\n",
       "  1739318400.0,\n",
       "  -0.8373808824162826,\n",
       "  1.137453236659066,\n",
       "  1.7269113502995237,\n",
       "  0.19843121642983966],\n",
       " [-0.029441226055023594,\n",
       "  1.6666637263534112,\n",
       "  0.9915174022412666,\n",
       "  -0.6356990162594838,\n",
       "  -0.36278068288727744,\n",
       "  -1.3559767258268578,\n",
       "  -0.10832642821297321,\n",
       "  -0.12895969216667863,\n",
       "  1747008000.0,\n",
       "  0.35257443099330704,\n",
       "  -1.5778654998174528,\n",
       "  1.6103054757844237,\n",
       "  0.9413907716694957],\n",
       " [1.2615931552725717,\n",
       "  -0.04384321499741807,\n",
       "  -1.2080524300304187,\n",
       "  0.08044902407558806,\n",
       "  0.5166546792283916,\n",
       "  0.9143034691078065,\n",
       "  -1.5424367158320647,\n",
       "  -1.1407805061671281,\n",
       "  1772582400.0,\n",
       "  1.4771417514652097,\n",
       "  1.6336613053235969,\n",
       "  1.2915998735570975,\n",
       "  0.2151844787368947],\n",
       " [-0.8678098487538817,\n",
       "  -1.3020007237111955,\n",
       "  -1.3528786538325943,\n",
       "  1.1102746764045683,\n",
       "  -1.305931607759985,\n",
       "  0.3562154272684082,\n",
       "  1.6890511029485507,\n",
       "  1.1065519585838277,\n",
       "  1771977600.0,\n",
       "  0.5617539000557957,\n",
       "  -0.3569088830633154,\n",
       "  0.5587211309423087,\n",
       "  1.4000672838144754],\n",
       " [-0.8972553173983272,\n",
       "  -1.5996298822053714,\n",
       "  0.8016033715290788,\n",
       "  -1.4777530471972957,\n",
       "  1.6132289314130972,\n",
       "  0.958598425736412,\n",
       "  -0.729539985129249,\n",
       "  1.4868843884162866,\n",
       "  1762560000.0,\n",
       "  -0.3796790897818813,\n",
       "  -0.7437668961387534,\n",
       "  0.7638071201414363,\n",
       "  0.9062716844057764],\n",
       " [-0.6731330098025106,\n",
       "  1.2622256179911515,\n",
       "  0.12997522283564036,\n",
       "  -0.07314985000371212,\n",
       "  -0.31443611203083055,\n",
       "  -0.03748148111658916,\n",
       "  -1.2886526073397055,\n",
       "  0.24218711922244388,\n",
       "  1753142400.0,\n",
       "  -0.29051759319891735,\n",
       "  0.3424349129712241,\n",
       "  -0.34625296941783085,\n",
       "  -1.8128686133514287],\n",
       " [-1.467130153387334,\n",
       "  -0.8433209121526687,\n",
       "  -0.4371877278068621,\n",
       "  1.12334919640701,\n",
       "  0.9159446674997191,\n",
       "  0.1029460983419272,\n",
       "  0.2527529745434045,\n",
       "  0.7803819717268988,\n",
       "  1766361600.0,\n",
       "  0.07899823754252812,\n",
       "  0.2886588196722833,\n",
       "  -0.5054878120620256,\n",
       "  -1.2124407572096636],\n",
       " [1.2600343889703378,\n",
       "  -0.9736589544927854,\n",
       "  0.5246875910562309,\n",
       "  0.06404751769563966,\n",
       "  0.9058100808228565,\n",
       "  -0.034160749307803155,\n",
       "  -0.013450821953775921,\n",
       "  -0.9060950381217139,\n",
       "  1788912000.0,\n",
       "  1.0107835221124828,\n",
       "  0.25961852236713767,\n",
       "  0.2853903090723524,\n",
       "  -1.1647326017746278],\n",
       " [0.05881007271539758,\n",
       "  0.9096322735214873,\n",
       "  -0.35206612708605206,\n",
       "  0.2537833825133284,\n",
       "  -0.07707535476436818,\n",
       "  1.6391143685844394,\n",
       "  0.44687921653737905,\n",
       "  -1.526703543444027,\n",
       "  1748649600.0,\n",
       "  -1.5273832314837945,\n",
       "  -1.4587381447182994,\n",
       "  -1.1199614966367124,\n",
       "  -0.8891197720774483],\n",
       " [1.2227355320540187,\n",
       "  1.5914969842318105,\n",
       "  0.9102379673618268,\n",
       "  0.6104499952323714,\n",
       "  -1.030898886598699,\n",
       "  -1.3068858235810779,\n",
       "  -1.6255476971413443,\n",
       "  0.313296365711071,\n",
       "  1774915200.0,\n",
       "  -1.6060961275960115,\n",
       "  -0.355629741809638,\n",
       "  0.2878305133660269,\n",
       "  1.3717352953097772],\n",
       " [1.5148018192104946,\n",
       "  -1.3624423186900507,\n",
       "  1.083988748073749,\n",
       "  0.013926740936736832,\n",
       "  1.0674883868711245,\n",
       "  0.7703706552393882,\n",
       "  -1.1534330495775458,\n",
       "  1.6908090609056718,\n",
       "  1791763200.0,\n",
       "  -0.06044539327588522,\n",
       "  -0.6626122580610133,\n",
       "  1.5359829666552072,\n",
       "  -0.8015102928331382],\n",
       " [-0.09577044591202871,\n",
       "  -0.23007130402722148,\n",
       "  0.8798507797447491,\n",
       "  0.5701308890589376,\n",
       "  -0.11961439942401803,\n",
       "  1.498897309434693,\n",
       "  -0.4999275642480666,\n",
       "  0.323216629370893,\n",
       "  1781049600.0,\n",
       "  1.4367200158693325,\n",
       "  0.20445147707038017,\n",
       "  -1.3544744478078734,\n",
       "  0.7322250937231537],\n",
       " [0.4900315373868047,\n",
       "  0.7486712976922516,\n",
       "  1.7773200764127317,\n",
       "  -1.5342243503457955,\n",
       "  1.0911788789470087,\n",
       "  -0.39265834570319613,\n",
       "  0.644999803136195,\n",
       "  -1.1509667152610779,\n",
       "  1772236800.0,\n",
       "  0.5665506722731379,\n",
       "  0.6650726973909917,\n",
       "  -0.7960432505046068,\n",
       "  -0.36048159452471323],\n",
       " [0.2972880236135546,\n",
       "  0.37694741371212415,\n",
       "  0.7761525198085836,\n",
       "  -0.9745164405573411,\n",
       "  1.5885333906168713,\n",
       "  1.386747775151279,\n",
       "  1.7517165188525672,\n",
       "  -0.491821731787119,\n",
       "  1774224000.0,\n",
       "  0.14298517994798052,\n",
       "  0.5378976082958767,\n",
       "  -0.21784794830680076,\n",
       "  -0.05983294491287342],\n",
       " [0.5434306279716441,\n",
       "  1.1441170962527472,\n",
       "  -0.8893075857961271,\n",
       "  -0.6879351955835032,\n",
       "  0.7978209820080816,\n",
       "  -1.536333280492171,\n",
       "  -0.24531220685194663,\n",
       "  -0.938395480012349,\n",
       "  1789516800.0,\n",
       "  -0.10844877213021996,\n",
       "  -1.4268092854973644,\n",
       "  -1.4204251287330292,\n",
       "  -1.166626378001283],\n",
       " [-0.08115013437744846,\n",
       "  1.6366186105354774,\n",
       "  0.4458661107820161,\n",
       "  -1.528112565609106,\n",
       "  -1.527739693755635,\n",
       "  -1.4600864912927007,\n",
       "  -1.1164291101803934,\n",
       "  -0.8852260475405936,\n",
       "  1748736000.0,\n",
       "  -0.44586096807140596,\n",
       "  -1.695413536033723,\n",
       "  1.2239906765588224,\n",
       "  0.8277119581512999],\n",
       " [-0.711467455487619,\n",
       "  0.9250129042520742,\n",
       "  -0.045571919910388434,\n",
       "  0.6193772739850876,\n",
       "  1.4444420166441152,\n",
       "  0.05446523137305249,\n",
       "  1.4345549211065194,\n",
       "  0.391068054273266,\n",
       "  1783123200.0,\n",
       "  -1.4521567664017303,\n",
       "  -0.9139827450373986,\n",
       "  1.3421951239469636,\n",
       "  0.015193915384738148],\n",
       " [-1.2042459195975534,\n",
       "  0.7471093509822595,\n",
       "  0.3193787222699973,\n",
       "  -0.8075124699129372,\n",
       "  -0.6706184604014543,\n",
       "  -1.425265333027561,\n",
       "  0.22553513468379408,\n",
       "  1.0801983530225343,\n",
       "  1766102400.0,\n",
       "  -0.21356471690586884,\n",
       "  1.0523136891424352,\n",
       "  -0.11142009541590749,\n",
       "  1.4549985208945166],\n",
       " [1.1298408567852816,\n",
       "  -0.08125955012283782,\n",
       "  -0.19820861564331568,\n",
       "  -1.0569443603398108,\n",
       "  -0.8825162648080146,\n",
       "  -0.02639532162854138,\n",
       "  -1.5221622873939555,\n",
       "  0.12071820497998365,\n",
       "  1776038400.0,\n",
       "  -1.479746905224487,\n",
       "  -1.0842190071770654,\n",
       "  -0.47900107764898875,\n",
       "  -1.708662931055279],\n",
       " [1.1234285106818163,\n",
       "  0.7884917907576396,\n",
       "  0.852594974663758,\n",
       "  -0.9205337915859522,\n",
       "  0.36999031304448315,\n",
       "  1.4108109942456122,\n",
       "  0.5179474207463777,\n",
       "  -1.1340427689109556,\n",
       "  1764115200.0,\n",
       "  0.6975114484299423,\n",
       "  -0.3767055497654769,\n",
       "  0.6311630519074258,\n",
       "  1.4235709982980589],\n",
       " [0.6860677761039575,\n",
       "  -1.6501373032102755,\n",
       "  -0.4916838377907267,\n",
       "  -0.348995219878688,\n",
       "  1.2373663890731663,\n",
       "  1.3994449967375076,\n",
       "  1.5202944401168765,\n",
       "  1.0614595756728353,\n",
       "  1752105600.0,\n",
       "  0.4983654156304089,\n",
       "  -1.4362926774390927,\n",
       "  -0.08847718075440204,\n",
       "  -1.0929081322104468],\n",
       " [-0.40625227876022446,\n",
       "  -1.0483524509694684,\n",
       "  1.3137700822654426,\n",
       "  1.4356077926990305,\n",
       "  0.03276225376765635,\n",
       "  0.09888989652765927,\n",
       "  -0.02695125369795282,\n",
       "  -0.36069714016147914,\n",
       "  1746662400.0,\n",
       "  1.628895369281984,\n",
       "  -1.197132061129171,\n",
       "  -1.6703298871722974,\n",
       "  1.1727192801584858],\n",
       " [1.6083571620084225,\n",
       "  -0.2536740018657075,\n",
       "  -0.512518652057906,\n",
       "  -0.26009912128471596,\n",
       "  -0.9958625987322576,\n",
       "  0.26617413324863504,\n",
       "  0.7234995449849355,\n",
       "  1.302242777675603,\n",
       "  1787011200.0,\n",
       "  -1.4292860217098133,\n",
       "  -1.5587395428348714,\n",
       "  -0.388157870208812,\n",
       "  -1.3214714894552617],\n",
       " [0.15391377053282732,\n",
       "  -1.3341339885679233,\n",
       "  1.1948288761252577,\n",
       "  0.5155423976258797,\n",
       "  -1.2037323361737486,\n",
       "  0.8533226030495161,\n",
       "  0.119364034656096,\n",
       "  -0.16647109279844877,\n",
       "  1744329600.0,\n",
       "  1.006205590647519,\n",
       "  0.9098226150650719,\n",
       "  -0.9668857584568313,\n",
       "  -0.4175696035328754],\n",
       " [0.015372932074219562,\n",
       "  -0.1788523248767501,\n",
       "  -0.19669401911048917,\n",
       "  -1.4113641218867876,\n",
       "  1.4865214773588438,\n",
       "  -0.7417004015439188,\n",
       "  1.2799356677383862,\n",
       "  -1.212356919847709,\n",
       "  1748390400.0,\n",
       "  -0.4675499408303804,\n",
       "  0.4272702311905862,\n",
       "  0.46969759038488196,\n",
       "  1.3950074851880254],\n",
       " [-0.4141617374873529,\n",
       "  -1.111101439663544,\n",
       "  0.6255934108329958,\n",
       "  0.42257645556402146,\n",
       "  -1.5340786522462144,\n",
       "  1.6081498528401728,\n",
       "  1.728244295544156,\n",
       "  -0.16653033279563606,\n",
       "  1756684800.0,\n",
       "  1.0191959643432191,\n",
       "  0.2147221669326761,\n",
       "  1.4210241955805252,\n",
       "  0.7730093331156825],\n",
       " [-1.4387177059872844,\n",
       "  -1.4548282599075537,\n",
       "  0.7331305565679763,\n",
       "  1.4583750173004653,\n",
       "  0.21138873490229962,\n",
       "  -1.2654634441387838,\n",
       "  0.6441088505138117,\n",
       "  0.5447973523791754,\n",
       "  1770076800.0,\n",
       "  0.613920274389329,\n",
       "  0.6791496935375061,\n",
       "  0.5246050852019236,\n",
       "  1.2901526361944011],\n",
       " [1.0412830878653,\n",
       "  -0.699412619173716,\n",
       "  -0.6377400686617652,\n",
       "  0.6415795896223563,\n",
       "  -1.6081925782449302,\n",
       "  -0.06141095850128503,\n",
       "  1.548312124668108,\n",
       "  -0.8582465716313932,\n",
       "  1776556800.0,\n",
       "  0.6172071013519239,\n",
       "  0.6895970646126438,\n",
       "  -0.34938599297704037,\n",
       "  -0.29908465988944066],\n",
       " [0.2736801435220143,\n",
       "  -1.4113083170510452,\n",
       "  -1.0190332327767235,\n",
       "  0.7306198385088052,\n",
       "  -0.669385081233104,\n",
       "  1.2645415513073375,\n",
       "  0.13138143709849473,\n",
       "  -0.07255465913498371,\n",
       "  1753056000.0,\n",
       "  -0.3153615753072004,\n",
       "  -0.03570711739565755,\n",
       "  -1.2923669881471216,\n",
       "  0.23810038426555144],\n",
       " [-1.2071853988137997,\n",
       "  0.8512040875225344,\n",
       "  0.11794284677553042,\n",
       "  -0.16711884508903824,\n",
       "  1.0085288430682324,\n",
       "  0.907765185219194,\n",
       "  -0.9635149615148293,\n",
       "  -0.4135951369195173,\n",
       "  1744416000.0,\n",
       "  0.7324577470538765,\n",
       "  0.8665372698133662,\n",
       "  0.5228563469726546,\n",
       "  0.3462435854729649],\n",
       " [1.4509515112778513,\n",
       "  -0.40836442287655855,\n",
       "  -0.24368869736311885,\n",
       "  0.6396100647898377,\n",
       "  -1.5295596492751489,\n",
       "  0.5866229067240629,\n",
       "  -0.16506274282434458,\n",
       "  -0.24719151890502775,\n",
       "  1768089600.0,\n",
       "  -0.04595282183369771,\n",
       "  -1.4614622126853138,\n",
       "  -0.8861560959501902,\n",
       "  0.1486319796315769],\n",
       " [-1.5505218548715587,\n",
       "  0.5667183471393408,\n",
       "  -1.7450212017255653,\n",
       "  0.8151752777496282,\n",
       "  1.1281683733634598,\n",
       "  0.7905801849355788,\n",
       "  0.8531019291411475,\n",
       "  -0.9194646177317576,\n",
       "  1764028800.0,\n",
       "  0.36834171358571866,\n",
       "  1.4130190675509202,\n",
       "  0.5161421348373144,\n",
       "  -1.1378938966241081],\n",
       " [0.318025378265635,\n",
       "  -0.31017053398844197,\n",
       "  0.8259755835381597,\n",
       "  -0.43100691708369965,\n",
       "  1.3923386211572208,\n",
       "  0.5920568989259295,\n",
       "  0.0966958476647375,\n",
       "  -0.2146222456230712,\n",
       "  1760140800.0,\n",
       "  -0.05778470937066796,\n",
       "  -0.4227817667320634,\n",
       "  0.09930509885722362,\n",
       "  -0.08426174113158232],\n",
       " [1.367943207538823,\n",
       "  -1.3662125778428424,\n",
       "  -0.7651785890396757,\n",
       "  -1.1607705050569168,\n",
       "  -1.5767735094794826,\n",
       "  1.6356075145045752,\n",
       "  1.7018178091898744,\n",
       "  1.7044079844250308,\n",
       "  1761350400.0,\n",
       "  -1.5652424559875757,\n",
       "  0.2845075802740344,\n",
       "  1.3612800300340007,\n",
       "  -1.056449532404171],\n",
       " [0.19518531489763014,\n",
       "  0.670113931357835,\n",
       "  -1.190408941232582,\n",
       "  0.7640048663360957,\n",
       "  -0.4120913426172917,\n",
       "  0.3326134626031438,\n",
       "  0.12744825296160436,\n",
       "  -0.5572214637609184,\n",
       "  1757980800.0,\n",
       "  0.37288996552691145,\n",
       "  0.8864972965875921,\n",
       "  -0.8251692533004364,\n",
       "  -1.3755674995009286],\n",
       " [-1.1888622539957598,\n",
       "  -1.0728256768091524,\n",
       "  0.41393435549298196,\n",
       "  -0.045295326888189165,\n",
       "  -0.7056195630405925,\n",
       "  0.15597354731285243,\n",
       "  0.7351423435386557,\n",
       "  1.146564824315837,\n",
       "  1770595200.0,\n",
       "  -0.5220671633602919,\n",
       "  1.1783292883335188,\n",
       "  1.0925267821001807,\n",
       "  1.093853417035328],\n",
       " [1.172827799880171,\n",
       "  0.47916455070987296,\n",
       "  -1.6900714011040214,\n",
       "  -0.3022478075779329,\n",
       "  -0.4023569975407688,\n",
       "  -1.0471463116186692,\n",
       "  1.3137031301657223,\n",
       "  1.4353590621565295,\n",
       "  1746576000.0,\n",
       "  0.03146995529676642,\n",
       "  0.10070509839042001,\n",
       "  -0.029332352328885064,\n",
       "  -0.3646806627845366],\n",
       " [-0.1730688124317808,\n",
       "  1.2186105981638231,\n",
       "  1.762843948536497,\n",
       "  -1.52792134844488,\n",
       "  -1.665957028240906,\n",
       "  -1.563730053204527,\n",
       "  -0.6057015004307617,\n",
       "  1.463084858735742,\n",
       "  1751846400.0,\n",
       "  -1.1395068933851158,\n",
       "  0.9813169134595874,\n",
       "  1.512907890607547,\n",
       "  -0.2717681502241484],\n",
       " [-1.6301579657697223,\n",
       "  -1.6084279152759136,\n",
       "  0.042521428204690334,\n",
       "  -0.10788176634575872,\n",
       "  0.8024054550202825,\n",
       "  -1.6539127870676957,\n",
       "  -0.3767151388871779,\n",
       "  -0.9129089384632396,\n",
       "  1753488000.0,\n",
       "  -1.4312354715348212,\n",
       "  -0.7935965584391694,\n",
       "  0.27163136196754073,\n",
       "  -1.3553596830269714],\n",
       " [0.5826898219054032,\n",
       "  0.08698079720163882,\n",
       "  -0.9060820557203465,\n",
       "  -1.2925475955315524,\n",
       "  1.069367278509634,\n",
       "  0.9245104542231662,\n",
       "  1.373990495352766,\n",
       "  1.409608987477144,\n",
       "  1773878400.0,\n",
       "  -0.5750258101083048,\n",
       "  -0.07447132853193808,\n",
       "  0.8930237801874169,\n",
       "  -0.7800333869986568],\n",
       " [-0.77778608166925,\n",
       "  0.7257458652774286,\n",
       "  0.6449114784287053,\n",
       "  0.40885606103708994,\n",
       "  -0.40869007941895463,\n",
       "  0.9103961738597657,\n",
       "  1.1913490476544595,\n",
       "  -1.7547684427014456,\n",
       "  1757289600.0,\n",
       "  -1.0110133693645291,\n",
       "  -0.17330694330313332,\n",
       "  -1.3753894621916392,\n",
       "  1.6035698462560053],\n",
       " [-0.27675150938187093,\n",
       "  -1.5745388225536887,\n",
       "  -0.9317997540066433,\n",
       "  0.5655079459384792,\n",
       "  -0.8641694069558528,\n",
       "  -1.3009164141856686,\n",
       "  -1.3496271110195102,\n",
       "  1.1102079204714095,\n",
       "  1771891200.0,\n",
       "  -1.305809498585358,\n",
       "  0.3581076885310385,\n",
       "  1.6884833616151413,\n",
       "  1.1023172464472912],\n",
       " [-1.3863744101007505,\n",
       "  1.119852719679865,\n",
       "  1.0518902667380388,\n",
       "  1.4095062001356893,\n",
       "  -0.10840559158813635,\n",
       "  -0.461466456920868,\n",
       "  -1.2900465151138873,\n",
       "  -0.6434289913186662,\n",
       "  1789257600.0,\n",
       "  0.41052976344101905,\n",
       "  -1.4633793832546376,\n",
       "  1.4128311496584514,\n",
       "  0.2435553822874703],\n",
       " [0.3498935823399143,\n",
       "  -1.5801289046248832,\n",
       "  1.6113930703358388,\n",
       "  0.9455725589049214,\n",
       "  -0.08217452644292678,\n",
       "  -0.46301368388839415,\n",
       "  -1.5461745562865514,\n",
       "  -1.6096757223873468,\n",
       "  1747180800.0,\n",
       "  1.480445311891933,\n",
       "  -1.3839277773204124,\n",
       "  0.05035260419714471,\n",
       "  1.0344466328532917],\n",
       " [-0.5251899397707456,\n",
       "  1.1739179565692939,\n",
       "  1.0935164848047438,\n",
       "  1.0981466520767833,\n",
       "  -1.3094877026526273,\n",
       "  1.0831451308651445,\n",
       "  1.2397454490155961,\n",
       "  0.4694149741000682,\n",
       "  1770768000.0,\n",
       "  1.2844530504721905,\n",
       "  -0.9262779141553802,\n",
       "  -1.021389904009617,\n",
       "  -1.4657556690760716],\n",
       " [1.6170154580067748,\n",
       "  -1.6163384867451385,\n",
       "  -1.7065155684097162,\n",
       "  1.1304163862551666,\n",
       "  0.30050386000907636,\n",
       "  -1.273546463781801,\n",
       "  -0.6072089953597727,\n",
       "  -0.9492342635125399,\n",
       "  1783382400.0,\n",
       "  1.2585611734128919,\n",
       "  0.08843062471063881,\n",
       "  -0.900203728696081,\n",
       "  0.22560716569657296],\n",
       " [0.220153570452729,\n",
       "  -0.48056995362307214,\n",
       "  0.25169294211369314,\n",
       "  -0.4314081770594768,\n",
       "  0.8908080543593455,\n",
       "  0.6765734121159894,\n",
       "  0.051818564950814175,\n",
       "  1.60101557142855,\n",
       "  1790467200.0,\n",
       "  1.1878655701082033,\n",
       "  1.5664465462552253,\n",
       "  0.17506736579134521,\n",
       "  0.6053907416421412],\n",
       " [-0.26293446197348636,\n",
       "  1.3950164163134082,\n",
       "  -1.2365892877902316,\n",
       "  -1.8103487423600308,\n",
       "  0.4007422832729642,\n",
       "  -0.29634980468943634,\n",
       "  -0.2365970479235375,\n",
       "  0.46517044952805164,\n",
       "  1754956800.0,\n",
       "  1.2745319318628863,\n",
       "  -0.9369015812334851,\n",
       "  -0.5961588922591408,\n",
       "  -0.6691904513774319],\n",
       " [1.1856067667153891,\n",
       "  1.5617327512818426,\n",
       "  0.17588361254306686,\n",
       "  0.609326918117747,\n",
       "  1.1491827228901914,\n",
       "  0.7601735996378313,\n",
       "  -1.3982460769674814,\n",
       "  -1.4402039907693494,\n",
       "  1790640000.0,\n",
       "  1.211986740716637,\n",
       "  0.14372743880564,\n",
       "  1.7556206341576752,\n",
       "  1.0434107756535496],\n",
       " [-1.0375961666339655,\n",
       "  -0.10261385954307448,\n",
       "  -1.4613292016470052,\n",
       "  -0.12897363358719557,\n",
       "  0.8066389845360151,\n",
       "  -0.09355063399548558,\n",
       "  -1.5515715411826472,\n",
       "  0.9181290457821192,\n",
       "  1781654400.0,\n",
       "  0.44041684467427916,\n",
       "  -0.5317878774157488,\n",
       "  -0.11270993406154399,\n",
       "  0.4328570198654872],\n",
       " [0.23090796744976522,\n",
       "  0.9480316971653492,\n",
       "  1.185922542632439,\n",
       "  1.198180704814016,\n",
       "  -0.5728254656715815,\n",
       "  1.2686704185478856,\n",
       "  1.0012521021874639,\n",
       "  0.7083500202902044,\n",
       "  1790899200.0,\n",
       "  -1.5360422363005781,\n",
       "  -0.7211253370683226,\n",
       "  0.9499596926104564,\n",
       "  1.26004676559138],\n",
       " [-1.4122499744401233,\n",
       "  -1.2935515512766855,\n",
       "  1.1998659465583572,\n",
       "  -0.47005762867088086,\n",
       "  0.7954113540204463,\n",
       "  1.3331622598857786,\n",
       "  0.19575134916645284,\n",
       "  -0.9540135139674365,\n",
       "  1782259200.0,\n",
       "  1.147218614500052,\n",
       "  1.6094491905868165,\n",
       "  1.6418052752365024,\n",
       "  -0.9511393908653446],\n",
       " [0.14891470951457184,\n",
       "  -1.5251868128151949,\n",
       "  1.4774298797033176,\n",
       "  -0.3205636836995352,\n",
       "  0.6371491465699437,\n",
       "  -1.7014951583685156,\n",
       "  -1.3761708297878288,\n",
       "  -0.2665871180441419,\n",
       "  1769385600.0,\n",
       "  0.6734188125274225,\n",
       "  -0.5983256591899566,\n",
       "  1.3978234529942994,\n",
       "  -1.1195395722421966],\n",
       " [0.2504599411984461,\n",
       "  -1.1886257837461278,\n",
       "  -0.5885888504894565,\n",
       "  -0.11550776092755839,\n",
       "  -0.23058374970011528,\n",
       "  0.45935113502297736,\n",
       "  1.7289668747335867,\n",
       "  1.6782593152015175,\n",
       "  1794268800.0,\n",
       "  -1.6201838032416354,\n",
       "  1.6437603048911331,\n",
       "  1.1000974632554303,\n",
       "  -0.9865095504482154],\n",
       " [-1.577117023160271,\n",
       "  -0.7578475873474232,\n",
       "  -1.015646932300069,\n",
       "  1.6446566586773763,\n",
       "  -1.2924025411266802,\n",
       "  1.2668222867898582,\n",
       "  -0.6701507238891121,\n",
       "  0.0985589758412437,\n",
       "  1780012800.0,\n",
       "  1.6804056398150182,\n",
       "  1.2298460543756766,\n",
       "  -1.2656521928114213,\n",
       "  0.8945739279708342],\n",
       " [0.09680498879857832,\n",
       "  1.6044649624840401,\n",
       "  -0.8617699056630626,\n",
       "  0.6777633246339364,\n",
       "  -1.07748264195423,\n",
       "  0.11230124339842887,\n",
       "  1.5729467606542233,\n",
       "  -0.9925669015346849,\n",
       "  1759104000.0,\n",
       "  0.9287135421744442,\n",
       "  1.5270905765348943,\n",
       "  1.2234929108255939,\n",
       "  -0.9972333687992756],\n",
       " [0.007002983636368211,\n",
       "  0.36769284487662524,\n",
       "  -0.8647528833724882,\n",
       "  1.2617346969078707,\n",
       "  0.301571749991888,\n",
       "  0.37883813897237145,\n",
       "  0.7767546026371972,\n",
       "  -0.9734170715863084,\n",
       "  1774137600.0,\n",
       "  1.585597329778891,\n",
       "  1.3889486424198714,\n",
       "  1.7512149981678604,\n",
       "  -0.49578280619575693],\n",
       " [-1.0393598946630098,\n",
       "  0.6797278088669737,\n",
       "  -0.012735758884512553,\n",
       "  -0.14076775368147953,\n",
       "  -0.795224138373069,\n",
       "  0.7192676223320578,\n",
       "  -0.41984280303135546,\n",
       "  0.09708031133807506,\n",
       "  1778889600.0,\n",
       "  1.5267842842180566,\n",
       "  -0.20336523658700895,\n",
       "  -0.09335586761574181,\n",
       "  0.5350982688495247],\n",
       " [-0.9237547829226123,\n",
       "  -0.3516095291533087,\n",
       "  0.8348080272687588,\n",
       "  0.20760437795201026,\n",
       "  0.26649136853093097,\n",
       "  -0.4331495219585627,\n",
       "  -1.0494806503678136,\n",
       "  -0.864947880387571,\n",
       "  1745712000.0,\n",
       "  -0.3885940302356901,\n",
       "  -0.3022219097177499,\n",
       "  -1.485946142070341,\n",
       "  0.025836101947092942],\n",
       " [1.5011332187467923,\n",
       "  0.7960556974744185,\n",
       "  -1.4142155951077047,\n",
       "  -1.3929218530989234,\n",
       "  0.3711762585928725,\n",
       "  -1.6054799117448129,\n",
       "  1.7192025734682836,\n",
       "  1.5950430553028323,\n",
       "  1756080000.0,\n",
       "  1.4045355185350243,\n",
       "  1.1345057099318658,\n",
       "  -0.10634668092617816,\n",
       "  -0.3474360705357904],\n",
       " [0.6675480066842896,\n",
       "  -0.5496083441312046,\n",
       "  -1.604109307262836,\n",
       "  1.3881215682809753,\n",
       "  0.13170759106749394,\n",
       "  1.5923918338130414,\n",
       "  -1.6323844004692556,\n",
       "  -1.6849951154294165,\n",
       "  1788220800.0,\n",
       "  0.5566972373899949,\n",
       "  -0.35365832135915776,\n",
       "  1.6867220110608967,\n",
       "  1.0205201431825848],\n",
       " [-0.04883503325797452,\n",
       "  -1.4638163316031423,\n",
       "  -0.885540485350283,\n",
       "  0.15223427260549768,\n",
       "  -0.724246385264651,\n",
       "  -0.5349057841019752,\n",
       "  1.6548560112588593,\n",
       "  0.8176253283289099,\n",
       "  1768262400.0,\n",
       "  1.4884111304553382,\n",
       "  1.1813894334175634,\n",
       "  -0.4598700373827625,\n",
       "  -0.32677535349016057],\n",
       " [0.3668541227384425,\n",
       "  -1.6064180065771327,\n",
       "  1.7197747756563844,\n",
       "  1.595381154844994,\n",
       "  1.4072800747406775,\n",
       "  1.1323810160213887,\n",
       "  -0.10388428457882493,\n",
       "  -0.34344959517455254,\n",
       "  1756166400.0,\n",
       "  1.0503646011153704,\n",
       "  -1.1534878910660622,\n",
       "  -1.5307504460602874,\n",
       "  -0.32507561210869906],\n",
       " [0.2962207229186439,\n",
       "  -1.2746439130595748,\n",
       "  -0.6095354892615756,\n",
       "  -0.9503200982944284,\n",
       "  1.261151336137668,\n",
       "  0.08661909749456659,\n",
       "  -0.8969033225092098,\n",
       "  0.22969176147830064,\n",
       "  1783468800.0,\n",
       "  1.0714164277319798,\n",
       "  -1.1395688572251308,\n",
       "  0.4503450039280894,\n",
       "  -0.04273390158329726],\n",
       " [0.3542004887309872,\n",
       "  0.36902872297978234,\n",
       "  -1.4504907014800104,\n",
       "  0.44657830208403543,\n",
       "  0.33685460233352804,\n",
       "  -1.2571775392271165,\n",
       "  1.3017324244184856,\n",
       "  -0.9427253109833216,\n",
       "  1763424000.0,\n",
       "  -0.7082725461926896,\n",
       "  1.0439349727272171,\n",
       "  1.0181796995909789,\n",
       "  -1.2727302455427736],\n",
       " [-1.6293983329311523,\n",
       "  1.0387543681555202,\n",
       "  1.2840719202879085,\n",
       "  -0.5354107637156269,\n",
       "  -0.267328993888154,\n",
       "  -0.8472089076679019,\n",
       "  -0.6087572454862259,\n",
       "  -0.6893969326998765,\n",
       "  1771459200.0,\n",
       "  -0.5978780580422249,\n",
       "  1.3264997661610851,\n",
       "  -0.913443672915706,\n",
       "  1.696473308219241],\n",
       " [-0.1113625607117212,\n",
       "  -1.429190409747602,\n",
       "  -1.4199105276628163,\n",
       "  -1.1639855182883991,\n",
       "  -0.34725218621684173,\n",
       "  1.068871060571726,\n",
       "  0.20746457796378412,\n",
       "  -1.2254653422429453,\n",
       "  1789689600.0,\n",
       "  -1.0613434891292886,\n",
       "  1.6632328596706925,\n",
       "  -0.5134890951121381,\n",
       "  1.3874483766797054],\n",
       " [0.41731567221667004,\n",
       "  -0.32719075475797116,\n",
       "  -1.2408346197856615,\n",
       "  -0.7356952251763763,\n",
       "  1.3710955608308413,\n",
       "  -0.09225119793104675,\n",
       "  -1.4223526301644898,\n",
       "  -1.7960746542374393,\n",
       "  1766966400.0,\n",
       "  0.8998704067700188,\n",
       "  -1.7302618785750796,\n",
       "  1.6175171700825928,\n",
       "  -0.04469556806473832],\n",
       " [1.5778126873023912,\n",
       "  -0.8496619201770833,\n",
       "  0.6494444202466979,\n",
       "  -0.26297791505656176,\n",
       "  -0.947691012778242,\n",
       "  -1.509261125947245,\n",
       "  -1.3477186089022746,\n",
       "  1.223228956662236,\n",
       "  1758326400.0,\n",
       "  0.2855015023979227,\n",
       "  0.11226164767594685,\n",
       "  -0.19414928131233947,\n",
       "  -0.6776151560077075],\n",
       " [-0.5281276376358377,\n",
       "  -1.7566840869910751,\n",
       "  -0.7649004630207525,\n",
       "  0.676154621164449,\n",
       "  0.15712599010079106,\n",
       "  -1.333426023049553,\n",
       "  -0.8808366444576398,\n",
       "  0.48097901446597907,\n",
       "  1760400000.0,\n",
       "  -1.0666878134050324,\n",
       "  -0.9056673469278024,\n",
       "  -1.1669411247965964,\n",
       "  -0.30585524719722834],\n",
       " [1.12156765186622,\n",
       "  -0.6606442962574388,\n",
       "  0.8902436085139447,\n",
       "  -0.06433004890230791,\n",
       "  -0.9466565431297568,\n",
       "  0.65182901868283,\n",
       "  -1.114619042480564,\n",
       "  -0.4870113452138538,\n",
       "  1768521600.0,\n",
       "  1.127984480349747,\n",
       "  0.27919380326753346,\n",
       "  -0.5100240350003858,\n",
       "  -1.3590342440655077],\n",
       " [1.551685869520164,\n",
       "  -0.5433650980621626,\n",
       "  -0.9593866324388596,\n",
       "  -1.2969522636179551,\n",
       "  1.0005916497963812,\n",
       "  1.168540912706363,\n",
       "  -1.457022306722173,\n",
       "  1.462319122178826,\n",
       "  1769212800.0,\n",
       "  0.15169705492826252,\n",
       "  -1.5228805577564763,\n",
       "  1.476367607602285,\n",
       "  -0.32382062122135996],\n",
       " [1.3300453450579433,\n",
       "  0.26658954782229377,\n",
       "  -0.5360674717786788,\n",
       "  1.5340056462390845,\n",
       "  -1.2667936742804615,\n",
       "  -0.5477106958068303,\n",
       "  -1.518602586064103,\n",
       "  -1.8081913683776865,\n",
       "  1755388800.0,\n",
       "  -0.39692272973923504,\n",
       "  0.21804262917682674,\n",
       "  -0.011819358475151885,\n",
       "  1.4184608946568957],\n",
       " [-1.5888432414056672,\n",
       "  0.054020873200779806,\n",
       "  1.770498862628854,\n",
       "  -0.6850403171606722,\n",
       "  1.66507724843403,\n",
       "  1.475024918384336,\n",
       "  1.560244676930124,\n",
       "  -0.6469283654460546,\n",
       "  1794700800.0,\n",
       "  -1.3726983308421121,\n",
       "  0.5450622054428207,\n",
       "  1.1123903472371581,\n",
       "  0.8848341435248273],\n",
       " [0.5944670912963076,\n",
       "  -0.46348491154752336,\n",
       "  1.6449834404143435,\n",
       "  -0.10814098826201105,\n",
       "  -0.8409847743907493,\n",
       "  -1.16433831943308,\n",
       "  -1.0181356550701015,\n",
       "  1.7179740000823231,\n",
       "  1785024000.0,\n",
       "  -0.9857040292196213,\n",
       "  -0.6270922666068294,\n",
       "  0.3895685830922901,\n",
       "  1.1751886452467122],\n",
       " [1.6109334209103077,\n",
       "  -0.8273114705901958,\n",
       "  0.23341443206922843,\n",
       "  -0.758528702812682,\n",
       "  0.4886187256941814,\n",
       "  -0.4119597572641281,\n",
       "  -0.9320828732200576,\n",
       "  -1.7807712521012249,\n",
       "  1776816000.0,\n",
       "  0.020577198928068273,\n",
       "  -1.2945819556948976,\n",
       "  -0.11681453543394253,\n",
       "  0.6876521650977426],\n",
       " [-1.4941310328823776,\n",
       "  1.3570097473283875,\n",
       "  -1.1771485856649382,\n",
       "  0.9889946571531195,\n",
       "  -1.2007912339851334,\n",
       "  0.7491778687567339,\n",
       "  0.3205492344919972,\n",
       "  -0.8065065143719996,\n",
       "  1766016000.0,\n",
       "  -0.6711675963850714,\n",
       "  -1.4239065588148647,\n",
       "  0.2234208468955882,\n",
       "  1.075968152559827],\n",
       " [0.8197410914943632,\n",
       "  -1.5743117094230723,\n",
       "  -1.1519433055468995,\n",
       "  1.5593609102693122,\n",
       "  -0.85424013164453,\n",
       "  -0.06942217344984199,\n",
       "  -0.4788729336097333,\n",
       "  0.9091541281030565,\n",
       "  1779667200.0,\n",
       "  -0.8393639391795157,\n",
       "  1.0250096550090755,\n",
       "  -0.37716730357369943,\n",
       "  1.1968422051420484],\n",
       " [0.9910431661709241,\n",
       "  -0.916520708765424,\n",
       "  -1.389303877278061,\n",
       "  0.5260900519803199,\n",
       "  -1.138737481015914,\n",
       "  0.2902553726938356,\n",
       "  -0.014691827966889972,\n",
       "  -1.5146374099503928,\n",
       "  1795305600.0,\n",
       "  -1.5846809653856557,\n",
       "  -0.33025173328350493,\n",
       "  0.4635152532115288,\n",
       "  1.059534725869174],\n",
       " [0.34093705058754276,\n",
       "  -1.112079664058858,\n",
       "  1.179628648297455,\n",
       "  -0.27681246126692904,\n",
       "  -0.5733064985664685,\n",
       "  0.7177040593165769,\n",
       "  -1.593800176295289,\n",
       "  -1.6119553138490512,\n",
       "  1791590400.0,\n",
       "  1.5168943751223438,\n",
       "  -1.3600091364933353,\n",
       "  1.083000846353766,\n",
       "  0.010425474753416077],\n",
       " [1.5296834295115742,\n",
       "  0.22726351310591936,\n",
       "  -0.539764868328704,\n",
       "  -0.6935643213556112,\n",
       "  -1.052768725200776,\n",
       "  -1.7645768830881514,\n",
       "  0.32192386960513325,\n",
       "  -1.4942496282748332,\n",
       "  1790121600.0,\n",
       "  1.512466767160531,\n",
       "  0.7107026390450042,\n",
       "  0.3913527186914119,\n",
       "  0.1582952008370181],\n",
       " [-0.04756238022431062,\n",
       "  0.8203986730462911,\n",
       "  0.5838602058572901,\n",
       "  -0.3762146017394205,\n",
       "  -0.5132369296883578,\n",
       "  -0.7993935013044388,\n",
       "  0.9722336965122892,\n",
       "  1.1756705035980326,\n",
       "  1792108800.0,\n",
       "  0.3614091112709192,\n",
       "  -1.0959986681463407,\n",
       "  -0.5373072476447004,\n",
       "  -1.697984028426672],\n",
       " [-0.9853662952334218,\n",
       "  -0.24954775660047912,\n",
       "  1.125681862206485,\n",
       "  0.049804106263452635,\n",
       "  -0.04861019643476207,\n",
       "  -0.9027191304126055,\n",
       "  1.0381194978004449,\n",
       "  -0.6955434501562356,\n",
       "  1784073600.0,\n",
       "  -1.6240662144666236,\n",
       "  0.689345968416278,\n",
       "  1.0491006806070442,\n",
       "  -1.5399424176343925],\n",
       " [-1.691632181984743,\n",
       "  -0.20089198613554146,\n",
       "  -1.5764819064613584,\n",
       "  1.7016058576911255,\n",
       "  -1.2376850414589693,\n",
       "  1.2871518182789805,\n",
       "  -1.0422151047328267,\n",
       "  1.659889979006647,\n",
       "  1743379200.0,\n",
       "  0.7419279430864536,\n",
       "  -0.9013357102307256,\n",
       "  0.357873378653277,\n",
       "  1.613363256254668],\n",
       " [-0.15596384554420542,\n",
       "  0.608290250241648,\n",
       "  -1.1451954848704808,\n",
       "  -1.6303632445371292,\n",
       "  -1.0558677015136406,\n",
       "  -1.8140833020456664,\n",
       "  -0.19638533958846416,\n",
       "  -1.6113290892484315,\n",
       "  1756944000.0,\n",
       "  1.0872178377930986,\n",
       "  -0.3272630307011038,\n",
       "  1.1793452423430748,\n",
       "  1.5577360879072495],\n",
       " [0.8405944154305607,\n",
       "  1.0009759474922029,\n",
       "  -1.6453631958003656,\n",
       "  0.07346298550422387,\n",
       "  1.344033907487287,\n",
       "  -1.6432993470004693,\n",
       "  0.2515885949771278,\n",
       "  -0.2067038103719439,\n",
       "  1749772800.0,\n",
       "  -1.1447076555825892,\n",
       "  0.3748212449806157,\n",
       "  -0.4909399636386642,\n",
       "  0.7289457304503473],\n",
       " [1.2195924230175912,\n",
       "  0.7244960449271525,\n",
       "  0.5001084488126459,\n",
       "  1.7070757922814768,\n",
       "  -1.323661396426861,\n",
       "  0.5216599972956999,\n",
       "  -0.017423252001154303,\n",
       "  -1.3965727107595154,\n",
       "  1781308800.0,\n",
       "  0.08575410656065018,\n",
       "  0.4164444735806161,\n",
       "  -0.5889577771511769,\n",
       "  -1.3113920899591593],\n",
       " [-1.2046371686325508,\n",
       "  -1.4685291472339914,\n",
       "  0.9442778320795164,\n",
       "  -1.461925596152714,\n",
       "  0.49770979021782963,\n",
       "  1.3304577870214287,\n",
       "  0.24477979196150176,\n",
       "  1.7166389399474329,\n",
       "  1739059200.0,\n",
       "  0.19146451777090628,\n",
       "  0.12021521067833844,\n",
       "  1.335072333038948,\n",
       "  -0.7886292237729784],\n",
       " [0.18918760353157404,\n",
       "  -1.6879302307717816,\n",
       "  -0.5939140099781954,\n",
       "  0.9554605426915591,\n",
       "  -1.2626672719568113,\n",
       "  -0.22111835944181338,\n",
       "  1.1324634186596987,\n",
       "  -1.698544365251488,\n",
       "  1782691200.0,\n",
       "  -1.4283362003714564,\n",
       "  1.193154705532892,\n",
       "  -1.432230471972461,\n",
       "  0.07139067555391351],\n",
       " [-1.2483346267753805,\n",
       "  1.1485635317607619,\n",
       "  -0.0732700263427586,\n",
       "  1.7109296325596037,\n",
       "  -1.1314421203543963,\n",
       "  -1.5187267060709597,\n",
       "  0.938291848121799,\n",
       "  -1.6636213804700049,\n",
       "  1750723200.0,\n",
       "  -0.9049150760809076,\n",
       "  -1.4615205517300929,\n",
       "  0.08272056485329204,\n",
       "  -0.4424152345086549],\n",
       " [-0.6399304176091963,\n",
       "  1.4830309827966075,\n",
       "  0.7730573216571321,\n",
       "  0.07474196178738467,\n",
       "  0.8736385216856795,\n",
       "  1.4909044833404819,\n",
       "  -0.3558327573170869,\n",
       "  1.6689038387075812,\n",
       "  1787356800.0,\n",
       "  -1.039245415612879,\n",
       "  -0.4963319757665446,\n",
       "  0.41821823579240897,\n",
       "  -1.4937243257591037],\n",
       " [-1.4623682833376397,\n",
       "  -0.7606462309344069,\n",
       "  0.10116213894294687,\n",
       "  -1.7753552088172864,\n",
       "  -1.3916450697829335,\n",
       "  -0.9857157825862024,\n",
       "  0.7059183491057337,\n",
       "  1.0308559853184518,\n",
       "  1786665600.0,\n",
       "  0.3358153995074511,\n",
       "  -1.669245000436099,\n",
       "  1.0272360620018337,\n",
       "  -0.8467616703445948],\n",
       " [1.1732935972486958,\n",
       "  -1.3205705011425077,\n",
       "  -1.4087478812440921,\n",
       "  -0.07018255288897142,\n",
       "  0.1768214711767939,\n",
       "  0.4144618903739907,\n",
       "  -0.7436484844706422,\n",
       "  -1.6106833973144588,\n",
       "  1792627200.0,\n",
       "  -0.7415748278673747,\n",
       "  -0.7095947559471096,\n",
       "  1.6387389886811778,\n",
       "  -0.04034310680420949],\n",
       " [0.1795540811797262,\n",
       "  0.26024954179988596,\n",
       "  -0.6406925237198139,\n",
       "  0.5732070998246844,\n",
       "  0.15811833579653944,\n",
       "  -1.333065112973803,\n",
       "  1.1949099396911014,\n",
       "  0.5158083043350201,\n",
       "  1744243200.0,\n",
       "  -1.203718206452268,\n",
       "  0.8553637293723924,\n",
       "  0.11713755230226172,\n",
       "  -0.17048786645323888],\n",
       " [-0.49100640643342797,\n",
       "  0.568325749175651,\n",
       "  -1.6642689035300253,\n",
       "  0.2275872579493457,\n",
       "  0.8300662504484031,\n",
       "  0.03153946401219854,\n",
       "  1.796430735811656,\n",
       "  0.25223346440659783,\n",
       "  1784678400.0,\n",
       "  -0.826756866340445,\n",
       "  0.11539279793069752,\n",
       "  -0.25013057856717186,\n",
       "  0.9220169716391364],\n",
       " [-1.5373494216816177,\n",
       "  1.6056689602206078,\n",
       "  1.7288277636685072,\n",
       "  -0.16717811824057735,\n",
       "  1.0215329563632514,\n",
       "  0.21287283143174196,\n",
       "  1.4218742716408677,\n",
       "  0.7771876588770141,\n",
       "  1756771200.0,\n",
       "  -0.15302753277470382,\n",
       "  0.6122604395492758,\n",
       "  -1.1457620140711562,\n",
       "  -1.6326634384574727],\n",
       " [-0.6181988608551416,\n",
       "  0.8043403671576889,\n",
       "  -1.3638115814566387,\n",
       "  -0.05923710133644316,\n",
       "  -0.15013423758031233,\n",
       "  0.41725554995820524,\n",
       "  -0.5624438838853768,\n",
       "  -0.8385711592162526,\n",
       "  1775779200.0,\n",
       "  -0.2397302622443838,\n",
       "  -0.15822136380889593,\n",
       "  0.2808477453564369,\n",
       "  0.8920313088796304],\n",
       " [1.4817229858995378,\n",
       "  -1.414680539110149,\n",
       "  1.481654446186322,\n",
       "  -1.710751356431526,\n",
       "  -1.4798561975998596,\n",
       "  0.5700833656397761,\n",
       "  0.6631104273823706,\n",
       "  0.7992134808461422,\n",
       "  1783814400.0,\n",
       "  0.15902781251587833,\n",
       "  -0.11242800553438727,\n",
       "  -0.028784205146439087,\n",
       "  -0.01830564798352759],\n",
       " [-0.08168734282837421,\n",
       "  1.1775273833016635,\n",
       "  0.05342776030166224,\n",
       "  1.290250531248892,\n",
       "  1.1702352680113912,\n",
       "  -0.914540140403574,\n",
       "  -0.23439714083252536,\n",
       "  -1.6050556430450496,\n",
       "  1788652800.0,\n",
       "  -0.2646936440588192,\n",
       "  -0.5142750924656692,\n",
       "  -1.0842026391426558,\n",
       "  0.23819240146684],\n",
       " [-0.013023492784906826,\n",
       "  -0.1059742045329885,\n",
       "  -0.621962196721318,\n",
       "  0.017990086004223686,\n",
       "  -1.5766807457586283,\n",
       "  0.26050347019392117,\n",
       "  -1.4656848827605367,\n",
       "  1.3714637693179534,\n",
       "  1753833600.0,\n",
       "  0.8736941160841813,\n",
       "  1.038965657845245,\n",
       "  0.4748424259351904,\n",
       "  -1.54136752056392],\n",
       " [0.07662857305150554,\n",
       "  -1.4739157513423835,\n",
       "  -0.6829369306653951,\n",
       "  -0.03851413402152395,\n",
       "  -1.4695395787077592,\n",
       "  -1.13497018945701,\n",
       "  -0.9861628377964893,\n",
       "  0.229908936289725,\n",
       "  1769904000.0,\n",
       "  -1.4351335870117654,\n",
       "  -1.4524671310431057,\n",
       "  0.7322089759702628,\n",
       "  1.4538186533087458],\n",
       " [-0.5848795772859151,\n",
       "  0.018226209976333268,\n",
       "  1.5571335351029338,\n",
       "  -0.6903607866003375,\n",
       "  -0.379519454755753,\n",
       "  0.15718791774042304,\n",
       "  -1.290598787282001,\n",
       "  0.14891441749518308,\n",
       "  1770336000.0,\n",
       "  -1.307379345540799,\n",
       "  1.366462335869436,\n",
       "  -0.4059586757995602,\n",
       "  -0.89285333204652],\n",
       " [-1.3949944375647794,\n",
       "  -0.9869514134749832,\n",
       "  0.7052280046926753,\n",
       "  1.0308783310203402,\n",
       "  0.33742959668240036,\n",
       "  -1.6705303269299285,\n",
       "  1.0285018279292013,\n",
       "  -0.8428606929610257,\n",
       "  1786752000.0,\n",
       "  1.616477453442282,\n",
       "  -0.30147431279245446,\n",
       "  0.0512273012515276,\n",
       "  -0.7401116842299303],\n",
       " [1.0673176600732979,\n",
       "  1.1343885928710684,\n",
       "  1.0993192427154832,\n",
       "  1.2560388159223421,\n",
       "  1.489122006016621,\n",
       "  1.5889950004053601,\n",
       "  -0.6939637873599004,\n",
       "  1.5344293897764216,\n",
       "  1754784000.0,\n",
       "  -0.25994412774958003,\n",
       "  1.3996001864440537,\n",
       "  -1.2371385412375544,\n",
       "  -1.8125174658030967],\n",
       " [-1.0304628005076193,\n",
       "  -0.0485587816465341,\n",
       "  -1.282440557445803,\n",
       "  0.4431559036573736,\n",
       "  0.7174535420669969,\n",
       "  -1.0786710575052332,\n",
       "  -1.092086796175822,\n",
       "  0.38487441166223735,\n",
       "  1736380800.0,\n",
       "  -0.1442621704274851,\n",
       "  1.130702608681344,\n",
       "  -1.347596374094555,\n",
       "  1.3724001343631433],\n",
       " [0.7932634131244533,\n",
       "  -1.5373045712050082,\n",
       "  -0.24718777933474861,\n",
       "  -0.9394752487432836,\n",
       "  -0.10730446226204818,\n",
       "  -1.428167190711905,\n",
       "  -1.4165755674392235,\n",
       "  -1.1627801700620257,\n",
       "  1789603200.0,\n",
       "  -0.3481429774090567,\n",
       "  1.070976735619059,\n",
       "  0.20533119441165248,\n",
       "  -1.2293008186316323],\n",
       " [1.4395276264040453,\n",
       "  0.05273023089778242,\n",
       "  1.4347724538767246,\n",
       "  0.3907323352357524,\n",
       "  -1.4524336634884119,\n",
       "  -0.9154941767002295,\n",
       "  1.3431284133992571,\n",
       "  0.019242482756580102,\n",
       "  1783209600.0,\n",
       "  1.6190563947954286,\n",
       "  -1.6141033223930998,\n",
       "  -1.7069759938374311,\n",
       "  1.1260995797737599],\n",
       " [1.003855000415628,\n",
       "  0.905620532924303,\n",
       "  -0.966285410701562,\n",
       "  -0.41438119504890814,\n",
       "  0.7344914631014717,\n",
       "  0.864492798433549,\n",
       "  0.5246545452381052,\n",
       "  0.35034883745563244,\n",
       "  1744502400.0,\n",
       "  1.3554685317562833,\n",
       "  0.27382532345204436,\n",
       "  -1.055051724293056,\n",
       "  -0.8253478071222582],\n",
       " [-0.7632948683353105,\n",
       "  1.6585347734068288,\n",
       "  0.8086214683771445,\n",
       "  -1.7057169929876164,\n",
       "  -1.3995234992698202,\n",
       "  -1.1343519577538812,\n",
       "  -0.9925709405837231,\n",
       "  1.5751509248684852,\n",
       "  1785542400.0,\n",
       "  -1.289356890733892,\n",
       "  0.21286445706430893,\n",
       "  -1.2031656462982068,\n",
       "  1.0913472504883222],\n",
       " [-1.0617242095337662,\n",
       "  1.282168896599837,\n",
       "  0.7631734672988036,\n",
       "  -0.3558651331227995,\n",
       "  -1.6079436652908965,\n",
       "  0.6794045859770002,\n",
       "  -0.5007646950844001,\n",
       "  0.6193456838936331,\n",
       "  1771113600.0,\n",
       "  1.5183508888347228,\n",
       "  1.4572477019976224,\n",
       "  -0.535076432423998,\n",
       "  -1.1529177278144702],\n",
       " [-1.0523797672956359,\n",
       "  1.486376695363715,\n",
       "  0.8795078736110631,\n",
       "  -1.3032909354431297,\n",
       "  0.9193086837089766,\n",
       "  -0.3445137840791213,\n",
       "  0.48794100572192756,\n",
       "  -1.4926968466190624,\n",
       "  1779408000.0,\n",
       "  -0.29787522331455063,\n",
       "  -0.31525589577312585,\n",
       "  -1.383507435715729,\n",
       "  0.4626135846530993],\n",
       " [-0.19720309883248427,\n",
       "  0.07138020211342058,\n",
       "  -1.73307047462556,\n",
       "  1.3700000812780402,\n",
       "  -1.4425127516872231,\n",
       "  0.1988345509867746,\n",
       "  -0.5867950928288941,\n",
       "  1.238522503617396,\n",
       "  1740096000.0,\n",
       "  0.2673716222356824,\n",
       "  1.1797165892754957,\n",
       "  0.5355404246203898,\n",
       "  1.6783153177411751],\n",
       " [0.6818702485296979,\n",
       "  0.3526228007915811,\n",
       "  -1.4000304387598677,\n",
       "  0.598209746410419,\n",
       "  0.9436742043011732,\n",
       "  0.026968244713991542,\n",
       "  0.07914284274874755,\n",
       "  -0.2692951427042374,\n",
       "  1738800000.0,\n",
       "  1.569104442665486,\n",
       "  -0.03905116957231933,\n",
       "  -0.9077165986641961,\n",
       "  -1.3145723708218096],\n",
       " [-0.2935233751937722,\n",
       "  0.3386750010810922,\n",
       "  -0.3455352840998598,\n",
       "  -1.8107001465917212,\n",
       "  0.4219992388567466,\n",
       "  -1.19149974273046,\n",
       "  -0.2649919949270676,\n",
       "  0.7320523135934118,\n",
       "  1753315200.0,\n",
       "  -1.626477167148799,\n",
       "  -1.6061865813376046,\n",
       "  0.041730390297874634,\n",
       "  -0.11129405745729523],\n",
       " [1.2159128963814785,\n",
       "  -0.7501373663720342,\n",
       "  0.6005990870010564,\n",
       "  -1.1987556521949134,\n",
       "  -0.9387700184624528,\n",
       "  -0.8753704044193378,\n",
       "  0.49645074087658403,\n",
       "  -1.704016234577544,\n",
       "  1747612800.0,\n",
       "  -1.6464463972432801,\n",
       "  -0.5541142430108995,\n",
       "  -1.5613652965740419,\n",
       "  -1.0456629851750359],\n",
       " [-0.676816566881272,\n",
       "  1.5763521068687245,\n",
       "  1.398282506709234,\n",
       "  -0.5921054952937173,\n",
       "  -0.56083349605456,\n",
       "  0.898894025673643,\n",
       "  -0.8194385068147483,\n",
       "  0.615141632371915,\n",
       "  1738368000.0,\n",
       "  -1.3998215643544087,\n",
       "  -0.2972224988458581,\n",
       "  0.9757240668313187,\n",
       "  1.544428653909736],\n",
       " [-0.26768637805779133,\n",
       "  -0.5173673626772286,\n",
       "  -1.0836244714543868,\n",
       "  0.24186016170650762,\n",
       "  1.2648496757491035,\n",
       "  -0.9724169391018052,\n",
       "  0.5256026078965564,\n",
       "  0.06456596741463749,\n",
       "  1788825600.0,\n",
       "  0.9035953567272762,\n",
       "  -0.032385391151536755,\n",
       "  -0.0158176542252663,\n",
       "  -0.9099851899376206],\n",
       " [0.8657421942461646,\n",
       "  -0.6744719715244227,\n",
       "  -1.3678391356666655,\n",
       "  -0.8839223469182003,\n",
       "  1.4431423855159788,\n",
       "  0.8841335250090039,\n",
       "  -0.07473681471645525,\n",
       "  -1.1598374527576163,\n",
       "  1755907200.0,\n",
       "  1.5032326774671079,\n",
       "  0.8001723281775609,\n",
       "  -1.414731272665021,\n",
       "  -1.395395486176507],\n",
       " [-0.3252372632312366,\n",
       "  1.073616338775961,\n",
       "  -0.6569441994416365,\n",
       "  1.2943050773914095,\n",
       "  -1.0409957847812012,\n",
       "  0.5730196189049694,\n",
       "  -0.8731124254340417,\n",
       "  0.24001448909613543,\n",
       "  1778284800.0,\n",
       "  -0.9283171736821756,\n",
       "  0.3679814718564542,\n",
       "  0.1615210087232633,\n",
       "  -0.4050422863944335],\n",
       " [1.1256954210031134,\n",
       "  0.2754831757330989,\n",
       "  -0.5093373124320727,\n",
       "  -1.3565340314893977,\n",
       "  1.5648849213209453,\n",
       "  0.14750611415799872,\n",
       "  -0.5061501218902342,\n",
       "  1.238185137736882,\n",
       "  1768694400.0,\n",
       "  1.099124786739184,\n",
       "  1.0042655344118447,\n",
       "  0.31223255064810423,\n",
       "  -0.9709926862735621],\n",
       " [0.7448805801727617,\n",
       "  0.4662006471427408,\n",
       "  0.19190919482681582,\n",
       "  -0.9914161811754567,\n",
       "  1.6803582413075047,\n",
       "  1.2428899342092345,\n",
       "  -1.567663581606302,\n",
       "  0.7498507207298145,\n",
       "  1760918400.0,\n",
       "  -1.42538367584394,\n",
       "  -0.9790124433066467,\n",
       "  1.1800386000578524,\n",
       "  0.6208547232765406],\n",
       " [0.5591787429384364,\n",
       "  -0.3601237901526156,\n",
       "  0.5596099117246508,\n",
       "  1.4045843563969003,\n",
       "  0.49442168309119194,\n",
       "  0.7507405656854943,\n",
       "  1.7766762623226842,\n",
       "  -1.5328119095627397,\n",
       "  1772150400.0,\n",
       "  1.0887683019736032,\n",
       "  -0.3909903442073955,\n",
       "  0.6433287777448297,\n",
       "  -1.1548149456353576],\n",
       " [0.7776416582827117,\n",
       "  0.13127375641012162,\n",
       "  -1.1024179601453727,\n",
       "  1.571241855904155,\n",
       "  0.08079046689936097,\n",
       "  -1.4729140143396324,\n",
       "  -0.6805190927831893,\n",
       "  -0.03793831659057198,\n",
       "  1769817600.0,\n",
       "  -1.4692446082303157,\n",
       "  -1.133524482674956,\n",
       "  -0.9895575675096613,\n",
       "  0.22582430332819242],\n",
       " [-1.4328671861020665,\n",
       "  -1.5610178526696077,\n",
       "  -0.38744810748051217,\n",
       "  -1.3189438190938059,\n",
       "  1.440517982312772,\n",
       "  0.9955390150758778,\n",
       "  -0.3444826630825483,\n",
       "  -0.24998581135762674,\n",
       "  1787184000.0,\n",
       "  -0.6367496958704009,\n",
       "  1.4876833969516536,\n",
       "  0.7721281938852799,\n",
       "  0.07119627310220851],\n",
       " [1.5246967253534234,\n",
       "  -0.20669980159697887,\n",
       "  -0.0925903692752172,\n",
       "  0.5389830626283766,\n",
       "  0.9239612287868126,\n",
       "  1.6669299179275248,\n",
       "  -0.2928330187517471,\n",
       "  -0.0886499629008258,\n",
       "  1779062400.0,\n",
       "  -1.516208253847064,\n",
       "  -0.9820371723078298,\n",
       "  -0.7723514946275885,\n",
       "  0.2462946299285618],\n",
       " [1.6350917564187708,\n",
       "  1.0540992789178443,\n",
       "  -1.5738026945276902,\n",
       "  -0.004587318049338734,\n",
       "  -0.31274819307070106,\n",
       "  -0.10685384402782526,\n",
       "  1.0657930694150926,\n",
       "  -1.6747752122336206,\n",
       "  1747958400.0,\n",
       "  0.5637994811915763,\n",
       "  -1.3358432404166223,\n",
       "  0.15365937666380752,\n",
       "  -0.37038666242214935],\n",
       " [-0.4833709299743504,\n",
       "  0.6293939868951742,\n",
       "  -0.3225417592421579,\n",
       "  1.1476095829906936,\n",
       "  -1.6048748199874325,\n",
       "  0.11486348353336803,\n",
       "  0.2249560312841048,\n",
       "  0.45187768990052213,\n",
       "  1741392000.0,\n",
       "  -0.8603625804904994,\n",
       "  0.40251815247319905,\n",
       "  -0.15189700812889084,\n",
       "  -0.5041992769550796],\n",
       " [0.6146599629213374,\n",
       "  0.6855666061896271,\n",
       "  -0.3486688999921765,\n",
       "  -0.2958096407672746,\n",
       "  1.6159424492981211,\n",
       "  -0.825999163025726,\n",
       "  0.2346919220329355,\n",
       "  -0.7575501462712184,\n",
       "  1776729600.0,\n",
       "  0.4868447884426255,\n",
       "  -0.41029753582127143,\n",
       "  -0.9354204548191641,\n",
       "  -1.7845116614549765],\n",
       " [-0.3666978032884504,\n",
       "  -1.3570346020252166,\n",
       "  -0.11003131716486703,\n",
       "  -0.12958645076664022,\n",
       "  0.3542063537843915,\n",
       "  -1.5791781828715803,\n",
       "  1.6109557431062875,\n",
       "  0.9455979288636215,\n",
       "  1747094400.0,\n",
       "  -0.08334538754463701,\n",
       "  -0.46136675119257836,\n",
       "  -1.55016106918259,\n",
       "  -1.6134454228838933],\n",
       " [0.04865143856797581,\n",
       "  -0.7585145372853769,\n",
       "  -0.553137660258365,\n",
       "  1.4541130616032818,\n",
       "  0.9999711783183168,\n",
       "  1.1998125160857442,\n",
       "  1.71191723421091,\n",
       "  -0.8401786134049967,\n",
       "  1794528000.0,\n",
       "  -1.5851833072199784,\n",
       "  0.057558778601751265,\n",
       "  1.7693811930358412,\n",
       "  -0.688031022583037],\n",
       " [-0.1013277380736563,\n",
       "  0.9382833185636473,\n",
       "  -0.37179628433708367,\n",
       "  0.12047721930717772,\n",
       "  -0.09170373860016234,\n",
       "  -0.2284721359832715,\n",
       "  0.8803238159001334,\n",
       "  0.5703662617741329,\n",
       "  1780963200.0,\n",
       "  -0.1207457031301851,\n",
       "  1.501131761306347,\n",
       "  -0.5028084728244628,\n",
       "  0.319116022356932],\n",
       " [-0.8636562864975803,\n",
       "  0.39871141718352643,\n",
       "  -0.15114257764502304,\n",
       "  -0.5010741934056681,\n",
       "  -0.14987622966282801,\n",
       "  1.4801777710774187,\n",
       "  1.0126304088225448,\n",
       "  -0.5665072158721784,\n",
       "  1741564800.0,\n",
       "  1.5923960099390755,\n",
       "  -0.1255436963679449,\n",
       "  1.7925568334102076,\n",
       "  -0.3039838537638361],\n",
       " [0.47221824939691504,\n",
       "  -1.1390952026732597,\n",
       "  -1.558877538797096,\n",
       "  0.21256853220798375,\n",
       "  -1.3486636115554589,\n",
       "  1.6752310925045624,\n",
       "  -0.19278591689151078,\n",
       "  1.083274982343288,\n",
       "  1737244800.0,\n",
       "  0.0733174045877411,\n",
       "  -0.11763333258520905,\n",
       "  -0.3567579254319373,\n",
       "  -0.890900227153666],\n",
       " [-1.0148709023005196,\n",
       "  0.24470679957066324,\n",
       "  -0.2670484488686101,\n",
       "  1.0179629686868088,\n",
       "  0.5836813491985808,\n",
       "  -0.03564811198648202,\n",
       "  0.5522406097286261,\n",
       "  1.3830647711348394,\n",
       "  1749513600.0,\n",
       "  -0.01015942265464227,\n",
       "  -1.689806143206205,\n",
       "  0.5226354778383747,\n",
       "  -1.4953762261815842],\n",
       " [-0.8406629765238736,\n",
       "  1.1330737599631606,\n",
       "  1.7280209904942787,\n",
       "  0.20206991186594914,\n",
       "  -1.1306087159548772,\n",
       "  1.0843038914922312,\n",
       "  1.0912326513334194,\n",
       "  -0.5357280425938692,\n",
       "  1739491200.0,\n",
       "  1.317311671398875,\n",
       "  -1.5222380801742172,\n",
       "  0.08782171869349681,\n",
       "  0.5590522098672563],\n",
       " [-1.3953655406220515,\n",
       "  1.4335506723447256,\n",
       "  -0.3235503108956018,\n",
       "  0.09906435259647797,\n",
       "  -1.1392832379351627,\n",
       "  0.21553569424384608,\n",
       "  0.2364530685630232,\n",
       "  -0.6946140668445995,\n",
       "  1778544000.0,\n",
       "  -0.18060690399377236,\n",
       "  0.6914198964930356,\n",
       "  0.6894449431505669,\n",
       "  -0.7610041726391095],\n",
       " [1.5599040677301357,\n",
       "  0.14572644666175882,\n",
       "  -0.5083506969884595,\n",
       "  1.2383235176046696,\n",
       "  1.1015463175122537,\n",
       "  1.0021798309006442,\n",
       "  0.31425308719757256,\n",
       "  -0.9671129805825113,\n",
       "  1768780800.0,\n",
       "  -1.390318989949607,\n",
       "  -0.8241567036058923,\n",
       "  0.03892385123235863,\n",
       "  0.017989282718157345],\n",
       " [1.23256626824649,\n",
       "  1.397064299041991,\n",
       "  1.5206188038587962,\n",
       "  1.061499049029175,\n",
       "  0.5001515379664871,\n",
       "  -1.4376477435816124,\n",
       "  -0.0860336477742171,\n",
       "  -1.0890493017240284,\n",
       "  1752192000.0,\n",
       "  -1.5391088503015704,\n",
       "  -0.8198080502854146,\n",
       "  -0.3225274876393584,\n",
       "  -1.3999205352671351],\n",
       " [-0.8559869312188971,\n",
       "  0.7857025799150792,\n",
       "  -1.5374296767844948,\n",
       "  -0.6997950145343828,\n",
       "  1.0720265423147224,\n",
       "  1.1366431247739297,\n",
       "  1.0995191626677356,\n",
       "  1.2558905270279928,\n",
       "  1754697600.0,\n",
       "  1.4862909790676209,\n",
       "  1.5912564331753956,\n",
       "  -0.6970497405271743,\n",
       "  1.5301214260537288],\n",
       " [1.4272647555767182,\n",
       "  1.234793833923291,\n",
       "  -0.4745707288337207,\n",
       "  -0.19815788442959698,\n",
       "  -0.3375979443316693,\n",
       "  0.04775777661436564,\n",
       "  -0.9323350801656188,\n",
       "  0.32178716827038367,\n",
       "  1740528000.0,\n",
       "  -1.1213106130669668,\n",
       "  -0.9467538281068638,\n",
       "  1.1065634774435236,\n",
       "  0.8953063253404872],\n",
       " [-0.5427983316996187,\n",
       "  -1.6352537908401086,\n",
       "  -1.5687629100730496,\n",
       "  0.5626222013923861,\n",
       "  1.358633930576944,\n",
       "  -0.7992990138683305,\n",
       "  0.48923782056409254,\n",
       "  0.46885973135383613,\n",
       "  1765152000.0,\n",
       "  1.405010533818711,\n",
       "  1.2186573270458165,\n",
       "  1.1836835002888204,\n",
       "  0.8413346616502225],\n",
       " [-1.5688923147141096,\n",
       "  0.2807928116662171,\n",
       "  1.3623205435426942,\n",
       "  -1.0537281351426462,\n",
       "  1.5812083666080716,\n",
       "  -0.38351288107851306,\n",
       "  -0.883030947304508,\n",
       "  -1.3316255023754984,\n",
       "  1761523200.0,\n",
       "  -0.4954442821241813,\n",
       "  0.5229333486432564,\n",
       "  -0.8008435431870488,\n",
       "  0.9297004784110023],\n",
       " [0.9428007994317756,\n",
       "  1.5677109194802714,\n",
       "  -0.9539212190494722,\n",
       "  1.0036598551070188,\n",
       "  -0.3531454085648161,\n",
       "  -0.562783218418196,\n",
       "  -1.4358287668289151,\n",
       "  1.6647932450387781,\n",
       "  1757721600.0,\n",
       "  0.6751292487938526,\n",
       "  0.8968157350299486,\n",
       "  1.3580604549970603,\n",
       "  -0.9296841062108069],\n",
       " [-0.15416870150882603,\n",
       "  0.41534638128630114,\n",
       "  -0.564714600703136,\n",
       "  -0.83959506010774,\n",
       "  -0.23872480558508566,\n",
       "  -0.15995905006555294,\n",
       "  0.2829014122732928,\n",
       "  0.8962300144056484,\n",
       "  1775865600.0,\n",
       "  1.1321278226367333,\n",
       "  -0.07782715217421865,\n",
       "  -0.19895414944887754,\n",
       "  -1.0596634083083825],\n",
       " [1.5201847528906254,\n",
       "  -1.3775711008607314,\n",
       "  0.1272708291446431,\n",
       "  -1.5000457020457965,\n",
       "  -0.2263054210941926,\n",
       "  0.47465577577637513,\n",
       "  -1.1508355032673714,\n",
       "  -1.3484167219398422,\n",
       "  1775347200.0,\n",
       "  0.021599311827899884,\n",
       "  0.9843061301497856,\n",
       "  0.8520597856178032,\n",
       "  0.6558976773527184],\n",
       " [1.151810953936127,\n",
       "  1.0685962695635742,\n",
       "  -1.3386853682691262,\n",
       "  -0.7099828415567938,\n",
       "  0.43239734675861397,\n",
       "  -0.8843240569720096,\n",
       "  -1.3940094053875285,\n",
       "  0.6990623017447848,\n",
       "  1795996800.0,\n",
       "  0.6945528226451458,\n",
       "  0.9625332412267874,\n",
       "  -0.849625271967804,\n",
       "  -0.8988534394231738],\n",
       " [0.9263237977479749,\n",
       "  1.5224074520165307,\n",
       "  1.2245073741399934,\n",
       "  -0.9944686854495458,\n",
       "  -1.063364024384799,\n",
       "  -1.4667787989022358,\n",
       "  -0.8672409945829898,\n",
       "  1.5244748308937979,\n",
       "  1759276800.0,\n",
       "  1.4978391144737657,\n",
       "  1.5656809407552732,\n",
       "  0.37501316402751717,\n",
       "  1.1263877631907797],\n",
       " [0.4176490576344971,\n",
       "  -1.1926365809574788,\n",
       "  -0.2668920883181679,\n",
       "  0.7319074303532447,\n",
       "  -1.6269384386434402,\n",
       "  -1.607490785823026,\n",
       "  0.04403647381404328,\n",
       "  -0.10726714822972136,\n",
       "  1753401600.0,\n",
       "  0.8002999839044314,\n",
       "  -1.6526224842404047,\n",
       "  -0.3794658447573783,\n",
       "  -0.9167979237558116],\n",
       " [-1.1481450318450959,\n",
       "  0.37103609413572863,\n",
       "  -0.490249633013446,\n",
       "  0.7329722236877648,\n",
       "  -0.30947900256711963,\n",
       "  -1.0679537817796585,\n",
       "  1.6016165039735621,\n",
       "  1.6680524354462063,\n",
       "  1749945600.0,\n",
       "  -1.4184840946729327,\n",
       "  0.35943610999034403,\n",
       "  -1.0251191217381237,\n",
       "  0.6997203573131981],\n",
       " [0.15624917109394743,\n",
       "  -0.11583343873219135,\n",
       "  -0.028006498811706693,\n",
       "  -0.014825383800966551,\n",
       "  -0.9817907597845754,\n",
       "  -0.24795794329326076,\n",
       "  1.125848975356145,\n",
       "  0.050330523014090515,\n",
       "  1783987200.0,\n",
       "  -0.04981652019626669,\n",
       "  -0.9012038730998385,\n",
       "  1.0368638951877014,\n",
       "  -0.6994696478971244],\n",
       " [-0.7093474965336622,\n",
       "  0.15418981477549332,\n",
       "  0.7344884120628133,\n",
       "  1.1466519278121006,\n",
       "  -0.521360327509375,\n",
       "  1.1761914748244784,\n",
       "  1.093723625964029,\n",
       "  1.098086679936539,\n",
       "  1770681600.0,\n",
       "  -1.3093618362576611,\n",
       "  1.0852550804641992,\n",
       "  1.2387029113142087,\n",
       "  0.46528933828144453],\n",
       " [-1.1493738161724298,\n",
       "  0.862946820573344,\n",
       "  -0.4253642345301424,\n",
       "  1.3274106346620909,\n",
       "  -0.20087831172075601,\n",
       "  1.6723431796706323,\n",
       "  -1.203631708409267,\n",
       "  -1.3676780904015855,\n",
       "  1777161600.0,\n",
       "  -1.1494103560604512,\n",
       "  1.6648441826313654,\n",
       "  1.4847671076452913,\n",
       "  -0.2900863569625991],\n",
       " [-1.2866028195433636,\n",
       "  -1.6294140800005383,\n",
       "  1.0538150384525247,\n",
       "  -0.5592810632744022,\n",
       "  1.0818699103903535,\n",
       "  1.444353559387878,\n",
       "  -0.8780412825892482,\n",
       "  -0.21799791055045986,\n",
       "  1745107200.0,\n",
       "  1.3373182125689536,\n",
       "  -0.11313280565945712,\n",
       "  -1.2617241691004177,\n",
       "  1.3094482541017864],\n",
       " [-0.8300335924806014,\n",
       "  0.11180982196734403,\n",
       "  -0.2493947202372964,\n",
       "  0.926184596930155,\n",
       "  1.516002050431694,\n",
       "  -1.2252443557933765,\n",
       "  1.4019730059439626,\n",
       "  -1.1450994138518495,\n",
       "  1784851200.0,\n",
       "  0.5970244273711651,\n",
       "  -0.460350617516068,\n",
       "  1.643889496428613,\n",
       "  -0.11155309002479745],\n",
       " [1.6143651964115657,\n",
       "  1.1764082670496223,\n",
       "  -1.2342291777603092,\n",
       "  -1.4261219903304048,\n",
       "  -0.3039154523501483,\n",
       "  0.3768160942113047,\n",
       "  1.242945393753515,\n",
       "  0.15517063481577528,\n",
       "  1769644800.0,\n",
       "  0.7801064889869462,\n",
       "  0.13487191261970258,\n",
       "  -1.102992575386267,\n",
       "  1.5666030482860347],\n",
       " [0.39805092766989736,\n",
       "  0.7867968969172336,\n",
       "  -1.2699315740562735,\n",
       "  -1.3669909578228872,\n",
       "  -0.2652738901219118,\n",
       "  -0.7943152668838892,\n",
       "  -0.12386338250577598,\n",
       "  -0.07967004923767813,\n",
       "  1736121600.0,\n",
       "  1.6403291577062056,\n",
       "  1.6229331911657503,\n",
       "  1.692411668458784,\n",
       "  0.7549883609213007],\n",
       " [-0.5170710246400123,\n",
       "  -0.8007185817018231,\n",
       "  0.9718751795654249,\n",
       "  1.1757738964254347,\n",
       "  0.36305037828642445,\n",
       "  -1.0974556091461452,\n",
       "  -0.5343899215384329,\n",
       "  -1.6942288032140116,\n",
       "  1792195200.0,\n",
       "  -0.028371746148819963,\n",
       "  -1.2075375139723852,\n",
       "  -0.4196678319240253,\n",
       "  -1.6000964498099324],\n",
       " [-1.5512445954850091,\n",
       "  -0.3499684648856919,\n",
       "  0.2966545503238897,\n",
       "  0.17863313687821367,\n",
       "  1.3689194794992716,\n",
       "  0.21260474856927256,\n",
       "  1.35693785922657,\n",
       "  0.7118694044857325,\n",
       "  1784505600.0,\n",
       "  -0.48790089312053525,\n",
       "  0.5722647695041435,\n",
       "  -1.6647373146519462,\n",
       "  0.22392992335780967],\n",
       " [0.8516843348709545,\n",
       "  -0.3178844652896961,\n",
       "  1.5505525803817726,\n",
       "  1.3053009943282863,\n",
       "  0.3095089725606548,\n",
       "  -0.9630928326874263,\n",
       "  -0.2907402836137587,\n",
       "  0.0047300598976687536,\n",
       "  1742947200.0,\n",
       "  1.1100354346573056,\n",
       "  -0.5574889589849147,\n",
       "  -0.3413059567624684,\n",
       "  -0.2707458306736524],\n",
       " [-0.23192346498036343,\n",
       "  -0.19992555937066445,\n",
       "  0.0654351898538,\n",
       "  1.3961420236320081,\n",
       "  -0.00891109846229543,\n",
       "  -0.10431543139973609,\n",
       "  -0.6196202384784754,\n",
       "  0.018534297881205353,\n",
       "  1753747200.0,\n",
       "  -1.5762725744290846,\n",
       "  0.2623670692948481,\n",
       "  -1.4695863395164723,\n",
       "  1.367183704917163],\n",
       " [1.5670382667911222,\n",
       "  -0.04251378598687019,\n",
       "  -0.9071050643182087,\n",
       "  -1.3120396573126805,\n",
       "  -1.2011826990401555,\n",
       "  -1.4675248229909243,\n",
       "  0.9446706923787687,\n",
       "  -1.4605535955735331,\n",
       "  1738972800.0,\n",
       "  0.49592624772975347,\n",
       "  1.3326417975378309,\n",
       "  0.2426858406486962,\n",
       "  1.7122997823883983],\n",
       " [0.622790175843834,\n",
       "  0.1263623869591447,\n",
       "  -0.7024625287074471,\n",
       "  -0.2611405380735621,\n",
       "  -1.573868210579681,\n",
       "  -0.756501915578787,\n",
       "  -1.0128150554659316,\n",
       "  1.6442909969532205,\n",
       "  1779926400.0,\n",
       "  -1.2922947261949962,\n",
       "  1.2689872408471359,\n",
       "  -0.6732115129927971,\n",
       "  0.0944968296767306],\n",
       " [-0.2655151115756907,\n",
       "  1.2312112606760663,\n",
       "  0.8717907286953767,\n",
       "  0.5855188797287145,\n",
       "  0.9395607730549934,\n",
       "  0.857856035312174,\n",
       "  0.025707898121929296,\n",
       "  -0.3544627363315747,\n",
       "  1772928000.0,\n",
       "  0.33271876055441774,\n",
       "  0.468016905739441,\n",
       "  -0.029527726272931168,\n",
       "  -1.7642159084693194],\n",
       " [0.17591945874133752,\n",
       "  1.6576469926005828,\n",
       "  -0.8477049285281875,\n",
       "  -1.1573862976696405,\n",
       "  1.525143676287086,\n",
       "  -1.3765230885500224,\n",
       "  0.12868040887389143,\n",
       "  -1.4986523790403683,\n",
       "  1775260800.0,\n",
       "  -0.2273239995529412,\n",
       "  0.47658350550632034,\n",
       "  -1.154404248114309,\n",
       "  -1.352231149348316],\n",
       " [-1.6170863683047778,\n",
       "  -1.4564376167730755,\n",
       "  -0.5643674892207171,\n",
       "  -0.814398836179828,\n",
       "  1.0960385786685816,\n",
       "  1.1412390671307655,\n",
       "  0.571616909119462,\n",
       "  0.21575737851020219,\n",
       "  1767657600.0,\n",
       "  -0.08606490239613239,\n",
       "  1.5387051248053523,\n",
       "  -1.4112916496777583,\n",
       "  1.7011603668045376],\n",
       " [-0.6340400422919876,\n",
       "  0.9901386909342754,\n",
       "  1.371449271544288,\n",
       "  -0.7406115125535961,\n",
       "  -0.548117213487984,\n",
       "  0.7839430621367991,\n",
       "  1.363869104804926,\n",
       "  -1.0430336173679307,\n",
       "  1743897600.0,\n",
       "  1.151387510920538,\n",
       "  1.424453612934619,\n",
       "  -0.3658944399805751,\n",
       "  0.32188181666112603],\n",
       " [1.4028614466655422,\n",
       "  1.2142145672846163,\n",
       "  1.184690437189393,\n",
       "  0.8454433094362128,\n",
       "  -0.931017838604435,\n",
       "  -0.8333041870370037,\n",
       "  1.518914004964376,\n",
       "  1.6060415790980977,\n",
       "  1765324800.0,\n",
       "  -1.5105458741022308,\n",
       "  -1.6598130489438672,\n",
       "  -1.30331785652789,\n",
       "  -0.388367657029427],\n",
       " [0.8254908878342783,\n",
       "  0.02981546972797916,\n",
       "  1.7970991638676188,\n",
       "  0.2518200449798953,\n",
       "  -0.8263722933076356,\n",
       "  0.1135731989664491,\n",
       "  -0.24751640134021835,\n",
       "  0.9262208115174206,\n",
       "  1784764800.0,\n",
       "  1.5131426231580005,\n",
       "  -1.2238256827574945,\n",
       "  1.4011018995480604,\n",
       "  -1.1489486486940057],\n",
       " [0.0991450959820139,\n",
       "  1.1480121852812635,\n",
       "  1.5493951162542947,\n",
       "  -0.23345552698660904,\n",
       "  0.6169885948043554,\n",
       "  0.28686685500008485,\n",
       "  -0.737239248742139,\n",
       "  1.1785104815731033,\n",
       "  1765843200.0,\n",
       "  -1.490518929506916,\n",
       "  1.3615638754257036,\n",
       "  -1.1777090749168364,\n",
       "  0.9847811522290459],\n",
       " [1.0168519377217806,\n",
       "  0.2110617827142174,\n",
       "  1.4220760043911986,\n",
       "  0.777068036156564,\n",
       "  -0.151930372767169,\n",
       "  0.6102920918010435,\n",
       "  -1.1422023921225837,\n",
       "  -1.628897028602277,\n",
       "  1756857600.0,\n",
       "  -1.0560097993478208,\n",
       "  -1.8128409643142813,\n",
       "  -0.1989454849059634,\n",
       "  -1.615098506692552],\n",
       " [-0.14423145100802295,\n",
       "  -0.20539437241753197,\n",
       "  1.735611011830078,\n",
       "  -0.6189219825089649,\n",
       "  0.47659855986448635,\n",
       "  -1.1379326479818996,\n",
       "  -1.555369641915872,\n",
       "  0.2130039069117393,\n",
       "  1737158400.0,\n",
       "  -1.3484963535423906,\n",
       "  1.6775183497681299,\n",
       "  -0.1953422585782113,\n",
       "  1.0790442551690476],\n",
       " [0.46546087786045615,\n",
       "  -1.2199991120759421,\n",
       "  -0.46818757322397664,\n",
       "  0.5305095738329022,\n",
       "  -1.073363527456413,\n",
       "  -0.26092797717170657,\n",
       "  0.0973172963969652,\n",
       "  0.8725857782592346,\n",
       "  1763251200.0,\n",
       "  0.3568791623445887,\n",
       "  0.37281230824251504,\n",
       "  -1.4509995221195653,\n",
       "  0.44276100539866303],\n",
       " [-0.5556503948547499,\n",
       "  1.1674049701257085,\n",
       "  -1.5527167481183781,\n",
       "  -0.003839417814450588,\n",
       "  -0.09775588188971318,\n",
       "  0.942886643281098,\n",
       "  0.4346436924746541,\n",
       "  0.7763458460511566,\n",
       "  1787875200.0,\n",
       "  -1.2035600955798431,\n",
       "  1.4528909489114559,\n",
       "  -0.27369822255820453,\n",
       "  -0.7372178014759942],\n",
       " [0.6326802403483571,\n",
       "  -1.7023871582487455,\n",
       "  -1.3794554459293111,\n",
       "  -0.26729090142995854,\n",
       "  0.6753900845434918,\n",
       "  -0.5999315900790256,\n",
       "  1.3986980201776043,\n",
       "  -1.1156853017748638,\n",
       "  1769472000.0,\n",
       "  1.6164074716143626,\n",
       "  1.180821541048414,\n",
       "  -1.234778877328457,\n",
       "  -1.428571372354763],\n",
       " [-0.8165722690017099,\n",
       "  -0.8283165401135568,\n",
       "  -1.113690351411794,\n",
       "  0.672844292072857,\n",
       "  -0.1359554987641257,\n",
       "  1.5699711409096184,\n",
       "  -1.1573706952802147,\n",
       "  -0.4293370729941664,\n",
       "  1759622400.0,\n",
       "  -1.0020998253769944,\n",
       "  0.039580897063748406,\n",
       "  1.7290343340331387,\n",
       "  -0.1486268564587406],\n",
       " [0.38109652307599995,\n",
       "  -1.0564230044144978,\n",
       "  -1.5294698577705719,\n",
       "  0.03609170514114841,\n",
       "  0.3132314395514852,\n",
       "  -1.3263768196167136,\n",
       "  -0.4952213599811623,\n",
       "  -0.11787942908654465,\n",
       "  1750377600.0,\n",
       "  -0.5250047243498696,\n",
       "  -0.20359491167782418,\n",
       "  1.3319227461179401,\n",
       "  1.3069668330467255],\n",
       " [1.0017755968729865,\n",
       "  -0.8884504876191069,\n",
       "  -0.6511806406863598,\n",
       "  0.43556287761053064,\n",
       "  1.304601352647348,\n",
       "  -1.3584347813780489,\n",
       "  1.277323243415106,\n",
       "  0.4540928267150939,\n",
       "  1795737600.0,\n",
       "  0.514714004636663,\n",
       "  0.5369075862094546,\n",
       "  -1.203142757027975,\n",
       "  -0.8308578891655868],\n",
       " [1.06278200889525,\n",
       "  0.7682919632424657,\n",
       "  -1.156440135663203,\n",
       "  1.6912007570040921,\n",
       "  -0.05925031141247706,\n",
       "  -0.6641989432745592,\n",
       "  1.5367116901602376,\n",
       "  -0.797601567196194,\n",
       "  1791849600.0,\n",
       "  0.745836101077318,\n",
       "  -1.4787873222449395,\n",
       "  1.224834906966532,\n",
       "  -0.5964305940540119],\n",
       " [-0.9965057404244456,\n",
       "  -0.09134551937994755,\n",
       "  -1.5249224191207222,\n",
       "  -0.41594724101263336,\n",
       "  1.6423218878218544,\n",
       "  1.4655129719076103,\n",
       "  0.568079712380586,\n",
       "  -0.9239937467719034,\n",
       "  1777852800.0,\n",
       "  1.6822921805774647,\n",
       "  1.5430673275487503,\n",
       "  0.6660481871861641,\n",
       "  0.9197929808709253],\n",
       " [1.6600411062581752,\n",
       "  1.4726079363174331,\n",
       "  1.5606188184485956,\n",
       "  -0.6478450112242773,\n",
       "  -1.3728911866923639,\n",
       "  0.543113975035248,\n",
       "  1.1135662227628411,\n",
       "  0.8890316167024876,\n",
       "  1794787200.0,\n",
       "  -1.1211947276261005,\n",
       "  -0.4666799305943379,\n",
       "  0.3073502863013175,\n",
       "  -0.10960329549360046],\n",
       " [-0.30088472287897366,\n",
       "  -0.31850326340353735,\n",
       "  -1.3829858549431935,\n",
       "  0.4664453932629935,\n",
       "  0.8243132794779159,\n",
       "  -1.5733581936122054,\n",
       "  -1.1489418155143192,\n",
       "  1.5590429585989987,\n",
       "  1779580800.0,\n",
       "  -0.8545952606911223,\n",
       "  -0.06765737477508178,\n",
       "  -0.4817315930511171,\n",
       "  0.9049532099998869],\n",
       " [-1.0594023594880266,\n",
       "  -1.8149212506655898,\n",
       "  -0.19819994946227287,\n",
       "  -1.6127854730821745,\n",
       "  1.0896267748786073,\n",
       "  -0.3289501104374591,\n",
       "  1.1804504390720394,\n",
       "  1.5620487800030587,\n",
       "  1757030400.0,\n",
       "  -1.5479388068756847,\n",
       "  -0.7302171732330759,\n",
       "  1.772240132508565,\n",
       "  -1.6383043844484737],\n",
       " [1.5110481716087365,\n",
       "  -1.226364993923253,\n",
       "  1.4021499418260899,\n",
       "  -1.1462948668378508,\n",
       "  0.5989148989216878,\n",
       "  -0.4619978544149272,\n",
       "  1.6445043118516374,\n",
       "  -0.10752622515056873,\n",
       "  1784937600.0,\n",
       "  -0.8413539084904628,\n",
       "  -1.1629014073107116,\n",
       "  -1.0215641715326338,\n",
       "  1.7136346139642074],\n",
       " [1.3640467644486904,\n",
       "  0.21079382855283596,\n",
       "  1.3570586815622177,\n",
       "  0.7117132256462906,\n",
       "  -0.48715792044443523,\n",
       "  0.5703083953818541,\n",
       "  -1.6606298530015342,\n",
       "  0.22801423195052067,\n",
       "  1784592000.0,\n",
       "  0.8279315540991666,\n",
       "  0.03333449693215887,\n",
       "  1.7959764661410935,\n",
       "  0.24814500953959526],\n",
       " [-1.5427455045729088,\n",
       "  -0.8226622159627403,\n",
       "  -0.32180531675398744,\n",
       "  -1.3974502099295691,\n",
       "  -0.07781984736253553,\n",
       "  1.1640233814479422,\n",
       "  0.44970692458571665,\n",
       "  1.433135764687188,\n",
       "  1752364800.0,\n",
       "  1.2593085094868357,\n",
       "  0.10533658448828802,\n",
       "  -0.1604923128894675,\n",
       "  0.9958639716219776],\n",
       " [-1.679229945857074,\n",
       "  1.3244112975366034,\n",
       "  0.6084190318844294,\n",
       "  0.8392326326527253,\n",
       "  -1.145888834068308,\n",
       "  0.8650709762535203,\n",
       "  -0.4232669314338766,\n",
       "  1.3272224240438755,\n",
       "  1777075200.0,\n",
       "  -0.2019237553941252,\n",
       "  1.6746295721120066,\n",
       "  -1.2072562447785793,\n",
       "  -1.3714892203101479],\n",
       " [-1.2958066733714726,\n",
       "  1.2645052585393104,\n",
       "  -0.672555642840388,\n",
       "  0.0980595507038504,\n",
       "  1.6834419770747924,\n",
       "  1.2276928181349835,\n",
       "  -1.2619660126245262,\n",
       "  0.8987730688616529,\n",
       "  1780099200.0,\n",
       "  0.17777246282647996,\n",
       "  -1.5347996813591158,\n",
       "  -1.2541068358225027,\n",
       "  0.876216415621579],\n",
       " [-1.6166331105011933,\n",
       "  1.1964610009217893,\n",
       "  0.7253877185768102,\n",
       "  -0.07995573124781374,\n",
       "  -0.5134686393245516,\n",
       "  -0.5667884782193398,\n",
       "  -0.22322367912866595,\n",
       "  1.2609949407956524,\n",
       "  1741046400.0,\n",
       "  1.592748931623899,\n",
       "  0.7380215041213202,\n",
       "  -0.05763761145693867,\n",
       "  -1.5602346636921787],\n",
       " [0.017728602944724378,\n",
       "  -1.2970661258718343,\n",
       "  -0.11605347221665767,\n",
       "  0.6916484733855901,\n",
       "  -1.6760375128049156,\n",
       "  1.3267570992622666,\n",
       "  0.6092298496389628,\n",
       "  0.839317483695791,\n",
       "  1776988800.0,\n",
       "  -1.145935819358984,\n",
       "  0.8671156207760323,\n",
       "  -0.42606683014603347,\n",
       "  1.32294993365489],\n",
       " [0.335345254176232,\n",
       "  -0.2234897661159419,\n",
       "  -0.4920226410504536,\n",
       "  -0.26882502233759986,\n",
       "  -1.5479814979810893,\n",
       "  -0.34842688465813093,\n",
       "  0.2978533415044116,\n",
       "  0.17908749329639884,\n",
       "  1784419200.0,\n",
       "  1.366215453485588,\n",
       "  0.21445400378938714,\n",
       "  1.356019162679274,\n",
       "  0.7077022610523068],\n",
       " [-0.3570678459468314,\n",
       "  -0.5642218905631111,\n",
       "  -1.4391877164336377,\n",
       "  1.6651703810839735,\n",
       "  0.6771023298963663,\n",
       "  0.8947621990934876,\n",
       "  1.3589769967193128,\n",
       "  -0.9257973273793901,\n",
       "  1757808000.0,\n",
       "  0.1979442930962629,\n",
       "  0.6741323379827165,\n",
       "  -1.190966923940001,\n",
       "  0.7599557052927187],\n",
       " [1.5986356316722974,\n",
       "  1.6759799416133434,\n",
       "  0.10673654999616844,\n",
       "  0.8483949697038815,\n",
       "  1.2097295627733995,\n",
       "  1.529668532351917,\n",
       "  1.6515233182615452,\n",
       "  0.6597804488065712,\n",
       "  1737849600.0,\n",
       "  -1.464574695163628,\n",
       "  0.6830375394314584,\n",
       "  1.4155675925577493,\n",
       "  -0.3337813431129259],\n",
       " [-0.807258467197812,\n",
       "  1.310207674481032,\n",
       "  0.3280716369322966,\n",
       "  1.166416930012696,\n",
       "  0.659980215587865,\n",
       "  0.6337240089313236,\n",
       "  -1.195499962363115,\n",
       "  0.8128599347782265,\n",
       "  1763078400.0,\n",
       "  0.4680833636325827,\n",
       "  -1.217454836053043,\n",
       "  -0.46888207413964333,\n",
       "  0.5266309695172551],\n",
       " [1.502296671018344,\n",
       "  -0.65025745915886,\n",
       "  -0.09418383855517438,\n",
       "  -0.8157290135850024,\n",
       "  -0.6144206015368872,\n",
       "  0.8064363735668203,\n",
       "  -1.3605464332278085,\n",
       "  -0.05864969254361419,\n",
       "  1775692800.0,\n",
       "  -0.15123329530876278,\n",
       "  0.4191660904611771,\n",
       "  -0.565390855555445,\n",
       "  -0.8424728709576723],\n",
       " [1.3391749249060898,\n",
       "  -1.644219285497025,\n",
       "  0.2503321581754889,\n",
       "  -0.20737407936976454,\n",
       "  -1.144659371293241,\n",
       "  0.37292398012952505,\n",
       "  -0.4880715836749521,\n",
       "  0.7331165113373161,\n",
       "  1749859200.0,\n",
       "  -0.31040970331691536,\n",
       "  -1.0664880060827862,\n",
       "  1.600956367564183,\n",
       "  1.6637215957797762],\n",
       " [-0.42164219653262747,\n",
       "  -0.7611001863152725,\n",
       "  0.1060204251422135,\n",
       "  0.29812161133327014,\n",
       "  0.23915896360375982,\n",
       "  -0.5944670849608158,\n",
       "  -1.6808693398203585,\n",
       "  -1.759799250788328,\n",
       "  1759881600.0,\n",
       "  1.2397107786358155,\n",
       "  0.9708225162011348,\n",
       "  0.46698132897083267,\n",
       "  -0.7256891347250628],\n",
       " [1.2570858038718558,\n",
       "  0.10176144542094386,\n",
       "  -0.15973950744399454,\n",
       "  1.0000855779134583,\n",
       "  -0.9701034261379282,\n",
       "  -0.4080334484495505,\n",
       "  0.08415145667416904,\n",
       "  -1.2249744382712806,\n",
       "  1752537600.0,\n",
       "  -1.4559626381243385,\n",
       "  -1.1031172740962976,\n",
       "  -1.4093213402291915,\n",
       "  -1.562212455867247],\n",
       " [0.9959221870818205,\n",
       "  1.1662710673292547,\n",
       "  -1.4604076633616796,\n",
       "  1.4625829412317501,\n",
       "  0.15311651465061973,\n",
       "  -1.524209701820708,\n",
       "  1.4771592621571976,\n",
       "  -0.3198301022597962,\n",
       "  1769299200.0,\n",
       "  0.635218278321006,\n",
       "  -1.7002191046869128,\n",
       "  -1.3799776940389463,\n",
       "  -0.2705867520764273],\n",
       " [-0.7118190320663111,\n",
       "  -1.5745824230903165,\n",
       "  -0.2580423794196766,\n",
       "  0.944467136017816,\n",
       "  0.9429033826331843,\n",
       "  1.59809125987723,\n",
       "  1.3974335743146182,\n",
       "  0.638930096959382,\n",
       "  1771718400.0,\n",
       "  -0.27375419738199686,\n",
       "  -1.5722710579482677,\n",
       "  -0.9324066204281704,\n",
       "  0.5616037770482395],\n",
       " [-0.93164521491999,\n",
       "  0.36420165130721055,\n",
       "  0.16233469438483641,\n",
       "  -0.4018447206378296,\n",
       "  -1.3920163777370476,\n",
       "  1.435948894813568,\n",
       "  -0.32157970952163645,\n",
       "  0.09956321569938195,\n",
       "  1778457600.0,\n",
       "  -1.139337202420965,\n",
       "  0.21738582717288477,\n",
       "  0.23435031812206927,\n",
       "  -0.6985404236936739],\n",
       " [1.2009077301068667,\n",
       "  -1.3559766713097188,\n",
       "  -1.1498607995579317,\n",
       "  -0.6278220423800702,\n",
       "  -0.4157978175726009,\n",
       "  -1.688798876474727,\n",
       "  0.14830777003693782,\n",
       "  0.1334756717697063,\n",
       "  1765670400.0,\n",
       "  0.10195257565217555,\n",
       "  1.1524033127035542,\n",
       "  1.5483192408931186,\n",
       "  -0.23677609269557306],\n",
       " [1.6082214004110484,\n",
       "  0.9564293694445662,\n",
       "  -0.7320189027751867,\n",
       "  1.487161955705504,\n",
       "  -0.3788216535614492,\n",
       "  -0.7453292858403409,\n",
       "  0.7653509664182988,\n",
       "  0.9104728282672396,\n",
       "  1762646400.0,\n",
       "  -1.273950218457759,\n",
       "  1.4439245351639245,\n",
       "  0.8847838641217329,\n",
       "  0.8413431611958534],\n",
       " [1.1433394591553845,\n",
       "  1.4531195349188666,\n",
       "  1.0221320865926404,\n",
       "  0.6648511420581757,\n",
       "  -1.0414912734684232,\n",
       "  -0.07039199713140205,\n",
       "  1.4506766941403666,\n",
       "  1.6339658972063242,\n",
       "  1793145600.0,\n",
       "  1.2997012537810069,\n",
       "  1.4674340953897271,\n",
       "  0.28143039759126426,\n",
       "  0.147428755011005],\n",
       " [-0.08624649220792974,\n",
       "  -0.4645002533420794,\n",
       "  -1.549670996141376,\n",
       "  -1.6111311808951405,\n",
       "  1.483270156022284,\n",
       "  -1.3852985201030747,\n",
       "  0.05264958594857332,\n",
       "  1.038669723714637,\n",
       "  1747267200.0,\n",
       "  0.4792890260722273,\n",
       "  -1.3315860810871678,\n",
       "  -0.21730824346078612,\n",
       "  -0.9624246291431764],\n",
       " [1.2974989572970386,\n",
       "  1.462797461694345,\n",
       "  0.28226675346247393,\n",
       "  0.15103016844657194,\n",
       "  0.19885343058004434,\n",
       "  0.5915171364242686,\n",
       "  1.1571152376409863,\n",
       "  -0.8288718186501608,\n",
       "  1793318400.0,\n",
       "  -0.7058897077323857,\n",
       "  -0.36235169425090846,\n",
       "  1.7596430684135278,\n",
       "  1.469153098892574],\n",
       " [0.7299688410006244,\n",
       "  0.8623689203246944,\n",
       "  0.5237383471168928,\n",
       "  0.3499903294359406,\n",
       "  1.3581611910147122,\n",
       "  0.2719582940585612,\n",
       "  -1.051587857764925,\n",
       "  -0.8214431631091386,\n",
       "  1744588800.0,\n",
       "  -0.6577480110315312,\n",
       "  0.031559278541983954,\n",
       "  -0.1970689505881472,\n",
       "  -1.4467325852026522],\n",
       " [-1.532832912407298,\n",
       "  0.5846324282553274,\n",
       "  -0.16683832491391154,\n",
       "  -0.2478844473187289,\n",
       "  -0.04474241153329643,\n",
       "  -1.4628097437471648,\n",
       "  -0.8828705186981959,\n",
       "  0.15270339519033638,\n",
       "  1768176000.0,\n",
       "  -0.7247388602377715,\n",
       "  -0.5332803804090603,\n",
       "  1.6542521348241113,\n",
       "  0.813440079735917],\n",
       " [0.7394438220131506,\n",
       "  -0.9041263406821399,\n",
       "  0.35872418692410507,\n",
       "  1.618036244852497,\n",
       "  1.374109416568978,\n",
       "  -0.3191009900511579,\n",
       "  1.7871102131488419,\n",
       "  -0.8963942913462027,\n",
       "  1743552000.0,\n",
       "  0.8841284746272052,\n",
       "  1.3786570451048892,\n",
       "  0.8639239765799054,\n",
       "  0.010762266936680072],\n",
       " [-0.6403284170098514,\n",
       "  -1.498004589861792,\n",
       "  0.9826887753615691,\n",
       "  -0.8659460506259138,\n",
       "  1.5072457178821006,\n",
       "  -0.6488601107658315,\n",
       "  -0.092498670902316,\n",
       "  -0.8147184621322133,\n",
       "  1775606400.0,\n",
       "  -0.6150291138152075,\n",
       "  0.8084634592125213,\n",
       "  -1.3643367866545606,\n",
       "  -0.06268492496256083],\n",
       " [1.2675843894371404,\n",
       "  0.24821989108217157,\n",
       "  -1.2734380134548455,\n",
       "  -1.333778934740104,\n",
       "  1.4235576950107836,\n",
       "  1.3996117860915243,\n",
       "  -0.20259378698306363,\n",
       "  -1.234812072481688,\n",
       "  1764547200.0,\n",
       "  0.33066566981241835,\n",
       "  -1.695558767927058,\n",
       "  0.7790007022853628,\n",
       "  0.42440749126730104],\n",
       " [-1.2857238631550234,\n",
       "  0.5648418909776086,\n",
       "  -1.1443210768852796,\n",
       "  -0.3668310469065166,\n",
       "  1.387110162126252,\n",
       "  -0.980174007259945,\n",
       "  0.8760742211856182,\n",
       "  0.43259579358029693,\n",
       "  1754524800.0,\n",
       "  -0.8526970983289425,\n",
       "  0.7898111360496274,\n",
       "  -1.537922063746425,\n",
       "  -0.7027749423822804],\n",
       " [1.6519327099508678,\n",
       "  -0.3462899726884674,\n",
       "  -0.6133256778601115,\n",
       "  0.12832090968087673,\n",
       "  0.6653607563374874,\n",
       "  -0.9177433456346331,\n",
       "  -1.0798455951664945,\n",
       "  1.1305204368010655,\n",
       "  1776297600.0,\n",
       "  0.14198099285290822,\n",
       "  -1.066685299325426,\n",
       "  -1.298511519293441,\n",
       "  -0.13061039081561124],\n",
       " [0.9161627005881562,\n",
       "  -0.3434198100551789,\n",
       "  -0.8296067341621522,\n",
       "  1.172884523589826,\n",
       "  1.177594937352863,\n",
       "  0.4811043718926183,\n",
       "  -1.686400240813274,\n",
       "  -0.3015244710970839,\n",
       "  1746489600.0,\n",
       "  -0.40318956730635197,\n",
       "  -1.0456743048604684,\n",
       "  1.3127387460288111,\n",
       "  1.4310680590354252],\n",
       " [1.0084352449594547,\n",
       "  0.25592315002210897,\n",
       "  0.2862274136090691,\n",
       "  -1.162090357740981,\n",
       "  -1.3990968936163748,\n",
       "  0.41930042231051273,\n",
       "  -1.3155081389079584,\n",
       "  1.174676729222363,\n",
       "  1789084800.0,\n",
       "  -1.382816725122403,\n",
       "  1.1242218850665398,\n",
       "  1.0509084324474527,\n",
       "  1.4049855323905804],\n",
       " [0.12950574017558228,\n",
       "  -1.522982118016799,\n",
       "  1.124830251559813,\n",
       "  -0.11166717778792559,\n",
       "  1.6036378700913225,\n",
       "  1.6784946053068652,\n",
       "  0.10817168348507392,\n",
       "  0.8484746958069332,\n",
       "  1737763200.0,\n",
       "  1.207193730132209,\n",
       "  1.5319121990572662,\n",
       "  1.6509159200582264,\n",
       "  0.6556222228769599],\n",
       " [0.48060125985820457,\n",
       "  -1.364843991883203,\n",
       "  1.492935055942907,\n",
       "  -0.3021775577535002,\n",
       "  -1.4616628925564166,\n",
       "  0.5636139451309649,\n",
       "  -1.5506275540634462,\n",
       "  0.8818117466412231,\n",
       "  1742169600.0,\n",
       "  -0.634930728242389,\n",
       "  1.2022512775475451,\n",
       "  0.9512219404444316,\n",
       "  -0.8603095794732428],\n",
       " [1.0771555963368464,\n",
       "  1.4419513020118255,\n",
       "  -0.8807052320395582,\n",
       "  -0.21867450042249675,\n",
       "  1.339991674680404,\n",
       "  -0.11488399021552936,\n",
       "  -1.258042135406306,\n",
       "  1.3137184326399527,\n",
       "  1745193600.0,\n",
       "  0.9853790419023496,\n",
       "  -1.176763477042808,\n",
       "  0.0749719596840878,\n",
       "  -0.30912874864959633],\n",
       " [-1.0668945457042482,\n",
       "  -1.4677834812961783,\n",
       "  -0.8698914869335186,\n",
       "  1.5247734361103291,\n",
       "  1.5006823556020554,\n",
       "  1.5634271645985462,\n",
       "  0.3769674282274602,\n",
       "  1.1306265968474298,\n",
       "  1759363200.0,\n",
       "  1.1354606761891837,\n",
       "  1.2371066586181265,\n",
       "  -1.3575169961109388,\n",
       "  -0.5059060030487943],\n",
       " [-1.6405230860728233,\n",
       "  0.6958303512686205,\n",
       "  -0.3475684875377981,\n",
       "  -0.5031267153968638,\n",
       "  0.6610788346951351,\n",
       "  -1.3285465825791003,\n",
       "  1.3141295402747424,\n",
       "  1.2412167269023258,\n",
       "  1773619200.0,\n",
       "  -1.2503350599450793,\n",
       "  -0.7853713542590987,\n",
       "  1.087772623685785,\n",
       "  0.4809853453557972],\n",
       " [0.19287043126631728,\n",
       "  1.5532173148126514,\n",
       "  -0.6121233206858421,\n",
       "  0.4420697578114125,\n",
       "  -0.012717361422655298,\n",
       "  -0.2124366412912399,\n",
       "  -0.5702844107815292,\n",
       "  -1.0933331550595617,\n",
       "  1744848000.0,\n",
       "  0.7804231394542538,\n",
       "  0.1804979062717759,\n",
       "  -1.0174487602785849,\n",
       "  -1.43398170502394]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[num_col_names] = scaler.fit_transform(x_train[num_col_names])\n",
    "x_train = x_train.values.tolist()\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d94c446-5579-410c-b781-a366b2d65c2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.3029533097167298,\n",
       "  -0.3155203579200086,\n",
       "  -1.3420648770569676,\n",
       "  -1.2029867122957856,\n",
       "  1.2799226780518171,\n",
       "  -0.45529779141236093,\n",
       "  0.3712607501308026,\n",
       "  1.4543660792107902,\n",
       "  1796256000.0,\n",
       "  -0.9302832634595462,\n",
       "  -0.7183818546966878,\n",
       "  1.0740229839198503,\n",
       "  0.398575111804636],\n",
       " [1.2750990736204555,\n",
       "  -0.45678806510788816,\n",
       "  0.3701534241799101,\n",
       "  1.454625447250934,\n",
       "  -0.930008187755192,\n",
       "  -0.7199518439956923,\n",
       "  1.0752393607273025,\n",
       "  0.40268932435265686,\n",
       "  1796342400.0,\n",
       "  0.32193834226129514,\n",
       "  0.5140645695865892,\n",
       "  1.413305803151964,\n",
       "  -0.038644988818313845],\n",
       " [-0.9336122980981445,\n",
       "  -0.7213150627046089,\n",
       "  1.0750091882746364,\n",
       "  0.40236010929379085,\n",
       "  0.3235378620135044,\n",
       "  0.5121256190359719,\n",
       "  1.414164026886776,\n",
       "  -0.034605640115474685,\n",
       "  1796428800.0,\n",
       "  -0.6534367604684743,\n",
       "  -0.9993182669415084,\n",
       "  -1.5406769490419758,\n",
       "  -0.8041958517632669],\n",
       " [0.3192420141954598,\n",
       "  0.5101709051882477,\n",
       "  1.4143561527143163,\n",
       "  -0.03517959237536658,\n",
       "  -0.6528688710150353,\n",
       "  -1.0008041514484156,\n",
       "  -1.5367004477544748,\n",
       "  -0.8002875859662699,\n",
       "  1796515200.0,\n",
       "  1.0362782865317788,\n",
       "  -0.9130200073948074,\n",
       "  -0.06580545516363642,\n",
       "  1.081147321127748],\n",
       " [-0.6566259136345851,\n",
       "  -1.0020325387205389,\n",
       "  -1.5401850829218893,\n",
       "  -0.8012900610117637,\n",
       "  1.0386333461045851,\n",
       "  -0.9145317272753478,\n",
       "  -0.06338585486651738,\n",
       "  1.0853784084034663,\n",
       "  1796601600.0,\n",
       "  -0.7109761309039406,\n",
       "  -0.560989480692666,\n",
       "  1.5263017463335382,\n",
       "  -1.5620218119110785],\n",
       " [1.0339428910483732,\n",
       "  -0.9158015321701796,\n",
       "  -0.06503474810983458,\n",
       "  1.0854312682120864,\n",
       "  -0.710469099429906,\n",
       "  -0.5626065890275674,\n",
       "  1.5270406895096176,\n",
       "  -1.5582433063087162,\n",
       "  1796688000.0,\n",
       "  0.7752423643124458,\n",
       "  -0.9348578633332238,\n",
       "  -0.9290945164117143,\n",
       "  0.010822598726714663],\n",
       " [-0.7141943568297777,\n",
       "  -0.564045345968633,\n",
       "  1.5273734590413803,\n",
       "  -1.5596699800680551,\n",
       "  0.7773213325992685,\n",
       "  -0.9363630455481093,\n",
       "  -0.9257636125874596,\n",
       "  0.014870417611529007,\n",
       "  1796774400.0,\n",
       "  1.296908939300177,\n",
       "  -1.4727615230065463,\n",
       "  -0.03503178091478287,\n",
       "  -0.8500139237741656],\n",
       " [0.7727750759252913,\n",
       "  -0.9376223696744671,\n",
       "  -0.9284870237999189,\n",
       "  0.014324155201440505,\n",
       "  1.2995396615154184,\n",
       "  -1.4741056713593428,\n",
       "  -0.03264466586408333,\n",
       "  -0.8461135032638896,\n",
       "  1796860800.0,\n",
       "  -0.9383421656401273,\n",
       "  -0.022317805814971583,\n",
       "  -0.5890319253090096,\n",
       "  -0.6670816028327661],\n",
       " [1.294705231951137,\n",
       "  -1.4751068362719817,\n",
       "  -0.03425525575404966,\n",
       "  -0.847141625315741,\n",
       "  -0.9380756136387476,\n",
       "  -0.024096177935020346,\n",
       "  -0.5860599976986673,\n",
       "  -0.6631498593871213,\n",
       "  1796947200.0,\n",
       "  -0.24233501202721122,\n",
       "  0.14274108975041697,\n",
       "  0.1775043237911942,\n",
       "  0.7731482412670875],\n",
       " [-0.9416752721781048,\n",
       "  -0.02579346268778279,\n",
       "  -0.588360140065064,\n",
       "  -0.6640755837126546,\n",
       "  -0.2413323103478066,\n",
       "  0.14091330344448744,\n",
       "  0.1796670818906054,\n",
       "  0.7773265908132321,\n",
       "  1797033600.0,\n",
       "  1.214794127513795,\n",
       "  0.18365778009802072,\n",
       "  0.9798356491374914,\n",
       "  -0.08095695707939622],\n",
       " [-0.2453164489415621,\n",
       "  0.1391368010215527,\n",
       "  0.1783210312770523,\n",
       "  0.7772070458476521,\n",
       "  1.2173379989086912,\n",
       "  0.18181774443748636,\n",
       "  0.9811514517968993,\n",
       "  -0.07692485332397993,\n",
       "  1797120000.0,\n",
       "  1.0509719850798143,\n",
       "  0.35962500271788966,\n",
       "  -1.5037939796851214,\n",
       "  1.2812272450826598],\n",
       " [1.2125489302392491,\n",
       "  0.18002160463075964,\n",
       "  0.9808040463243419,\n",
       "  -0.07752249002259584,\n",
       "  1.0533425858168153,\n",
       "  0.3577322872122753,\n",
       "  -1.4998564127263119,\n",
       "  1.2854925914247604,\n",
       "  1797206400.0,\n",
       "  -1.3503814466747692,\n",
       "  0.46695173920152977,\n",
       "  0.39229590366192796,\n",
       "  -0.7133878439515319],\n",
       " [1.0486440138411324,\n",
       "  0.3558516944388976,\n",
       "  -1.5032951404276083,\n",
       "  1.2856574474579376,\n",
       "  -1.3505506985045608,\n",
       "  0.46502689296289185,\n",
       "  0.39423192388972494,\n",
       "  -0.7094640293802942,\n",
       "  1797292800.0,\n",
       "  0.23114005337113028,\n",
       "  -0.3058474538978703,\n",
       "  -0.8166461946899218,\n",
       "  -1.1714596386362885],\n",
       " [-1.3539227431690262,\n",
       "  0.4630947902482758,\n",
       "  0.3931532198956898,\n",
       "  -0.7104156739684716,\n",
       "  0.23264353800245782,\n",
       "  -0.3075409448808856,\n",
       "  -0.8134339933452949,\n",
       "  -1.167614258281297,\n",
       "  1797379200.0,\n",
       "  -0.238832742846771,\n",
       "  -1.7187713218974014,\n",
       "  1.684772145958816,\n",
       "  1.4730054955324563],\n",
       " [0.22839784790315298,\n",
       "  -0.30910215361018406,\n",
       "  -0.8160174424665917,\n",
       "  -1.1688223119612347,\n",
       "  -0.23782633690324187,\n",
       "  -1.720041821545054,\n",
       "  1.6853438049185099,\n",
       "  1.4773036794710683,\n",
       "  1797465600.0,\n",
       "  -0.7789358717369875,\n",
       "  0.023466904587316234,\n",
       "  1.2252772022227345,\n",
       "  -0.19089244324386453],\n",
       " [-0.24181241017918853,\n",
       "  -1.7209249175524033,\n",
       "  1.685873819266196,\n",
       "  1.4775758848053544,\n",
       "  -0.7785007196122861,\n",
       "  0.021674825758625286,\n",
       "  1.226333912345155,\n",
       "  -0.18687916340163171,\n",
       "  1797552000.0,\n",
       "  0.1653360262849798,\n",
       "  0.6691628679017417,\n",
       "  0.015133402836278093,\n",
       "  0.0952387645912262],\n",
       " [-0.7821884354944927,\n",
       "  0.019955567285057558,\n",
       "  1.2262920028773576,\n",
       "  -0.18753833730573974,\n",
       "  0.16676991161247728,\n",
       "  0.6671774850996758,\n",
       "  0.01746756261284773,\n",
       "  0.09930103779495934,\n",
       "  1797638400.0,\n",
       "  -0.8426542500223528,\n",
       "  -0.666425436025651,\n",
       "  0.9050527581368425,\n",
       "  0.49667661077715664],\n",
       " [0.16256057219690087,\n",
       "  0.6651483340288129,\n",
       "  0.015919412285463015,\n",
       "  0.09880202796114897,\n",
       "  -0.8422864912619517,\n",
       "  -0.668010979676459,\n",
       "  0.9064475029668366,\n",
       "  0.5008076209413455,\n",
       "  1797724800.0,\n",
       "  1.702729419609224,\n",
       "  -0.8149979044980741,\n",
       "  -1.2573153364322134,\n",
       "  -1.401028615818566],\n",
       " [-0.8459390085899162,\n",
       "  -0.669399134129817,\n",
       "  0.9060070167826478,\n",
       "  0.500533318925683,\n",
       "  1.7057893681827934,\n",
       "  -0.8165389695550521,\n",
       "  -1.2536379567815055,\n",
       "  -1.3972225438493093,\n",
       "  1797811200.0,\n",
       "  1.5031623505343161,\n",
       "  0.2229101024780648,\n",
       "  -0.5713106774818876,\n",
       "  -0.2848606296237727],\n",
       " [1.7007307600600945,\n",
       "  -0.8178558187645224,\n",
       "  -1.2567698976334445,\n",
       "  -1.3985591004705296,\n",
       "  1.5060112219186912,\n",
       "  0.22105831572984933,\n",
       "  -0.5683574567408606,\n",
       "  -0.28086343966337995,\n",
       "  1797897600.0,\n",
       "  1.4872370113497482,\n",
       "  -0.41934924265825113,\n",
       "  -0.5099098074060936,\n",
       "  -1.0343434754537928],\n",
       " [1.5010628562801043,\n",
       "  0.2192433373290732,\n",
       "  -0.5706355418380521,\n",
       "  -0.2815752129582464,\n",
       "  1.4900690388938662,\n",
       "  -0.4210087542639757,\n",
       "  -0.5070214025326375,\n",
       "  -1.030474617122382,\n",
       "  1797984000.0,\n",
       "  -1.4370816030778262,\n",
       "  1.3255803033260207,\n",
       "  -0.11433879180974395,\n",
       "  -0.4697202092971734],\n",
       " [1.4851294705431293,\n",
       "  -0.42251548942349054,\n",
       "  -0.5092230632417776,\n",
       "  -1.0316059190108424,\n",
       "  -1.437342555534385,\n",
       "  1.3233984068307163,\n",
       "  -0.11186795884577597,\n",
       "  -0.4657546722706996,\n",
       "  1798070400.0,\n",
       "  -0.050193636157309686,\n",
       "  -1.0974424704388122,\n",
       "  1.4022660355443137,\n",
       "  1.0154711204222768],\n",
       " [-1.4406667063220746,\n",
       "  1.3210542175444537,\n",
       "  -0.11357726052546702,\n",
       "  -0.466569922089284,\n",
       "  -0.04898771126209812,\n",
       "  -1.098898979203113,\n",
       "  1.4031359130572298,\n",
       "  1.0196909621653338,\n",
       "  1798156800.0,\n",
       "  0.4400027379952158,\n",
       "  0.9831115265618734,\n",
       "  0.010175035529811362,\n",
       "  0.44815186275393887],\n",
       " [-0.05307799032619668,\n",
       "  -1.100080273158866,\n",
       "  1.4033142979152595,\n",
       "  1.019707059232461,\n",
       "  0.4417271315600784,\n",
       "  0.9810321559906363,\n",
       "  0.012514429448475518,\n",
       "  0.45227456417564693,\n",
       "  1798243200.0,\n",
       "  0.6919087954965666,\n",
       "  1.5887903943876014,\n",
       "  0.5555939399197254,\n",
       "  -0.3759214057666448],\n",
       " [0.43736606400246847,\n",
       "  0.9788523297246706,\n",
       "  0.010960107544260324,\n",
       "  0.45197310007161123,\n",
       "  0.6938996239136567,\n",
       "  1.5865296998831326,\n",
       "  0.5573575797907031,\n",
       "  -0.3719398078612321,\n",
       "  1798329600.0,\n",
       "  -1.5394610978210994,\n",
       "  -0.9028449526683126,\n",
       "  -1.5169891588720352,\n",
       "  -1.3979192905494184],\n",
       " [0.689399401385888,\n",
       "  1.5840591866559013,\n",
       "  0.5564821294716664,\n",
       "  -0.372702553102367,\n",
       "  -1.5398303345556295,\n",
       "  -0.904359718686075,\n",
       "  -1.5130376628437239,\n",
       "  -1.3941126861800153,\n",
       "  1798416000.0,\n",
       "  0.2632313535593887,\n",
       "  -1.5309398194587345,\n",
       "  1.1109507490190962,\n",
       "  0.775848567207036],\n",
       " [-1.543097930071575,\n",
       "  -0.9056344069537571,\n",
       "  -1.5164928143105687,\n",
       "  -1.3954475023333057,\n",
       "  0.26476878037102053,\n",
       "  -1.5322665507971662,\n",
       "  1.1121281442106623,\n",
       "  0.7800273791216372,\n",
       "  1798502400.0,\n",
       "  -1.219369115158706,\n",
       "  -1.5157583371938144,\n",
       "  0.42026850129980525,\n",
       "  0.1414212276608277],\n",
       " [0.2605053627745513,\n",
       "  -1.5332397938635831,\n",
       "  1.1119439349804445,\n",
       "  0.7799093456835727,\n",
       "  -1.2193997984620648,\n",
       "  -1.5170896134589766,\n",
       "  0.42217499314825074,\n",
       "  0.14549140854483547,\n",
       "  1798588800.0,\n",
       "  -0.4618151495552969,\n",
       "  0.7707323937069802,\n",
       "  0.7882942263504973,\n",
       "  -1.3498356628640058],\n",
       " [-1.2228442154119106,\n",
       "  -1.5180701426619612,\n",
       "  0.4211311060656705,\n",
       "  0.14501824968798618,\n",
       "  -0.4610445866286845,\n",
       "  0.7687166037256419,\n",
       "  0.789812223595721,\n",
       "  -1.3460208252837926,\n",
       "  1798675200.0,\n",
       "  1.528740101406099,\n",
       "  -1.3214751860157392,\n",
       "  -0.6992987938703762,\n",
       "  -1.0929865632665305],\n",
       " [-0.4649074825961565,\n",
       "  0.7666387058049516,\n",
       "  0.7892264104913999,\n",
       "  -1.3473287262690974,\n",
       "  1.5316160257495868,\n",
       "  -1.322864625421476,\n",
       "  -0.6962104665617673,\n",
       "  -1.0891277462096192,\n",
       "  1798761600.0,\n",
       "  0.9683841649313872,\n",
       "  0.07571123992708625,\n",
       "  0.09985181944370636,\n",
       "  -0.45247939242281765],\n",
       " [1.5266535307518467,\n",
       "  -1.323938398060613,\n",
       "  -0.6986478558098735,\n",
       "  -1.090291874002356,\n",
       "  0.9706674145587116,\n",
       "  0.07390352055209906,\n",
       "  0.10209654892938817,\n",
       "  -0.4485109033046092,\n",
       "  1798848000.0,\n",
       "  1.6483878165379624,\n",
       "  -1.6366526383155364,\n",
       "  0.17666662162512003,\n",
       "  -0.6735994644553887],\n",
       " [0.9660144647715629,\n",
       "  0.07215918815257819,\n",
       "  0.10065384585605569,\n",
       "  -0.44931650244780325,\n",
       "  1.651390289332157,\n",
       "  -1.6379477220843957,\n",
       "  0.17883026401806962,\n",
       "  -0.6696688370430249,\n",
       "  1798934400.0,\n",
       "  -0.5349927044575739,\n",
       "  0.4595090256276909,\n",
       "  -0.751206178448182,\n",
       "  -1.1165150539393724],\n",
       " [1.6463616999562434,\n",
       "  -1.638870229786393,\n",
       "  0.1774831707340245,\n",
       "  -0.6705982097900465,\n",
       "  -0.534299539634128,\n",
       "  0.4575864075369558,\n",
       "  -0.7480630567667802,\n",
       "  -1.1126602655931277,\n",
       "  1799020800.0,\n",
       "  -1.04713213953129,\n",
       "  -1.7686690817737045,\n",
       "  1.7469823704993022,\n",
       "  -0.13736684254850032],\n",
       " [-0.5381220117206909,\n",
       "  0.4556578768469014,\n",
       "  -0.7505650540586619,\n",
       "  -1.1138375636333977,\n",
       "  -1.0469806520142861,\n",
       "  -1.7699246433765272,\n",
       "  1.7474883592222323,\n",
       "  -0.13334439768325504,\n",
       "  1799107200.0,\n",
       "  -1.6106249478890717,\n",
       "  1.0568719505856639,\n",
       "  1.1168364033844076,\n",
       "  0.9258107044549438],\n",
       " [-1.050520214080694,\n",
       "  -1.7707837916634541,\n",
       "  1.7480958053446667,\n",
       "  -0.133973610234537,\n",
       "  -1.6110694528806053,\n",
       "  1.0547704981309216,\n",
       "  1.1180075855729097,\n",
       "  0.9300151939223612,\n",
       "  1799193600.0,\n",
       "  1.3051383107034649,\n",
       "  1.5902032100477705,\n",
       "  -1.677169638556622,\n",
       "  0.6052520702436331],\n",
       " [-1.6142977369026918,\n",
       "  1.0525552715981477,\n",
       "  1.1178307020944704,\n",
       "  0.9299811029052367,\n",
       "  1.3077777369227923,\n",
       "  1.5879420925843608,\n",
       "  -1.6730490531205242,\n",
       "  0.6094016714478415,\n",
       "  1799280000.0,\n",
       "  -1.4669616816358029,\n",
       "  -0.3844366438311644,\n",
       "  -1.3569580696744932,\n",
       "  1.5896178767209217],\n",
       " [1.3029387613863204,\n",
       "  1.5854709012963406,\n",
       "  -1.676703577904434,\n",
       "  0.6091881453526184,\n",
       "  -1.4672542375178375,\n",
       "  -0.3861066073282706,\n",
       "  -1.3531755053546715,\n",
       "  1.5939360278367956,\n",
       "  1799366400.0,\n",
       "  -1.4558294516427526,\n",
       "  0.7904884214948966,\n",
       "  0.8396653285651011,\n",
       "  0.5934128926152784],\n",
       " [-1.4705618823053088,\n",
       "  -0.38763009829321643,\n",
       "  -1.3564314694476884,\n",
       "  1.5942735078181904,\n",
       "  -1.456110233238442,\n",
       "  0.7884667170911576,\n",
       "  0.8411290975468816,\n",
       "  0.5975604666337289,\n",
       "  1799452800.0,\n",
       "  0.0740589952973561,\n",
       "  1.01927031402879,\n",
       "  0.3957865571785935,\n",
       "  -0.08478940458943363],\n",
       " [-1.4594240275609733,\n",
       "  0.7863793375458153,\n",
       "  0.840607224986814,\n",
       "  0.5973403134708318,\n",
       "  0.07539633915020953,\n",
       "  1.0171801184908706,\n",
       "  0.3977188926094847,\n",
       "  -0.08075795705214786,\n",
       "  1799539200.0,\n",
       "  -0.834925193898679,\n",
       "  -0.26275177985023557,\n",
       "  -0.7652683316293126,\n",
       "  0.6778488903914932],\n",
       " [0.07123742191443007,\n",
       "  1.0149829383289541,\n",
       "  0.39664453335940153,\n",
       "  -0.08135773899174274,\n",
       "  -0.8345492603053793,\n",
       "  -0.26445817251686354,\n",
       "  -0.762110365685,\n",
       "  0.6820109221246194,\n",
       "  1799625600.0,\n",
       "  -1.687505925139853,\n",
       "  -0.6097987593742397,\n",
       "  0.498902836914544,\n",
       "  0.3824919793233949],\n",
       " [-0.8382060472272748,\n",
       "  -0.26604006440220074,\n",
       "  -0.7646298658469587,\n",
       "  0.6818380326390605,\n",
       "  -1.6880317452534448,\n",
       "  -0.611401255526252,\n",
       "  0.5007263209378977,\n",
       "  0.3866034380063982,\n",
       "  1799712000.0,\n",
       "  -1.5899418357487456,\n",
       "  -1.0413544309164176,\n",
       "  -1.34235559613171,\n",
       "  1.2720065778769223],\n",
       " [-1.6912175595937726,\n",
       "  -0.612816587147969,\n",
       "  0.49978030838008847,\n",
       "  0.38626522029458554,\n",
       "  -1.5903644647203796,\n",
       "  -1.0428277309284797,\n",
       "  -1.3385884464467326,\n",
       "  1.2762703453927038,\n",
       "  1799798400.0,\n",
       "  0.2918876968570165,\n",
       "  1.145727385344868,\n",
       "  0.038766461479280416,\n",
       "  -0.7058436818507957],\n",
       " [-1.5936041742630798,\n",
       "  -1.0440359435413598,\n",
       "  -1.341826235144138,\n",
       "  1.2764300400888784,\n",
       "  0.2934554327793843,\n",
       "  1.143599331967136,\n",
       "  0.0410756737722491,\n",
       "  -0.7019185755160212,\n",
       "  1799884800.0,\n",
       "  0.3133886252976884,\n",
       "  -0.8799716124199891,\n",
       "  1.5594742505842645,\n",
       "  1.490674605809295],\n",
       " [0.2891761851840814,\n",
       "  1.1413414605317675,\n",
       "  0.03955693902223888,\n",
       "  -0.7028659972033896,\n",
       "  0.31497910222417763,\n",
       "  -0.8814932260995082,\n",
       "  1.560178176265643,\n",
       "  1.494975815174996,\n",
       "  1799971200.0,\n",
       "  -1.166423451791553,\n",
       "  1.3052513285270413,\n",
       "  1.3807413543133744,\n",
       "  0.7958265386478462],\n",
       " [0.31068797733983594,\n",
       "  -0.8827788921016366,\n",
       "  1.5605522349246506,\n",
       "  1.4952579109250876,\n",
       "  -1.166398135766689,\n",
       "  1.3030755179790348,\n",
       "  1.3816339536686106,\n",
       "  0.8000087713286905,\n",
       "  1800057600.0,\n",
       "  0.1994280859259596,\n",
       "  0.9424438434191872,\n",
       "  -0.19121215868345015,\n",
       "  -1.7279618453430978],\n",
       " [-1.1698718003347897,\n",
       "  1.3007410852951962,\n",
       "  1.381785547202852,\n",
       "  0.7999019207086292,\n",
       "  0.20089802958791186,\n",
       "  0.9403766476565072,\n",
       "  -0.18866017680480288,\n",
       "  -1.7242117531392842,\n",
       "  1800144000.0,\n",
       "  1.0490417132652263,\n",
       "  0.2414374456754665,\n",
       "  0.029584339298535357,\n",
       "  -0.7639271561073726],\n",
       " [0.19666985743925613,\n",
       "  0.9382163392668658,\n",
       "  -0.19046516116803774,\n",
       "  -1.72573131306571,\n",
       "  1.0514102724011212,\n",
       "  0.23958011233991017,\n",
       "  0.03190324440553994,\n",
       "  -0.7600119952261996,\n",
       "  1800230400.0,\n",
       "  -1.0145759702186046,\n",
       "  0.7672184228067195,\n",
       "  -1.4432799647291588,\n",
       "  1.1947500753813969],\n",
       " [1.0467127667234044,\n",
       "  0.23775624200418227,\n",
       "  0.03037308085870956,\n",
       "  -0.760991929569997,\n",
       "  -1.0143900488406368,\n",
       "  0.765203684813586,\n",
       "  -1.4394062774576355,\n",
       "  1.1990006145052678,\n",
       "  1800316800.0,\n",
       "  0.8841012833751091,\n",
       "  1.0201409747386545,\n",
       "  -1.190044484454188,\n",
       "  0.10748889517907835],\n",
       " [-1.0179475952017223,\n",
       "  0.7631274733732688,\n",
       "  -1.4427696846210334,\n",
       "  1.1991170642999507,\n",
       "  0.8862953890679228,\n",
       "  1.0180505185483781,\n",
       "  -1.1864381171299798,\n",
       "  0.11155326593477326,\n",
       "  1800403200.0,\n",
       "  1.1481265815673967,\n",
       "  0.8115800650197766,\n",
       "  -1.6678254088405844,\n",
       "  -0.7322752379192392],\n",
       " [0.8816889978351186,\n",
       "  1.015852920525233,\n",
       "  -1.1894863273492784,\n",
       "  0.11106111320261032,\n",
       "  1.1505999403357654,\n",
       "  0.8095520463462728,\n",
       "  -1.663714687342165,\n",
       "  -0.7283546573780378,\n",
       "  1800489600.0,\n",
       "  0.6920022943435351,\n",
       "  -1.3078218724322763,\n",
       "  0.56184671316857,\n",
       "  -1.5039047725013666],\n",
       " [1.1458476993649453,\n",
       "  0.8074545441664951,\n",
       "  -1.6673575815573713,\n",
       "  -0.729316874325372,\n",
       "  0.69399322165206,\n",
       "  -1.3092153992722164,\n",
       "  0.563603752499159,\n",
       "  -1.5001163156981459,\n",
       "  1800576000.0,\n",
       "  1.4153001291124157,\n",
       "  -0.49106714052457606,\n",
       "  0.23537112355130083,\n",
       "  1.2626113136770005],\n",
       " [0.6894929474747621,\n",
       "  -1.3102957246250895,\n",
       "  0.5627360848771521,\n",
       "  -1.5015104580127114,\n",
       "  1.4180560707823837,\n",
       "  -0.49270518172409195,\n",
       "  0.23747279641160426,\n",
       "  1.2668734724707595,\n",
       "  1800662400.0,\n",
       "  -0.3921484863039111,\n",
       "  -0.7717429837363723,\n",
       "  0.45921511815619975,\n",
       "  -0.8142900137674826],\n",
       " [1.4131562409548106,\n",
       "  -0.49417749689818785,\n",
       "  0.23619877140216236,\n",
       "  1.2670279080979667,\n",
       "  -0.391304238658032,\n",
       "  -0.7732969981511385,\n",
       "  0.4610804972523767,\n",
       "  -0.8103834763626168,\n",
       "  1800748800.0,\n",
       "  0.3498244650048,\n",
       "  -1.132269126547358,\n",
       "  -1.449701887698966,\n",
       "  -1.352865589488878],\n",
       " [-0.39520561906109863,\n",
       "  -0.7746346069448438,\n",
       "  0.4600850862151074,\n",
       "  -0.8113916016903188,\n",
       "  0.3514534792243756,\n",
       "  -1.1337152091492113,\n",
       "  -1.4458214213295533,\n",
       "  -1.3490512707136268,\n",
       "  1800835200.0,\n",
       "  0.2896099055432874,\n",
       "  0.4423278795315688,\n",
       "  0.8675789094287643,\n",
       "  -0.5640453214282828],\n",
       " [0.3471422268836422,\n",
       "  -1.1348797885465194,\n",
       "  -1.4491928217271264,\n",
       "  -1.3503608677228804,\n",
       "  0.291175232301707,\n",
       "  0.4404104050130352,\n",
       "  0.8690132123303661,\n",
       "  -0.5600959353989413,\n",
       "  1800921600.0,\n",
       "  1.6525231002352343,\n",
       "  0.5342646052729052,\n",
       "  -1.3791794091524145,\n",
       "  0.09287368622640478],\n",
       " [0.2868972429769889,\n",
       "  0.4384901201697736,\n",
       "  0.8685260832247998,\n",
       "  -0.5609639844001263,\n",
       "  1.6555299468174662,\n",
       "  0.532319607375886,\n",
       "  -1.375373387585243,\n",
       "  0.09693555446508648,\n",
       "  1801008000.0,\n",
       "  -1.2115716286920077,\n",
       "  1.3435171486465467,\n",
       "  -0.6533747769542415,\n",
       "  0.39129680961599217],\n",
       " [1.6504990730769555,\n",
       "  0.5303551988082318,\n",
       "  -1.3786570101181028,\n",
       "  0.0964352207610826,\n",
       "  -1.2115940647853745,\n",
       "  1.3413298823430548,\n",
       "  -0.650334927867441,\n",
       "  0.39540977592284654,\n",
       "  1801094400.0,\n",
       "  1.2207475251644944,\n",
       "  1.0360480618571455,\n",
       "  0.4590479250720336,\n",
       "  1.6666974021003114],\n",
       " [-1.2150427891306332,\n",
       "  1.338977084522901,\n",
       "  -0.6527151564452611,\n",
       "  0.3950764867802334,\n",
       "  1.223297693321918,\n",
       "  1.0339528435135965,\n",
       "  0.46091348066025034,\n",
       "  1.6710287513048514,\n",
       "  1801180800.0,\n",
       "  1.0254947808882722,\n",
       "  0.19199159412141317,\n",
       "  -0.2779464043447145,\n",
       "  -0.948642362754783],\n",
       " [1.2185053359468345,\n",
       "  1.0317476111101505,\n",
       "  0.45991786152122077,\n",
       "  1.6714093771234824,\n",
       "  1.0278384350119156,\n",
       "  0.19014906354151176,\n",
       "  -0.27530286422961714,\n",
       "  -0.9447588300869822,\n",
       "  1801267200.0,\n",
       "  -0.8086957372091189,\n",
       "  0.3592808378078497,\n",
       "  -1.1809185161800884,\n",
       "  0.06729969699156634],\n",
       " [1.023153936852576,\n",
       "  0.188348924039232,\n",
       "  -0.2772158049074707,\n",
       "  -0.9458421601406233,\n",
       "  -0.8082920613634637,\n",
       "  0.357388225335936,\n",
       "  -1.177321782392838,\n",
       "  0.07135718627519078,\n",
       "  1801353600.0,\n",
       "  1.4405487995103117,\n",
       "  -1.7253790029879055,\n",
       "  -1.1186486996595697,\n",
       "  1.0883872177511935],\n",
       " [-0.8119633376521458,\n",
       "  0.3555077977396136,\n",
       "  -1.180358633708918,\n",
       "  0.07084253734063028,\n",
       "  1.443331446079055,\n",
       "  -1.7266475244738813,\n",
       "  -1.1151176990154534,\n",
       "  1.0926195446920122,\n",
       "  1801440000.0,\n",
       "  1.4754002331164522,\n",
       "  0.09753717279993568,\n",
       "  0.3849275127667492,\n",
       "  0.6662135451856253],\n",
       " [1.4384176686790788,\n",
       "  -1.727527449218637,\n",
       "  -1.118077044383885,\n",
       "  1.092676457086579,\n",
       "  1.478219741190849,\n",
       "  0.09572291932873814,\n",
       "  0.38687131120107454,\n",
       "  0.6703735846345886,\n",
       "  1801526400.0,\n",
       "  -1.4463767495864486,\n",
       "  -1.3380013927368373,\n",
       "  -0.6864580535457372,\n",
       "  -0.8178058089212635],\n",
       " [1.4732867115733932,\n",
       "  0.09396811188304902,\n",
       "  0.38578343592389,\n",
       "  0.6701941821780694,\n",
       "  -1.4466475332912554,\n",
       "  -1.3393858846415743,\n",
       "  -0.6833832811545646,\n",
       "  -0.8138998735151249,\n",
       "  1801612800.0,\n",
       "  -0.19545873922250054,\n",
       "  1.4466428368413335,\n",
       "  1.3743951188002999,\n",
       "  -1.041262003202229],\n",
       " [-1.4499665493638536,\n",
       "  -1.3404517257627597,\n",
       "  -0.6858046877998146,\n",
       "  -0.8149099668352958,\n",
       "  -0.19440645766025558,\n",
       "  1.4444246974854802,\n",
       "  1.3752944173563793,\n",
       "  -1.0373943295089205,\n",
       "  1801699200.0,\n",
       "  -0.07829769664494438,\n",
       "  1.3086134785619379,\n",
       "  0.9283569080648477,\n",
       "  -1.0890575751496314],\n",
       " [-0.19841649109118967,\n",
       "  1.442022405957485,\n",
       "  1.3754381118630512,\n",
       "  -1.0385295040947111,\n",
       "  -0.07712149672450033,\n",
       "  1.306436661476803,\n",
       "  0.9297270526132217,\n",
       "  -1.0851980853442402,\n",
       "  1801785600.0,\n",
       "  1.0238157936993244,\n",
       "  0.9799612271987252,\n",
       "  -1.4448886407570825,\n",
       "  1.1487024130011223],\n",
       " [-0.08119625087531458,\n",
       "  1.304100615176857,\n",
       "  0.9293155726205593,\n",
       "  -1.0863600138566758,\n",
       "  1.0261576719994405,\n",
       "  0.9778827997422338,\n",
       "  -1.4410132553380859,\n",
       "  1.1529450675262238,\n",
       "  1801872000.0,\n",
       "  -0.8025256451341897,\n",
       "  -0.5918200195565504,\n",
       "  -0.9834740817443761,\n",
       "  0.9225478104169399],\n",
       " [1.0214741013263808,\n",
       "  0.9757044854176575,\n",
       "  -1.444378664787133,\n",
       "  1.153035741799633,\n",
       "  -0.8021154433336348,\n",
       "  -0.5934278980588337,\n",
       "  -0.9800857738686674,\n",
       "  0.9267517411891057,\n",
       "  1801958400.0,\n",
       "  1.621654121519506,\n",
       "  0.2927709103074969,\n",
       "  0.5653298395611012,\n",
       "  -1.6578485119993573],\n",
       " [-0.8057901280317338,\n",
       "  -0.5948518583211102,\n",
       "  -0.9828768701969551,\n",
       "  0.9267158237427915,\n",
       "  1.6246283187408448,\n",
       "  0.2908982091157912,\n",
       "  0.5670832020405524,\n",
       "  -1.654086414506388,\n",
       "  1802044800.0,\n",
       "  -0.8696763917624931,\n",
       "  -1.5887471087871874,\n",
       "  -1.1861862046752576,\n",
       "  0.6967450524052058],\n",
       " [1.619614497277102,\n",
       "  0.28904970201355584,\n",
       "  0.5662198697936425,\n",
       "  -1.6555667279733468,\n",
       "  -0.8693372136579635,\n",
       "  -1.5900565341807904,\n",
       "  -1.1825839102208784,\n",
       "  0.7009103196696936,\n",
       "  1802131200.0,\n",
       "  -1.5133895227320107,\n",
       "  -0.8999603364097679,\n",
       "  0.020461277205830148,\n",
       "  -1.278179324922042],\n",
       " [-0.8729748037334245,\n",
       "  -1.5910020334605797,\n",
       "  -1.1856273181194497,\n",
       "  0.7007480074512704,\n",
       "  -1.5137311842016774,\n",
       "  -0.9014759660039133,\n",
       "  0.022789812781974856,\n",
       "  -1.2743522178487694,\n",
       "  1802217600.0,\n",
       "  -1.2396582161513057,\n",
       "  -1.4082086052295415,\n",
       "  -0.3689720137503778,\n",
       "  0.17743998112004455],\n",
       " [-1.5170131818693202,\n",
       "  -0.9027520387021561,\n",
       "  0.021248293949189572,\n",
       "  -1.2756200086663152,\n",
       "  -1.2397103587386469,\n",
       "  -1.4095720789865658,\n",
       "  -0.3662323853577444,\n",
       "  0.18151632938377427,\n",
       "  1802304000.0,\n",
       "  -0.5176853558496604,\n",
       "  0.5064419319472903,\n",
       "  -1.1017660241838538,\n",
       "  -0.6432633863037192],\n",
       " [-1.2431435678228653,\n",
       "  -1.410604225154299,\n",
       "  -0.3682586237215632,\n",
       "  0.18106333229188842,\n",
       "  -0.5169738854685214,\n",
       "  0.504505263408993,\n",
       "  -1.0982528451969311,\n",
       "  -0.6393275645385457,\n",
       "  1802390400.0,\n",
       "  -1.227092441512146,\n",
       "  0.9357486669255864,\n",
       "  -0.47510196727191334,\n",
       "  0.32512795387016674],\n",
       " [-0.5208059182762633,\n",
       "  0.5025542079378276,\n",
       "  -1.1011911770497513,\n",
       "  -0.6402399564403445,\n",
       "  -1.227131293588166,\n",
       "  0.9336834755183495,\n",
       "  -0.47225030618325675,\n",
       "  0.32922959028856136,\n",
       "  1802476800.0,\n",
       "  0.052055833341510614,\n",
       "  0.4064265520576658,\n",
       "  -0.6555786339886088,\n",
       "  0.8818350169838797],\n",
       " [-1.230571444109253,\n",
       "  0.9315263803834763,\n",
       "  -0.4744086422965342,\n",
       "  0.3288592626371348,\n",
       "  0.05336990499018447,\n",
       "  0.4045198254292297,\n",
       "  -0.6525364584705133,\n",
       "  0.886031976630381,\n",
       "  1802563200.0,\n",
       "  -0.42182924330680416,\n",
       "  -1.256023687738731,\n",
       "  -1.422476823702972,\n",
       "  -0.2984285818720324],\n",
       " [0.04922314248135258,\n",
       "  0.40261677091765574,\n",
       "  -0.654919430143423,\n",
       "  0.8859732698953389,\n",
       "  -0.42101638826888577,\n",
       "  -1.2574327215594852,\n",
       "  -1.418625096602895,\n",
       "  -0.2944337151101274,\n",
       "  1802649600.0,\n",
       "  0.428909209695256,\n",
       "  0.453149692765567,\n",
       "  -1.6842885743853342,\n",
       "  1.1032994144942103],\n",
       " [-0.4249013727785944,\n",
       "  -1.2585379067146518,\n",
       "  -1.4219626105286156,\n",
       "  -0.29515308316711053,\n",
       "  0.4306218699076038,\n",
       "  0.4512289784877409,\n",
       "  -1.6801604740719824,\n",
       "  1.1075342948043427,\n",
       "  1802736000.0,\n",
       "  0.0014455821940733457,\n",
       "  -0.017778852476899303,\n",
       "  -0.5958548951688896,\n",
       "  0.7133838690568705],\n",
       " [0.42626693050592174,\n",
       "  0.44930349986907875,\n",
       "  -1.6838238596475,\n",
       "  1.1075995544118733,\n",
       "  0.002706124622690278,\n",
       "  -0.01955858343727705,\n",
       "  -0.5928757651083161,\n",
       "  0.7175519853344574,\n",
       "  1802822400.0,\n",
       "  1.381317317442958,\n",
       "  1.3600985052095416,\n",
       "  0.30877424793785474,\n",
       "  -0.2987756067345535],\n",
       " [-0.0014126803687321064,\n",
       "  -0.021258046596160717,\n",
       "  -0.5951843998836247,\n",
       "  0.7173989868173253,\n",
       "  1.3840373163273687,\n",
       "  1.3579062748946735,\n",
       "  0.3107984351341333,\n",
       "  -0.29478079939264207,\n",
       "  1802908800.0,\n",
       "  -1.1243547866571784,\n",
       "  -1.2090500178699888,\n",
       "  -0.7506281539596824,\n",
       "  0.2590727884865544],\n",
       " [1.3791562588834,\n",
       "  1.3555455190881855,\n",
       "  0.3096157734694678,\n",
       "  -0.29550036169937133,\n",
       "  -1.1242849756380708,\n",
       "  -1.2104731143418133,\n",
       "  -0.7474856424513717,\n",
       "  0.2631631144833383,\n",
       "  1802995200.0,\n",
       "  -0.08263773531321164,\n",
       "  1.5469625843463466,\n",
       "  0.14713444007942772,\n",
       "  0.8420558983772775],\n",
       " [-1.1277818792814818,\n",
       "  -1.211600843841977,\n",
       "  -0.7499869202881747,\n",
       "  0.2627558119621236,\n",
       "  -0.08146612574511049,\n",
       "  1.544714411961169,\n",
       "  0.14932925717667356,\n",
       "  0.8462460467683662,\n",
       "  1803081600.0,\n",
       "  -0.12352495173522121,\n",
       "  1.195821693041248,\n",
       "  -1.5718537889042419,\n",
       "  -1.227198738015365],\n",
       " [-0.08553848242300424,\n",
       "  1.542263973396673,\n",
       "  0.14794540579946677,\n",
       "  0.8461650733760199,\n",
       "  -0.12239658757206763,\n",
       "  1.1936786427775643,\n",
       "  -1.5678443767814174,\n",
       "  -1.2233629016939176,\n",
       "  1803168000.0,\n",
       "  -1.5838442618301356,\n",
       "  0.261451258947028,\n",
       "  -0.9162690845747533,\n",
       "  -0.75974264757864],\n",
       " [-0.1264463578166,\n",
       "  1.1913967292914416,\n",
       "  -1.5713678171140504,\n",
       "  -1.2246021557490216,\n",
       "  -1.5842604415475434,\n",
       "  0.25958793401504304,\n",
       "  -0.912951719508019,\n",
       "  -0.7558267701970173,\n",
       "  1803254400.0,\n",
       "  -1.2031654503190803,\n",
       "  0.7371979159657707,\n",
       "  0.7313546430185623,\n",
       "  0.47579592559999423],\n",
       " [-1.5875035194400366,\n",
       "  0.2577544583341854,\n",
       "  -0.9156591671717789,\n",
       "  -0.7568043622310638,\n",
       "  -1.2031789954039702,\n",
       "  0.7351921653034938,\n",
       "  0.7329327467164833,\n",
       "  0.4799233604290597,\n",
       "  1803340800.0,\n",
       "  -1.6719842330317445,\n",
       "  0.791098246119171,\n",
       "  -0.8162013243126691,\n",
       "  -1.1509044802634927],\n",
       " [-1.2066323633910383,\n",
       "  0.7331303617786131,\n",
       "  0.7322760620950864,\n",
       "  0.4796373702946706,\n",
       "  -1.6724936362326817,\n",
       "  0.7890763591503709,\n",
       "  -0.8129895925812484,\n",
       "  -1.1470555803123255,\n",
       "  1803427200.0,\n",
       "  -1.1191030902918038,\n",
       "  -1.153191650257876,\n",
       "  -0.8470778082772226,\n",
       "  1.4502361644100477],\n",
       " [-1.6756880248829071,\n",
       "  0.7869886869283705,\n",
       "  -0.8155724879816239,\n",
       "  -1.1482521280895848,\n",
       "  -1.11902772468239,\n",
       "  -1.1546314692198802,\n",
       "  -0.8438334827715892,\n",
       "  1.454530449626534,\n",
       "  1803513600.0,\n",
       "  -1.368167150902415,\n",
       "  0.9010116953968811,\n",
       "  1.7565634499383649,\n",
       "  0.32596355919476716],\n",
       " [-1.122527529405903,\n",
       "  -1.1557860071494033,\n",
       "  -0.8464548094904341,\n",
       "  1.454789909658488,\n",
       "  -1.3683552142348938,\n",
       "  0.8989569033029449,\n",
       "  1.7570593247007706,\n",
       "  0.33006533869127636,\n",
       "  1803600000.0,\n",
       "  -0.920667334775695,\n",
       "  1.475170916182989,\n",
       "  -0.8630362969284684,\n",
       "  -0.7662916306932522],\n",
       " [-1.3717174339306164,\n",
       "  0.8968164796836778,\n",
       "  1.7576786961938407,\n",
       "  0.32969547877614097,\n",
       "  -0.9203820885396619,\n",
       "  1.4729442362888594,\n",
       "  -0.8597751253539475,\n",
       "  -0.7623768746737475,\n",
       "  1803686400.0,\n",
       "  1.699168092196224,\n",
       "  -1.3125730184853446,\n",
       "  0.26886206511554894,\n",
       "  -1.5148418428881743],\n",
       " [-0.9239915108004075,\n",
       "  1.4705282531147872,\n",
       "  -0.8624163152722534,\n",
       "  -0.7633581325497687,\n",
       "  1.7022242740412261,\n",
       "  -1.3139651229601743,\n",
       "  0.27092838433297123,\n",
       "  -1.5110552588056791,\n",
       "  1803772800.0,\n",
       "  0.07251409783842185,\n",
       "  0.3868204771641116,\n",
       "  -0.04743265412318314,\n",
       "  0.11811974610187585],\n",
       " [1.69716763322497,\n",
       "  -1.3150431680680494,\n",
       "  0.2696960448030861,\n",
       "  -1.5124555232266854,\n",
       "  0.07384980769116326,\n",
       "  0.38491962006622016,\n",
       "  -0.04503244848672077,\n",
       "  0.12218593714528513,\n",
       "  1803859200.0,\n",
       "  -0.7340550643870526,\n",
       "  -1.2719496182997372,\n",
       "  0.16332014257057803,\n",
       "  -1.4844487181419916],\n",
       " [0.06969174386939825,\n",
       "  0.38302597521153847,\n",
       "  -0.04665847348607701,\n",
       "  0.12169973511094158,\n",
       "  -0.7335724429343297,\n",
       "  -1.2733538843259997,\n",
       "  0.16549787374790265,\n",
       "  -1.480656929938775,\n",
       "  1803945600.0,\n",
       "  0.1941986825110418,\n",
       "  1.4993008976184579,\n",
       "  0.47915286091948917,\n",
       "  1.6677892874031384],\n",
       " [-0.7372849513422478,\n",
       "  -1.2744514260572235,\n",
       "  0.16413416837850556,\n",
       "  -1.482040181582303,\n",
       "  0.19566309516139432,\n",
       "  1.49706699385806,\n",
       "  0.4809971933742584,\n",
       "  1.6721208235678209,\n",
       "  1804032000.0,\n",
       "  0.6037149368585029,\n",
       "  -1.5544713326650006,\n",
       "  1.474266652763928,\n",
       "  1.5194087633721338],\n",
       " [0.19143781177803215,\n",
       "  1.4946394298424703,\n",
       "  0.4800265984314179,\n",
       "  1.6725020605773655,\n",
       "  0.605612484796645,\n",
       "  -1.5557910193024265,\n",
       "  1.475060525124719,\n",
       "  1.523714892798738,\n",
       "  1804118400.0,\n",
       "  -1.5972186218917557,\n",
       "  0.29595119779685125,\n",
       "  0.915088081930815,\n",
       "  1.6273491216844893],\n",
       " [0.6011609812790053,\n",
       "  -1.5567529687536434,\n",
       "  1.475328527655976,\n",
       "  1.5240130727070964,\n",
       "  -1.5976489473414337,\n",
       "  0.29407754451276286,\n",
       "  0.9164722332917384,\n",
       "  1.6316737334047073,\n",
       "  1804204800.0,\n",
       "  0.7211352027552319,\n",
       "  -0.13255340029402177,\n",
       "  0.24068414528779716,\n",
       "  1.3470832011205802],\n",
       " [-1.6008846371278458,\n",
       "  0.2922275110767633,\n",
       "  0.9160442378667019,\n",
       "  1.6320323337309135,\n",
       "  0.7231569432257134,\n",
       "  -0.13429877084734124,\n",
       "  0.24278020962638344,\n",
       "  1.3513598237742914,\n",
       "  1804291200.0,\n",
       "  0.2880681324114718,\n",
       "  -1.4430772074272982,\n",
       "  -1.4824840154096361,\n",
       "  1.2822764423368895],\n",
       " [0.7186405757911081,\n",
       "  -0.13594314959382772,\n",
       "  0.24151279762477698,\n",
       "  1.3515615431683448,\n",
       "  0.2896318284743034,\n",
       "  -1.444430242464346,\n",
       "  -1.4785689436340497,\n",
       "  1.28654196832979,\n",
       "  1804377600.0,\n",
       "  0.4162450845249071,\n",
       "  -1.2997128116956973,\n",
       "  0.2739800741228945,\n",
       "  0.17642554597938512],\n",
       " [0.2853546908376959,\n",
       "  -1.4454456539422051,\n",
       "  -1.481981147265294,\n",
       "  1.2867074116589285,\n",
       "  0.41794435020299153,\n",
       "  -1.301108766169926,\n",
       "  0.2760409906775591,\n",
       "  0.18050172054452407,\n",
       "  1804464000.0,\n",
       "  1.38207419359751,\n",
       "  -1.7069784963074763,\n",
       "  -0.7660244356578825,\n",
       "  0.8998843836404941],\n",
       " [0.4135964065678172,\n",
       "  -1.3021929833512076,\n",
       "  0.27481502142721476,\n",
       "  0.18004815561502832,\n",
       "  1.3847949930112464,\n",
       "  -1.708252526409357,\n",
       "  -0.7628656715564994,\n",
       "  0.9040844338242078,\n",
       "  1804550400.0,\n",
       "  1.238854103491003,\n",
       "  -1.293954772949114,\n",
       "  0.6368258144520791,\n",
       "  -0.8015155585643007],\n",
       " [1.3799135174626889,\n",
       "  -1.7091412822156817,\n",
       "  -0.7653861128254427,\n",
       "  0.9040358303563062,\n",
       "  1.2414234225317704,\n",
       "  -1.2953524512249954,\n",
       "  0.6385037044889629,\n",
       "  -0.7976068338289913,\n",
       "  1804636800.0,\n",
       "  1.1039084926990412,\n",
       "  -1.8049136047913223,\n",
       "  -0.6897606560636096,\n",
       "  -1.233254448584942],\n",
       " [1.236621062934463,\n",
       "  -1.2964394318951074,\n",
       "  0.6377293617974524,\n",
       "  -0.7986078085604453,\n",
       "  1.1063350830804553,\n",
       "  -1.806158315760549,\n",
       "  -0.6866823973855622,\n",
       "  -1.2294196491640803,\n",
       "  1804723200.0,\n",
       "  -0.6396759007813456,\n",
       "  1.1723994111948253,\n",
       "  1.1624777190707252,\n",
       "  0.689778100756252],\n",
       " [1.1016072685442277,\n",
       "  -1.8070000690039667,\n",
       "  -0.6891079147115909,\n",
       "  -1.2306622929481859,\n",
       "  -0.6390934568044719,\n",
       "  1.1702633729312217,\n",
       "  1.1636007214619437,\n",
       "  0.693942175091163,\n",
       "  1804809600.0,\n",
       "  -0.7170822419221644,\n",
       "  -1.2354489711026957,\n",
       "  0.7842988927031079,\n",
       "  -0.01720516200198602],\n",
       " [-0.6428581010356627,\n",
       "  1.1679927006362607,\n",
       "  1.1634806467814398,\n",
       "  0.6937759630697713,\n",
       "  -0.7165816687318367,\n",
       "  -1.2368641644392324,\n",
       "  0.7858211074946997,\n",
       "  -0.013162142223930478,\n",
       "  1804896000.0,\n",
       "  0.06893697042764484,\n",
       "  1.0327142914932128,\n",
       "  1.5966246709729424,\n",
       "  -1.5881308771795135],\n",
       " [-0.7203035530659515,\n",
       "  -1.237979224137124,\n",
       "  0.7852303214815471,\n",
       "  -0.013724093381407293,\n",
       "  0.0702688968405494,\n",
       "  1.0306200711906837,\n",
       "  1.5972893799994894,\n",
       "  -1.5843568421516228,\n",
       "  1804982400.0,\n",
       "  0.5297726951408452,\n",
       "  -0.1876479030137957,\n",
       "  0.037176957064338524,\n",
       "  0.42595372404287274],\n",
       " [0.06611280905327535,\n",
       "  1.0284164387829253,\n",
       "  1.5977096790153609,\n",
       "  -1.5857981306543047,\n",
       "  0.5315920361853509,\n",
       "  -0.18937677975750206,\n",
       "  0.03948784726687975,\n",
       "  0.43007262454596473,\n",
       "  1805068800.0,\n",
       "  1.5385644163514824,\n",
       "  -1.5080948437428614,\n",
       "  -1.1110239861560847,\n",
       "  0.4041393522777709],\n",
       " [0.5271813789678825,\n",
       "  -0.1909947166807241,\n",
       "  0.03796713409372882,\n",
       "  0.42975873486879457,\n",
       "  1.5414507316316814,\n",
       "  -1.509428414251473,\n",
       "  -1.1075010342972722,\n",
       "  0.4082545175734737,\n",
       "  1805155200.0,\n",
       "  0.9017889228047251,\n",
       "  1.6594051614712,\n",
       "  -0.5381105355521274,\n",
       "  -1.3540033085923056],\n",
       " [1.5364828096018701,\n",
       "  -1.5104126214391822,\n",
       "  -1.1104508893431262,\n",
       "  0.4079284171395695,\n",
       "  0.904001736279497,\n",
       "  1.6571233268081553,\n",
       "  -0.5351923614806345,\n",
       "  -1.3501891846251768,\n",
       "  1805241600.0,\n",
       "  -1.4479529551861967,\n",
       "  1.0520439100369252,\n",
       "  0.4488005443114457,\n",
       "  -0.3077573087150107],\n",
       " [0.899385574249748,\n",
       "  1.6546189230274404,\n",
       "  -0.5374291230505361,\n",
       "  -1.3514994184811548,\n",
       "  -1.4482254060049675,\n",
       "  1.0499439029674336,\n",
       "  0.4506769172198976,\n",
       "  -0.3037640392821423,\n",
       "  1805328000.0,\n",
       "  -1.4843553046425835,\n",
       "  0.8214598612853469,\n",
       "  -0.0862127072826865,\n",
       "  -0.05655068714865985],\n",
       " [-1.4515435513686776,\n",
       "  1.0477309935840775,\n",
       "  0.4496685433788127,\n",
       "  -0.30448862916331293,\n",
       "  -1.4846662573326246,\n",
       "  0.8194288848670486,\n",
       "  -0.08377156472160277,\n",
       "  -0.052514404383150116,\n",
       "  1805414400.0,\n",
       "  1.5118319095035093,\n",
       "  1.2464384648759284,\n",
       "  1.76772861183719,\n",
       "  -1.7112966897706143],\n",
       " [-1.4879642937402322,\n",
       "  0.817326641019521,\n",
       "  -0.08544585844789496,\n",
       "  -0.053098379490769135,\n",
       "  1.514689950467551,\n",
       "  1.244280261314608,\n",
       "  1.7682127004530128,\n",
       "  -1.70754374404377,\n",
       "  1805500800.0,\n",
       "  -1.0891877535827448,\n",
       "  -1.2683581105154846,\n",
       "  -1.4015731948366086,\n",
       "  -0.32309321921926176],\n",
       " [1.5097367956935557,\n",
       "  1.2419740550284961,\n",
       "  1.768845968991264,\n",
       "  -1.7090539755254974,\n",
       "  -1.0890807472561745,\n",
       "  -1.269763451742406,\n",
       "  -1.3977435339847573,\n",
       "  -0.3191025757069036,\n",
       "  1805587200.0,\n",
       "  -0.48000749759677047,\n",
       "  -0.031848648311848596,\n",
       "  0.7579793881852499,\n",
       "  -0.10244403082112255],\n",
       " [-1.0925970774567972,\n",
       "  -1.270862717166728,\n",
       "  -1.401055029597672,\n",
       "  -0.3198357499779654,\n",
       "  -0.4792561762700234,\n",
       "  -0.03362416715445886,\n",
       "  0.759529386321235,\n",
       "  -0.0984156062308675,\n",
       "  1805673600.0,\n",
       "  0.5774922264772743,\n",
       "  -0.9207445763671585,\n",
       "  -1.122813479057915,\n",
       "  -1.5759852439295559],\n",
       " [-0.4831090226353781,\n",
       "  -0.03531687771487138,\n",
       "  0.758905840967309,\n",
       "  -0.09902527047871615,\n",
       "  0.5793620392984656,\n",
       "  -0.9222539837198843,\n",
       "  -1.119278081997435,\n",
       "  -1.572209129242459,\n",
       "  1805760000.0,\n",
       "  0.7015838909649897,\n",
       "  0.8080006723175898,\n",
       "  0.5987384386558734,\n",
       "  1.234257917701925],\n",
       " [0.5749250214208965,\n",
       "  -0.9235200813176632,\n",
       "  -1.122242611180306,\n",
       "  -1.5736436191366552,\n",
       "  0.7035849524930141,\n",
       "  0.8059737252178155,\n",
       "  0.6004565344146416,\n",
       "  1.2385152216314095,\n",
       "  1805846400.0,\n",
       "  0.8265882971310953,\n",
       "  -0.991678741105053,\n",
       "  1.0126416363677224,\n",
       "  0.2711021893283522],\n",
       " [0.6990793853632356,\n",
       "  0.8038779409166745,\n",
       "  0.5996347851573265,\n",
       "  1.2386537862344789,\n",
       "  0.8287215727504162,\n",
       "  -0.9931669126801514,\n",
       "  1.013922808434417,\n",
       "  0.27519457508222633,\n",
       "  1805932800.0,\n",
       "  -1.6385558990592084,\n",
       "  -1.782688127638083,\n",
       "  -0.444422392059597,\n",
       "  1.715091776416361],\n",
       " [0.8241469521624465,\n",
       "  -0.9943989664340835,\n",
       "  1.0136162358929792,\n",
       "  0.2747940061075431,\n",
       "  -1.6390299459320345,\n",
       "  -1.7839394923163119,\n",
       "  -0.44160311688471715,\n",
       "  1.719431412039895,\n",
       "  1806019200.0,\n",
       "  -0.1968454762561383,\n",
       "  0.8728951360157166,\n",
       "  0.4440625207382929,\n",
       "  0.48864995441432824],\n",
       " [-1.642242800667842,\n",
       "  -1.7847919123614946,\n",
       "  -0.44372326676776064,\n",
       "  1.7198391269692475,\n",
       "  -0.19579466141160667,\n",
       "  0.8708487612620687,\n",
       "  0.44594389519001415,\n",
       "  0.4927795901989805,\n",
       "  1806105600.0,\n",
       "  -1.1174274721352815,\n",
       "  1.6480868053683753,\n",
       "  0.11411836695828102,\n",
       "  -1.3307125752210587],\n",
       " [-0.19980392879764114,\n",
       "  0.8687218317857244,\n",
       "  0.44492962402936836,\n",
       "  0.49250079520275963,\n",
       "  -1.1173503342656832,\n",
       "  1.645808359116179,\n",
       "  0.11634803641870169,\n",
       "  -1.3268944632537103,\n",
       "  1806192000.0,\n",
       "  -0.9740478191408107,\n",
       "  0.03771289035849451,\n",
       "  1.0282101284367944,\n",
       "  0.23618710257990258],\n",
       " [-1.1208510646143952,\n",
       "  1.6433093874195548,\n",
       "  0.11492309062082902,\n",
       "  -1.328191659948572,\n",
       "  -0.9738190321324942,\n",
       "  0.03591654666551654,\n",
       "  1.029474866122038,\n",
       "  0.24027350993149116,\n",
       "  1806278400.0,\n",
       "  -0.8722090136839481,\n",
       "  0.82118110080315,\n",
       "  0.14504218024174836,\n",
       "  -1.0753584562768181],\n",
       " [-0.9773989665763031,\n",
       "  0.03419045103362278,\n",
       "  1.0291876713594135,\n",
       "  0.23985339697748903,\n",
       "  -0.8718725142714439,\n",
       "  0.819150207838229,\n",
       "  0.14723920596627255,\n",
       "  -1.0714966208136838,\n",
       "  1806364800.0,\n",
       "  -1.1591410991830784,\n",
       "  -1.0346059671953618,\n",
       "  -0.1652319866476357,\n",
       "  0.3702108573276599],\n",
       " [-0.8755087053058044,\n",
       "  0.8170480977778315,\n",
       "  0.14585275039668963,\n",
       "  -1.0726508811425097,\n",
       "  -1.1591080807926566,\n",
       "  -1.0360812875156271,\n",
       "  -0.16270742990788406,\n",
       "  0.3743202131521385,\n",
       "  1806451200.0,\n",
       "  -0.9963015410356911,\n",
       "  1.1918985817598753,\n",
       "  0.8574864616045959,\n",
       "  0.3163918802815711],\n",
       " [-1.1625857681920062,\n",
       "  -1.0372927389577227,\n",
       "  -0.16448007729044006,\n",
       "  0.37397512099100755,\n",
       "  -0.99609629124265,\n",
       "  1.1897567059700025,\n",
       "  0.8589314182764266,\n",
       "  0.3204920208491123,\n",
       "  1806537600.0,\n",
       "  -1.4506402119903032,\n",
       "  -0.277776723828685,\n",
       "  1.3152930910825076,\n",
       "  1.1151218804558183],\n",
       " [-0.9996639325481479,\n",
       "  1.1874766753253618,\n",
       "  0.8584317273106139,\n",
       "  0.32011680311556245,\n",
       "  -1.450915505054618,\n",
       "  -0.27947861843192745,\n",
       "  1.3162547788066397,\n",
       "  1.1193587850902218,\n",
       "  1806624000.0,\n",
       "  1.3597362573135385,\n",
       "  -0.5434142255446179,\n",
       "  1.478697115452026,\n",
       "  0.2062155067041763],\n",
       " [-1.4542321659556519,\n",
       "  -0.281053299309022,\n",
       "  1.3163249102466097,\n",
       "  1.1194306624109465,\n",
       "  1.3624334304405081,\n",
       "  -0.5450365954373518,\n",
       "  1.4794863109363736,\n",
       "  0.21029678211212757,\n",
       "  1806710400.0,\n",
       "  -1.2599664861904951,\n",
       "  0.025275272578107914,\n",
       "  -0.9580294466583017,\n",
       "  0.9966313133658664],\n",
       " [1.3575642945509798,\n",
       "  -0.5464837873722465,\n",
       "  1.4797598279725441,\n",
       "  0.20985989233456576,\n",
       "  -1.2600401083364485,\n",
       "  0.023482652372766335,\n",
       "  -0.9546679985990107,\n",
       "  1.0008479292270467,\n",
       "  1806796800.0,\n",
       "  -0.9393838603327935,\n",
       "  -1.3515114828246872,\n",
       "  0.5103908555398665,\n",
       "  1.4133604705957754],\n",
       " [-1.2634620989659013,\n",
       "  0.021762525998692224,\n",
       "  -0.957427424518341,\n",
       "  1.0008534805721445,\n",
       "  -0.9391184101063145,\n",
       "  -1.3528919301724762,\n",
       "  0.5122022126032448,\n",
       "  1.417648441701294,\n",
       "  1806883200.0,\n",
       "  0.22011421771528145,\n",
       "  -1.0889163220720623,\n",
       "  -0.07510833682200281,\n",
       "  1.6487090608039021],\n",
       " [-0.9427174932049884,\n",
       "  -1.3539512873180064,\n",
       "  0.5112704989436804,\n",
       "  1.4178872602895516,\n",
       "  0.22160604059094186,\n",
       "  -1.0903753833354504,\n",
       "  -0.07267891623496195,\n",
       "  1.6530373299204133,\n",
       "  1806969600.0,\n",
       "  -0.732240253399914,\n",
       "  -1.1102329567121172,\n",
       "  0.04995635913385482,\n",
       "  0.16456875393979978],\n",
       " [0.21736644125359364,\n",
       "  -1.0915607692948899,\n",
       "  -0.07433938858191363,\n",
       "  1.6534078866313024,\n",
       "  -0.7317557124661672,\n",
       "  -1.1116856363494627,\n",
       "  0.05225375916872984,\n",
       "  0.1686428983031197,\n",
       "  1807056000.0,\n",
       "  1.119751478867619,\n",
       "  -1.274837823197234,\n",
       "  1.5576344420591444,\n",
       "  1.024932074873993],\n",
       " [-0.7354692233905443,\n",
       "  -1.11286079169318,\n",
       "  0.05074895225198246,\n",
       "  0.16818269644615247,\n",
       "  1.122194825986527,\n",
       "  -1.2762412245727717,\n",
       "  1.5583403098756354,\n",
       "  1.0291535365870108,\n",
       "  1807142400.0,\n",
       "  -0.5347944375198481,\n",
       "  0.664983131008734,\n",
       "  -0.8191013558738742,\n",
       "  1.2758008484009893],\n",
       " [1.1174582596549303,\n",
       "  -1.2773373801511185,\n",
       "  1.5587120785631736,\n",
       "  1.0291749294937125,\n",
       "  -0.53410106299433,\n",
       "  0.6629989995072723,\n",
       "  -0.8158865628167525,\n",
       "  1.280065265597974,\n",
       "  1807228800.0,\n",
       "  0.6326615419766514,\n",
       "  0.440161920516892,\n",
       "  -0.20375441300296093,\n",
       "  -0.9748949125508473],\n",
       " [-0.5379236446051738,\n",
       "  0.660971854441705,\n",
       "  -0.8184730678261959,\n",
       "  1.280227084165276,\n",
       "  0.6345897060283306,\n",
       "  0.4382450944281264,\n",
       "  -0.2011891912940961,\n",
       "  -0.9710158750259293,\n",
       "  1807315200.0,\n",
       "  0.06339390030917018,\n",
       "  -1.061678088014454,\n",
       "  1.040030054613365,\n",
       "  0.7023085968763266],\n",
       " [0.6301222121688493,\n",
       "  0.43632584910609906,\n",
       "  -0.20300978674085424,\n",
       "  -0.9721139001394447,\n",
       "  0.06471996395290376,\n",
       "  -1.0631453036711946,\n",
       "  1.0412823149710269,\n",
       "  0.7064748167693221,\n",
       "  1807401600.0,\n",
       "  -0.833423335821754,\n",
       "  1.1038804086868783,\n",
       "  -1.6585510407794761,\n",
       "  0.5091255864935121],\n",
       " [0.06056693820298036,\n",
       "  -1.064343762233806,\n",
       "  1.0410098322250845,\n",
       "  0.7063156187862684,\n",
       "  -0.83304581375004,\n",
       "  1.1017648831664064,\n",
       "  -1.65445010947151,\n",
       "  0.5132587282572989,\n",
       "  1807488000.0,\n",
       "  1.4232381041844488,\n",
       "  1.062785167823899,\n",
       "  0.09040878284352291,\n",
       "  -0.8080390714108427],\n",
       " [-0.8367034303106426,\n",
       "  1.0995270955925178,\n",
       "  -1.6580814600733644,\n",
       "  0.5129913946483224,\n",
       "  1.426002441655758,\n",
       "  1.0606819451112453,\n",
       "  0.09266348056921483,\n",
       "  -0.804131463676456,\n",
       "  1807574400.0,\n",
       "  -0.467702331840019,\n",
       "  1.520976971398903,\n",
       "  0.9027761121637549,\n",
       "  -0.23060782257699505],\n",
       " [1.421098226825715,\n",
       "  1.0584638806139302,\n",
       "  0.09120902394430196,\n",
       "  -0.8051360899927129,\n",
       "  -0.4669379956415672,\n",
       "  1.5187365784060691,\n",
       "  0.9041732602623624,\n",
       "  -0.22660134307629615,\n",
       "  1807660800.0,\n",
       "  1.5191380470369558,\n",
       "  0.022351209206948424,\n",
       "  1.425261272328855,\n",
       "  -1.7060762558559026],\n",
       " [-0.4707976394813084,\n",
       "  1.5162986112670518,\n",
       "  0.9037299403842034,\n",
       "  -0.22728274795917622,\n",
       "  1.5220038155232867,\n",
       "  0.020559464387392354,\n",
       "  1.4261068756544453,\n",
       "  -1.7023224162503097,\n",
       "  1807747200.0,\n",
       "  0.12119939524356002,\n",
       "  -1.4656964013980454,\n",
       "  0.026001956082779422,\n",
       "  -1.3676184891817653],\n",
       " [1.5170466247790548,\n",
       "  0.018840741375959837,\n",
       "  1.4263138822062258,\n",
       "  -1.7038297255553518,\n",
       "  0.12258659834004654,\n",
       "  -1.4670426648578843,\n",
       "  0.028324642818217186,\n",
       "  -1.363806696499887,\n",
       "  1807833600.0,\n",
       "  0.994233435372217,\n",
       "  0.7139614778725472,\n",
       "  1.6539806940008437,\n",
       "  0.1965919782581371],\n",
       " [0.1184016403610914,\n",
       "  -1.4680472205751895,\n",
       "  0.026790020353383,\n",
       "  -1.3651245515543968,\n",
       "  0.996544025138236,\n",
       "  0.7119626835737382,\n",
       "  1.654584856973428,\n",
       "  0.2006716058590853,\n",
       "  1807920000.0,\n",
       "  1.6176500394831985,\n",
       "  -0.3714588529040343,\n",
       "  1.775400985676447,\n",
       "  -0.9907389318793496],\n",
       " [0.9918767960022995,\n",
       "  0.709912032046952,\n",
       "  1.655076545840218,\n",
       "  0.20022932923994755,\n",
       "  1.6206200016852756,\n",
       "  -0.3731327016020623,\n",
       "  1.7758769751958545,\n",
       "  -0.9868626072768439,\n",
       "  1808006400.0,\n",
       "  -1.573581098855227,\n",
       "  -1.0547859844527252,\n",
       "  -0.17139053639651378,\n",
       "  0.9352674545137611],\n",
       " [1.6156083921092572,\n",
       "  -0.37466242107324954,\n",
       "  1.7765197933785137,\n",
       "  -0.9879695011979414,\n",
       "  -1.573986423477137,\n",
       "  -1.056255263419567,\n",
       "  -0.16885947858040184,\n",
       "  0.9394735632312343,\n",
       "  1808092800.0,\n",
       "  0.8580623623344714,\n",
       "  -0.7899669665346857,\n",
       "  1.46462985830932,\n",
       "  0.40280531931685315],\n",
       " [-1.577235170824949,\n",
       "  -1.057457029749293,\n",
       "  -0.1706397913819537,\n",
       "  0.9394447657002439,\n",
       "  0.8602289272998074,\n",
       "  -0.7915155251800405,\n",
       "  1.4654339034444122,\n",
       "  0.40692025619021915,\n",
       "  1808179200.0,\n",
       "  -0.9841428698532706,\n",
       "  -1.2382906268919625,\n",
       "  1.1661693122004686,\n",
       "  1.1085068575097567],\n",
       " [0.8556369201803362,\n",
       "  -0.7928443876323046,\n",
       "  1.4656899112577106,\n",
       "  0.40659340902144975,\n",
       "  -0.9839247601322392,\n",
       "  -1.2397049695133233,\n",
       "  1.1672884176792961,\n",
       "  1.1127426294742462,\n",
       "  1808265600.0,\n",
       "  0.6750483055193399,\n",
       "  0.5137087609863266,\n",
       "  1.7436512249989176,\n",
       "  0.13027064958091547],\n",
       " [-0.9874991179873205,\n",
       "  -1.2408186653989204,\n",
       "  1.1671729378481082,\n",
       "  1.11281080398671,\n",
       "  0.6770213010101395,\n",
       "  0.5117699169552171,\n",
       "  1.7441607301392101,\n",
       "  0.13433892118593566,\n",
       "  1808352000.0,\n",
       "  -0.27952549496971313,\n",
       "  1.3048857542492382,\n",
       "  -0.9216006986376756,\n",
       "  0.16626363357727614],\n",
       " [0.6725303923551806,\n",
       "  0.5098153738727718,\n",
       "  1.7447640300540084,\n",
       "  0.13385952071012786,\n",
       "  -0.27856212875101694,\n",
       "  1.3027100531443203,\n",
       "  -0.9182777054228284,\n",
       "  0.17033806814959288,\n",
       "  1808438400.0,\n",
       "  0.45614956299723325,\n",
       "  0.29876916230698414,\n",
       "  0.6902686629121789,\n",
       "  -0.8190089526480201],\n",
       " [-0.28252572301727435,\n",
       "  1.3003757959126587,\n",
       "  -0.9209917892359064,\n",
       "  0.16987881501410013,\n",
       "  0.45789103466246406,\n",
       "  0.29689466540025045,\n",
       "  0.6918901377128597,\n",
       "  -0.8151032232524597,\n",
       "  1808524800.0,\n",
       "  -1.075193631787077,\n",
       "  1.3495960661925954,\n",
       "  -0.08960339500635082,\n",
       "  -1.2363693817554693],\n",
       " [0.4535210474664238,\n",
       "  0.2950432795222492,\n",
       "  0.6911823142251364,\n",
       "  -0.8161139900412742,\n",
       "  -1.0750718242214667,\n",
       "  1.3474069800249846,\n",
       "  -0.08715867317405807,\n",
       "  -1.2325351156949775,\n",
       "  1808611200.0,\n",
       "  -1.4077357926603702,\n",
       "  1.3285786784825955,\n",
       "  0.8426206078963863,\n",
       "  -1.805993542596021],\n",
       " [-1.0785958848896304,\n",
       "  1.3450512647147825,\n",
       "  -0.08883718721895542,\n",
       "  -1.2337795030860774,\n",
       "  -1.4079657067737483,\n",
       "  1.3263958843545594,\n",
       "  0.8440812572319217,\n",
       "  -1.8022568115183175,\n",
       "  1808697600.0,\n",
       "  1.679018579519192,\n",
       "  -0.21362952226718418,\n",
       "  0.08171568715257645,\n",
       "  1.333038346895098],\n",
       " [-1.4113060684275576,\n",
       "  1.32405025604077,\n",
       "  0.843563063046674,\n",
       "  -1.8038200502672626,\n",
       "  1.6820534497193462,\n",
       "  -0.21535062081415132,\n",
       "  0.08397956146710807,\n",
       "  1.3373125646918713,\n",
       "  1808784000.0,\n",
       "  -0.9759191847192457,\n",
       "  -1.7171547910320262,\n",
       "  -1.226183356843268,\n",
       "  1.6532703551140215],\n",
       " [1.6770079396589883,\n",
       "  -0.216956088228611,\n",
       "  0.08251428472649272,\n",
       "  1.3375064223743816,\n",
       "  -0.9756923770083558,\n",
       "  -1.7184257746254632,\n",
       "  -1.222538840672569,\n",
       "  1.657599405246846,\n",
       "  1808870400.0,\n",
       "  -0.9094237858346477,\n",
       "  -1.3468514670743008,\n",
       "  0.4509726747202769,\n",
       "  -1.7705052553318932],\n",
       " [-0.979271277694486,\n",
       "  -1.719309646463818,\n",
       "  -1.2256320321959402,\n",
       "  1.6579725151761278,\n",
       "  -0.909126647572951,\n",
       "  -1.3482333095052432,\n",
       "  0.4528467546886328,\n",
       "  -1.7667624477045534,\n",
       "  1808956800.0,\n",
       "  -1.2393489948371024,\n",
       "  0.11062060206083005,\n",
       "  0.6677399084003541,\n",
       "  0.27107018291605445],\n",
       " [-0.9127422808622558,\n",
       "  -1.349294903159078,\n",
       "  0.45184108445316545,\n",
       "  -1.7683058216209304,\n",
       "  -1.2394008103686516,\n",
       "  0.10880243176344,\n",
       "  0.6693851649612473,\n",
       "  0.2751625631895696,\n",
       "  1809043200.0,\n",
       "  -1.6591873659549021,\n",
       "  -0.7596105893441879,\n",
       "  0.454410265668103,\n",
       "  1.5039605450176754],\n",
       " [-1.2428341902692575,\n",
       "  0.1070413451118931,\n",
       "  0.6686493004005718,\n",
       "  0.27476197629905924,\n",
       "  -1.6596832342237204,\n",
       "  -0.7611682358709322,\n",
       "  0.45628071685335914,\n",
       "  1.5082640292936436,\n",
       "  1809129600.0,\n",
       "  0.7331275176933139,\n",
       "  -0.4823839933904505,\n",
       "  1.532615673621786,\n",
       "  0.37657924163937284],\n",
       " [-1.6628846919681706,\n",
       "  -0.7625116674348316,\n",
       "  0.4552793253159662,\n",
       "  1.508553561946957,\n",
       "  0.7351619421408703,\n",
       "  -0.4840246340902542,\n",
       "  1.5333479517021678,\n",
       "  0.380689687902595,\n",
       "  1809216000.0,\n",
       "  0.1028993756082726,\n",
       "  -0.6707930444346188,\n",
       "  1.7511925341537602,\n",
       "  -1.386943992266323],\n",
       " [0.730638950053234,\n",
       "  -0.48550111661736295,\n",
       "  1.5336885800481235,\n",
       "  0.38034816049191644,\n",
       "  0.10426722322329254,\n",
       "  -0.6723772805411528,\n",
       "  1.7516940785518862,\n",
       "  -1.3831355086305495,\n",
       "  1809302400.0,\n",
       "  -1.0565721819426979,\n",
       "  1.1661837946466587,\n",
       "  -1.358154772681377,\n",
       "  0.6192833621363577],\n",
       " [0.10009237432512536,\n",
       "  -0.6737633388229521,\n",
       "  1.752306764977601,\n",
       "  -1.3844641812790506,\n",
       "  -1.0564306789267806,\n",
       "  1.1640496171711723,\n",
       "  -1.3543709451002444,\n",
       "  0.6234353658752676,\n",
       "  1809388800.0,\n",
       "  -1.098333099436878,\n",
       "  -0.5359070225379066,\n",
       "  -0.8377744186793064,\n",
       "  -0.8075518836161014],\n",
       " [-1.0599650262364133,\n",
       "  1.161781927973002,\n",
       "  -1.3576283987046458,\n",
       "  0.6232296938999711,\n",
       "  -1.0982357659180813,\n",
       "  -0.5375316398849419,\n",
       "  -0.8345399139997851,\n",
       "  -0.8036441924620559,\n",
       "  1809475200.0,\n",
       "  -0.48478247064988017,\n",
       "  -1.735683220355426,\n",
       "  -0.2960599672403926,\n",
       "  -0.9767017417132628],\n",
       " [-1.1017470441547217,\n",
       "  -0.5389824347951846,\n",
       "  -0.8371496609827735,\n",
       "  -0.8046485460713235,\n",
       "  -0.48403619969489636,\n",
       "  -1.7369486570363653,\n",
       "  -0.29339730612110687,\n",
       "  -0.9728230135661126,\n",
       "  1809561600.0,\n",
       "  -0.007636016752486439,\n",
       "  -0.6787284980702739,\n",
       "  1.1217369643473016,\n",
       "  -1.086767726768469],\n",
       " [-0.4878864083260127,\n",
       "  -1.7378236364184976,\n",
       "  -0.2953327923745855,\n",
       "  -0.973922050065681,\n",
       "  -0.0063850797081040755,\n",
       "  -0.6803103585158072,\n",
       "  1.12290297341513,\n",
       "  -1.0829078448794236,\n",
       "  1809648000.0,\n",
       "  -0.462627370137063,\n",
       "  -0.5516589311060545,\n",
       "  -1.2418135111306683,\n",
       "  -0.5772028965055873],\n",
       " [-0.010498867949858198,\n",
       "  -0.6816926082894579,\n",
       "  1.1227321895631655,\n",
       "  -1.0840684916322083,\n",
       "  -0.4618576662762183,\n",
       "  -0.5532788327560939,\n",
       "  -1.238152495486767,\n",
       "  -0.57325576340712,\n",
       "  1809734400.0,\n",
       "  -0.1289364418511006,\n",
       "  -1.5703359322975776,\n",
       "  1.0371544480317993,\n",
       "  -1.6126129043774047],\n",
       " [-0.46572011356638604,\n",
       "  -0.5547220677617748,\n",
       "  -1.2412651415386342,\n",
       "  -0.5741311774587501,\n",
       "  -0.1278138012881798,\n",
       "  -1.5716508695013391,\n",
       "  1.0384097439317121,\n",
       "  -1.6088430613312894,\n",
       "  1809820800.0,\n",
       "  -0.8038641956059377,\n",
       "  -1.115441095647128,\n",
       "  -0.18506777668481497,\n",
       "  -1.066428620044693],\n",
       " [-0.13186058218123303,\n",
       "  -1.5726052049635204,\n",
       "  1.038133681977967,\n",
       "  -1.610298053830662,\n",
       "  -0.8034554095573527,\n",
       "  -1.116892216108008,\n",
       "  -0.18252228092679493,\n",
       "  -1.0625652555533271,\n",
       "  1809907200.0,\n",
       "  0.723067528996872,\n",
       "  1.5770352912578816,\n",
       "  0.9021364182971621,\n",
       "  -0.7952475056133796],\n",
       " [-0.8071293548292037,\n",
       "  -1.1180648718794908,\n",
       "  -0.18431961750533848,\n",
       "  -1.0637145173399498,\n",
       "  0.7250913132413769,\n",
       "  1.5747781159145529,\n",
       "  0.9035342416681705,\n",
       "  -0.7913377076187553,\n",
       "  1809993600.0,\n",
       "  1.1534208664464425,\n",
       "  -1.6214134644194973,\n",
       "  1.604771057701656,\n",
       "  -0.09465503974548534],\n",
       " [0.7205738783739231,\n",
       "  1.5723132443819383,\n",
       "  0.9030901255763383,\n",
       "  -0.7923351737609818,\n",
       "  1.1558998248499426,\n",
       "  -1.622713110386407,\n",
       "  1.6054271672552194,\n",
       "  -0.09062528147038557,\n",
       "  1810080000.0,\n",
       "  1.3602456589360132,\n",
       "  -0.6719055503325041,\n",
       "  -0.04345230371735368,\n",
       "  -1.3585340092878027],\n",
       " [1.1511446592727768,\n",
       "  -1.6236429319132502,\n",
       "  1.6058576059095,\n",
       "  -0.09123058577258682,\n",
       "  1.362943370844572,\n",
       "  -0.6734894533847483,\n",
       "  -0.041056299810679035,\n",
       "  -1.3547206610985372,\n",
       "  1810166400.0,\n",
       "  0.5033400375568772,\n",
       "  -1.8174022937195802,\n",
       "  -0.2930146081067737,\n",
       "  -0.10420217787707768],\n",
       " [1.3580739535574138,\n",
       "  -0.6748749777351593,\n",
       "  -0.04267737055053342,\n",
       "  -1.3560334310479045,\n",
       "  0.5051314214284303,\n",
       "  -1.8186432659118446,\n",
       "  -0.29035516172359954,\n",
       "  -0.10017405432890376,\n",
       "  1810252800.0,\n",
       "  1.6263587955160128,\n",
       "  0.4076170827612132,\n",
       "  0.8962582744511477,\n",
       "  0.33686273928026855],\n",
       " [0.5007353658275876,\n",
       "  -1.8194790253865714,\n",
       "  -0.29228685748179856,\n",
       "  -0.10078470271263466,\n",
       "  1.6293379687555285,\n",
       "  0.4057099997199629,\n",
       "  0.8976623028969802,\n",
       "  0.3409663850096645,\n",
       "  1810339200.0,\n",
       "  -1.5797190062272277,\n",
       "  0.25964691549007923,\n",
       "  -0.021367197186950702,\n",
       "  -0.1470296639473347],\n",
       " [1.6243215483913225,\n",
       "  0.40380637383010437,\n",
       "  0.8972108704015571,\n",
       "  0.34060262599159175,\n",
       "  -1.5801308227630675,\n",
       "  0.25778413072990797,\n",
       "  -0.018994506717665414,\n",
       "  -0.1430088736171032,\n",
       "  1810425600.0,\n",
       "  -0.07943971069986339,\n",
       "  0.05342172642240936,\n",
       "  0.9659303840208544,\n",
       "  0.0762896601518063],\n",
       " [-1.583376179480556,\n",
       "  0.2559515210180389,\n",
       "  -0.02058808858399807,\n",
       "  -0.14364349500448348,\n",
       "  -0.07826471865964653,\n",
       "  0.051620679927182694,\n",
       "  0.9672608653292982,\n",
       "  0.08034868875901,\n",
       "  1810512000.0,\n",
       "  -1.1808176175116947,\n",
       "  -1.4258543259793823,\n",
       "  -1.4449824169629826,\n",
       "  0.09748811287762885],\n",
       " [-0.08233884195253975,\n",
       "  0.04988704506276324,\n",
       "  0.96689615226198,\n",
       "  0.07983907202314768,\n",
       "  -1.1808075258425077,\n",
       "  -1.4272125170830716,\n",
       "  -1.441106932552129,\n",
       "  0.10155077123031016,\n",
       "  1810598400.0,\n",
       "  1.6980229983992332,\n",
       "  -0.5197081662534252,\n",
       "  0.6352778134178614,\n",
       "  0.9494104354623092],\n",
       " [-1.1842732389555257,\n",
       "  -1.4282361944380122,\n",
       "  -1.4444724587224727,\n",
       "  0.10105302048592171,\n",
       "  1.7010779691066407,\n",
       "  -0.5213376331015598,\n",
       "  0.6369573375525994,\n",
       "  0.9536189658386554,\n",
       "  1810684800.0,\n",
       "  -0.2797343608945236,\n",
       "  0.01957297287506167,\n",
       "  -1.6352259691528253,\n",
       "  -1.3663709031505473],\n",
       " [1.6960219608495806,\n",
       "  -0.5227962024225661,\n",
       "  0.6361810680963443,\n",
       "  0.9535980849463707,\n",
       "  -0.27877121558818796,\n",
       "  0.017782059784604804,\n",
       "  -1.6311496602118025,\n",
       "  -1.3625588968483726,\n",
       "  1810771200.0,\n",
       "  1.6844650051651069,\n",
       "  0.22096548592725482,\n",
       "  -1.1288359109924906,\n",
       "  -0.9035134696074837],\n",
       " [-0.28273469447519717,\n",
       "  0.016064670148199706,\n",
       "  -1.6347519785813265,\n",
       "  -1.3638760535573284,\n",
       "  1.6875056359159464,\n",
       "  0.21911428134483768,\n",
       "  -1.125294156544074,\n",
       "  -0.8996222096589267,\n",
       "  1810857600.0,\n",
       "  -1.111040990678857,\n",
       "  -0.6433881279644946,\n",
       "  -1.5026586856987627,\n",
       "  -0.24429696074287705],\n",
       " [1.6824571172054361,\n",
       "  0.21730023623512718,\n",
       "  -1.1282661817229238,\n",
       "  -0.9006802784792014,\n",
       "  -1.110957097984623,\n",
       "  -0.6449805683646044,\n",
       "  -1.4987223171767925,\n",
       "  -0.24029282519095557,\n",
       "  1810944000.0,\n",
       "  0.08544261608253773,\n",
       "  1.3333081535439786,\n",
       "  -1.4384999881917497,\n",
       "  0.2390415632101561],\n",
       " [-1.1144613562780192,\n",
       "  -0.6463797792464293,\n",
       "  -1.5021596318012373,\n",
       "  -0.24098189267067052,\n",
       "  0.08679200011160525,\n",
       "  1.331123943538543,\n",
       "  -1.4346313467498029,\n",
       "  0.24312845932220742,\n",
       "  1811030400.0,\n",
       "  -0.12566611710903053,\n",
       "  -0.28395426857658007,\n",
       "  -1.141191742585732,\n",
       "  0.9398356375633296],\n",
       " [0.08262679447043222,\n",
       "  1.3287760453804403,\n",
       "  -1.4379888043756566,\n",
       "  0.24270994417375927,\n",
       "  -0.12454001760392297,\n",
       "  -0.28565431378937667,\n",
       "  -1.1376369450982953,\n",
       "  0.9440425284766535,\n",
       "  1811116800.0,\n",
       "  -0.6874853823392235,\n",
       "  -0.08106069942642315,\n",
       "  -1.1774824820572254,\n",
       "  1.2113420328955005],\n",
       " [-0.12858860505115918,\n",
       "  -0.2872260298416998,\n",
       "  -1.140624349324172,\n",
       "  0.9440162880200786,\n",
       "  -0.6869535052771764,\n",
       "  -0.0828214855069304,\n",
       "  -1.1738893754096622,\n",
       "  1.2155954130089253,\n",
       "  1811203200.0,\n",
       "  -0.2096588826641694,\n",
       "  0.7398208434171991,\n",
       "  0.22055428292712845,\n",
       "  0.7261514843502344],\n",
       " [-0.6906917391590269,\n",
       "  -0.0844905774430916,\n",
       "  -1.1769219499654155,\n",
       "  1.2157211502751486,\n",
       "  -0.20862162024500108,\n",
       "  0.7378143075211171,\n",
       "  0.22267159671203982,\n",
       "  0.730321786787088,\n",
       "  1811289600.0,\n",
       "  -0.5957259822572633,\n",
       "  0.45226752739039217,\n",
       "  1.3546122482084455,\n",
       "  1.1601842666278013],\n",
       " [-0.21262380940034897,\n",
       "  0.735751245159498,\n",
       "  0.2213791294887309,\n",
       "  0.7301759350375137,\n",
       "  -0.595097053530624,\n",
       "  0.45034707720910977,\n",
       "  1.3555324299200708,\n",
       "  1.1644288871551773,\n",
       "  1811376000.0,\n",
       "  1.0402548587778162,\n",
       "  -0.6819135467154966,\n",
       "  -0.38132527168706976,\n",
       "  -0.2772780603893081],\n",
       " [-0.5988859760569115,\n",
       "  0.4484220219731771,\n",
       "  1.35565150109849,\n",
       "  1.1645259884814947,\n",
       "  1.0426141242734543,\n",
       "  -0.6834944536432855,\n",
       "  -0.3785726029722144,\n",
       "  -0.2732795720890439,\n",
       "  1811462400.0,\n",
       "  0.8267613868276393,\n",
       "  1.0900976969725598,\n",
       "  -1.1223038042026858,\n",
       "  -1.722626277041949],\n",
       " [1.0379214725261516,\n",
       "  -0.684875174798123,\n",
       "  -0.38061421717968313,\n",
       "  -0.2739871009844228,\n",
       "  0.8288948455196826,\n",
       "  1.0879862976246049,\n",
       "  -1.1187689451641896,\n",
       "  -1.7188752712452822,\n",
       "  1811548800.0,\n",
       "  -0.36393253636344924,\n",
       "  1.2960707472591646,\n",
       "  -1.647697663829562,\n",
       "  -1.3183380770676945],\n",
       " [0.8243201293155463,\n",
       "  1.0857551248672455,\n",
       "  -1.1217328399653514,\n",
       "  -1.7203918445476936,\n",
       "  -0.3630584454000755,\n",
       "  1.2938976851298223,\n",
       "  -1.643608189542355,\n",
       "  -1.314517846253311,\n",
       "  1811635200.0,\n",
       "  -0.8720221516612375,\n",
       "  -1.5364763149256329,\n",
       "  1.3342514560306826,\n",
       "  0.24003611880378758],\n",
       " [-0.3669754125250769,\n",
       "  1.2915676585354365,\n",
       "  -1.64722603117128,\n",
       "  -1.315808116230856,\n",
       "  -0.8716854546093598,\n",
       "  -1.5378013887865005,\n",
       "  1.3351931309623195,\n",
       "  0.2441231852105163,\n",
       "  1811721600.0,\n",
       "  -1.021313886933177,\n",
       "  -1.6904665842791506,\n",
       "  -0.9618989956404367,\n",
       "  1.5481019813557184],\n",
       " [-0.8753217488678326,\n",
       "  -1.5387719746906343,\n",
       "  1.3352868594854879,\n",
       "  0.24370522677195386,\n",
       "  -1.021135092084289,\n",
       "  -1.6917455576025853,\n",
       "  -0.9585334628153422,\n",
       "  1.5524130238332683,\n",
       "  1811808000.0,\n",
       "  -1.33712067998382,\n",
       "  -0.3954047874801624,\n",
       "  -0.3339115410334776,\n",
       "  -1.1883632287716235],\n",
       " [-1.0246889163649744,\n",
       "  -1.6926422380663269,\n",
       "  -0.961297705081943,\n",
       "  1.5527272649836596,\n",
       "  -1.3372759062262605,\n",
       "  -0.39707146741059274,\n",
       "  -0.3312089231091614,\n",
       "  -1.1845207427660753,\n",
       "  1811894400.0,\n",
       "  -1.6725687730400813,\n",
       "  -0.10713306867536039,\n",
       "  1.378045882573112,\n",
       "  1.314895100933999],\n",
       " [-1.3406552762468982,\n",
       "  -0.3985896943709357,\n",
       "  -0.33319152243058753,\n",
       "  -1.1857382583562295,\n",
       "  -1.673078794494634,\n",
       "  -0.10888604939102496,\n",
       "  1.378941327317007,\n",
       "  1.3191662121188974,\n",
       "  1811980800.0,\n",
       "  -0.7437465280281848,\n",
       "  1.0645786157617132,\n",
       "  -0.6692832379784681,\n",
       "  0.16511460769017236],\n",
       " [-1.6762728602401693,\n",
       "  -0.1105426282642537,\n",
       "  1.379089565853542,\n",
       "  1.3193499139846285,\n",
       "  -0.7432741569986104,\n",
       "  1.0624748561390704,\n",
       "  -0.6662265956328468,\n",
       "  0.1691888455183412,\n",
       "  1812067200.0,\n",
       "  -0.4721189645930519,\n",
       "  1.3320144022391502,\n",
       "  1.5653522946842529,\n",
       "  -0.79788862509651],\n",
       " [-0.7469813117626061,\n",
       "  1.0602559309019162,\n",
       "  -0.6686266251417794,\n",
       "  0.16872894920706788,\n",
       "  -0.47135929975862595,\n",
       "  1.3298305795479957,\n",
       "  1.566050015396101,\n",
       "  -0.7939792793326038,\n",
       "  1812153600.0,\n",
       "  -1.1170919647610102,\n",
       "  -0.7420821203410197,\n",
       "  -1.1719666598191643,\n",
       "  0.5547779303227293],\n",
       " [-0.4752165038142467,\n",
       "  1.3274833023074375,\n",
       "  1.5664313903345477,\n",
       "  -0.7949782238610915,\n",
       "  -1.1170144720334996,\n",
       "  -0.7436450144190853,\n",
       "  -1.1683793757731908,\n",
       "  0.5589188889961131,\n",
       "  1812240000.0,\n",
       "  -0.9454617327428073,\n",
       "  0.6725636883532529,\n",
       "  -0.9086335140676862,\n",
       "  0.6351233728030161],\n",
       " [-1.120515387719234,\n",
       "  -0.7449968585224686,\n",
       "  -1.1714050848995354,\n",
       "  0.5586771096259129,\n",
       "  -0.9452027109327525,\n",
       "  0.6705772874371776,\n",
       "  -0.9053242092471048,\n",
       "  0.6392780887779476,\n",
       "  1812326400.0,\n",
       "  -0.6812271385476046,\n",
       "  1.221908339808771,\n",
       "  0.07855010988611728,\n",
       "  -1.6035392708193248],\n",
       " [-0.948798436564908,\n",
       "  0.6685465041908909,\n",
       "  -0.9080221530747999,\n",
       "  0.6390812833663548,\n",
       "  -0.6806886422947513,\n",
       "  1.2197574799059403,\n",
       "  0.08081732584119301,\n",
       "  -1.5997678741230072,\n",
       "  1812412800.0,\n",
       "  0.07867315811536456,\n",
       "  -0.5496851758657709,\n",
       "  0.47571106941352115,\n",
       "  0.2026681519703787],\n",
       " [-0.6844303332817494,\n",
       "  1.2174630465045932,\n",
       "  0.07934810897228436,\n",
       "  -1.6012177875885543,\n",
       "  0.08001538225494378,\n",
       "  -0.5513056684049472,\n",
       "  0.4775590350855751,\n",
       "  0.20674881997575356,\n",
       "  1812499200.0,\n",
       "  -1.4777562437616774,\n",
       "  -0.001316559541336483,\n",
       "  1.2880357134497777,\n",
       "  -0.4346391648459332],\n",
       " [0.07585391611781747,\n",
       "  -0.5527498506863935,\n",
       "  0.4765841562163127,\n",
       "  0.20630994454001325,\n",
       "  -1.4780602167870447,\n",
       "  -0.0031012188686486814,\n",
       "  1.2890261745541043,\n",
       "  -0.43066762100074985,\n",
       "  1812585600.0,\n",
       "  0.05657968405543118,\n",
       "  -1.102342710645556,\n",
       "  -0.4946996413954766,\n",
       "  -0.530754143565494],\n",
       " [-1.4813618985699524,\n",
       "  -0.004808582870971185,\n",
       "  1.289062379302109,\n",
       "  -0.4314632339439577,\n",
       "  0.05789854046993568,\n",
       "  -1.103797752409974,\n",
       "  -0.4918272926480113,\n",
       "  -0.5267990571907615,\n",
       "  1812672000.0,\n",
       "  0.40649914724548436,\n",
       "  0.135814118225457,\n",
       "  1.569096493984024,\n",
       "  0.03800540016705681],\n",
       " [0.05374927894890319,\n",
       "  -1.1049766945651098,\n",
       "  -0.4940100215793428,\n",
       "  -0.5276484712076962,\n",
       "  0.40818810488499035,\n",
       "  0.1339884056681573,\n",
       "  1.5697902622514577,\n",
       "  0.042057873478865096,\n",
       "  1812758400.0,\n",
       "  -0.3619385829893851,\n",
       "  0.024521113546176285,\n",
       "  -0.2829301298168278,\n",
       "  0.46064339582718017],\n",
       " [0.40384554498542263,\n",
       "  0.13221522774672054,\n",
       "  1.570176297517028,\n",
       "  0.04152682684392296,\n",
       "  -0.36106238307048305,\n",
       "  0.022728719115728328,\n",
       "  -0.2802813287910982,\n",
       "  0.46476823613545076,\n",
       "  1812844800.0,\n",
       "  0.23072803323265384,\n",
       "  -0.5068405959837022,\n",
       "  -1.2013229612119662,\n",
       "  1.5629402796102805],\n",
       " [-0.3649804516716658,\n",
       "  0.021008954689559198,\n",
       "  -0.2822004726085645,\n",
       "  0.46447376425989795,\n",
       "  0.23223108208039683,\n",
       "  -0.5084739150356637,\n",
       "  -1.197704688123963,\n",
       "  1.5672538628037347,\n",
       "  1812931200.0,\n",
       "  -1.1520980918029733,\n",
       "  -0.8377493756851815,\n",
       "  0.6353780408016024,\n",
       "  1.2893762439710323],\n",
       " [0.2279856195843924,\n",
       "  -0.509938659964074,\n",
       "  -1.200766936429095,\n",
       "  1.5675764098018619,\n",
       "  -1.1520576241965654,\n",
       "  -0.8392836295647162,\n",
       "  0.6370574591345036,\n",
       "  1.2936429856410017,\n",
       "  1813017600.0,\n",
       "  0.010351586258131948,\n",
       "  -0.4925736881837096,\n",
       "  -1.548329011554185,\n",
       "  -1.0557830534400634],\n",
       " [-1.1555392022108988,\n",
       "  -0.8405895595290633,\n",
       "  0.636281314429192,\n",
       "  1.2938124031368752,\n",
       "  0.011621548348587429,\n",
       "  -0.49421127836344975,\n",
       "  -1.5443444326112727,\n",
       "  -1.0519178661412627,\n",
       "  1813104000.0,\n",
       "  -0.21571812974707527,\n",
       "  -1.6470187409577297,\n",
       "  1.373684807512931,\n",
       "  -0.1973312672278663],\n",
       " [0.007497823607548614,\n",
       "  -0.4956828704914163,\n",
       "  -1.5478385921420081,\n",
       "  -1.0530611689928537,\n",
       "  -0.21468727604478005,\n",
       "  -1.6483107213947688,\n",
       "  1.3745848558864362,\n",
       "  -0.1933190898855442,\n",
       "  1813190400.0,\n",
       "  -1.3655617201954255,\n",
       "  1.6600357836197437,\n",
       "  0.8408668507847674,\n",
       "  1.0600974019578355],\n",
       " [-0.21868611802239282,\n",
       "  -1.6492282540331848,\n",
       "  1.3747276662833978,\n",
       "  -0.19398186796923475,\n",
       "  -1.3657470278278143,\n",
       "  1.6577537601654198,\n",
       "  0.8423293514179889,\n",
       "  1.0643248849210174,\n",
       "  1813276800.0,\n",
       "  1.2785300971733609,\n",
       "  -1.0410992816674431,\n",
       "  -1.4599903773828764,\n",
       "  -1.1366151344671418],\n",
       " [-1.369110686784807,\n",
       "  1.6552490537265705,\n",
       "  0.8418089743676797,\n",
       "  1.0643659618809256,\n",
       "  1.2811413805385217,\n",
       "  -1.0425726580643155,\n",
       "  -1.4560990502979063,\n",
       "  -1.1327637877955015,\n",
       "  1813363200.0,\n",
       "  0.11518658759431728,\n",
       "  -0.13331152800427043,\n",
       "  -0.01944406704418292,\n",
       "  0.755611233701149],\n",
       " [1.2763171035972185,\n",
       "  -1.04378099313245,\n",
       "  -1.459483256564958,\n",
       "  -1.1339523370052436,\n",
       "  0.11656743109177951,\n",
       "  -0.13505667159458093,\n",
       "  -0.017073406665814934,\n",
       "  0.7597865804397431,\n",
       "  1813449600.0,\n",
       "  1.2482901503613197,\n",
       "  -0.5582001030593018,\n",
       "  -0.28797061291559484,\n",
       "  0.07208311620171479],\n",
       " [0.11238579463703582,\n",
       "  -0.13670068648845166,\n",
       "  -0.018664594851990894,\n",
       "  0.7596572190038318,\n",
       "  1.2508694496771882,\n",
       "  -0.5598180464587079,\n",
       "  -0.285316491064857,\n",
       "  0.07614142453541188,\n",
       "  1813536000.0,\n",
       "  -1.43638199765464,\n",
       "  -0.6651041481836021,\n",
       "  -1.6993634545010077,\n",
       "  -0.5657362352297297],\n",
       " [1.2460618775302752,\n",
       "  -0.5612581421219102,\n",
       "  -0.28724190866697547,\n",
       "  0.07562945315530775,\n",
       "  -1.4366422101557195,\n",
       "  -0.6666900873923884,\n",
       "  -1.6952194408718995,\n",
       "  -0.5617871387303272,\n",
       "  1813622400.0,\n",
       "  -0.0214582539229105,\n",
       "  0.6039722615926272,\n",
       "  0.27712460179395665,\n",
       "  -1.575445360510462],\n",
       " [-1.439966747411177,\n",
       "  -0.6680788759790606,\n",
       "  -1.6989015898376811,\n",
       "  -0.5626561342330805,\n",
       "  -0.02022193631942005,\n",
       "  0.6020063951015532,\n",
       "  0.2791821989284103,\n",
       "  -1.5716691533807976,\n",
       "  1813708800.0,\n",
       "  -0.8350955339030702,\n",
       "  -0.33119227621644104,\n",
       "  0.7087564188324228,\n",
       "  0.8118240461008525],\n",
       " [-0.02432808904410857,\n",
       "  0.6000085313353293,\n",
       "  0.2779601436063649,\n",
       "  -1.573103341071237,\n",
       "  -0.834719780474211,\n",
       "  -0.3328781796425611,\n",
       "  0.7103583776239992,\n",
       "  0.8160090179854056,\n",
       "  1813795200.0,\n",
       "  -0.8303828521737749,\n",
       "  0.1837735630723142,\n",
       "  -0.4089631281110453,\n",
       "  -0.9375439711173728],\n",
       " [-0.8383764732988923,\n",
       "  -0.33442722448473233,\n",
       "  0.709673565462189,\n",
       "  0.8159111220890449,\n",
       "  -0.8300021142571563,\n",
       "  0.18193349274947707,\n",
       "  -0.40618128437571044,\n",
       "  -0.9336585381063076,\n",
       "  1813881600.0,\n",
       "  1.0412941880396052,\n",
       "  -1.4922684449990111,\n",
       "  -0.3286446948218171,\n",
       "  -0.804715149705426],\n",
       " [-0.8336614104058383,\n",
       "  0.180137297374358,\n",
       "  -0.40825729884919576,\n",
       "  -0.9347356557527392,\n",
       "  1.043654552808286,\n",
       "  -1.49360675350497,\n",
       "  -0.3259476366754999,\n",
       "  -0.800806972826209,\n",
       "  1813968000.0,\n",
       "  0.18285745616190455,\n",
       "  0.9031157227589496,\n",
       "  1.5565690906159755,\n",
       "  -1.1525426705029977],\n",
       " [1.0389613269269833,\n",
       "  -1.4945985563477415,\n",
       "  -0.3279236804628076,\n",
       "  -0.8018097385525857,\n",
       "  0.1843098734755971,\n",
       "  0.9010603007759135,\n",
       "  1.557276083036694,\n",
       "  -1.1486940510540768,\n",
       "  1814054400.0,\n",
       "  1.0108010863457664,\n",
       "  -1.719444415971146,\n",
       "  0.3230361076368447,\n",
       "  0.6812474524022978],\n",
       " [0.18009085507859465,\n",
       "  0.8989188673586284,\n",
       "  1.557646525703412,\n",
       "  -1.1498915158204988,\n",
       "  1.0131291993094516,\n",
       "  -1.7207147141125692,\n",
       "  0.3250452397564049,\n",
       "  0.6854100660606828,\n",
       "  1814140800.0,\n",
       "  1.5414586666255032,\n",
       "  -0.7473824431888729,\n",
       "  0.138298396791036,\n",
       "  0.5655821074533078],\n",
       " [1.00845281806737,\n",
       "  -1.7215974870779875,\n",
       "  0.32388032953237256,\n",
       "  0.6852390789454696,\n",
       "  1.5443480430831575,\n",
       "  -0.7489437504930931,\n",
       "  0.14050254137518756,\n",
       "  0.5697249160925164,\n",
       "  1814227200.0,\n",
       "  1.6459752526088103,\n",
       "  -1.4887179074496324,\n",
       "  -1.6215989050147273,\n",
       "  1.3256614337389925],\n",
       " [1.5393785222457808,\n",
       "  -0.7502930507818839,\n",
       "  0.13910769195837192,\n",
       "  0.5694891844407686,\n",
       "  1.6489751736933702,\n",
       "  -1.4900572788908657,\n",
       "  -1.617536981048762,\n",
       "  1.3299343884097485,\n",
       "  1814313600.0,\n",
       "  -0.02656650805367706,\n",
       "  0.8646998637765704,\n",
       "  0.8829810387304429,\n",
       "  0.7724371078154074],\n",
       " [1.6439479170375384,\n",
       "  -1.491050785763654,\n",
       "  -1.6211223380945068,\n",
       "  1.3301241168102897,\n",
       "  -0.02533559332516298,\n",
       "  0.8626559424666123,\n",
       "  0.8843990828661364,\n",
       "  0.7766153355963712,\n",
       "  1814400000.0,\n",
       "  1.3235022053977812,\n",
       "  0.3150341664455338,\n",
       "  -0.6997673586026136,\n",
       "  -0.7642597784361572],\n",
       " [-0.029438924208415127,\n",
       "  0.8605329461946614,\n",
       "  0.8839311244711011,\n",
       "  0.776495392568556,\n",
       "  1.326161054657657,\n",
       "  0.3131548002348156,\n",
       "  -0.6966785366686095,\n",
       "  -0.7603446745088764,\n",
       "  1814486400.0,\n",
       "  -1.60560185158491,\n",
       "  0.37242712094471264,\n",
       "  0.9801817805436578,\n",
       "  1.1824060856315626],\n",
       " [1.321311934755291,\n",
       "  0.3112956081993286,\n",
       "  -0.6991165091295085,\n",
       "  -0.7613247950404947,\n",
       "  -1.6060410437708097,\n",
       "  0.3705305728298496,\n",
       "  0.9814972178205009,\n",
       "  1.186654511132258,\n",
       "  1814572800.0,\n",
       "  1.4356107139765146,\n",
       "  0.22579773830707936,\n",
       "  -0.33666411278416186,\n",
       "  -0.127522439138452],\n",
       " [-1.6092721025924512,\n",
       "  0.3686438358618453,\n",
       "  0.9811502431705177,\n",
       "  1.1867640512869295,\n",
       "  1.4383881376534287,\n",
       "  0.22394508707850294,\n",
       "  -0.33395858919538435,\n",
       "  -0.12349830864646688,\n",
       "  1814659200.0,\n",
       "  1.4045935651425274,\n",
       "  -1.053423572109335,\n",
       "  1.2259305880533489,\n",
       "  1.3745862678037852],\n",
       " [1.4334770880923615,\n",
       "  0.22212872279796617,\n",
       "  -0.335944614585714,\n",
       "  -0.12412201071977008,\n",
       "  1.407338182742652,\n",
       "  -1.0548932589457225,\n",
       "  1.2269866084498842,\n",
       "  1.3788675997225173,\n",
       "  1814745600.0,\n",
       "  -0.07983022849416097,\n",
       "  -1.223234563351795,\n",
       "  -0.9895186361999975,\n",
       "  -1.0218157526612588],\n",
       " [1.40244426730874,\n",
       "  -1.0560956791458824,\n",
       "  1.226945512237863,\n",
       "  1.379084714162567,\n",
       "  -0.07865564949502715,\n",
       "  -1.2246534133528995,\n",
       "  -0.986123947583419,\n",
       "  -1.0179447492466318,\n",
       "  1814832000.0,\n",
       "  1.3058947532074012,\n",
       "  -0.8207350645532082,\n",
       "  -0.4265530437142342,\n",
       "  1.656003543404875],\n",
       " [-0.08272955706269108,\n",
       "  -1.2257743351821304,\n",
       "  -0.9889225674431281,\n",
       "  -1.019069038649145,\n",
       "  1.308534979497393,\n",
       "  -0.8222744120590515,\n",
       "  -0.42375263174625194,\n",
       "  1.6603330615330747,\n",
       "  1814918400.0,\n",
       "  0.31583893401475216,\n",
       "  -1.1372200351289714,\n",
       "  -0.5488231192340787,\n",
       "  -0.02129078540447955],\n",
       " [1.3036955860958839,\n",
       "  -0.8235885078001224,\n",
       "  -0.4258505400224503,\n",
       "  1.660707701384817,\n",
       "  0.3174320025726115,\n",
       "  -1.1386646355621959,\n",
       "  -0.5458936367657437,\n",
       "  -0.017248465195079336,\n",
       "  1815004800.0,\n",
       "  -0.7644146865422048,\n",
       "  -0.9956086788643699,\n",
       "  -1.2115459203323762,\n",
       "  0.8273170707304993],\n",
       " [0.31313952411765794,\n",
       "  -1.1398268388413204,\n",
       "  -0.5481437320661173,\n",
       "  -0.017812703310622686,\n",
       "  -0.7639641757164466,\n",
       "  -0.9970956739219939,\n",
       "  -1.2079168557040625,\n",
       "  0.8315046954377283,\n",
       "  1815091200.0,\n",
       "  -0.9587106544154055,\n",
       "  -0.6840450629284572,\n",
       "  0.6218916194667693,\n",
       "  0.7484435881454818],\n",
       " [-0.7676599132203343,\n",
       "  -0.998325841558173,\n",
       "  -1.2109918283141412,\n",
       "  0.8314154718770582,\n",
       "  -0.9584656456645166,\n",
       "  -0.6856253317377249,\n",
       "  0.6235852743096445,\n",
       "  0.7526177075903023,\n",
       "  1815177600.0,\n",
       "  1.505047070041837,\n",
       "  -1.71715305018523,\n",
       "  1.1222074800111106,\n",
       "  -1.0485588909987507],\n",
       " [-0.9620540524837851,\n",
       "  -0.6870050299016611,\n",
       "  0.6227923433357304,\n",
       "  0.7524843340115166,\n",
       "  1.5078979348477615,\n",
       "  -1.7184240342998294,\n",
       "  1.123372992394105,\n",
       "  -1.0446924667289648,\n",
       "  1815264000.0,\n",
       "  -1.5574306495510852,\n",
       "  -0.9569902704816983,\n",
       "  -0.4926605098285031,\n",
       "  -1.4106861934485804],\n",
       " [1.5029485280746764,\n",
       "  -1.719307906973679,\n",
       "  1.1232027941832174,\n",
       "  -1.0458317258019345,\n",
       "  -1.557818892239292,\n",
       "  -0.9584888268502332,\n",
       "  -0.48979031362515385,\n",
       "  -1.406881775116463,\n",
       "  1815350400.0,\n",
       "  0.4351892123688097,\n",
       "  0.9275831859206937,\n",
       "  1.1144310340289618,\n",
       "  -1.1839373871166954],\n",
       " [-1.5610765612276283,\n",
       "  -0.9597375288424514,\n",
       "  -0.49197050449176466,\n",
       "  -1.4082237376385431,\n",
       "  0.43690851478579884,\n",
       "  0.9255204390384537,\n",
       "  1.115604755368805,\n",
       "  -1.180094143287973,\n",
       "  1815436800.0,\n",
       "  -0.9830817270395694,\n",
       "  -1.1004277735787804,\n",
       "  0.729945823214957,\n",
       "  -1.0357546405469118],\n",
       " [0.4325501062591846,\n",
       "  0.9233672628100946,\n",
       "  1.1154248779770743,\n",
       "  -1.1813091814803653,\n",
       "  -0.982862494973837,\n",
       "  -1.1018833886237591,\n",
       "  0.731525414088511,\n",
       "  -1.031886023844934,\n",
       "  1815523200.0,\n",
       "  -0.5123265653619491,\n",
       "  0.5960680456353747,\n",
       "  0.8252281638201088,\n",
       "  0.880520638168286],\n",
       " [-0.9864374390129033,\n",
       "  -1.1030632498257142,\n",
       "  0.7308669759383574,\n",
       "  -1.033018115643544,\n",
       "  -0.5116094271196803,\n",
       "  0.5941045454535822,\n",
       "  0.8267071729337808,\n",
       "  0.8847173727577691,\n",
       "  1815609600.0,\n",
       "  0.12646594017215743,\n",
       "  -0.8528325207246881,\n",
       "  1.1864635043668579,\n",
       "  0.19436084800294656],\n",
       " [-0.5154444201671948,\n",
       "  0.5921104752034273,\n",
       "  0.8261673307345293,\n",
       "  0.8846579302894155,\n",
       "  0.12785871356391085,\n",
       "  -0.8543622591170078,\n",
       "  1.187561186929849,\n",
       "  0.19844009357436376,\n",
       "  1815696000.0,\n",
       "  0.09538198129811261,\n",
       "  0.3563141342231022,\n",
       "  -1.0667455530653789,\n",
       "  1.2270050941115191],\n",
       " [0.12367084630238566,\n",
       "  -0.8556609501403406,\n",
       "  1.1874709668582606,\n",
       "  0.19799656806348243,\n",
       "  0.09674187794973757,\n",
       "  0.35442240990230506,\n",
       "  -1.0632693423203636,\n",
       "  1.2312611561624585,\n",
       "  1815782400.0,\n",
       "  0.13308213140795447,\n",
       "  -0.22102103394862457,\n",
       "  0.9115098379296054,\n",
       "  -1.3642664989107285],\n",
       " [0.09257118172178118,\n",
       "  0.3525434061331885,\n",
       "  -1.06616408491995,\n",
       "  1.2313956609436154,\n",
       "  0.13448190258273743,\n",
       "  -0.22273991967615586,\n",
       "  0.9128977665495324,\n",
       "  -1.3604541322779262,\n",
       "  1815868800.0,\n",
       "  0.49163184345893557,\n",
       "  -1.2106388431333008,\n",
       "  0.04862566797147251,\n",
       "  1.4499944544252412],\n",
       " [0.13029038048296374,\n",
       "  -0.22434183963967416,\n",
       "  0.9124653173584862,\n",
       "  -1.3617701110309677,\n",
       "  0.49341084386105055,\n",
       "  -1.2120614639536518,\n",
       "  0.05092447270797557,\n",
       "  1.4542886982544747,\n",
       "  1815955200.0,\n",
       "  0.3334982693975278,\n",
       "  -0.4953010494091083,\n",
       "  1.0042686411646653,\n",
       "  0.14380612311875102],\n",
       " [0.4890212559625588,\n",
       "  -1.2131884309197196,\n",
       "  0.04941800950756894,\n",
       "  1.454548022987468,\n",
       "  0.3351100158008499,\n",
       "  -0.4969378230903853,\n",
       "  1.0055586519163422,\n",
       "  0.14787671236102976,\n",
       "  1816041600.0,\n",
       "  -1.2330247606448812,\n",
       "  -0.3858320604499138,\n",
       "  1.501020157566054,\n",
       "  1.3914276319776582],\n",
       " [0.3308077821843389,\n",
       "  -0.49840810626010845,\n",
       "  1.0052416576816328,\n",
       "  0.14740488846713914,\n",
       "  -1.2330698871891976,\n",
       "  -0.3875016061968834,\n",
       "  1.501785788443912,\n",
       "  1.3957118475910748,\n",
       "  1816128000.0,\n",
       "  0.48875167253396845,\n",
       "  -0.5794644941895418,\n",
       "  1.4480884812086716,\n",
       "  1.3317449161598387],\n",
       " [-1.236506760648589,\n",
       "  -0.3890244274514626,\n",
       "  1.5020870905070847,\n",
       "  1.3959383891098969,\n",
       "  0.49052762665001,\n",
       "  -0.5810760716032048,\n",
       "  1.4489099877202276,\n",
       "  1.336018912486469,\n",
       "  1816214400.0,\n",
       "  0.790570784606644,\n",
       "  0.13847473309060443,\n",
       "  -0.21862989601647706,\n",
       "  -0.9876881342275767],\n",
       " [0.4861396297815359,\n",
       "  -0.5825059617242143,\n",
       "  1.4491454068249152,\n",
       "  1.3362120461615115,\n",
       "  0.7926659653872689,\n",
       "  0.1366482240169034,\n",
       "  -0.21604897147903884,\n",
       "  -0.9838112872464276,\n",
       "  1816300800.0,\n",
       "  0.31784439193829866,\n",
       "  0.4944528127189187,\n",
       "  0.8827324022594487,\n",
       "  1.1451120531856696],\n",
       " [0.7881112411683275,\n",
       "  0.13487376917118987,\n",
       "  -0.21788808213062835,\n",
       "  -0.984916473460864,\n",
       "  0.31943958161976577,\n",
       "  0.4925197333998761,\n",
       "  0.8841507088602922,\n",
       "  1.1493540929445674,\n",
       "  1816387200.0,\n",
       "  0.7455226496938075,\n",
       "  -1.475115797343687,\n",
       "  1.7632599727436251,\n",
       "  -0.6606173235473038],\n",
       " [0.31514599533342347,\n",
       "  0.4905744319360268,\n",
       "  0.8836824409926043,\n",
       "  1.1494427574873842,\n",
       "  0.747570184168156,\n",
       "  -1.4764592408901822,\n",
       "  1.7637487785355945,\n",
       "  -0.6566844732431159,\n",
       "  1816473600.0,\n",
       "  1.3438556950813199,\n",
       "  0.18899898688795846,\n",
       "  -1.1130529615974867,\n",
       "  0.8788065611207191],\n",
       " [0.7430403449080429,\n",
       "  -1.4774592759023253,\n",
       "  1.764376485051553,\n",
       "  -0.6576065791402724,\n",
       "  1.3465360717275154,\n",
       "  0.18715735221402804,\n",
       "  -1.109527867915548,\n",
       "  0.8830030022140922,\n",
       "  1816560000.0,\n",
       "  -0.25539280495890265,\n",
       "  -1.6577514980637658,\n",
       "  -1.1250744450583523,\n",
       "  0.11107115155386],\n",
       " [1.3416757083906818,\n",
       "  0.18535864897104207,\n",
       "  -1.112480248385004,\n",
       "  0.8829426002783712,\n",
       "  -0.2544039141864873,\n",
       "  -1.6590402654025174,\n",
       "  -1.1215366612813213,\n",
       "  0.11513613568823139,\n",
       "  1816646400.0,\n",
       "  1.6359665022832406,\n",
       "  0.5120932717014062,\n",
       "  -0.7864595941638595,\n",
       "  1.133383056495421],\n",
       " [-0.25838083954843816,\n",
       "  -1.6599526470067556,\n",
       "  -1.1245040046416264,\n",
       "  0.11464598815069987,\n",
       "  1.638955837358316,\n",
       "  0.5101549113042598,\n",
       "  -0.7832792583400255,\n",
       "  1.1376230879345022,\n",
       "  1816732800.0,\n",
       "  0.2140269364143865,\n",
       "  -0.14354256382498434,\n",
       "  -0.7756806458362195,\n",
       "  -1.6395017103066603],\n",
       " [1.6339341096181708,\n",
       "  0.5082011435529283,\n",
       "  -0.7858251348264441,\n",
       "  1.137705187084244,\n",
       "  0.21551232092206976,\n",
       "  -0.14528464451884163,\n",
       "  -0.7725116884649466,\n",
       "  -1.6357364713475975,\n",
       "  1816819200.0,\n",
       "  1.6187380161421197,\n",
       "  -1.409344364791779,\n",
       "  0.5440818300311403,\n",
       "  0.4178333206666251],\n",
       " [0.21127608424878835,\n",
       "  -0.14692374917253181,\n",
       "  -0.7750441486181966,\n",
       "  -1.6372065150559434,\n",
       "  1.6217091290703969,\n",
       "  -1.4107074985329928,\n",
       "  0.5458576222932663,\n",
       "  0.4219508307381694,\n",
       "  1816905600.0,\n",
       "  -1.3927184515586997,\n",
       "  1.140019917522441,\n",
       "  1.1294549310331161,\n",
       "  -1.7146321446170483],\n",
       " [1.6166969184871578,\n",
       "  -1.4117390996090722,\n",
       "  0.5449678430900895,\n",
       "  0.4216323956048533,\n",
       "  -1.3929324821990998,\n",
       "  1.1378935728067894,\n",
       "  1.1306127928758967,\n",
       "  -1.710879770009818,\n",
       "  1816992000.0,\n",
       "  1.6110084882172102,\n",
       "  1.3427656582408616,\n",
       "  -0.9959357927612948,\n",
       "  0.17169452027436505],\n",
       " [-1.3962811395551786,\n",
       "  1.1356384405894553,\n",
       "  1.1304516154168096,\n",
       "  -1.7123918685371873,\n",
       "  1.6139714258135767,\n",
       "  1.3405786169133487,\n",
       "  -0.9925343300783336,\n",
       "  0.17576988476060912,\n",
       "  1817078400.0,\n",
       "  -1.4647969271257402,\n",
       "  -1.6659738394604822,\n",
       "  -0.5757305465741488,\n",
       "  0.17431603955937874],\n",
       " [1.6089634850848953,\n",
       "  1.3382261797603305,\n",
       "  -0.9953409372395683,\n",
       "  0.17531367160431094,\n",
       "  -1.4650871934000786,\n",
       "  -1.6672601452517675,\n",
       "  -0.5727726601394694,\n",
       "  0.1783918529202597,\n",
       "  1817164800.0,\n",
       "  0.9753837049434024,\n",
       "  0.03925294942082214,\n",
       "  0.5761500043054286,\n",
       "  -0.46012053394794494],\n",
       " [-1.4683960340156783,\n",
       "  -1.668168580660155,\n",
       "  -0.5750562465559456,\n",
       "  0.17793710717886613,\n",
       "  0.977674357812345,\n",
       "  0.03745614467565724,\n",
       "  0.577891944823525,\n",
       "  -0.45615335319876005,\n",
       "  1817251200.0,\n",
       "  -1.3612425844109042,\n",
       "  -0.19930111515357604,\n",
       "  0.6351860987666753,\n",
       "  0.5755320109632376],\n",
       " [0.9730175414219429,\n",
       "  0.035729309914312585,\n",
       "  0.5770420802110016,\n",
       "  -0.45696322952771673,\n",
       "  -1.3614233237994169,\n",
       "  -0.2010265032395593,\n",
       "  0.6368657197170559,\n",
       "  0.5796765232936417,\n",
       "  1817337600.0,\n",
       "  0.06704465458614052,\n",
       "  0.6505656384965622,\n",
       "  -1.485506317696006,\n",
       "  0.26551216159388136],\n",
       " [-1.3647893686824057,\n",
       "  -0.2026388473692965,\n",
       "  0.6360893361054788,\n",
       "  0.5794463611743377,\n",
       "  0.06837457954303963,\n",
       "  0.6485858232038846,\n",
       "  -1.4815880555235326,\n",
       "  0.26960359018460067,\n",
       "  1817424000.0,\n",
       "  1.1955930298896182,\n",
       "  1.3464701446537843,\n",
       "  0.12700220180693522,\n",
       "  -1.2189377857991017],\n",
       " [0.06421953708654113,\n",
       "  0.6465655976088653,\n",
       "  -1.4850040209516773,\n",
       "  0.26919989215034434,\n",
       "  1.1981165927549822,\n",
       "  1.3442819943028554,\n",
       "  0.12921827085856158,\n",
       "  -1.2151005349803634,\n",
       "  1817510400.0,\n",
       "  -1.0838777816660068,\n",
       "  -0.6876629855319882,\n",
       "  1.5408202127544137,\n",
       "  0.34289746631306384],\n",
       " [1.1933381309291922,\n",
       "  1.3419277792342525,\n",
       "  0.12780936130240422,\n",
       "  -1.2163351649060636,\n",
       "  -1.0837651591125104,\n",
       "  -0.6892421712327119,\n",
       "  1.5415438299750839,\n",
       "  0.3470021453500997,\n",
       "  1817596800.0,\n",
       "  -1.099446623514252,\n",
       "  -0.9023878024049952,\n",
       "  1.1034789442082205,\n",
       "  0.8816896270353183],\n",
       " [-1.0872844225851273,\n",
       "  -0.6906201330261331,\n",
       "  1.5418946703405383,\n",
       "  0.34664176431533755,\n",
       "  -1.0993504677425328,\n",
       "  -0.9039027052812287,\n",
       "  1.1046642267719124,\n",
       "  0.8858865617871485,\n",
       "  1817683200.0,\n",
       "  0.6495196047894417,\n",
       "  -0.2404233924012767,\n",
       "  1.1632644990356473,\n",
       "  -0.7733102274423095],\n",
       " [-1.102861130859349,\n",
       "  -0.90517761295168,\n",
       "  1.1044707175413917,\n",
       "  0.885827773669002,\n",
       "  0.6514655992002594,\n",
       "  -0.2421364695854767,\n",
       "  1.1643866708877229,\n",
       "  -0.7693966731954123,\n",
       "  1817769600.0,\n",
       "  -1.3610924287956279,\n",
       "  0.13111662168678306,\n",
       "  0.7658802830869569,\n",
       "  -0.5652634445048],\n",
       " [0.6469887928087535,\n",
       "  -0.24372907766291216,\n",
       "  1.1642675754959044,\n",
       "  -0.7703818597831306,\n",
       "  -1.3612730093682328,\n",
       "  0.12929231543337477,\n",
       "  0.7674219408955654,\n",
       "  -0.5613142670509044,\n",
       "  1817856000.0,\n",
       "  -1.0531029799117204,\n",
       "  1.4845584690517175,\n",
       "  1.569802041321225,\n",
       "  -0.8042170180976645],\n",
       " [-1.3646391371984141,\n",
       "  0.12752139200861423,\n",
       "  0.7668082296214688,\n",
       "  -0.5621829979055353,\n",
       "  -1.0529578076059907,\n",
       "  1.4823289787772032,\n",
       "  1.5704950648001448,\n",
       "  -0.8003087559249135,\n",
       "  1817942400.0,\n",
       "  1.4652682826955359,\n",
       "  -0.24396518147225313,\n",
       "  0.2182665130056989,\n",
       "  -1.6971727901024913],\n",
       " [-1.0564940713312503,\n",
       "  1.4799084901806008,\n",
       "  1.5708819782458356,\n",
       "  -0.8013112428184203,\n",
       "  1.468077074454732,\n",
       "  -0.2456771983402375,\n",
       "  0.2203862418018646,\n",
       "  -1.6934174259840022,\n",
       "  1818028800.0,\n",
       "  -1.154172736008802,\n",
       "  0.5760453411923866,\n",
       "  -1.3542617560721115,\n",
       "  -0.9303652497684156],\n",
       " [1.4631496418097047,\n",
       "  -0.24726810658636433,\n",
       "  0.2190909270388379,\n",
       "  -1.6949197515079129,\n",
       "  -1.1541344627026342,\n",
       "  0.5740878352687998,\n",
       "  -1.3504820380296334,\n",
       "  -0.9264785875671029,\n",
       "  1818115200.0,\n",
       "  1.6033779525812322,\n",
       "  -1.1772829721892608,\n",
       "  -1.07160075922851,\n",
       "  0.4321478588167703],\n",
       " [-1.1576148946665095,\n",
       "  0.572103374630966,\n",
       "  -1.3537346460770963,\n",
       "  -0.9275516868709026,\n",
       "  1.6063328195474011,\n",
       "  -1.1787155788586108,\n",
       "  -1.0681194232401665,\n",
       "  0.43626781992239655,\n",
       "  1818201600.0,\n",
       "  -0.040742291380542174,\n",
       "  -1.7748595474311955,\n",
       "  -0.18814511225547828,\n",
       "  1.4128857172583364],\n",
       " [1.6013290939891258,\n",
       "  -1.1798585545006952,\n",
       "  -1.0710202090140504,\n",
       "  0.4359573974582049,\n",
       "  -0.03952637003000942,\n",
       "  -1.7761132557754,\n",
       "  -0.18559636800644216,\n",
       "  1.4171736070733099,\n",
       "  1818288000.0,\n",
       "  0.0717611196801,\n",
       "  0.0670047435061944,\n",
       "  1.185034183818876,\n",
       "  -1.5305506113643674],\n",
       " [-0.04362187009440236,\n",
       "  -1.7769694330363488,\n",
       "  -0.1873975348806725,\n",
       "  1.4174121599148581,\n",
       "  0.07309603312633045,\n",
       "  0.06519963062164227,\n",
       "  1.1861333751984562,\n",
       "  -1.5267667170457,\n",
       "  1818374400.0,\n",
       "  -1.1739398117377506,\n",
       "  -1.3182753963313314,\n",
       "  0.34085688226372046,\n",
       "  1.5446887924126713],\n",
       " [0.06893838525586964,\n",
       "  0.06345947678129242,\n",
       "  1.1860413760812603,\n",
       "  -1.528175774566618,\n",
       "  -1.1739224455822603,\n",
       "  -1.3196657936678824,\n",
       "  0.3428472024516777,\n",
       "  1.5489992504604382,\n",
       "  1818460800.0,\n",
       "  -1.1808020529082561,\n",
       "  0.7843827515987454,\n",
       "  -1.3674029129301402,\n",
       "  -1.0969482436409956],\n",
       " [-1.1773919580515413,\n",
       "  -1.3207411020005848,\n",
       "  0.34170447337579163,\n",
       "  1.5493115810529496,\n",
       "  -1.1807919447767703,\n",
       "  0.7823628750680581,\n",
       "  -1.3636093228451065,\n",
       "  -1.0930901049303583,\n",
       "  1818547200.0,\n",
       "  -1.2870425437831015,\n",
       "  -0.6117687291218776,\n",
       "  0.18327187381872284,\n",
       "  -1.07971587919921],\n",
       " [-1.1842576664878028,\n",
       "  0.7802784258521742,\n",
       "  -1.3668782874176464,\n",
       "  -1.0942564503031305,\n",
       "  -1.2871448036103998,\n",
       "  -0.6133706355180277,\n",
       "  0.18542854358814242,\n",
       "  -1.075854789844122,\n",
       "  1818633600.0,\n",
       "  -1.4343329301306,\n",
       "  -0.3953820196972774,\n",
       "  -0.03514772306405221,\n",
       "  0.6941206321090916],\n",
       " [-1.2905518372037905,\n",
       "  -0.6147850216807726,\n",
       "  0.18408967172435078,\n",
       "  -1.0770114892728158,\n",
       "  -1.434590975383268,\n",
       "  -0.39704870644376844,\n",
       "  -0.032760485622725564,\n",
       "  0.6982854500022115,\n",
       "  1818720000.0,\n",
       "  -0.2011153178801726,\n",
       "  0.7679180810303609,\n",
       "  0.8803852882641808,\n",
       "  -1.1481096334944123],\n",
       " [-1.4379166445604148,\n",
       "  -0.39856694433118517,\n",
       "  -0.03437121982347766,\n",
       "  0.6981216687450211,\n",
       "  -0.20006901914229364,\n",
       "  0.7659031335784073,\n",
       "  0.8818060725209551,\n",
       "  -1.1442602549902794,\n",
       "  1818806400.0,\n",
       "  0.7038444031973501,\n",
       "  1.6481702319235372,\n",
       "  1.4920268531563343,\n",
       "  -0.8881957175964386],\n",
       " [-0.20407592783283,\n",
       "  0.7638265863470732,\n",
       "  0.8813348832492128,\n",
       "  -1.1454552383312864,\n",
       "  0.7058478556136626,\n",
       "  1.6458917606956782,\n",
       "  1.4928019775287786,\n",
       "  -0.8843018348365939,\n",
       "  1818892800.0,\n",
       "  -0.9726827019439407,\n",
       "  1.085320667154949,\n",
       "  1.0835502533444659,\n",
       "  0.4969880069698088],\n",
       " [0.7013410397584053,\n",
       "  1.643392748959665,\n",
       "  1.49309208581269,\n",
       "  -0.885351329431329,\n",
       "  -0.9724524710846815,\n",
       "  1.083210697921006,\n",
       "  1.084756572994217,\n",
       "  0.5011190704534044,\n",
       "  1818979200.0,\n",
       "  -0.38470633557425976,\n",
       "  0.35793189527628794,\n",
       "  -1.2034435277718671,\n",
       "  -0.1373357217074185],\n",
       " [-0.9760331596304149,\n",
       "  1.0809818178311894,\n",
       "  1.0845382589359789,\n",
       "  0.5008449427440753,\n",
       "  -0.38385421654827345,\n",
       "  0.35603968664142144,\n",
       "  -1.1998230161754984,\n",
       "  -0.13331327151344788,\n",
       "  1819065600.0,\n",
       "  0.050051188777421804,\n",
       "  -1.0395202584033156,\n",
       "  -0.9800677244381514,\n",
       "  0.7033079411834696],\n",
       " [-0.3877597080563805,\n",
       "  0.35415990645088824,\n",
       "  -1.2028879039057956,\n",
       "  -0.13394246664460774,\n",
       "  0.05136314016275821,\n",
       "  -1.0409941075172073,\n",
       "  -0.976683012374746,\n",
       "  0.707474332191099,\n",
       "  1819152000.0,\n",
       "  -0.5788210197864224,\n",
       "  0.7936493792395104,\n",
       "  -1.6436963196911067,\n",
       "  -0.10972465116706108],\n",
       " [0.0472174850360086,\n",
       "  -1.0422032004151074,\n",
       "  -0.9794698688808245,\n",
       "  0.707315693598449,\n",
       "  -0.5781742110960281,\n",
       "  0.7916267285301934,\n",
       "  -1.6396110692950512,\n",
       "  -0.10569747321490347,\n",
       "  1819238400.0,\n",
       "  0.3311052155416423,\n",
       "  1.0666985857712503,\n",
       "  -0.9170791109649373,\n",
       "  0.8604452267669991],\n",
       " [-0.5819724720620955,\n",
       "  0.7895378319281232,\n",
       "  -1.643223930534011,\n",
       "  -0.10631121284410504,\n",
       "  0.3327144308706553,\n",
       "  1.0645941914867085,\n",
       "  -0.9137608908197135,\n",
       "  0.8646385239058961,\n",
       "  1819324800.0,\n",
       "  0.3306720593887552,\n",
       "  0.5223332554841874,\n",
       "  0.44956185987587527,\n",
       "  -1.5549717228161504],\n",
       " [0.32841351919670175,\n",
       "  1.0623742488000893,\n",
       "  -0.9164693467065018,\n",
       "  0.8645678440767973,\n",
       "  0.3322808165791401,\n",
       "  0.5203918295118092,\n",
       "  0.4514374291258652,\n",
       "  -1.5511920100488439,\n",
       "  1819411200.0,\n",
       "  0.35143163940024225,\n",
       "  1.5568271037650354,\n",
       "  -1.6026803654334965,\n",
       "  -0.6830074269240768],\n",
       " [0.3279801441841945,\n",
       "  0.5184331472258499,\n",
       "  0.4504300028784553,\n",
       "  -1.5526147374684107,\n",
       "  0.35306235348871656,\n",
       "  1.5545759782085398,\n",
       "  -1.5986384122196495,\n",
       "  -0.6790784104080207,\n",
       "  1819497600.0,\n",
       "  1.4097300235246153,\n",
       "  -1.412250741050589,\n",
       "  -1.7299582379322,\n",
       "  -1.1250809944491724],\n",
       " [0.34875021333167877,\n",
       "  1.5521208053081992,\n",
       "  -1.6022002217520033,\n",
       "  -0.6800130493319602,\n",
       "  1.4124800738306604,\n",
       "  -1.4136130047010622,\n",
       "  -1.7257819278970508,\n",
       "  -1.1212276728224204,\n",
       "  1819584000.0,\n",
       "  -1.5127730381606992,\n",
       "  1.5850379849761698,\n",
       "  -1.1546543195340961,\n",
       "  0.937815649510814],\n",
       " [1.4075833209750526,\n",
       "  -1.4146432109031781,\n",
       "  -1.729502157554497,\n",
       "  -1.1224097657115584,\n",
       "  -1.5131140475897709,\n",
       "  1.5827784138419716,\n",
       "  -1.1510853107072503,\n",
       "  0.9420221945478331,\n",
       "  1819670400.0,\n",
       "  0.8590555372307733,\n",
       "  0.7375832345629061,\n",
       "  -1.144392753575532,\n",
       "  -0.22458170026838642],\n",
       " [-1.516396385808542,\n",
       "  1.5803097015302867,\n",
       "  -1.1540894715231167,\n",
       "  0.9419948233879321,\n",
       "  0.8612231526528128,\n",
       "  0.7355773685466235,\n",
       "  -1.1408345770430726,\n",
       "  -0.2205741889334079,\n",
       "  1819756800.0,\n",
       "  0.3277362726382891,\n",
       "  -0.7189449492030392,\n",
       "  -0.7083480002416792,\n",
       "  -0.20945906456955496],\n",
       " [0.8566305968953913,\n",
       "  0.7335153800935604,\n",
       "  -1.1438259655008622,\n",
       "  -0.2212522206495357,\n",
       "  0.3293419247191074,\n",
       "  -0.7205147699267209,\n",
       "  -0.7052501204273638,\n",
       "  -0.20544896383245134,\n",
       "  1819843200.0,\n",
       "  -0.46046262500192064,\n",
       "  0.17293868811505014,\n",
       "  -0.5764552850716292,\n",
       "  0.6403737841372283],\n",
       " [0.32504287407681715,\n",
       "  -0.721877718386435,\n",
       "  -0.707698773034742,\n",
       "  -0.20611853054084553,\n",
       "  -0.45969063154329526,\n",
       "  0.17110186146183348,\n",
       "  -0.5734966335899006,\n",
       "  0.6445293991238491,\n",
       "  1819929600.0,\n",
       "  -1.5526178425630701,\n",
       "  -0.5257562896211176,\n",
       "  0.8953140836709946,\n",
       "  -0.19898700209152867],\n",
       " [-0.4635542746564125,\n",
       "  0.16931086613090338,\n",
       "  -0.575781122073336,\n",
       "  0.6443355326690251,\n",
       "  -1.5530009948634893,\n",
       "  -0.5273839458240805,\n",
       "  0.8967191088216702,\n",
       "  -0.19497510825556483,\n",
       "  1820016000.0,\n",
       "  -0.7262649799802641,\n",
       "  -0.6844769940945518,\n",
       "  -1.4340430289301436,\n",
       "  0.5350581029652703],\n",
       " [-1.5562613224858397,\n",
       "  -0.5288396124342667,\n",
       "  0.8962665011115881,\n",
       "  -0.1956388131491518,\n",
       "  -0.725774119146526,\n",
       "  -0.6860571335952665,\n",
       "  -1.4301790923349018,\n",
       "  0.5391956850736239,\n",
       "  1820102400.0,\n",
       "  0.40473012691143007,\n",
       "  0.733104524784713,\n",
       "  0.6665261064267718,\n",
       "  -0.34364207549293035],\n",
       " [-0.7294909308608987,\n",
       "  -0.6874366244599807,\n",
       "  -1.4335310024761072,\n",
       "  0.5389428673834898,\n",
       "  0.4064172135015617,\n",
       "  0.7310999995734608,\n",
       "  0.6681726442989538,\n",
       "  -0.339654950497659,\n",
       "  1820188800.0,\n",
       "  0.2584239045997123,\n",
       "  0.2964163826458742,\n",
       "  0.6965755695664197,\n",
       "  1.4548424339522463],\n",
       " [0.402075630823321,\n",
       "  0.729040160613479,\n",
       "  0.6674352689441653,\n",
       "  -0.3403996271437523,\n",
       "  0.25995624669061185,\n",
       "  0.2945425900979763,\n",
       "  0.698190386682511,\n",
       "  1.4591375078860156,\n",
       "  1820275200.0,\n",
       "  -0.7134520712908919,\n",
       "  0.4430191570488446,\n",
       "  0.1694600095459768,\n",
       "  -0.1836312377841195],\n",
       " [0.2556954847683378,\n",
       "  0.2926923334031223,\n",
       "  0.6974904132705433,\n",
       "  1.4593995463115828,\n",
       "  -0.7129476585582154,\n",
       "  0.4411014755804485,\n",
       "  0.17163125936881427,\n",
       "  -0.17961671462814013,\n",
       "  1820361600.0,\n",
       "  0.49744468425256616,\n",
       "  -0.11390079834256607,\n",
       "  -0.6081119800928355,\n",
       "  1.1144779338137623],\n",
       " [-0.7166715482283307,\n",
       "  0.4391808589683709,\n",
       "  0.17027519616435283,\n",
       "  -0.18027182401852207,\n",
       "  0.4992298327536719,\n",
       "  -0.11565175298232228,\n",
       "  -0.6051199112320096,\n",
       "  1.1187147281871743,\n",
       "  1820448000.0,\n",
       "  -0.15618933774872878,\n",
       "  1.6434194675011635,\n",
       "  1.3019220424685711,\n",
       "  -0.20500657315099258],\n",
       " [0.49483703379429816,\n",
       "  -0.11730508377991865,\n",
       "  -0.6074438021464161,\n",
       "  1.11878624505398,\n",
       "  -0.15509552190468645,\n",
       "  1.6411424185241648,\n",
       "  1.3028978449131488,\n",
       "  -0.20099571002755823,\n",
       "  1820534400.0,\n",
       "  1.029419616463967,\n",
       "  0.7254928353302891,\n",
       "  1.5339515654011389,\n",
       "  -0.28061859623805174],\n",
       " [-0.15912724807474893,\n",
       "  1.6386456868499915,\n",
       "  1.3029513336865464,\n",
       "  -0.20166278442078708,\n",
       "  1.0317674217898365,\n",
       "  0.7234905888537654,\n",
       "  1.5346824332900273,\n",
       "  -0.2766206799274062,\n",
       "  1820620800.0,\n",
       "  -0.19381739526238373,\n",
       "  -0.5209115111753853,\n",
       "  -0.9334066315006077,\n",
       "  0.24223155535408172],\n",
       " [1.0270807555191666,\n",
       "  0.7214344030159165,\n",
       "  1.5350247243927424,\n",
       "  -0.27733007871255544,\n",
       "  -0.19276337769093038,\n",
       "  -0.5225406177744739,\n",
       "  -0.930071175729773,\n",
       "  0.24631899767861884,\n",
       "  1820707200.0,\n",
       "  -0.41874436807620574,\n",
       "  -1.3653114216546691,\n",
       "  -0.7845050720931862,\n",
       "  -0.5573246303334047],\n",
       " [-0.1967743178137164,\n",
       "  -0.5239986095671937,\n",
       "  -0.9327999541423463,\n",
       "  0.24590226815198332,\n",
       "  -0.4179282502414957,\n",
       "  -1.3666877376726068,\n",
       "  -0.7813267994981558,\n",
       "  -0.5533740935409192,\n",
       "  1820793600.0,\n",
       "  -1.2294052198638663,\n",
       "  -1.6206771120593746,\n",
       "  0.05577096609793625,\n",
       "  1.4583315050921135],\n",
       " [-0.4218149388615577,\n",
       "  -1.3677404717336985,\n",
       "  -0.7838702432315369,\n",
       "  -0.5542383805853112,\n",
       "  -1.2294465181087655,\n",
       "  -1.6219769784703402,\n",
       "  0.058062228128667424,\n",
       "  1.46262717644874,\n",
       "  1820880000.0,\n",
       "  1.6747400243606378,\n",
       "  -1.3093374817135388,\n",
       "  0.34740780521437187,\n",
       "  -1.2873599937785416],\n",
       " [-1.2328853910321411,\n",
       "  -1.6229071533990294,\n",
       "  0.05656465853247333,\n",
       "  1.4628911679078105,\n",
       "  1.677770369238048,\n",
       "  -1.3107305548208974,\n",
       "  0.3493912101297294,\n",
       "  -1.2835344586827946,\n",
       "  1820966400.0,\n",
       "  -0.6311557857976026,\n",
       "  -0.4638316397995053,\n",
       "  -1.237760784044429,\n",
       "  0.2770130609426665],\n",
       " [1.6727272226866159,\n",
       "  -1.3118101527786443,\n",
       "  0.3482566348516161,\n",
       "  -1.2848073884479694,\n",
       "  -0.6305643303042963,\n",
       "  -0.4654778345740877,\n",
       "  -1.2341040465324467,\n",
       "  0.28110645879680035,\n",
       "  1821052800.0,\n",
       "  -1.16052048670453,\n",
       "  -0.7202569477505547,\n",
       "  -1.266645052907843,\n",
       "  0.5533705935307734],\n",
       " [-0.6343336811168137,\n",
       "  -0.46696322103953103,\n",
       "  -1.2372116482390607,\n",
       "  0.2807091984764367,\n",
       "  -1.1604889272584231,\n",
       "  -0.7218263756972226,\n",
       "  -1.2629578246398956,\n",
       "  0.5575113112302325,\n",
       "  1821139200.0,\n",
       "  -1.0422412051555923,\n",
       "  0.594182718190046,\n",
       "  0.05200053836553632,\n",
       "  -1.6489266525268282],\n",
       " [-1.1639658526728038,\n",
       "  -0.7231886944818875,\n",
       "  -1.266101377996209,\n",
       "  0.5572687440928026,\n",
       "  -1.0420845446173812,\n",
       "  0.592219782424491,\n",
       "  0.054295780527889206,\n",
       "  -1.6451630273714635,\n",
       "  1821225600.0,\n",
       "  0.37698554474910606,\n",
       "  -1.5710137178490127,\n",
       "  1.186390117652079,\n",
       "  -0.39796340360772353],\n",
       " [-1.045626808476012,\n",
       "  0.5902266170104387,\n",
       "  0.05279351795858602,\n",
       "  -1.6466383467612695,\n",
       "  0.37864328657586893,\n",
       "  -1.5723284521420429,\n",
       "  1.187487877683412,\n",
       "  -0.39398557988540883,\n",
       "  1821312000.0,\n",
       "  -0.9100238629478585,\n",
       "  1.1677261075328205,\n",
       "  -0.7842790234751452,\n",
       "  1.3962659564734703],\n",
       " [0.37431703023214025,\n",
       "  -1.5732824623106851,\n",
       "  1.1873975662689034,\n",
       "  -0.39476066329866566,\n",
       "  -0.9097273593729914,\n",
       "  1.165591468330413,\n",
       "  -0.7811009895011193,\n",
       "  1.4005510005382218,\n",
       "  1821398400.0,\n",
       "  0.4356902140236896,\n",
       "  -0.3587465371490686,\n",
       "  -1.0264449489939629,\n",
       "  -1.301357065929549],\n",
       " [-0.9133426611747822,\n",
       "  1.163323038921101,\n",
       "  -0.7836441518764792,\n",
       "  1.4007802503451419,\n",
       "  0.4374100463378286,\n",
       "  -0.360424191571905,\n",
       "  -1.023011280294578,\n",
       "  -1.2975339275091633,\n",
       "  1821484800.0,\n",
       "  1.1400213477372196,\n",
       "  1.1517648964996663,\n",
       "  0.002212604091126747,\n",
       "  1.1771090873082655],\n",
       " [0.4330513610537952,\n",
       "  -0.36196001213829915,\n",
       "  -1.0258558615690814,\n",
       "  -1.2988146922395098,\n",
       "  1.1424861337987657,\n",
       "  1.1496350356537732,\n",
       "  0.004560403296247514,\n",
       "  1.1813566058203255,\n",
       "  1821571200.0,\n",
       "  -1.5283872972943147,\n",
       "  0.7863380383654565,\n",
       "  0.5305626655271675,\n",
       "  -0.3785883948954213],\n",
       " [1.137738370225524,\n",
       "  1.1473742666007651,\n",
       "  0.002996170718953064,\n",
       "  1.181463180940815,\n",
       "  -1.528744821541911,\n",
       "  0.7843175764745958,\n",
       "  0.5323527288635482,\n",
       "  -0.37460725365030617,\n",
       "  1821657600.0,\n",
       "  1.4984129270280095,\n",
       "  -0.17997490574567668,\n",
       "  0.4734462543130798,\n",
       "  0.29606876952311856],\n",
       " [-1.532018534316001,\n",
       "  0.7822321888466277,\n",
       "  0.5314461226370262,\n",
       "  -0.37537149175842865,\n",
       "  1.5012567750637495,\n",
       "  -0.18170607957801904,\n",
       "  0.47529661076486446,\n",
       "  0.30016543022727915,\n",
       "  1821744000.0,\n",
       "  1.3455094671902799,\n",
       "  0.486480867908457,\n",
       "  -0.559820269851954,\n",
       "  -1.42431331001357],\n",
       " [1.4963110330456222,\n",
       "  -0.18332769904718768,\n",
       "  0.4743189129272733,\n",
       "  0.2997788364814277,\n",
       "  1.3481915929906318,\n",
       "  0.48455017517488946,\n",
       "  -0.5568791785927789,\n",
       "  -1.4205112250104635,\n",
       "  1821830400.0,\n",
       "  -0.5302756964594162,\n",
       "  -1.2468601004242943,\n",
       "  1.0511485450761286,\n",
       "  0.6871032613670618],\n",
       " [1.3433303160965349,\n",
       "  0.48260869973260945,\n",
       "  -0.559142961818181,\n",
       "  -1.4218608154123262,\n",
       "  -0.5295775425724225,\n",
       "  -1.2482718775761807,\n",
       "  1.0523890685544184,\n",
       "  0.6912668776974995,\n",
       "  1821916800.0,\n",
       "  -1.2974304231239917,\n",
       "  -1.0642958376645397,\n",
       "  -0.19041150708531496,\n",
       "  1.4699696128054789],\n",
       " [-0.5334026203728525,\n",
       "  -1.2493814606647942,\n",
       "  1.05213042476269,\n",
       "  0.6910991684148786,\n",
       "  -1.297543669956226,\n",
       "  -1.0657622696375693,\n",
       "  -0.1878603703889573,\n",
       "  1.4742672769192837,\n",
       "  1822003200.0,\n",
       "  0.4854726477186006,\n",
       "  -0.7050476184158362,\n",
       "  0.11322372233859501,\n",
       "  -0.6286162073501599]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[num_col_names] = scaler.transform(x_test[num_col_names])\n",
    "x_test = x_test.values.tolist()\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471101f5-8c1e-4cca-9c2f-03422c3be5a3",
   "metadata": {},
   "source": [
    "### Variáveis de entrada mais importantes para as tomadas de decisão do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e69cad-b5c7-45d3-9374-252e50b9b44c",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f9cb1f5-9e9b-42c1-8b33-ddeeebb86066",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'classifier':\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # Realizando Random Forest para identificar a relevância das variáveis.\n",
    "    # Feature Extraction by Random Forest\n",
    "    model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                           criterion='gini', max_depth=None, max_features=3, # nao sei o que eh este max_features\n",
    "                           max_leaf_nodes=None, max_samples=None,\n",
    "                           min_impurity_decrease=0.0,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=10,\n",
    "                           n_jobs=None, oob_score=False, random_state=None,\n",
    "                           verbose=0, warm_start=False)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    feature_importances_val = model.feature_importances_\n",
    "    pd.options.display.float_format = '{:.10f}'.format\n",
    "    \n",
    "    x_pd = pd.DataFrame(x_train, columns=col_names_order[:-1])\n",
    "    feature_importances = pd.DataFrame(feature_importances_val,\n",
    "                                       index = x_pd.columns,\n",
    "                                       columns=['importance']).sort_values('importance', ascending = False)\n",
    "    print(f'Accuracy: {model.score(x_test, y_test) * 100}')\n",
    "    print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e73007-2f3d-4a6e-925e-08f49f3ac156",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34b57b03-3f6d-475d-8003-e1baa11ac100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 6.53416319048907\n",
      "0-temperature_lag_2, Score: 0.068019450131539\n",
      "1-atmospheric_pressure_lag_2, Score: 0.0\n",
      "2-humidity_lag_2, Score: 0.0\n",
      "3-wind_speed_lag_2, Score: 0.0\n",
      "4-temperature_lag_1, Score: 0.2961292685234597\n",
      "5-atmospheric_pressure_lag_1, Score: 0.0\n",
      "6-humidity_lag_1, Score: 0.0\n",
      "7-wind_speed_lag_1, Score: 0.0\n",
      "8-data, Score: 0.0\n",
      "9-temperature, Score: 0.5623503417027282\n",
      "10-atmospheric_pressure, Score: 0.0\n",
      "11-humidity, Score: 0.07350093964227312\n",
      "12-wind_speed, Score: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    model = DecisionTreeClassifier(max_depth=3)\n",
    "else:\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    model = DecisionTreeRegressor(max_depth=3)    \n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    print(f'Accuracy: {model.score(x_test, y_test) * 100}')\n",
    "    print(f'Confusion matrix: {confusion_matrix(model.predict(x_test), y_test)}')\n",
    "else:\n",
    "    print(f'MSE: {mean_squared_error(model.predict(x_test), y_test)}')\n",
    "\n",
    "importance = model.feature_importances_\n",
    "for idx, score in enumerate(importance):\n",
    "    print(f'{idx}-{df.keys()[idx]}, Score: {score}')\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7a775-07df-43ad-b57c-a90dae2dc6ef",
   "metadata": {},
   "source": [
    "## Treinar diversos estimators disponíveis no Sklearn\n",
    "https://scikit-learn.org/stable/supervised_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "174d9ef1-cf9f-495a-bc0f-14ad12fc7900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ARDRegression\n",
      "Appending AdaBoostRegressor\n",
      "Appending BaggingRegressor\n",
      "Appending BayesianRidge\n",
      "Appending CCA\n",
      "Appending DecisionTreeRegressor\n",
      "Appending DummyRegressor\n",
      "Appending ElasticNet\n",
      "Appending ElasticNetCV\n",
      "Appending ExtraTreeRegressor\n",
      "Appending ExtraTreesRegressor\n",
      "Appending GammaRegressor\n",
      "Appending GaussianProcessRegressor\n",
      "Appending GradientBoostingRegressor\n",
      "Appending HistGradientBoostingRegressor\n",
      "Appending HuberRegressor\n",
      "Appending IsotonicRegression\n",
      "Appending KNeighborsRegressor\n",
      "Appending KernelRidge\n",
      "Appending Lars\n",
      "Appending LarsCV\n",
      "Appending Lasso\n",
      "Appending LassoCV\n",
      "Appending LassoLars\n",
      "Appending LassoLarsCV\n",
      "Appending LassoLarsIC\n",
      "Appending LinearRegression\n",
      "Appending LinearSVR\n",
      "Appending MLPRegressor\n",
      "Appending MultiOutputRegressor\n",
      "MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultiTaskElasticNet\n",
      "Appending MultiTaskElasticNetCV\n",
      "Appending MultiTaskLasso\n",
      "Appending MultiTaskLassoCV\n",
      "Appending NuSVR\n",
      "Appending OrthogonalMatchingPursuit\n",
      "Appending OrthogonalMatchingPursuitCV\n",
      "Appending PLSCanonical\n",
      "Appending PLSRegression\n",
      "Appending PassiveAggressiveRegressor\n",
      "Appending PoissonRegressor\n",
      "Appending QuantileRegressor\n",
      "Appending RANSACRegressor\n",
      "Appending RadiusNeighborsRegressor\n",
      "Appending RandomForestRegressor\n",
      "Appending RegressorChain\n",
      "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending Ridge\n",
      "Appending RidgeCV\n",
      "Appending SGDRegressor\n",
      "Appending SVR\n",
      "Appending StackingRegressor\n",
      "StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending TheilSenRegressor\n",
      "Appending TransformedTargetRegressor\n",
      "Appending TweedieRegressor\n",
      "Appending VotingRegressor\n",
      "VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# classifier, regressor, cluster, transformer\n",
    "estimators = all_estimators(type_filter=model_type)\n",
    "\n",
    "all_estimators = {}\n",
    "for name, estimator in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        est = estimator()\n",
    "        all_estimators[name] = est\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a626346-eda4-4754-be86-e8dbaddb3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_sklearn_estimators(estimators, x_train, y_train, x_test, y_test, model_type='classifier'):\n",
    "    if model_type == 'classifier':\n",
    "        best_acc = ['', 0.0]  # [estimator_name, accuracy]\n",
    "    else:\n",
    "        best_acc = ['', 99999.0]  # [estimator_name, error]\n",
    "    \n",
    "    for estimator_name, estimator in estimators.items():\n",
    "        try:\n",
    "            print(f'##### {estimator_name} #####')\n",
    "\n",
    "            estimator.fit(x_train, y_train)\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                print('Train ACC: %.3f%%' % (estimator.score(x_train, y_train) * 100.00))\n",
    "            else:\n",
    "                train_mse = mean_squared_error(estimator.predict(x_train), y_train)\n",
    "                print('Train MSE: %.3f' % (train_mse))\n",
    "                print(f'Train inference error (RMSE): ±{math.sqrt(train_mse)}')\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                test_acc = estimator.score(x_test, y_test) * 100.00\n",
    "                print('Test ACC: %.3f%%' % (test_acc))\n",
    "            else:\n",
    "                test_mse = mean_squared_error(estimator.predict(x_test), y_test)\n",
    "                print('Test MSE: %.3f' % (test_mse))\n",
    "                print(f'Test inference error (RMSE): ±{math.sqrt(test_mse)}')\n",
    "            print()\n",
    "    \n",
    "            if model_type == 'classifier' and test_acc > best_acc[1]:\n",
    "                best_acc = [estimator_name, test_acc]\n",
    "            elif model_type == 'regressor' and test_mse < best_acc[1]:\n",
    "                best_acc = [estimator_name, test_mse, math.sqrt(test_mse)]\n",
    "            \n",
    "            # Confusion Matrix\n",
    "            if model_type == 'classifier':\n",
    "                preds = estimator.predict(x_test)\n",
    "                matrix = confusion_matrix(y_test, preds)\n",
    "                print('Confusion Matrix Test:')\n",
    "                print(matrix)\n",
    "        except Exception as e:\n",
    "            print(f'Error ({estimator_name}): {e}')\n",
    "\n",
    "    print('########## Best Estimator ##########')\n",
    "    print(best_acc)\n",
    "    \n",
    "    return estimators, best_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c94079be-a30a-4a7b-97f4-7785c869ac03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ARDRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.072580611137334e-11\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±8.774720143308365e-11\n",
      "\n",
      "##### AdaBoostRegressor #####\n",
      "Train MSE: 1.502\n",
      "Train inference error (RMSE): ±1.2254829481739766\n",
      "Test MSE: 2.419\n",
      "Test inference error (RMSE): ±1.555308469371337\n",
      "\n",
      "##### BaggingRegressor #####\n",
      "Train MSE: 0.372\n",
      "Train inference error (RMSE): ±0.6095728205590261\n",
      "Test MSE: 2.054\n",
      "Test inference error (RMSE): ±1.4331813918421108\n",
      "\n",
      "##### BayesianRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.790525644301764e-10\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.673700966354142e-10\n",
      "\n",
      "##### CCA #####\n",
      "Error (CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0\n",
      "Test MSE: 4.322\n",
      "Test inference error (RMSE): ±2.07903134279667\n",
      "\n",
      "##### DummyRegressor #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.7453180260261307\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.898799515318269\n",
      "\n",
      "##### ElasticNet #####\n",
      "Train MSE: 4.060\n",
      "Train inference error (RMSE): ±2.014886950913734\n",
      "Test MSE: 4.476\n",
      "Test inference error (RMSE): ±2.115733525243542\n",
      "\n",
      "##### ElasticNetCV #####\n",
      "Train MSE: 14.009\n",
      "Train inference error (RMSE): ±3.7429130273370284\n",
      "Test MSE: 15.111\n",
      "Test inference error (RMSE): ±3.8872957525617258\n",
      "\n",
      "##### ExtraTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0\n",
      "Test MSE: 5.250\n",
      "Test inference error (RMSE): ±2.291351882792953\n",
      "\n",
      "##### ExtraTreesRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.3005909983581762e-14\n",
      "Test MSE: 1.241\n",
      "Test inference error (RMSE): ±1.113818826869484\n",
      "\n",
      "##### GammaRegressor #####\n",
      "Error (GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GaussianProcessRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.404613952999983e-10\n",
      "Test MSE: 84.527\n",
      "Test inference error (RMSE): ±9.193841514361852\n",
      "\n",
      "##### GradientBoostingRegressor #####\n",
      "Train MSE: 0.084\n",
      "Train inference error (RMSE): ±0.2901163125235125\n",
      "Test MSE: 0.742\n",
      "Test inference error (RMSE): ±0.861331721083657\n",
      "\n",
      "##### HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.011\n",
      "Train inference error (RMSE): ±0.10554554597633008\n",
      "Test MSE: 0.740\n",
      "Test inference error (RMSE): ±0.8603571755756513\n",
      "\n",
      "##### HuberRegressor #####\n",
      "Train MSE: 14.062\n",
      "Train inference error (RMSE): ±3.7499135372809276\n",
      "Test MSE: 15.444\n",
      "Test inference error (RMSE): ±3.92989095818202\n",
      "\n",
      "##### IsotonicRegression #####\n",
      "Error (IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### KNeighborsRegressor #####\n",
      "Train MSE: 4.918\n",
      "Train inference error (RMSE): ±2.2175633047839343\n",
      "Test MSE: 44.130\n",
      "Test inference error (RMSE): ±6.643035135354657\n",
      "\n",
      "##### KernelRidge #####\n",
      "Train MSE: 14.070\n",
      "Train inference error (RMSE): ±3.7510217521040343\n",
      "Test MSE: 15.235\n",
      "Test inference error (RMSE): ±3.9032284330347493\n",
      "\n",
      "##### Lars #####\n",
      "Train MSE: 0.013\n",
      "Train inference error (RMSE): ±0.11387743924071621\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.1178570631624669\n",
      "\n",
      "##### LarsCV #####\n",
      "Train MSE: 0.007\n",
      "Train inference error (RMSE): ±0.08649265631003616\n",
      "Test MSE: 0.007\n",
      "Test inference error (RMSE): ±0.0809049505460137\n",
      "\n",
      "##### Lasso #####\n",
      "Train MSE: 5.050\n",
      "Train inference error (RMSE): ±2.2471451564341955\n",
      "Test MSE: 5.687\n",
      "Test inference error (RMSE): ±2.384822666835201\n",
      "\n",
      "##### LassoCV #####\n",
      "Train MSE: 14.009\n",
      "Train inference error (RMSE): ±3.742913027336689\n",
      "Test MSE: 15.111\n",
      "Test inference error (RMSE): ±3.887295752562066\n",
      "\n",
      "##### LassoLars #####\n",
      "Train MSE: 5.050\n",
      "Train inference error (RMSE): ±2.247145157283197\n",
      "Test MSE: 5.687\n",
      "Test inference error (RMSE): ±2.3848226677925135\n",
      "\n",
      "##### LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.2398851208098796e-09\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.2831041710454804e-09\n",
      "\n",
      "##### LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.2398851208098796e-09\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.2831041710454804e-09\n",
      "\n",
      "##### LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.928307916180862e-09\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.847236513292127e-09\n",
      "\n",
      "##### LinearSVR #####\n",
      "Train MSE: 88.447\n",
      "Train inference error (RMSE): ±9.404613250745852\n",
      "Test MSE: 84.527\n",
      "Test inference error (RMSE): ±9.193841514361852\n",
      "\n",
      "##### MLPRegressor #####\n",
      "Train MSE: 226569.908\n",
      "Train inference error (RMSE): ±475.9936011880365\n",
      "Test MSE: 237271.228\n",
      "Test inference error (RMSE): ±487.1049453597567\n",
      "\n",
      "##### MultiTaskElasticNet #####\n",
      "Train MSE: 4.060\n",
      "Train inference error (RMSE): ±2.014886950913734\n",
      "Test MSE: 4.476\n",
      "Test inference error (RMSE): ±2.1157335252435416\n",
      "\n",
      "##### MultiTaskElasticNetCV #####\n",
      "Train MSE: 14.009\n",
      "Train inference error (RMSE): ±3.742913027337029\n",
      "Test MSE: 15.111\n",
      "Test inference error (RMSE): ±3.8872957525617258\n",
      "\n",
      "##### MultiTaskLasso #####\n",
      "Train MSE: 5.050\n",
      "Train inference error (RMSE): ±2.247145156434196\n",
      "Test MSE: 5.687\n",
      "Test inference error (RMSE): ±2.384822666835201\n",
      "\n",
      "##### MultiTaskLassoCV #####\n",
      "Train MSE: 14.009\n",
      "Train inference error (RMSE): ±3.742913027336689\n",
      "Test MSE: 15.111\n",
      "Test inference error (RMSE): ±3.887295752562066\n",
      "\n",
      "##### NuSVR #####\n",
      "Train MSE: 14.033\n",
      "Train inference error (RMSE): ±3.7460471084280162\n",
      "Test MSE: 15.155\n",
      "Test inference error (RMSE): ±3.8928976060149516\n",
      "\n",
      "##### OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.009\n",
      "Train inference error (RMSE): ±3.742888726537074\n",
      "Test MSE: 15.113\n",
      "Test inference error (RMSE): ±3.8874920827499415\n",
      "\n",
      "##### OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.217\n",
      "Train inference error (RMSE): ±1.1033972947936723\n",
      "Test MSE: 1.168\n",
      "Test inference error (RMSE): ±1.0807360714840926\n",
      "\n",
      "##### PLSCanonical #####\n",
      "Error (PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.041104031184708546\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04439808597093407\n",
      "\n",
      "##### PassiveAggressiveRegressor #####\n",
      "Train MSE: 18.273\n",
      "Train inference error (RMSE): ±4.274744120665815\n",
      "Test MSE: 21.913\n",
      "Test inference error (RMSE): ±4.681138240866231\n",
      "\n",
      "##### PoissonRegressor #####\n",
      "Error (PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### QuantileRegressor #####\n",
      "Train MSE: 14.018\n",
      "Train inference error (RMSE): ±3.744128722043436\n",
      "Test MSE: 15.164\n",
      "Test inference error (RMSE): ±3.8941005645733076\n",
      "\n",
      "##### RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.928307916180862e-09\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.847236513292127e-09\n",
      "\n",
      "##### RadiusNeighborsRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0\n",
      "Error (RadiusNeighborsRegressor): Input contains NaN.\n",
      "##### RandomForestRegressor #####\n",
      "Train MSE: 0.201\n",
      "Train inference error (RMSE): ±0.44847453329387027\n",
      "Test MSE: 1.685\n",
      "Test inference error (RMSE): ±1.2979918106467834\n",
      "\n",
      "##### Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0050478238369161\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0053048672660935305\n",
      "\n",
      "##### RidgeCV #####\n",
      "Train MSE: 2517633.702\n",
      "Train inference error (RMSE): ±1586.7052976772652\n",
      "Test MSE: 15886266.059\n",
      "Test inference error (RMSE): ±3985.7579026503226\n",
      "\n",
      "##### SGDRegressor #####\n",
      "Train MSE: 4109714624255354866791483771158031283870408980450770944.000\n",
      "Train inference error (RMSE): ±2.0272431093125844e+27\n",
      "Test MSE: 4312057722939532291913361738500641327423981790745853952.000\n",
      "Test inference error (RMSE): ±2.076549475196662e+27\n",
      "\n",
      "##### SVR #####\n",
      "Train MSE: 14.029\n",
      "Train inference error (RMSE): ±3.7455382111436752\n",
      "Test MSE: 15.227\n",
      "Test inference error (RMSE): ±3.902163501190881\n",
      "\n",
      "##### TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.544784155535048e-08\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.490143477250552e-08\n",
      "\n",
      "##### TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.928307916180862e-09\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.847236513292127e-09\n",
      "\n",
      "##### TweedieRegressor #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.745317790750327\n",
      "Test MSE: 15.200\n",
      "Test inference error (RMSE): ±3.898696718848026\n",
      "\n",
      "########## Best Estimator ##########\n",
      "['ARDRegression', 7.699571359338156e-21, 8.774720143308365e-11]\n",
      "Total time: 1.9753854274749756\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimators_trained, best_estimator_name = run_sklearn_estimators(\n",
    "    all_estimators,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    model_type\n",
    ")\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fda6aea5-fd41-49f6-b7da-a5ef7d849c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ARDRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ARDRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.ARDRegression.html\">?<span>Documentation for ARDRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ARDRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "ARDRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_trained[best_estimator_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9bb95-4f93-497e-a7bd-fe9ce5e291d8",
   "metadata": {},
   "source": [
    "### Save Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f2b4f21-99f9-42af-89c1-dd2a21e11b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(estimators_trained[best_estimator_name], open('results/estimator_sklearn.sav', 'wb'))\n",
    "\n",
    "# Scaler\n",
    "pickle.dump(scaler, open('results/scaler.pkl','wb'))\n",
    "\n",
    "# Save columns names and informations\n",
    "data_to_save = {\n",
    "    'col_names_order': col_names_order,\n",
    "    'num_col_names': num_col_names,\n",
    "    'cat_col_names': cat_col_names,\n",
    "    'date_col_names': date_col_names,\n",
    "    'target_cols': target_cols,\n",
    "    'category_mappings': category_mappings,\n",
    "    'window_size': window_size\n",
    "}\n",
    "with open('results/columns_metadata_sklearn.json', 'w') as json_file:\n",
    "    json.dump(data_to_save, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70756f5f-6703-4179-91f9-9a2ee059e073",
   "metadata": {},
   "source": [
    "## Stacking estimators\n",
    "Classificador: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier\n",
    "\n",
    "Regressor: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37139066-befd-458e-919e-9e21bffceed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ARDRegression\n",
      "Appending AdaBoostRegressor\n",
      "Appending BaggingRegressor\n",
      "Appending BayesianRidge\n",
      "Appending CCA\n",
      "Appending DecisionTreeRegressor\n",
      "Appending DummyRegressor\n",
      "Appending ElasticNet\n",
      "Appending ElasticNetCV\n",
      "Appending ExtraTreeRegressor\n",
      "Appending ExtraTreesRegressor\n",
      "Appending GammaRegressor\n",
      "Appending GaussianProcessRegressor\n",
      "Appending GradientBoostingRegressor\n",
      "Appending HistGradientBoostingRegressor\n",
      "Appending HuberRegressor\n",
      "Appending IsotonicRegression\n",
      "Appending KNeighborsRegressor\n",
      "Appending KernelRidge\n",
      "Appending Lars\n",
      "Appending LarsCV\n",
      "Appending Lasso\n",
      "Appending LassoCV\n",
      "Appending LassoLars\n",
      "Appending LassoLarsCV\n",
      "Appending LassoLarsIC\n",
      "Appending LinearRegression\n",
      "Appending LinearSVR\n",
      "Appending MLPRegressor\n",
      "Appending MultiOutputRegressor\n",
      "MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultiTaskElasticNet\n",
      "Appending MultiTaskElasticNetCV\n",
      "Appending MultiTaskLasso\n",
      "Appending MultiTaskLassoCV\n",
      "Appending NuSVR\n",
      "Appending OrthogonalMatchingPursuit\n",
      "Appending OrthogonalMatchingPursuitCV\n",
      "Appending PLSCanonical\n",
      "Appending PLSRegression\n",
      "Appending PassiveAggressiveRegressor\n",
      "Appending PoissonRegressor\n",
      "Appending QuantileRegressor\n",
      "Appending RANSACRegressor\n",
      "Appending RadiusNeighborsRegressor\n",
      "Appending RandomForestRegressor\n",
      "Appending RegressorChain\n",
      "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending Ridge\n",
      "Appending RidgeCV\n",
      "Appending SGDRegressor\n",
      "Appending SVR\n",
      "Appending StackingRegressor\n",
      "StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending TheilSenRegressor\n",
      "Appending TransformedTargetRegressor\n",
      "Appending TweedieRegressor\n",
      "Appending VotingRegressor\n",
      "VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# classifier, regressor, cluster, transformer\n",
    "estimators = all_estimators(type_filter=model_type)\n",
    "\n",
    "all_estimators = {}\n",
    "for name, estimator in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        est = estimator()\n",
    "        all_estimators[name] = est\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "837e27c3-4b1c-4ba2-94a1-d1040bad2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_sklearn_estimators_with_stacking(estimators, x_train, y_train, x_test, y_test, model_type):\n",
    "    if model_type == 'classifier':\n",
    "        best_acc = ['', 0.0]  # [estimator_name, accuracy]\n",
    "    else:\n",
    "        best_acc = ['', 99999.0]  # [estimator_name, error]\n",
    "    estimators_stacked_trained = {}\n",
    "    \n",
    "    idx = 0\n",
    "    for estimator_name, estimator in estimators.items():\n",
    "        count = 0\n",
    "        for estimator_name2, estimator2 in estimators.items():\n",
    "            if count <= idx:\n",
    "                count += 1\n",
    "                continue\n",
    "            try:\n",
    "                print(f'##### {estimator_name} - {estimator_name2} #####')\n",
    "\n",
    "                if model_type == 'classifier':\n",
    "                    stack = StackingClassifier([(estimator_name, copy.deepcopy(estimator)), (estimator_name2, copy.deepcopy(estimator2))],\n",
    "                                              final_estimator=LogisticRegression())\n",
    "                else:\n",
    "                    stack = StackingRegressor([(estimator_name, copy.deepcopy(estimator)), (estimator_name2, copy.deepcopy(estimator2))],\n",
    "                                              final_estimator=RidgeCV())\n",
    "\n",
    "                stack.fit(x_train, y_train)\n",
    "                \n",
    "                if model_type == 'classifier':\n",
    "                    print('Train ACC: %.3f%%' % (stack.score(x_train, y_train) * 100.00))\n",
    "                else:\n",
    "                    train_mse = mean_squared_error(stack.predict(x_train), y_train)\n",
    "                    print('Train MSE: %.3f' % (train_mse))\n",
    "                    print(f'Train inference error (RMSE): ±{math.sqrt(train_mse)}')\n",
    "                \n",
    "                if model_type == 'classifier':\n",
    "                    test_acc = stack.score(x_test, y_test) * 100.00\n",
    "                    print('Test ACC: %.3f%%' % (test_acc))\n",
    "                else:\n",
    "                    test_mse = mean_squared_error(stack.predict(x_test), y_test)\n",
    "                    print('Test MSE: %.3f' % (test_mse))\n",
    "                    print(f'Test inference error (RMSE): ±{math.sqrt(test_mse)}')\n",
    "        \n",
    "                if model_type == 'classifier' and test_acc > best_acc[1]:\n",
    "                    best_acc = [f'{estimator_name}-{estimator_name2}', test_acc]\n",
    "                elif model_type == 'regressor' and test_mse < best_acc[1]:\n",
    "                    best_acc = [f'{estimator_name}-{estimator_name2}', test_mse, math.sqrt(test_mse)]\n",
    "                \n",
    "                # Confusion Matrix\n",
    "                if model_type == 'classifier':\n",
    "                    preds = stack.predict(x_test)\n",
    "                    matrix = confusion_matrix(y_test, preds)\n",
    "                    print('Confusion Matrix Test:')\n",
    "                    print(matrix)\n",
    "\n",
    "                estimators_stacked_trained[f'{estimator_name}-{estimator_name2}'] = copy.deepcopy(stack)\n",
    "            except Exception as e:\n",
    "                print(f'Error ({estimator_name}-{estimator_name2}): {e}')\n",
    "                continue\n",
    "        \n",
    "        idx += 1\n",
    "\n",
    "    print('########## Best Estimator ##########')\n",
    "    print(best_acc)\n",
    "    \n",
    "    return estimators_stacked_trained, best_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f4d5044-760a-421c-9eee-908ad2d38951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ARDRegression - AdaBoostRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007145519267246555\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007544558790018069\n",
      "##### ARDRegression - BaggingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007064339964963458\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007362467467989793\n",
      "##### ARDRegression - BayesianRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0002190099344806881\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00023259554974214614\n",
      "##### ARDRegression - CCA #####\n",
      "Error (ARDRegression-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ARDRegression - DecisionTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.006251765352825974\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0077398571086248515\n",
      "##### ARDRegression - DummyRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007063322546256342\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007504319364668732\n",
      "##### ARDRegression - ElasticNet #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.006937788226566293\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007540458384274423\n",
      "##### ARDRegression - ElasticNetCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007195272156603715\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.006002576145729988\n",
      "##### ARDRegression - ExtraTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0060049247763177506\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.008913102106998404\n",
      "##### ARDRegression - ExtraTreesRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.005626685068662814\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0073321764338693035\n",
      "##### ARDRegression - GammaRegressor #####\n",
      "Error (ARDRegression-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ARDRegression - GaussianProcessRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.006893296961355974\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007320912801046569\n",
      "##### ARDRegression - GradientBoostingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00664618027604044\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007309204789683841\n",
      "##### ARDRegression - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.006121029177387935\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007428966996257565\n",
      "##### ARDRegression - HuberRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007228545668586691\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.009756268547834119\n",
      "##### ARDRegression - IsotonicRegression #####\n",
      "Error (ARDRegression-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ARDRegression - KNeighborsRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007132486123404889\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.005905249318872136\n",
      "##### ARDRegression - KernelRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007967503573660585\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.006739657722022342\n",
      "##### ARDRegression - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.016194942632071496\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.016401793785049405\n",
      "##### ARDRegression - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.018490884408169074\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.018840725300983026\n",
      "##### ARDRegression - Lasso #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0070071423336485585\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007623144602153108\n",
      "##### ARDRegression - LassoCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00719527216053274\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.006002576150368427\n",
      "##### ARDRegression - LassoLars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007007141944646145\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007623144152977291\n",
      "##### ARDRegression - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00021901032500191268\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00023259627290399016\n",
      "##### ARDRegression - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00021901032500191268\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00023259627290399016\n",
      "##### ARDRegression - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0002190097664934277\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0002325986629722905\n",
      "##### ARDRegression - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.006893296961355974\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007320912801046569\n",
      "##### ARDRegression - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007465557597323404\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007908084397506464\n",
      "##### ARDRegression - MultiTaskElasticNet #####\n",
      "Error (ARDRegression-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ARDRegression - MultiTaskElasticNetCV #####\n",
      "Error (ARDRegression-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ARDRegression - MultiTaskLasso #####\n",
      "Error (ARDRegression-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ARDRegression - MultiTaskLassoCV #####\n",
      "Error (ARDRegression-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ARDRegression - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007060938291467508\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007355106944435602\n",
      "##### ARDRegression - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007176538365692963\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.006647502429550925\n",
      "##### ARDRegression - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.006984083999938083\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007462486389739446\n",
      "##### ARDRegression - PLSCanonical #####\n",
      "Error (ARDRegression-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ARDRegression - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.02187133560478876\n",
      "Test MSE: 0.001\n",
      "Test inference error (RMSE): ±0.024362784619727403\n",
      "##### ARDRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.005969651642226045\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00645209994591363\n",
      "##### ARDRegression - PoissonRegressor #####\n",
      "Error (ARDRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ARDRegression - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007163460844592756\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.006558239395351314\n",
      "##### ARDRegression - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0002190097664934277\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0002325986629722905\n",
      "##### ARDRegression - RadiusNeighborsRegressor #####\n",
      "Error (ARDRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ARDRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.006325286676820661\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007350171739679027\n",
      "##### ARDRegression - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0013383805157290614\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0014196650355404008\n",
      "##### ARDRegression - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0083030576362656\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00925193433731514\n",
      "##### ARDRegression - SGDRegressor #####\n",
      "Train MSE: 173944593835722656252175058077607919041227424160087250567958590577906927483798683648.000\n",
      "Train inference error (RMSE): ±4.170666539484099e+41\n",
      "Test MSE: 180902152317122382581057213229124325610429956130154743523501960142437853947857207296.000\n",
      "Test inference error (RMSE): ±4.253259365676191e+41\n",
      "##### ARDRegression - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.006708580688683611\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.006745445244788655\n",
      "##### ARDRegression - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00021896990353098642\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00023255518211360313\n",
      "##### ARDRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0002190097664934277\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0002325986629722905\n",
      "##### ARDRegression - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.007063291668086371\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.007503453898071188\n",
      "##### AdaBoostRegressor - BaggingRegressor #####\n",
      "Train MSE: 0.652\n",
      "Train inference error (RMSE): ±0.8073219300389042\n",
      "Test MSE: 1.848\n",
      "Test inference error (RMSE): ±1.3593727576359036\n",
      "##### AdaBoostRegressor - BayesianRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.138974360198254e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012104972376387758\n",
      "##### AdaBoostRegressor - CCA #####\n",
      "Error (AdaBoostRegressor-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### AdaBoostRegressor - DecisionTreeRegressor #####\n",
      "Train MSE: 0.878\n",
      "Train inference error (RMSE): ±0.9369066801589662\n",
      "Test MSE: 1.841\n",
      "Test inference error (RMSE): ±1.3567171410736272\n",
      "##### AdaBoostRegressor - DummyRegressor #####\n",
      "Train MSE: 1.166\n",
      "Train inference error (RMSE): ±1.0797314042755244\n",
      "Test MSE: 2.114\n",
      "Test inference error (RMSE): ±1.4538197364592922\n",
      "##### AdaBoostRegressor - ElasticNet #####\n",
      "Train MSE: 0.718\n",
      "Train inference error (RMSE): ±0.8473021683756292\n",
      "Test MSE: 0.846\n",
      "Test inference error (RMSE): ±0.919916051587506\n",
      "##### AdaBoostRegressor - ElasticNetCV #####\n",
      "Train MSE: 1.199\n",
      "Train inference error (RMSE): ±1.0949806419799257\n",
      "Test MSE: 2.124\n",
      "Test inference error (RMSE): ±1.4572332083119295\n",
      "##### AdaBoostRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.910\n",
      "Train inference error (RMSE): ±0.9539668871634842\n",
      "Test MSE: 2.061\n",
      "Test inference error (RMSE): ±1.4355080614684141\n",
      "##### AdaBoostRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.375\n",
      "Train inference error (RMSE): ±0.6125732903930767\n",
      "Test MSE: 0.988\n",
      "Test inference error (RMSE): ±0.9941057523849152\n",
      "##### AdaBoostRegressor - GammaRegressor #####\n",
      "Error (AdaBoostRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### AdaBoostRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 1.199\n",
      "Train inference error (RMSE): ±1.0949515498397369\n",
      "Test MSE: 2.184\n",
      "Test inference error (RMSE): ±1.4777239976842944\n",
      "##### AdaBoostRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.140\n",
      "Train inference error (RMSE): ±0.37372197036516164\n",
      "Test MSE: 0.605\n",
      "Test inference error (RMSE): ±0.7776941173404853\n",
      "##### AdaBoostRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.075\n",
      "Train inference error (RMSE): ±0.27316755031373885\n",
      "Test MSE: 0.642\n",
      "Test inference error (RMSE): ±0.801139229600236\n",
      "##### AdaBoostRegressor - HuberRegressor #####\n",
      "Train MSE: 1.126\n",
      "Train inference error (RMSE): ±1.0611247812870508\n",
      "Test MSE: 1.937\n",
      "Test inference error (RMSE): ±1.3916079860914823\n",
      "##### AdaBoostRegressor - IsotonicRegression #####\n",
      "Error (AdaBoostRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### AdaBoostRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.926\n",
      "Train inference error (RMSE): ±0.962039073957104\n",
      "Test MSE: 2.813\n",
      "Test inference error (RMSE): ±1.6771699249377274\n",
      "##### AdaBoostRegressor - KernelRidge #####\n",
      "Train MSE: 1.091\n",
      "Train inference error (RMSE): ±1.0444937158515721\n",
      "Test MSE: 2.032\n",
      "Test inference error (RMSE): ±1.4254206613370994\n",
      "##### AdaBoostRegressor - Lars #####\n",
      "Train MSE: 0.003\n",
      "Train inference error (RMSE): ±0.052577843795723014\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04713521611366525\n",
      "##### AdaBoostRegressor - LarsCV #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11752219700934548\n",
      "Test MSE: 0.015\n",
      "Test inference error (RMSE): ±0.12283934428576677\n",
      "##### AdaBoostRegressor - Lasso #####\n",
      "Train MSE: 1.253\n",
      "Train inference error (RMSE): ±1.1195723092564915\n",
      "Test MSE: 2.175\n",
      "Test inference error (RMSE): ±1.4748022869616575\n",
      "##### AdaBoostRegressor - LassoCV #####\n",
      "Train MSE: 1.094\n",
      "Train inference error (RMSE): ±1.0461487326748045\n",
      "Test MSE: 1.985\n",
      "Test inference error (RMSE): ±1.4088499454732188\n",
      "##### AdaBoostRegressor - LassoLars #####\n",
      "Train MSE: 1.251\n",
      "Train inference error (RMSE): ±1.118673116990812\n",
      "Test MSE: 2.095\n",
      "Test inference error (RMSE): ±1.4475648574266469\n",
      "##### AdaBoostRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.241656817855507e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001251298004499536\n",
      "##### AdaBoostRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.676656263194693e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011452781164459781\n",
      "##### AdaBoostRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.858458391827992e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001166755412329486\n",
      "##### AdaBoostRegressor - LinearSVR #####\n",
      "Train MSE: 1.163\n",
      "Train inference error (RMSE): ±1.0783692793876165\n",
      "Test MSE: 2.145\n",
      "Test inference error (RMSE): ±1.4644972230096975\n",
      "##### AdaBoostRegressor - MLPRegressor #####\n",
      "Train MSE: 1.240\n",
      "Train inference error (RMSE): ±1.1135823196218435\n",
      "Test MSE: 2.218\n",
      "Test inference error (RMSE): ±1.4892545812665208\n",
      "##### AdaBoostRegressor - MultiTaskElasticNet #####\n",
      "Error (AdaBoostRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### AdaBoostRegressor - MultiTaskElasticNetCV #####\n",
      "Error (AdaBoostRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### AdaBoostRegressor - MultiTaskLasso #####\n",
      "Error (AdaBoostRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### AdaBoostRegressor - MultiTaskLassoCV #####\n",
      "Error (AdaBoostRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### AdaBoostRegressor - NuSVR #####\n",
      "Train MSE: 1.092\n",
      "Train inference error (RMSE): ±1.0451262419990128\n",
      "Test MSE: 2.081\n",
      "Test inference error (RMSE): ±1.4425928199553721\n",
      "##### AdaBoostRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 1.195\n",
      "Train inference error (RMSE): ±1.0931652049397582\n",
      "Test MSE: 2.230\n",
      "Test inference error (RMSE): ±1.4934819516933107\n",
      "##### AdaBoostRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.980\n",
      "Train inference error (RMSE): ±0.9898082423020886\n",
      "Test MSE: 1.185\n",
      "Test inference error (RMSE): ±1.08861623455545\n",
      "##### AdaBoostRegressor - PLSCanonical #####\n",
      "Error (AdaBoostRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### AdaBoostRegressor - PLSRegression #####\n",
      "Train MSE: 0.001\n",
      "Train inference error (RMSE): ±0.03854919628605007\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.039201115286329954\n",
      "##### AdaBoostRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 1.074\n",
      "Train inference error (RMSE): ±1.036309086603368\n",
      "Test MSE: 2.006\n",
      "Test inference error (RMSE): ±1.4163833710665734\n",
      "##### AdaBoostRegressor - PoissonRegressor #####\n",
      "Error (AdaBoostRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### AdaBoostRegressor - QuantileRegressor #####\n",
      "Train MSE: 1.109\n",
      "Train inference error (RMSE): ±1.0529874846178484\n",
      "Test MSE: 2.024\n",
      "Test inference error (RMSE): ±1.4226209535994467\n",
      "##### AdaBoostRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.871781265286367e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001169199469249818\n",
      "##### AdaBoostRegressor - RadiusNeighborsRegressor #####\n",
      "Error (AdaBoostRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### AdaBoostRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.275\n",
      "Train inference error (RMSE): ±0.5243858984002882\n",
      "Test MSE: 1.459\n",
      "Test inference error (RMSE): ±1.2077053754514744\n",
      "##### AdaBoostRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015358786601525815\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016523351320548482\n",
      "##### AdaBoostRegressor - RidgeCV #####\n",
      "Train MSE: 1.155\n",
      "Train inference error (RMSE): ±1.074629793711064\n",
      "Test MSE: 2.118\n",
      "Test inference error (RMSE): ±1.455476880312411\n",
      "##### AdaBoostRegressor - SGDRegressor #####\n",
      "Train MSE: 1514652609226771233640692744005665559160940513392669676878371477677770116908546260992.000\n",
      "Train inference error (RMSE): ±1.2307122365633533e+42\n",
      "Test MSE: 1562815653814140229874210650006933852532000521540663176899090169438668194520600936448.000\n",
      "Test inference error (RMSE): ±1.2501262551495109e+42\n",
      "##### AdaBoostRegressor - SVR #####\n",
      "Train MSE: 1.188\n",
      "Train inference error (RMSE): ±1.090152479574576\n",
      "Test MSE: 2.200\n",
      "Test inference error (RMSE): ±1.48334600179957\n",
      "##### AdaBoostRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.958785567829018e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012146271176026291\n",
      "##### AdaBoostRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±9.242879371705721e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012175127896774319\n",
      "##### AdaBoostRegressor - TweedieRegressor #####\n",
      "Train MSE: 1.170\n",
      "Train inference error (RMSE): ±1.0814383671011032\n",
      "Test MSE: 2.096\n",
      "Test inference error (RMSE): ±1.447844675863407\n",
      "##### BaggingRegressor - BayesianRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.710607703288253e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011320706075072655\n",
      "##### BaggingRegressor - CCA #####\n",
      "Error (BaggingRegressor-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BaggingRegressor - DecisionTreeRegressor #####\n",
      "Train MSE: 0.323\n",
      "Train inference error (RMSE): ±0.5679173293460544\n",
      "Test MSE: 1.908\n",
      "Test inference error (RMSE): ±1.3813256130018763\n",
      "##### BaggingRegressor - DummyRegressor #####\n",
      "Train MSE: 0.359\n",
      "Train inference error (RMSE): ±0.5990548465287237\n",
      "Test MSE: 1.788\n",
      "Test inference error (RMSE): ±1.3372650030564\n",
      "##### BaggingRegressor - ElasticNet #####\n",
      "Train MSE: 0.641\n",
      "Train inference error (RMSE): ±0.8004105133618027\n",
      "Test MSE: 0.851\n",
      "Test inference error (RMSE): ±0.9224834439532704\n",
      "##### BaggingRegressor - ElasticNetCV #####\n",
      "Train MSE: 0.311\n",
      "Train inference error (RMSE): ±0.5572724388308503\n",
      "Test MSE: 1.880\n",
      "Test inference error (RMSE): ±1.3710838968960053\n",
      "##### BaggingRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.323\n",
      "Train inference error (RMSE): ±0.5686000938128855\n",
      "Test MSE: 1.724\n",
      "Test inference error (RMSE): ±1.3129352048019132\n",
      "##### BaggingRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.331\n",
      "Train inference error (RMSE): ±0.5756371304563983\n",
      "Test MSE: 1.000\n",
      "Test inference error (RMSE): ±0.9999541093690235\n",
      "##### BaggingRegressor - GammaRegressor #####\n",
      "Error (BaggingRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### BaggingRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.306\n",
      "Train inference error (RMSE): ±0.5529691516511094\n",
      "Test MSE: 1.979\n",
      "Test inference error (RMSE): ±1.4067029789902206\n",
      "##### BaggingRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.134\n",
      "Train inference error (RMSE): ±0.3660379535242647\n",
      "Test MSE: 0.620\n",
      "Test inference error (RMSE): ±0.7875908859899119\n",
      "##### BaggingRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.062\n",
      "Train inference error (RMSE): ±0.2486992743949613\n",
      "Test MSE: 0.653\n",
      "Test inference error (RMSE): ±0.8079455425624091\n",
      "##### BaggingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.316\n",
      "Train inference error (RMSE): ±0.5618875695316836\n",
      "Test MSE: 1.957\n",
      "Test inference error (RMSE): ±1.3988371863677538\n",
      "##### BaggingRegressor - IsotonicRegression #####\n",
      "Error (BaggingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### BaggingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.398\n",
      "Train inference error (RMSE): ±0.6308713744835207\n",
      "Test MSE: 2.687\n",
      "Test inference error (RMSE): ±1.6391466943565431\n",
      "##### BaggingRegressor - KernelRidge #####\n",
      "Train MSE: 0.405\n",
      "Train inference error (RMSE): ±0.6364412946537075\n",
      "Test MSE: 1.943\n",
      "Test inference error (RMSE): ±1.394003481143735\n",
      "##### BaggingRegressor - Lars #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.061456364420841694\n",
      "Test MSE: 0.003\n",
      "Test inference error (RMSE): ±0.053764065282470276\n",
      "##### BaggingRegressor - LarsCV #####\n",
      "Train MSE: 0.012\n",
      "Train inference error (RMSE): ±0.10938362632174468\n",
      "Test MSE: 0.015\n",
      "Test inference error (RMSE): ±0.12058544446493244\n",
      "##### BaggingRegressor - Lasso #####\n",
      "Train MSE: 0.539\n",
      "Train inference error (RMSE): ±0.7344219665491892\n",
      "Test MSE: 1.844\n",
      "Test inference error (RMSE): ±1.3578475908456702\n",
      "##### BaggingRegressor - LassoCV #####\n",
      "Train MSE: 0.383\n",
      "Train inference error (RMSE): ±0.6189138530677725\n",
      "Test MSE: 1.835\n",
      "Test inference error (RMSE): ±1.354771846727147\n",
      "##### BaggingRegressor - LassoLars #####\n",
      "Train MSE: 0.546\n",
      "Train inference error (RMSE): ±0.7391523257846477\n",
      "Test MSE: 1.863\n",
      "Test inference error (RMSE): ±1.3648552135957337\n",
      "##### BaggingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.119728506384576e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001224507327702864\n",
      "##### BaggingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.459995577372568e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.976576570828334e-05\n",
      "##### BaggingRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.454456898717388e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00010625889164287975\n",
      "##### BaggingRegressor - LinearSVR #####\n",
      "Train MSE: 0.323\n",
      "Train inference error (RMSE): ±0.5680544903464242\n",
      "Test MSE: 1.961\n",
      "Test inference error (RMSE): ±1.4002143107474219\n",
      "##### BaggingRegressor - MLPRegressor #####\n",
      "Train MSE: 0.359\n",
      "Train inference error (RMSE): ±0.5994116656833335\n",
      "Test MSE: 2.018\n",
      "Test inference error (RMSE): ±1.4204286814312939\n",
      "##### BaggingRegressor - MultiTaskElasticNet #####\n",
      "Error (BaggingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### BaggingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (BaggingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### BaggingRegressor - MultiTaskLasso #####\n",
      "Error (BaggingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### BaggingRegressor - MultiTaskLassoCV #####\n",
      "Error (BaggingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### BaggingRegressor - NuSVR #####\n",
      "Train MSE: 0.349\n",
      "Train inference error (RMSE): ±0.5905520033256382\n",
      "Test MSE: 2.170\n",
      "Test inference error (RMSE): ±1.4731317024595223\n",
      "##### BaggingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.292\n",
      "Train inference error (RMSE): ±0.5399076448957175\n",
      "Test MSE: 1.980\n",
      "Test inference error (RMSE): ±1.4071971296240602\n",
      "##### BaggingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.682\n",
      "Train inference error (RMSE): ±0.8259375491246317\n",
      "Test MSE: 1.105\n",
      "Test inference error (RMSE): ±1.0512681365956347\n",
      "##### BaggingRegressor - PLSCanonical #####\n",
      "Error (BaggingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BaggingRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.039957974791380274\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.041531925589688996\n",
      "##### BaggingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.349\n",
      "Train inference error (RMSE): ±0.5903906591666778\n",
      "Test MSE: 1.797\n",
      "Test inference error (RMSE): ±1.3406077156818939\n",
      "##### BaggingRegressor - PoissonRegressor #####\n",
      "Error (BaggingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### BaggingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.339\n",
      "Train inference error (RMSE): ±0.5818422601350284\n",
      "Test MSE: 1.687\n",
      "Test inference error (RMSE): ±1.298896622147297\n",
      "##### BaggingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.532289737024497e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00011485685888775256\n",
      "##### BaggingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (BaggingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### BaggingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.214\n",
      "Train inference error (RMSE): ±0.4621596273128973\n",
      "Test MSE: 1.540\n",
      "Test inference error (RMSE): ±1.2409883242973012\n",
      "##### BaggingRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015539388631198782\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001641767887288444\n",
      "##### BaggingRegressor - RidgeCV #####\n",
      "Train MSE: 0.346\n",
      "Train inference error (RMSE): ±0.5881155042115249\n",
      "Test MSE: 1.698\n",
      "Test inference error (RMSE): ±1.3031664541764438\n",
      "##### BaggingRegressor - SGDRegressor #####\n",
      "Train MSE: 53404814212242824144318365312454426575529875052213838874606005430594413633172668416.000\n",
      "Train inference error (RMSE): ±2.310948164979968e+41\n",
      "Test MSE: 55442162815958678006907003524951184174409452418612984714596990935869011233372897280.000\n",
      "Test inference error (RMSE): ±2.3546159520388603e+41\n",
      "##### BaggingRegressor - SVR #####\n",
      "Train MSE: 0.317\n",
      "Train inference error (RMSE): ±0.5629265066808483\n",
      "Test MSE: 1.704\n",
      "Test inference error (RMSE): ±1.3052453021438697\n",
      "##### BaggingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.321602914417216e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001079519438018783\n",
      "##### BaggingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.30331603959542e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00010414893803468924\n",
      "##### BaggingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.316\n",
      "Train inference error (RMSE): ±0.5619550787889058\n",
      "Test MSE: 1.905\n",
      "Test inference error (RMSE): ±1.380282872031332\n",
      "##### BayesianRidge - CCA #####\n",
      "Error (BayesianRidge-CCA): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BayesianRidge - DecisionTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.274025725700278e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.290989107437899e-05\n",
      "##### BayesianRidge - DummyRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842487815773734e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.999967421598065e-05\n",
      "##### BayesianRidge - ElasticNet #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00016146139593103108\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001770169860491673\n",
      "##### BayesianRidge - ElasticNetCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8441718827275515e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.043972613468282e-05\n",
      "##### BayesianRidge - ExtraTreeRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1108896711093978e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.294140996416053e-05\n",
      "##### BayesianRidge - ExtraTreesRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.331551951848727e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00014736834665209474\n",
      "##### BayesianRidge - GammaRegressor #####\n",
      "Error (BayesianRidge-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### BayesianRidge - GaussianProcessRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830636779067372e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.9876117419003715e-05\n",
      "##### BayesianRidge - GradientBoostingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.225635638425274e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017708617749245635\n",
      "##### BayesianRidge - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.036408689359403e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019346807825293682\n",
      "##### BayesianRidge - HuberRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.84408192528242e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.997030814957799e-05\n",
      "##### BayesianRidge - IsotonicRegression #####\n",
      "Error (BayesianRidge-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### BayesianRidge - KNeighborsRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.3876595370240026e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±8.483938031668788e-05\n",
      "##### BayesianRidge - KernelRidge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830648357461889e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987622666511437e-05\n",
      "##### BayesianRidge - Lars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007064303600522197\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006762047175267046\n",
      "##### BayesianRidge - LarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007090707636117743\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006988313634576072\n",
      "##### BayesianRidge - Lasso #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.96680418510528e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.61332873907915e-05\n",
      "##### BayesianRidge - LassoCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844171999699044e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.043972735848838e-05\n",
      "##### BayesianRidge - LassoLars #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966797007255583e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.613320109672514e-05\n",
      "##### BayesianRidge - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.915307443672147e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9937959174358973e-05\n",
      "##### BayesianRidge - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.915307443672147e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9937959174358973e-05\n",
      "##### BayesianRidge - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153473189887204e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850909435215e-05\n",
      "##### BayesianRidge - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830636779067372e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.9876117419003715e-05\n",
      "##### BayesianRidge - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830719767325269e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.985602885332839e-05\n",
      "##### BayesianRidge - MultiTaskElasticNet #####\n",
      "Error (BayesianRidge-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### BayesianRidge - MultiTaskElasticNetCV #####\n",
      "Error (BayesianRidge-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### BayesianRidge - MultiTaskLasso #####\n",
      "Error (BayesianRidge-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### BayesianRidge - MultiTaskLassoCV #####\n",
      "Error (BayesianRidge-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### BayesianRidge - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8407680091124015e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.0020084661107944e-05\n",
      "##### BayesianRidge - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8302053275448974e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.984887688863121e-05\n",
      "##### BayesianRidge - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0001277522083415336\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012515444707928195\n",
      "##### BayesianRidge - PLSCanonical #####\n",
      "Error (BayesianRidge-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### BayesianRidge - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014550240152547337\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015445410487028135\n",
      "##### BayesianRidge - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8347149143269346e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.9971253477612876e-05\n",
      "##### BayesianRidge - PoissonRegressor #####\n",
      "Error (BayesianRidge-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### BayesianRidge - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830826267192644e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.978729557993514e-05\n",
      "##### BayesianRidge - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153473189887204e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850909435215e-05\n",
      "##### BayesianRidge - RadiusNeighborsRegressor #####\n",
      "Error (BayesianRidge-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### BayesianRidge - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.724454830419747e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012849134953247984\n",
      "##### BayesianRidge - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007474552543888951\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0008174774084611513\n",
      "##### BayesianRidge - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.90430547163442e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.397718608249836e-05\n",
      "##### BayesianRidge - SGDRegressor #####\n",
      "Train MSE: 30087143560380383975426564376424358879325420443358256409765400138039830526598053888.000\n",
      "Train inference error (RMSE): ±1.7345646012870315e+41\n",
      "Test MSE: 30415793238925412183835602888781968399884809253408951774886845904016081958148767744.000\n",
      "Test inference error (RMSE): ±1.744012420796521e+41\n",
      "##### BayesianRidge - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8415397158198504e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.004092256451553e-05\n",
      "##### BayesianRidge - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.915224790555215e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9933766654226296e-05\n",
      "##### BayesianRidge - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153473189887204e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850909435215e-05\n",
      "##### BayesianRidge - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8424821384060665e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.9999662341499654e-05\n",
      "##### CCA - DecisionTreeRegressor #####\n",
      "Error (CCA-DecisionTreeRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - DummyRegressor #####\n",
      "Error (CCA-DummyRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ElasticNet #####\n",
      "Error (CCA-ElasticNet): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ElasticNetCV #####\n",
      "Error (CCA-ElasticNetCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ExtraTreeRegressor #####\n",
      "Error (CCA-ExtraTreeRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - ExtraTreesRegressor #####\n",
      "Error (CCA-ExtraTreesRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GammaRegressor #####\n",
      "Error (CCA-GammaRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GaussianProcessRegressor #####\n",
      "Error (CCA-GaussianProcessRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - GradientBoostingRegressor #####\n",
      "Error (CCA-GradientBoostingRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - HistGradientBoostingRegressor #####\n",
      "Error (CCA-HistGradientBoostingRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - HuberRegressor #####\n",
      "Error (CCA-HuberRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - IsotonicRegression #####\n",
      "Error (CCA-IsotonicRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - KNeighborsRegressor #####\n",
      "Error (CCA-KNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - KernelRidge #####\n",
      "Error (CCA-KernelRidge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Lars #####\n",
      "Error (CCA-Lars): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LarsCV #####\n",
      "Error (CCA-LarsCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Lasso #####\n",
      "Error (CCA-Lasso): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoCV #####\n",
      "Error (CCA-LassoCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLars #####\n",
      "Error (CCA-LassoLars): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLarsCV #####\n",
      "Error (CCA-LassoLarsCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LassoLarsIC #####\n",
      "Error (CCA-LassoLarsIC): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LinearRegression #####\n",
      "Error (CCA-LinearRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - LinearSVR #####\n",
      "Error (CCA-LinearSVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MLPRegressor #####\n",
      "Error (CCA-MLPRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskElasticNet #####\n",
      "Error (CCA-MultiTaskElasticNet): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskElasticNetCV #####\n",
      "Error (CCA-MultiTaskElasticNetCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskLasso #####\n",
      "Error (CCA-MultiTaskLasso): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - MultiTaskLassoCV #####\n",
      "Error (CCA-MultiTaskLassoCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - NuSVR #####\n",
      "Error (CCA-NuSVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - OrthogonalMatchingPursuit #####\n",
      "Error (CCA-OrthogonalMatchingPursuit): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - OrthogonalMatchingPursuitCV #####\n",
      "Error (CCA-OrthogonalMatchingPursuitCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PLSCanonical #####\n",
      "Error (CCA-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PLSRegression #####\n",
      "Error (CCA-PLSRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PassiveAggressiveRegressor #####\n",
      "Error (CCA-PassiveAggressiveRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - PoissonRegressor #####\n",
      "Error (CCA-PoissonRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - QuantileRegressor #####\n",
      "Error (CCA-QuantileRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RANSACRegressor #####\n",
      "Error (CCA-RANSACRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RadiusNeighborsRegressor #####\n",
      "Error (CCA-RadiusNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RandomForestRegressor #####\n",
      "Error (CCA-RandomForestRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - Ridge #####\n",
      "Error (CCA-Ridge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - RidgeCV #####\n",
      "Error (CCA-RidgeCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - SGDRegressor #####\n",
      "Error (CCA-SGDRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - SVR #####\n",
      "Error (CCA-SVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TheilSenRegressor #####\n",
      "Error (CCA-TheilSenRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TransformedTargetRegressor #####\n",
      "Error (CCA-TransformedTargetRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### CCA - TweedieRegressor #####\n",
      "Error (CCA-TweedieRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor - DummyRegressor #####\n",
      "Train MSE: 0.391\n",
      "Train inference error (RMSE): ±0.6253965839512442\n",
      "Test MSE: 3.995\n",
      "Test inference error (RMSE): ±1.9988722834432757\n",
      "##### DecisionTreeRegressor - ElasticNet #####\n",
      "Train MSE: 0.659\n",
      "Train inference error (RMSE): ±0.8120695426753571\n",
      "Test MSE: 0.845\n",
      "Test inference error (RMSE): ±0.9190033921887326\n",
      "##### DecisionTreeRegressor - ElasticNetCV #####\n",
      "Train MSE: 0.379\n",
      "Train inference error (RMSE): ±0.6154697757299563\n",
      "Test MSE: 4.118\n",
      "Test inference error (RMSE): ±2.029405778089194\n",
      "##### DecisionTreeRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.046\n",
      "Train inference error (RMSE): ±0.21396579446832226\n",
      "Test MSE: 2.947\n",
      "Test inference error (RMSE): ±1.716689188058508\n",
      "##### DecisionTreeRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.301\n",
      "Train inference error (RMSE): ±0.5487880394680827\n",
      "Test MSE: 1.019\n",
      "Test inference error (RMSE): ±1.0096269511717946\n",
      "##### DecisionTreeRegressor - GammaRegressor #####\n",
      "Error (DecisionTreeRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### DecisionTreeRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.325\n",
      "Train inference error (RMSE): ±0.5699846901075337\n",
      "Test MSE: 4.104\n",
      "Test inference error (RMSE): ±2.0257495093131963\n",
      "##### DecisionTreeRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.141\n",
      "Train inference error (RMSE): ±0.3760239912913709\n",
      "Test MSE: 0.644\n",
      "Test inference error (RMSE): ±0.8024709943214934\n",
      "##### DecisionTreeRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.061\n",
      "Train inference error (RMSE): ±0.24740525174324232\n",
      "Test MSE: 0.678\n",
      "Test inference error (RMSE): ±0.8234901610756213\n",
      "##### DecisionTreeRegressor - HuberRegressor #####\n",
      "Train MSE: 0.327\n",
      "Train inference error (RMSE): ±0.5715320657815229\n",
      "Test MSE: 4.156\n",
      "Test inference error (RMSE): ±2.0386901235524255\n",
      "##### DecisionTreeRegressor - IsotonicRegression #####\n",
      "Error (DecisionTreeRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### DecisionTreeRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.325\n",
      "Train inference error (RMSE): ±0.5702381630385562\n",
      "Test MSE: 7.340\n",
      "Test inference error (RMSE): ±2.709305961201212\n",
      "##### DecisionTreeRegressor - KernelRidge #####\n",
      "Train MSE: 0.345\n",
      "Train inference error (RMSE): ±0.5876766437312616\n",
      "Test MSE: 4.179\n",
      "Test inference error (RMSE): ±2.04434940676284\n",
      "##### DecisionTreeRegressor - Lars #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06526426609864117\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06204902465611281\n",
      "##### DecisionTreeRegressor - LarsCV #####\n",
      "Train MSE: 0.013\n",
      "Train inference error (RMSE): ±0.11269202601601168\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.11699538055877173\n",
      "##### DecisionTreeRegressor - Lasso #####\n",
      "Train MSE: 1.126\n",
      "Train inference error (RMSE): ±1.0612964367488267\n",
      "Test MSE: 2.316\n",
      "Test inference error (RMSE): ±1.5216865248205946\n",
      "##### DecisionTreeRegressor - LassoCV #####\n",
      "Train MSE: 0.359\n",
      "Train inference error (RMSE): ±0.5995005260473536\n",
      "Test MSE: 4.151\n",
      "Test inference error (RMSE): ±2.037467249293223\n",
      "##### DecisionTreeRegressor - LassoLars #####\n",
      "Train MSE: 1.175\n",
      "Train inference error (RMSE): ±1.0841330498465265\n",
      "Test MSE: 2.287\n",
      "Test inference error (RMSE): ±1.5123902172736579\n",
      "##### DecisionTreeRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.109569289566067e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.121415010662799e-05\n",
      "##### DecisionTreeRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.0812652224598972e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.23723226137662e-05\n",
      "##### DecisionTreeRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.992564796267962e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.580939855187353e-05\n",
      "##### DecisionTreeRegressor - LinearSVR #####\n",
      "Train MSE: 0.397\n",
      "Train inference error (RMSE): ±0.6303516966296445\n",
      "Test MSE: 4.122\n",
      "Test inference error (RMSE): ±2.03035362652182\n",
      "##### DecisionTreeRegressor - MLPRegressor #####\n",
      "Train MSE: 0.355\n",
      "Train inference error (RMSE): ±0.596237664608\n",
      "Test MSE: 4.099\n",
      "Test inference error (RMSE): ±2.0245855687724483\n",
      "##### DecisionTreeRegressor - MultiTaskElasticNet #####\n",
      "Error (DecisionTreeRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### DecisionTreeRegressor - MultiTaskElasticNetCV #####\n",
      "Error (DecisionTreeRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### DecisionTreeRegressor - MultiTaskLasso #####\n",
      "Error (DecisionTreeRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### DecisionTreeRegressor - MultiTaskLassoCV #####\n",
      "Error (DecisionTreeRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### DecisionTreeRegressor - NuSVR #####\n",
      "Train MSE: 0.340\n",
      "Train inference error (RMSE): ±0.5829545606935367\n",
      "Test MSE: 4.226\n",
      "Test inference error (RMSE): ±2.0557912168592605\n",
      "##### DecisionTreeRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.385\n",
      "Train inference error (RMSE): ±0.6201842649972378\n",
      "Test MSE: 4.267\n",
      "Test inference error (RMSE): ±2.0655687633354294\n",
      "##### DecisionTreeRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.922\n",
      "Train inference error (RMSE): ±0.9604316725077245\n",
      "Test MSE: 1.122\n",
      "Test inference error (RMSE): ±1.059107335703577\n",
      "##### DecisionTreeRegressor - PLSCanonical #####\n",
      "Error (DecisionTreeRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DecisionTreeRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04106462988475854\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04381117273859591\n",
      "##### DecisionTreeRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.370\n",
      "Train inference error (RMSE): ±0.6078906143600132\n",
      "Test MSE: 4.222\n",
      "Test inference error (RMSE): ±2.054867370424609\n",
      "##### DecisionTreeRegressor - PoissonRegressor #####\n",
      "Error (DecisionTreeRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### DecisionTreeRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.369\n",
      "Train inference error (RMSE): ±0.6074522404239512\n",
      "Test MSE: 3.993\n",
      "Test inference error (RMSE): ±1.998197126188281\n",
      "##### DecisionTreeRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.249261565122427e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.115176576882985e-05\n",
      "##### DecisionTreeRegressor - RadiusNeighborsRegressor #####\n",
      "Error (DecisionTreeRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### DecisionTreeRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.226\n",
      "Train inference error (RMSE): ±0.47577897494687943\n",
      "Test MSE: 1.485\n",
      "Test inference error (RMSE): ±1.2187507982333594\n",
      "##### DecisionTreeRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015187474332126415\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001638175623901115\n",
      "##### DecisionTreeRegressor - RidgeCV #####\n",
      "Train MSE: 0.346\n",
      "Train inference error (RMSE): ±0.5884427570244423\n",
      "Test MSE: 4.178\n",
      "Test inference error (RMSE): ±2.044049725716363\n",
      "##### DecisionTreeRegressor - SGDRegressor #####\n",
      "Train MSE: 151222951818691383641847928556976625567270912578346830676528652716567338674028544.000\n",
      "Train inference error (RMSE): ±1.2297274162134118e+40\n",
      "Test MSE: 180058203128099740895586352712069352617242871103890232133834030239130394715750400.000\n",
      "Test inference error (RMSE): ±1.341857679219744e+40\n",
      "##### DecisionTreeRegressor - SVR #####\n",
      "Train MSE: 0.372\n",
      "Train inference error (RMSE): ±0.61018002901907\n",
      "Test MSE: 3.861\n",
      "Test inference error (RMSE): ±1.9650655941495654\n",
      "##### DecisionTreeRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.0873933478089926e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.045934036771692e-05\n",
      "##### DecisionTreeRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.15380584912846e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.209863248469123e-05\n",
      "##### DecisionTreeRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.377\n",
      "Train inference error (RMSE): ±0.6136604571572462\n",
      "Test MSE: 4.124\n",
      "Test inference error (RMSE): ±2.0306454188371563\n",
      "##### DummyRegressor - ElasticNet #####\n",
      "Train MSE: 0.711\n",
      "Train inference error (RMSE): ±0.8431333100279195\n",
      "Test MSE: 0.854\n",
      "Test inference error (RMSE): ±0.9243734276062076\n",
      "##### DummyRegressor - ElasticNetCV #####\n",
      "Train MSE: 14.045\n",
      "Train inference error (RMSE): ±3.747723697423858\n",
      "Test MSE: 15.306\n",
      "Test inference error (RMSE): ±3.9122900678813797\n",
      "##### DummyRegressor - ExtraTreeRegressor #####\n",
      "Train MSE: 0.493\n",
      "Train inference error (RMSE): ±0.7022611880182027\n",
      "Test MSE: 4.583\n",
      "Test inference error (RMSE): ±2.1407318580498114\n",
      "##### DummyRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.304\n",
      "Train inference error (RMSE): ±0.5510102776664678\n",
      "Test MSE: 1.005\n",
      "Test inference error (RMSE): ±1.0023849274029624\n",
      "##### DummyRegressor - GammaRegressor #####\n",
      "Error (DummyRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### DummyRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.745318029914043\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.8988124404302043\n",
      "##### DummyRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.134\n",
      "Train inference error (RMSE): ±0.3666782633676499\n",
      "Test MSE: 0.634\n",
      "Test inference error (RMSE): ±0.796140973070844\n",
      "##### DummyRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.25047869075615986\n",
      "Test MSE: 0.666\n",
      "Test inference error (RMSE): ±0.8159872877404128\n",
      "##### DummyRegressor - HuberRegressor #####\n",
      "Train MSE: 14.012\n",
      "Train inference error (RMSE): ±3.74330656309435\n",
      "Test MSE: 15.121\n",
      "Test inference error (RMSE): ±3.88861059825327\n",
      "##### DummyRegressor - IsotonicRegression #####\n",
      "Error (DummyRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### DummyRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 5.564\n",
      "Train inference error (RMSE): ±2.358864722634646\n",
      "Test MSE: 34.735\n",
      "Test inference error (RMSE): ±5.893682735392116\n",
      "##### DummyRegressor - KernelRidge #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.745277024576837\n",
      "Test MSE: 15.200\n",
      "Test inference error (RMSE): ±3.898719467550706\n",
      "##### DummyRegressor - Lars #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.06780660343586034\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06487810233609007\n",
      "##### DummyRegressor - LarsCV #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11928943188186496\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.11785838656203321\n",
      "##### DummyRegressor - Lasso #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.531110235569394\n",
      "Test MSE: 2.696\n",
      "Test inference error (RMSE): ±1.6420506236064414\n",
      "##### DummyRegressor - LassoCV #####\n",
      "Train MSE: 14.045\n",
      "Train inference error (RMSE): ±3.7477236974258945\n",
      "Test MSE: 15.306\n",
      "Test inference error (RMSE): ±3.9122900678927746\n",
      "##### DummyRegressor - LassoLars #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5311102366367595\n",
      "Test MSE: 2.696\n",
      "Test inference error (RMSE): ±1.6420506136672632\n",
      "##### DummyRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8426093590144655e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.00009968020613e-05\n",
      "##### DummyRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8426093590144655e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.00009968020613e-05\n",
      "##### DummyRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842514145325764e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000027564152745e-05\n",
      "##### DummyRegressor - LinearSVR #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.745318029914043\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.8988124404302043\n",
      "##### DummyRegressor - MLPRegressor #####\n",
      "Train MSE: 14.042\n",
      "Train inference error (RMSE): ±3.7472274504095573\n",
      "Test MSE: 15.287\n",
      "Test inference error (RMSE): ±3.9098545410067804\n",
      "##### DummyRegressor - MultiTaskElasticNet #####\n",
      "Error (DummyRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### DummyRegressor - MultiTaskElasticNetCV #####\n",
      "Error (DummyRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### DummyRegressor - MultiTaskLasso #####\n",
      "Error (DummyRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### DummyRegressor - MultiTaskLassoCV #####\n",
      "Error (DummyRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### DummyRegressor - NuSVR #####\n",
      "Train MSE: 14.028\n",
      "Train inference error (RMSE): ±3.745393400104479\n",
      "Test MSE: 15.205\n",
      "Test inference error (RMSE): ±3.8993464490547916\n",
      "##### DummyRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.013\n",
      "Train inference error (RMSE): ±3.743398031362705\n",
      "Test MSE: 15.124\n",
      "Test inference error (RMSE): ±3.888984680751151\n",
      "##### DummyRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1034049471145801\n",
      "Test MSE: 1.168\n",
      "Test inference error (RMSE): ±1.0807727560879667\n",
      "##### DummyRegressor - PLSCanonical #####\n",
      "Error (DummyRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### DummyRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04148519928242531\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04405077461892361\n",
      "##### DummyRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.028\n",
      "Train inference error (RMSE): ±3.745408113282515\n",
      "Test MSE: 15.215\n",
      "Test inference error (RMSE): ±3.9006686170967924\n",
      "##### DummyRegressor - PoissonRegressor #####\n",
      "Error (DummyRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### DummyRegressor - QuantileRegressor #####\n",
      "Train MSE: 14.009\n",
      "Train inference error (RMSE): ±3.742904583400116\n",
      "Test MSE: 15.114\n",
      "Test inference error (RMSE): ±3.887668705995486\n",
      "##### DummyRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842514145325764e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000027564152745e-05\n",
      "##### DummyRegressor - RadiusNeighborsRegressor #####\n",
      "Error (DummyRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### DummyRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.207\n",
      "Train inference error (RMSE): ±0.45493417157572813\n",
      "Test MSE: 1.433\n",
      "Test inference error (RMSE): ±1.1970443451900392\n",
      "##### DummyRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014959821125154313\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016367353685413709\n",
      "##### DummyRegressor - RidgeCV #####\n",
      "Train MSE: 14.437\n",
      "Train inference error (RMSE): ±3.79960297740948\n",
      "Test MSE: 17.716\n",
      "Test inference error (RMSE): ±4.209096195646329\n",
      "##### DummyRegressor - SGDRegressor #####\n",
      "Train MSE: 127601420166357093667577742398378000027411084003277765459805738379971820020587036672.000\n",
      "Train inference error (RMSE): ±3.57213409835573e+41\n",
      "Test MSE: 132541894050751174216651126284897229731267337897182631353175482901813983481784434688.000\n",
      "Test inference error (RMSE): ±3.640630358203798e+41\n",
      "##### DummyRegressor - SVR #####\n",
      "Train MSE: 14.029\n",
      "Train inference error (RMSE): ±3.7454773439298763\n",
      "Test MSE: 15.212\n",
      "Test inference error (RMSE): ±3.9002196360809176\n",
      "##### DummyRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842553958251983e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.0007947790734505e-05\n",
      "##### DummyRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842514145325764e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000027564152745e-05\n",
      "##### DummyRegressor - TweedieRegressor #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.745318781292894\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.8988177486034803\n",
      "##### ElasticNet - ElasticNetCV #####\n",
      "Train MSE: 0.695\n",
      "Train inference error (RMSE): ±0.8334617990175779\n",
      "Test MSE: 0.705\n",
      "Test inference error (RMSE): ±0.8394563472537097\n",
      "##### ElasticNet - ExtraTreeRegressor #####\n",
      "Train MSE: 0.646\n",
      "Train inference error (RMSE): ±0.8039124226128265\n",
      "Test MSE: 0.844\n",
      "Test inference error (RMSE): ±0.9186934080485791\n",
      "##### ElasticNet - ExtraTreesRegressor #####\n",
      "Train MSE: 0.368\n",
      "Train inference error (RMSE): ±0.6066584888405885\n",
      "Test MSE: 0.809\n",
      "Test inference error (RMSE): ±0.8992857565217869\n",
      "##### ElasticNet - GammaRegressor #####\n",
      "Error (ElasticNet-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ElasticNet - GaussianProcessRegressor #####\n",
      "Train MSE: 0.711\n",
      "Train inference error (RMSE): ±0.8431924666309122\n",
      "Test MSE: 0.855\n",
      "Test inference error (RMSE): ±0.9244265744062086\n",
      "##### ElasticNet - GradientBoostingRegressor #####\n",
      "Train MSE: 0.201\n",
      "Train inference error (RMSE): ±0.44869886474148446\n",
      "Test MSE: 0.564\n",
      "Test inference error (RMSE): ±0.751107038866446\n",
      "##### ElasticNet - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.134\n",
      "Train inference error (RMSE): ±0.3658364963710174\n",
      "Test MSE: 0.600\n",
      "Test inference error (RMSE): ±0.7746884497797417\n",
      "##### ElasticNet - HuberRegressor #####\n",
      "Train MSE: 0.697\n",
      "Train inference error (RMSE): ±0.8348164276018981\n",
      "Test MSE: 0.728\n",
      "Test inference error (RMSE): ±0.8533917574555315\n",
      "##### ElasticNet - IsotonicRegression #####\n",
      "Error (ElasticNet-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ElasticNet - KNeighborsRegressor #####\n",
      "Train MSE: 0.602\n",
      "Train inference error (RMSE): ±0.7759991571411714\n",
      "Test MSE: 0.742\n",
      "Test inference error (RMSE): ±0.8612667777844757\n",
      "##### ElasticNet - KernelRidge #####\n",
      "Train MSE: 0.710\n",
      "Train inference error (RMSE): ±0.8425394171870999\n",
      "Test MSE: 0.849\n",
      "Test inference error (RMSE): ±0.9212706267640673\n",
      "##### ElasticNet - Lars #####\n",
      "Train MSE: 0.001\n",
      "Train inference error (RMSE): ±0.0319274018693057\n",
      "Test MSE: 0.001\n",
      "Test inference error (RMSE): ±0.03323944494402697\n",
      "##### ElasticNet - LarsCV #####\n",
      "Train MSE: 0.016\n",
      "Train inference error (RMSE): ±0.12743012006292534\n",
      "Test MSE: 0.016\n",
      "Test inference error (RMSE): ±0.12730256742634163\n",
      "##### ElasticNet - Lasso #####\n",
      "Train MSE: 0.493\n",
      "Train inference error (RMSE): ±0.7021113500835825\n",
      "Test MSE: 0.594\n",
      "Test inference error (RMSE): ±0.7705811088976087\n",
      "##### ElasticNet - LassoCV #####\n",
      "Train MSE: 0.695\n",
      "Train inference error (RMSE): ±0.8334617990138888\n",
      "Test MSE: 0.705\n",
      "Test inference error (RMSE): ±0.8394563472119\n",
      "##### ElasticNet - LassoLars #####\n",
      "Train MSE: 0.493\n",
      "Train inference error (RMSE): ±0.7021113494360018\n",
      "Test MSE: 0.594\n",
      "Test inference error (RMSE): ±0.770581114460734\n",
      "##### ElasticNet - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00016146203089116996\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001770173612704421\n",
      "##### ElasticNet - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00016146203089116996\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001770173612704421\n",
      "##### ElasticNet - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00016146086807024876\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017701417908796353\n",
      "##### ElasticNet - LinearSVR #####\n",
      "Train MSE: 0.711\n",
      "Train inference error (RMSE): ±0.8431924666309122\n",
      "Test MSE: 0.855\n",
      "Test inference error (RMSE): ±0.9244265744062086\n",
      "##### ElasticNet - MLPRegressor #####\n",
      "Train MSE: 0.711\n",
      "Train inference error (RMSE): ±0.8433125286754274\n",
      "Test MSE: 0.866\n",
      "Test inference error (RMSE): ±0.9306127528765014\n",
      "##### ElasticNet - MultiTaskElasticNet #####\n",
      "Error (ElasticNet-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNet - MultiTaskElasticNetCV #####\n",
      "Error (ElasticNet-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ElasticNet - MultiTaskLasso #####\n",
      "Error (ElasticNet-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNet - MultiTaskLassoCV #####\n",
      "Error (ElasticNet-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ElasticNet - NuSVR #####\n",
      "Train MSE: 0.710\n",
      "Train inference error (RMSE): ±0.8426082679498429\n",
      "Test MSE: 0.845\n",
      "Test inference error (RMSE): ±0.919020555492356\n",
      "##### ElasticNet - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.692\n",
      "Train inference error (RMSE): ±0.8321401675448858\n",
      "Test MSE: 0.671\n",
      "Test inference error (RMSE): ±0.8190389941396485\n",
      "##### ElasticNet - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.709\n",
      "Train inference error (RMSE): ±0.8420583507062193\n",
      "Test MSE: 0.860\n",
      "Test inference error (RMSE): ±0.9274527913563143\n",
      "##### ElasticNet - PLSCanonical #####\n",
      "Error (ElasticNet-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ElasticNet - PLSRegression #####\n",
      "Train MSE: 0.001\n",
      "Train inference error (RMSE): ±0.03311691895849523\n",
      "Test MSE: 0.001\n",
      "Test inference error (RMSE): ±0.033715970860446205\n",
      "##### ElasticNet - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.711\n",
      "Train inference error (RMSE): ±0.8432178179022528\n",
      "Test MSE: 0.862\n",
      "Test inference error (RMSE): ±0.9283894506332702\n",
      "##### ElasticNet - PoissonRegressor #####\n",
      "Error (ElasticNet-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ElasticNet - QuantileRegressor #####\n",
      "Train MSE: 0.693\n",
      "Train inference error (RMSE): ±0.8323542805914216\n",
      "Test MSE: 0.655\n",
      "Test inference error (RMSE): ±0.8096067255634538\n",
      "##### ElasticNet - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00016146086807024876\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017701417908796353\n",
      "##### ElasticNet - RadiusNeighborsRegressor #####\n",
      "Error (ElasticNet-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ElasticNet - RandomForestRegressor #####\n",
      "Train MSE: 0.558\n",
      "Train inference error (RMSE): ±0.7470408929878766\n",
      "Test MSE: 0.851\n",
      "Test inference error (RMSE): ±0.9226261873585663\n",
      "##### ElasticNet - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015076476725853058\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016728548221111028\n",
      "##### ElasticNet - RidgeCV #####\n",
      "Train MSE: 0.786\n",
      "Train inference error (RMSE): ±0.8864377555973655\n",
      "Test MSE: 1.411\n",
      "Test inference error (RMSE): ±1.1878179458394222\n",
      "##### ElasticNet - SGDRegressor #####\n",
      "Train MSE: 1175420023143139655064497994268709691186997082787249775534017291452549461123339911168.000\n",
      "Train inference error (RMSE): ±1.084167894351765e+42\n",
      "Test MSE: 1181633922413407076774891564720355352555130650000863717342308618139673539630908571648.000\n",
      "Test inference error (RMSE): ±1.0870298627054397e+42\n",
      "##### ElasticNet - SVR #####\n",
      "Train MSE: 0.710\n",
      "Train inference error (RMSE): ±0.8424950226831115\n",
      "Test MSE: 0.839\n",
      "Test inference error (RMSE): ±0.9158946484047349\n",
      "##### ElasticNet - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00016146406582791798\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017700512652758503\n",
      "##### ElasticNet - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00016146086807024876\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017701417908796353\n",
      "##### ElasticNet - TweedieRegressor #####\n",
      "Train MSE: 0.711\n",
      "Train inference error (RMSE): ±0.8431320048975373\n",
      "Test MSE: 0.854\n",
      "Test inference error (RMSE): ±0.9243665934340363\n",
      "##### ElasticNetCV - ExtraTreeRegressor #####\n",
      "Train MSE: 0.348\n",
      "Train inference error (RMSE): ±0.5895685984585637\n",
      "Test MSE: 5.051\n",
      "Test inference error (RMSE): ±2.247478928807216\n",
      "##### ElasticNetCV - ExtraTreesRegressor #####\n",
      "Train MSE: 0.266\n",
      "Train inference error (RMSE): ±0.5160861270059621\n",
      "Test MSE: 0.987\n",
      "Test inference error (RMSE): ±0.9934809568708528\n",
      "##### ElasticNetCV - GammaRegressor #####\n",
      "Error (ElasticNetCV-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ElasticNetCV - GaussianProcessRegressor #####\n",
      "Train MSE: 14.049\n",
      "Train inference error (RMSE): ±3.7482128354396003\n",
      "Test MSE: 15.328\n",
      "Test inference error (RMSE): ±3.9150799781000125\n",
      "##### ElasticNetCV - GradientBoostingRegressor #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.3675371041256189\n",
      "Test MSE: 0.637\n",
      "Test inference error (RMSE): ±0.7981498578339253\n",
      "##### ElasticNetCV - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.2518229644519395\n",
      "Test MSE: 0.681\n",
      "Test inference error (RMSE): ±0.8253840783068319\n",
      "##### ElasticNetCV - HuberRegressor #####\n",
      "Train MSE: 14.022\n",
      "Train inference error (RMSE): ±3.7446491387172105\n",
      "Test MSE: 15.175\n",
      "Test inference error (RMSE): ±3.8954797520339457\n",
      "##### ElasticNetCV - IsotonicRegression #####\n",
      "Error (ElasticNetCV-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ElasticNetCV - KNeighborsRegressor #####\n",
      "Train MSE: 5.573\n",
      "Train inference error (RMSE): ±2.3606377462804726\n",
      "Test MSE: 36.646\n",
      "Test inference error (RMSE): ±6.053622139988864\n",
      "##### ElasticNetCV - KernelRidge #####\n",
      "Train MSE: 14.049\n",
      "Train inference error (RMSE): ±3.7482107700223035\n",
      "Test MSE: 15.328\n",
      "Test inference error (RMSE): ±3.9150742176285824\n",
      "##### ElasticNetCV - Lars #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.0677985004908562\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06480781953788976\n",
      "##### ElasticNetCV - LarsCV #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11691189608423987\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.11488516100759236\n",
      "##### ElasticNetCV - Lasso #####\n",
      "Train MSE: 2.329\n",
      "Train inference error (RMSE): ±1.5260559183540674\n",
      "Test MSE: 2.472\n",
      "Test inference error (RMSE): ±1.5721694175275553\n",
      "##### ElasticNetCV - LassoCV #####\n",
      "Train MSE: 14.061\n",
      "Train inference error (RMSE): ±3.7497461191680572\n",
      "Test MSE: 15.397\n",
      "Test inference error (RMSE): ±3.9239024139739564\n",
      "##### ElasticNetCV - LassoLars #####\n",
      "Train MSE: 2.329\n",
      "Train inference error (RMSE): ±1.5260559174851043\n",
      "Test MSE: 2.472\n",
      "Test inference error (RMSE): ±1.5721694429826096\n",
      "##### ElasticNetCV - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844300712112576e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.0441139400477647e-05\n",
      "##### ElasticNetCV - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844300712112576e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.0441139400477647e-05\n",
      "##### ElasticNetCV - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844194387381574e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.044063506055164e-05\n",
      "##### ElasticNetCV - LinearSVR #####\n",
      "Train MSE: 14.049\n",
      "Train inference error (RMSE): ±3.7482128354396003\n",
      "Test MSE: 15.328\n",
      "Test inference error (RMSE): ±3.9150799781000125\n",
      "##### ElasticNetCV - MLPRegressor #####\n",
      "Train MSE: 14.063\n",
      "Train inference error (RMSE): ±3.7500284599815017\n",
      "Test MSE: 15.407\n",
      "Test inference error (RMSE): ±3.9251929077212226\n",
      "##### ElasticNetCV - MultiTaskElasticNet #####\n",
      "Error (ElasticNetCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNetCV - MultiTaskElasticNetCV #####\n",
      "Error (ElasticNetCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ElasticNetCV - MultiTaskLasso #####\n",
      "Error (ElasticNetCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ElasticNetCV - MultiTaskLassoCV #####\n",
      "Error (ElasticNetCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ElasticNetCV - NuSVR #####\n",
      "Train MSE: 14.047\n",
      "Train inference error (RMSE): ±3.7479407684911594\n",
      "Test MSE: 15.317\n",
      "Test inference error (RMSE): ±3.9137123745111353\n",
      "##### ElasticNetCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.041\n",
      "Train inference error (RMSE): ±3.7471900314658972\n",
      "Test MSE: 15.283\n",
      "Test inference error (RMSE): ±3.909384777707164\n",
      "##### ElasticNetCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.225\n",
      "Train inference error (RMSE): ±1.1066839558624464\n",
      "Test MSE: 1.271\n",
      "Test inference error (RMSE): ±1.127377688987917\n",
      "##### ElasticNetCV - PLSCanonical #####\n",
      "Error (ElasticNetCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ElasticNetCV - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.046114256004095196\n",
      "Test MSE: 0.005\n",
      "Test inference error (RMSE): ±0.0671817329408196\n",
      "##### ElasticNetCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.047\n",
      "Train inference error (RMSE): ±3.7479637584456227\n",
      "Test MSE: 15.335\n",
      "Test inference error (RMSE): ±3.9160488379523084\n",
      "##### ElasticNetCV - PoissonRegressor #####\n",
      "Error (ElasticNetCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ElasticNetCV - QuantileRegressor #####\n",
      "Train MSE: 14.024\n",
      "Train inference error (RMSE): ±3.744869906252524\n",
      "Test MSE: 15.180\n",
      "Test inference error (RMSE): ±3.896189225469201\n",
      "##### ElasticNetCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844194387381574e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.044063506055164e-05\n",
      "##### ElasticNetCV - RadiusNeighborsRegressor #####\n",
      "Error (ElasticNetCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ElasticNetCV - RandomForestRegressor #####\n",
      "Train MSE: 0.202\n",
      "Train inference error (RMSE): ±0.4498826817973876\n",
      "Test MSE: 1.537\n",
      "Test inference error (RMSE): ±1.2398305209111624\n",
      "##### ElasticNetCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014772261632055215\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015005077572140054\n",
      "##### ElasticNetCV - RidgeCV #####\n",
      "Train MSE: 14.847\n",
      "Train inference error (RMSE): ±3.853159735588481\n",
      "Test MSE: 20.276\n",
      "Test inference error (RMSE): ±4.502935557598763\n",
      "##### ElasticNetCV - SGDRegressor #####\n",
      "Train MSE: 3025670105445340638224828684895225887280319776272661645738719298729489874288640.000\n",
      "Train inference error (RMSE): ±1.7394453441960573e+39\n",
      "Test MSE: 3274332695589330997035663952890099236237485369562365201985967527625017499058176.000\n",
      "Test inference error (RMSE): ±1.8095117285028387e+39\n",
      "##### ElasticNetCV - SVR #####\n",
      "Train MSE: 14.045\n",
      "Train inference error (RMSE): ±3.7476245252900715\n",
      "Test MSE: 15.307\n",
      "Test inference error (RMSE): ±3.9124718589636696\n",
      "##### ElasticNetCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8441162377680685e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.043975701166057e-05\n",
      "##### ElasticNetCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844194387381574e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.044063506055164e-05\n",
      "##### ElasticNetCV - TweedieRegressor #####\n",
      "Train MSE: 14.045\n",
      "Train inference error (RMSE): ±3.7477259828917395\n",
      "Test MSE: 15.306\n",
      "Test inference error (RMSE): ±3.912302372639105\n",
      "##### ExtraTreeRegressor - ExtraTreesRegressor #####\n",
      "Train MSE: 0.273\n",
      "Train inference error (RMSE): ±0.5222884419822955\n",
      "Test MSE: 1.003\n",
      "Test inference error (RMSE): ±1.0014787642212326\n",
      "##### ExtraTreeRegressor - GammaRegressor #####\n",
      "Error (ExtraTreeRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ExtraTreeRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.404\n",
      "Train inference error (RMSE): ±0.6359660756657094\n",
      "Test MSE: 4.590\n",
      "Test inference error (RMSE): ±2.1424474832887004\n",
      "##### ExtraTreeRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.137\n",
      "Train inference error (RMSE): ±0.36961967711423827\n",
      "Test MSE: 0.631\n",
      "Test inference error (RMSE): ±0.7944885922700193\n",
      "##### ExtraTreeRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.062\n",
      "Train inference error (RMSE): ±0.2479975816426049\n",
      "Test MSE: 0.662\n",
      "Test inference error (RMSE): ±0.8136286427216338\n",
      "##### ExtraTreeRegressor - HuberRegressor #####\n",
      "Train MSE: 0.503\n",
      "Train inference error (RMSE): ±0.7090549122728083\n",
      "Test MSE: 4.803\n",
      "Test inference error (RMSE): ±2.1916492101517004\n",
      "##### ExtraTreeRegressor - IsotonicRegression #####\n",
      "Error (ExtraTreeRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ExtraTreeRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.457\n",
      "Train inference error (RMSE): ±0.6761190146668451\n",
      "Test MSE: 10.296\n",
      "Test inference error (RMSE): ±3.208706234350332\n",
      "##### ExtraTreeRegressor - KernelRidge #####\n",
      "Train MSE: 0.445\n",
      "Train inference error (RMSE): ±0.6667416033206506\n",
      "Test MSE: 4.905\n",
      "Test inference error (RMSE): ±2.2146424117613757\n",
      "##### ExtraTreeRegressor - Lars #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06540931126986298\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06089298896098834\n",
      "##### ExtraTreeRegressor - LarsCV #####\n",
      "Train MSE: 0.013\n",
      "Train inference error (RMSE): ±0.11323219751918868\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.11572667126932797\n",
      "##### ExtraTreeRegressor - Lasso #####\n",
      "Train MSE: 1.292\n",
      "Train inference error (RMSE): ±1.1366827999143676\n",
      "Test MSE: 2.325\n",
      "Test inference error (RMSE): ±1.5249573598374855\n",
      "##### ExtraTreeRegressor - LassoCV #####\n",
      "Train MSE: 0.561\n",
      "Train inference error (RMSE): ±0.748957732432145\n",
      "Test MSE: 4.402\n",
      "Test inference error (RMSE): ±2.0979965786212484\n",
      "##### ExtraTreeRegressor - LassoLars #####\n",
      "Train MSE: 1.438\n",
      "Train inference error (RMSE): ±1.198974026406515\n",
      "Test MSE: 2.316\n",
      "Test inference error (RMSE): ±1.5219628768945745\n",
      "##### ExtraTreeRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.0915121120988804e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.508761080617456e-05\n",
      "##### ExtraTreeRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.8514516978876157e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±7.054777433666324e-05\n",
      "##### ExtraTreeRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9839562466844196e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.556594508597014e-05\n",
      "##### ExtraTreeRegressor - LinearSVR #####\n",
      "Train MSE: 0.489\n",
      "Train inference error (RMSE): ±0.6994793012241807\n",
      "Test MSE: 4.870\n",
      "Test inference error (RMSE): ±2.2067599406512604\n",
      "##### ExtraTreeRegressor - MLPRegressor #####\n",
      "Train MSE: 0.527\n",
      "Train inference error (RMSE): ±0.7260945812546646\n",
      "Test MSE: 5.202\n",
      "Test inference error (RMSE): ±2.28081742380101\n",
      "##### ExtraTreeRegressor - MultiTaskElasticNet #####\n",
      "Error (ExtraTreeRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreeRegressor - MultiTaskElasticNetCV #####\n",
      "Error (ExtraTreeRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ExtraTreeRegressor - MultiTaskLasso #####\n",
      "Error (ExtraTreeRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreeRegressor - MultiTaskLassoCV #####\n",
      "Error (ExtraTreeRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ExtraTreeRegressor - NuSVR #####\n",
      "Train MSE: 0.471\n",
      "Train inference error (RMSE): ±0.6863832584385137\n",
      "Test MSE: 4.788\n",
      "Test inference error (RMSE): ±2.1881562850199674\n",
      "##### ExtraTreeRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.329\n",
      "Train inference error (RMSE): ±0.5739224804216847\n",
      "Test MSE: 4.782\n",
      "Test inference error (RMSE): ±2.1868443571318052\n",
      "##### ExtraTreeRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.003\n",
      "Train inference error (RMSE): ±1.001321915393347\n",
      "Test MSE: 1.113\n",
      "Test inference error (RMSE): ±1.0548543451089318\n",
      "##### ExtraTreeRegressor - PLSCanonical #####\n",
      "Error (ExtraTreeRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ExtraTreeRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04108738312763466\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04285528983911778\n",
      "##### ExtraTreeRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.514\n",
      "Train inference error (RMSE): ±0.7172017166742297\n",
      "Test MSE: 3.567\n",
      "Test inference error (RMSE): ±1.8885744788064156\n",
      "##### ExtraTreeRegressor - PoissonRegressor #####\n",
      "Error (ExtraTreeRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ExtraTreeRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.495\n",
      "Train inference error (RMSE): ±0.703374574591401\n",
      "Test MSE: 4.478\n",
      "Test inference error (RMSE): ±2.1160558592784606\n",
      "##### ExtraTreeRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.8678153479431455e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.0205911473000907e-05\n",
      "##### ExtraTreeRegressor - RadiusNeighborsRegressor #####\n",
      "Error (ExtraTreeRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ExtraTreeRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.201\n",
      "Train inference error (RMSE): ±0.44840912170467623\n",
      "Test MSE: 1.468\n",
      "Test inference error (RMSE): ±1.2117084980439654\n",
      "##### ExtraTreeRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001525397739988117\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016522829369760312\n",
      "##### ExtraTreeRegressor - RidgeCV #####\n",
      "Train MSE: 0.520\n",
      "Train inference error (RMSE): ±0.7212946156975034\n",
      "Test MSE: 4.048\n",
      "Test inference error (RMSE): ±2.0120433681113195\n",
      "##### ExtraTreeRegressor - SGDRegressor #####\n",
      "Train MSE: 10618842610322400323211168432494982856202503214238976281272207569307198172430336.000\n",
      "Train inference error (RMSE): ±3.25865656526158e+39\n",
      "Test MSE: 11034904056831157318453978007886411262951081634404824847006439895942570214162432.000\n",
      "Test inference error (RMSE): ±3.321882607322414e+39\n",
      "##### ExtraTreeRegressor - SVR #####\n",
      "Train MSE: 0.321\n",
      "Train inference error (RMSE): ±0.566916850606369\n",
      "Test MSE: 4.490\n",
      "Test inference error (RMSE): ±2.1188491121131587\n",
      "##### ExtraTreeRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.1218957672153112e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±6.952040961102148e-05\n",
      "##### ExtraTreeRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±2.082447593994484e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±5.886651976644801e-05\n",
      "##### ExtraTreeRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.503\n",
      "Train inference error (RMSE): ±0.7090858395262586\n",
      "Test MSE: 4.859\n",
      "Test inference error (RMSE): ±2.2042252238065956\n",
      "##### ExtraTreesRegressor - GammaRegressor #####\n",
      "Error (ExtraTreesRegressor-GammaRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### ExtraTreesRegressor - GaussianProcessRegressor #####\n",
      "Train MSE: 0.315\n",
      "Train inference error (RMSE): ±0.5615193623384872\n",
      "Test MSE: 1.003\n",
      "Test inference error (RMSE): ±1.0012803560045604\n",
      "##### ExtraTreesRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.153\n",
      "Train inference error (RMSE): ±0.39177422763856895\n",
      "Test MSE: 0.639\n",
      "Test inference error (RMSE): ±0.7994103291184872\n",
      "##### ExtraTreesRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.094\n",
      "Train inference error (RMSE): ±0.306874623465165\n",
      "Test MSE: 0.660\n",
      "Test inference error (RMSE): ±0.8126483291501785\n",
      "##### ExtraTreesRegressor - HuberRegressor #####\n",
      "Train MSE: 0.307\n",
      "Train inference error (RMSE): ±0.5539980608292181\n",
      "Test MSE: 1.047\n",
      "Test inference error (RMSE): ±1.0232506661551308\n",
      "##### ExtraTreesRegressor - IsotonicRegression #####\n",
      "Error (ExtraTreesRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### ExtraTreesRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.477\n",
      "Train inference error (RMSE): ±0.6910019075022056\n",
      "Test MSE: 1.365\n",
      "Test inference error (RMSE): ±1.168434090426295\n",
      "##### ExtraTreesRegressor - KernelRidge #####\n",
      "Train MSE: 0.283\n",
      "Train inference error (RMSE): ±0.5318607360476539\n",
      "Test MSE: 0.999\n",
      "Test inference error (RMSE): ±0.9993720474585341\n",
      "##### ExtraTreesRegressor - Lars #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.06804712408824042\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04485623637482853\n",
      "##### ExtraTreesRegressor - LarsCV #####\n",
      "Train MSE: 0.010\n",
      "Train inference error (RMSE): ±0.09757291973802655\n",
      "Test MSE: 0.015\n",
      "Test inference error (RMSE): ±0.12148695482331329\n",
      "##### ExtraTreesRegressor - Lasso #####\n",
      "Train MSE: 0.520\n",
      "Train inference error (RMSE): ±0.7208315356969744\n",
      "Test MSE: 0.882\n",
      "Test inference error (RMSE): ±0.9390135969326605\n",
      "##### ExtraTreesRegressor - LassoCV #####\n",
      "Train MSE: 0.297\n",
      "Train inference error (RMSE): ±0.5449886542660712\n",
      "Test MSE: 1.022\n",
      "Test inference error (RMSE): ±1.011030546649674\n",
      "##### ExtraTreesRegressor - LassoLars #####\n",
      "Train MSE: 0.581\n",
      "Train inference error (RMSE): ±0.7622291954365684\n",
      "Test MSE: 0.946\n",
      "Test inference error (RMSE): ±0.9728504141814486\n",
      "##### ExtraTreesRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±7.802365062150067e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001484185755327238\n",
      "##### ExtraTreesRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.328670744664338e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001518693687813754\n",
      "##### ExtraTreesRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.172784220627886e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001519492881719183\n",
      "##### ExtraTreesRegressor - LinearSVR #####\n",
      "Train MSE: 0.323\n",
      "Train inference error (RMSE): ±0.5678957340780607\n",
      "Test MSE: 0.991\n",
      "Test inference error (RMSE): ±0.9953711461566255\n",
      "##### ExtraTreesRegressor - MLPRegressor #####\n",
      "Train MSE: 2963323.502\n",
      "Train inference error (RMSE): ±1721.430655660083\n",
      "Test MSE: 3109650.274\n",
      "Test inference error (RMSE): ±1763.420050371387\n",
      "##### ExtraTreesRegressor - MultiTaskElasticNet #####\n",
      "Error (ExtraTreesRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreesRegressor - MultiTaskElasticNetCV #####\n",
      "Error (ExtraTreesRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### ExtraTreesRegressor - MultiTaskLasso #####\n",
      "Error (ExtraTreesRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### ExtraTreesRegressor - MultiTaskLassoCV #####\n",
      "Error (ExtraTreesRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### ExtraTreesRegressor - NuSVR #####\n",
      "Train MSE: 0.310\n",
      "Train inference error (RMSE): ±0.5566069011625855\n",
      "Test MSE: 0.977\n",
      "Test inference error (RMSE): ±0.9882648112985716\n",
      "##### ExtraTreesRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.278\n",
      "Train inference error (RMSE): ±0.5267963090886437\n",
      "Test MSE: 0.986\n",
      "Test inference error (RMSE): ±0.9932212340336101\n",
      "##### ExtraTreesRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.220\n",
      "Train inference error (RMSE): ±0.4689776285190233\n",
      "Test MSE: 0.895\n",
      "Test inference error (RMSE): ±0.9458863670841916\n",
      "##### ExtraTreesRegressor - PLSCanonical #####\n",
      "Error (ExtraTreesRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### ExtraTreesRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04190686450620816\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.03928493628419148\n",
      "##### ExtraTreesRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.317\n",
      "Train inference error (RMSE): ±0.5632287236544296\n",
      "Test MSE: 1.026\n",
      "Test inference error (RMSE): ±1.0126751000107692\n",
      "##### ExtraTreesRegressor - PoissonRegressor #####\n",
      "Error (ExtraTreesRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### ExtraTreesRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.290\n",
      "Train inference error (RMSE): ±0.5380873027330999\n",
      "Test MSE: 1.005\n",
      "Test inference error (RMSE): ±1.0026796968287472\n",
      "##### ExtraTreesRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.424398991577006e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00015209850028824218\n",
      "##### ExtraTreesRegressor - RadiusNeighborsRegressor #####\n",
      "Error (ExtraTreesRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### ExtraTreesRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.309\n",
      "Train inference error (RMSE): ±0.5555626616734989\n",
      "Test MSE: 0.992\n",
      "Test inference error (RMSE): ±0.9960313942611848\n",
      "##### ExtraTreesRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016604798498331941\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016442785607364274\n",
      "##### ExtraTreesRegressor - RidgeCV #####\n",
      "Train MSE: 0.292\n",
      "Train inference error (RMSE): ±0.5400023932382505\n",
      "Test MSE: 1.038\n",
      "Test inference error (RMSE): ±1.0187669519008595\n",
      "##### ExtraTreesRegressor - SGDRegressor #####\n",
      "Train MSE: 19416578331379844271081180933126782076810530347211435054983141811786906840596480.000\n",
      "Train inference error (RMSE): ±4.4064246653471615e+39\n",
      "Test MSE: 19795883755741333223173358762064384791192590336979853160895339477912674499559424.000\n",
      "Test inference error (RMSE): ±4.4492565396638274e+39\n",
      "##### ExtraTreesRegressor - SVR #####\n",
      "Train MSE: 0.288\n",
      "Train inference error (RMSE): ±0.536490948490626\n",
      "Test MSE: 1.011\n",
      "Test inference error (RMSE): ±1.005349490878498\n",
      "##### ExtraTreesRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.59646006168938e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001517089203584076\n",
      "##### ExtraTreesRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.047210420254641e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.000146006763690709\n",
      "##### ExtraTreesRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.282\n",
      "Train inference error (RMSE): ±0.5311130707739994\n",
      "Test MSE: 0.967\n",
      "Test inference error (RMSE): ±0.9832760528696827\n",
      "##### GammaRegressor - GaussianProcessRegressor #####\n",
      "Error (GammaRegressor-GaussianProcessRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - GradientBoostingRegressor #####\n",
      "Error (GammaRegressor-GradientBoostingRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - HistGradientBoostingRegressor #####\n",
      "Error (GammaRegressor-HistGradientBoostingRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - HuberRegressor #####\n",
      "Error (GammaRegressor-HuberRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - IsotonicRegression #####\n",
      "Error (GammaRegressor-IsotonicRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - KNeighborsRegressor #####\n",
      "Error (GammaRegressor-KNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - KernelRidge #####\n",
      "Error (GammaRegressor-KernelRidge): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Lars #####\n",
      "Error (GammaRegressor-Lars): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LarsCV #####\n",
      "Error (GammaRegressor-LarsCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Lasso #####\n",
      "Error (GammaRegressor-Lasso): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoCV #####\n",
      "Error (GammaRegressor-LassoCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLars #####\n",
      "Error (GammaRegressor-LassoLars): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLarsCV #####\n",
      "Error (GammaRegressor-LassoLarsCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LassoLarsIC #####\n",
      "Error (GammaRegressor-LassoLarsIC): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LinearRegression #####\n",
      "Error (GammaRegressor-LinearRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - LinearSVR #####\n",
      "Error (GammaRegressor-LinearSVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MLPRegressor #####\n",
      "Error (GammaRegressor-MLPRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskElasticNet #####\n",
      "Error (GammaRegressor-MultiTaskElasticNet): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GammaRegressor-MultiTaskElasticNetCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskLasso #####\n",
      "Error (GammaRegressor-MultiTaskLasso): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - MultiTaskLassoCV #####\n",
      "Error (GammaRegressor-MultiTaskLassoCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - NuSVR #####\n",
      "Error (GammaRegressor-NuSVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - OrthogonalMatchingPursuit #####\n",
      "Error (GammaRegressor-OrthogonalMatchingPursuit): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Error (GammaRegressor-OrthogonalMatchingPursuitCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PLSCanonical #####\n",
      "Error (GammaRegressor-PLSCanonical): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PLSRegression #####\n",
      "Error (GammaRegressor-PLSRegression): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PassiveAggressiveRegressor #####\n",
      "Error (GammaRegressor-PassiveAggressiveRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - PoissonRegressor #####\n",
      "Error (GammaRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - QuantileRegressor #####\n",
      "Error (GammaRegressor-QuantileRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RANSACRegressor #####\n",
      "Error (GammaRegressor-RANSACRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GammaRegressor-RadiusNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RandomForestRegressor #####\n",
      "Error (GammaRegressor-RandomForestRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - Ridge #####\n",
      "Error (GammaRegressor-Ridge): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - RidgeCV #####\n",
      "Error (GammaRegressor-RidgeCV): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - SGDRegressor #####\n",
      "Error (GammaRegressor-SGDRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - SVR #####\n",
      "Error (GammaRegressor-SVR): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TheilSenRegressor #####\n",
      "Error (GammaRegressor-TheilSenRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TransformedTargetRegressor #####\n",
      "Error (GammaRegressor-TransformedTargetRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GammaRegressor - TweedieRegressor #####\n",
      "Error (GammaRegressor-TweedieRegressor): Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n",
      "##### GaussianProcessRegressor - GradientBoostingRegressor #####\n",
      "Train MSE: 0.137\n",
      "Train inference error (RMSE): ±0.36948056907565535\n",
      "Test MSE: 0.634\n",
      "Test inference error (RMSE): ±0.7963339676493423\n",
      "##### GaussianProcessRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.065\n",
      "Train inference error (RMSE): ±0.25451196944080073\n",
      "Test MSE: 0.665\n",
      "Test inference error (RMSE): ±0.8157150248937025\n",
      "##### GaussianProcessRegressor - HuberRegressor #####\n",
      "Train MSE: 14.012\n",
      "Train inference error (RMSE): ±3.743235432450679\n",
      "Test MSE: 15.119\n",
      "Test inference error (RMSE): ±3.888304347045328\n",
      "##### GaussianProcessRegressor - IsotonicRegression #####\n",
      "Error (GaussianProcessRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### GaussianProcessRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 5.563\n",
      "Train inference error (RMSE): ±2.3585538985574557\n",
      "Test MSE: 34.749\n",
      "Test inference error (RMSE): ±5.894848504063885\n",
      "##### GaussianProcessRegressor - KernelRidge #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.7453171493353374\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.8987975427491577\n",
      "##### GaussianProcessRegressor - Lars #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06704575313486195\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.064177122769908\n",
      "##### GaussianProcessRegressor - LarsCV #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.1167468924731133\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.11506101624069204\n",
      "##### GaussianProcessRegressor - Lasso #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5310503429350029\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.6414398680729818\n",
      "##### GaussianProcessRegressor - LassoCV #####\n",
      "Train MSE: 14.049\n",
      "Train inference error (RMSE): ±3.748212835442103\n",
      "Test MSE: 15.328\n",
      "Test inference error (RMSE): ±3.9150799781140773\n",
      "##### GaussianProcessRegressor - LassoLars #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5310503444315773\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.6414398584325538\n",
      "##### GaussianProcessRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8307747818741546e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987761133113668e-05\n",
      "##### GaussianProcessRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8307747818741546e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987761133113668e-05\n",
      "##### GaussianProcessRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830680996167425e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987690473549088e-05\n",
      "##### GaussianProcessRegressor - LinearSVR #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.7453180260261307\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.898799515318269\n",
      "##### GaussianProcessRegressor - MLPRegressor #####\n",
      "Train MSE: 14.912\n",
      "Train inference error (RMSE): ±3.8616373105014086\n",
      "Test MSE: 16.689\n",
      "Test inference error (RMSE): ±4.085158907495079\n",
      "##### GaussianProcessRegressor - MultiTaskElasticNet #####\n",
      "Error (GaussianProcessRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### GaussianProcessRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GaussianProcessRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### GaussianProcessRegressor - MultiTaskLasso #####\n",
      "Error (GaussianProcessRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### GaussianProcessRegressor - MultiTaskLassoCV #####\n",
      "Error (GaussianProcessRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### GaussianProcessRegressor - NuSVR #####\n",
      "Train MSE: 14.030\n",
      "Train inference error (RMSE): ±3.745720136160786\n",
      "Test MSE: 15.223\n",
      "Test inference error (RMSE): ±3.9016792457867977\n",
      "##### GaussianProcessRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.025\n",
      "Train inference error (RMSE): ±3.744983426437943\n",
      "Test MSE: 15.187\n",
      "Test inference error (RMSE): ±3.897005903710494\n",
      "##### GaussianProcessRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1034179868535814\n",
      "Test MSE: 1.169\n",
      "Test inference error (RMSE): ±1.081008609848041\n",
      "##### GaussianProcessRegressor - PLSCanonical #####\n",
      "Error (GaussianProcessRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### GaussianProcessRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04143971688335196\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.0439892056911056\n",
      "##### GaussianProcessRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.035\n",
      "Train inference error (RMSE): ±3.746355136135701\n",
      "Test MSE: 15.260\n",
      "Test inference error (RMSE): ±3.906360536258431\n",
      "##### GaussianProcessRegressor - PoissonRegressor #####\n",
      "Error (GaussianProcessRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### GaussianProcessRegressor - QuantileRegressor #####\n",
      "Train MSE: 14.013\n",
      "Train inference error (RMSE): ±3.7433801855392304\n",
      "Test MSE: 15.122\n",
      "Test inference error (RMSE): ±3.8887433344507527\n",
      "##### GaussianProcessRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830680996167425e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987690473549088e-05\n",
      "##### GaussianProcessRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GaussianProcessRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### GaussianProcessRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.209\n",
      "Train inference error (RMSE): ±0.4572043818873685\n",
      "Test MSE: 1.521\n",
      "Test inference error (RMSE): ±1.2334301122845166\n",
      "##### GaussianProcessRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015015978790626533\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001642268641756241\n",
      "##### GaussianProcessRegressor - RidgeCV #####\n",
      "Train MSE: 14.422\n",
      "Train inference error (RMSE): ±3.7976181137276255\n",
      "Test MSE: 17.623\n",
      "Test inference error (RMSE): ±4.197922506880719\n",
      "##### GaussianProcessRegressor - SGDRegressor #####\n",
      "Train MSE: 2080911274526452375282574880159644696895651854241930867062965223793812952400730783744.000\n",
      "Train inference error (RMSE): ±1.442536403189345e+42\n",
      "Test MSE: 2164293545352817214519963031245441345285924317365401773968289637930015954058432479232.000\n",
      "Test inference error (RMSE): ±1.4711538143079456e+42\n",
      "##### GaussianProcessRegressor - SVR #####\n",
      "Train MSE: 14.029\n",
      "Train inference error (RMSE): ±3.7455038604277218\n",
      "Test MSE: 15.213\n",
      "Test inference error (RMSE): ±3.9004449286964955\n",
      "##### GaussianProcessRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830886445576621e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.988420074242132e-05\n",
      "##### GaussianProcessRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830680996167425e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987690473549088e-05\n",
      "##### GaussianProcessRegressor - TweedieRegressor #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.745319279659386\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.8988169334417084\n",
      "##### GradientBoostingRegressor - HistGradientBoostingRegressor #####\n",
      "Train MSE: 0.085\n",
      "Train inference error (RMSE): ±0.2916523364234904\n",
      "Test MSE: 0.590\n",
      "Test inference error (RMSE): ±0.7680892010743842\n",
      "##### GradientBoostingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.36677613177589913\n",
      "Test MSE: 0.631\n",
      "Test inference error (RMSE): ±0.7942233671157545\n",
      "##### GradientBoostingRegressor - IsotonicRegression #####\n",
      "Error (GradientBoostingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### GradientBoostingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.179\n",
      "Train inference error (RMSE): ±0.4236518044910128\n",
      "Test MSE: 0.752\n",
      "Test inference error (RMSE): ±0.8670104123183137\n",
      "##### GradientBoostingRegressor - KernelRidge #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.36740684126780293\n",
      "Test MSE: 0.633\n",
      "Test inference error (RMSE): ±0.7956165718225767\n",
      "##### GradientBoostingRegressor - Lars #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.061003727059924545\n",
      "Test MSE: 0.003\n",
      "Test inference error (RMSE): ±0.053978041585020564\n",
      "##### GradientBoostingRegressor - LarsCV #####\n",
      "Train MSE: 0.011\n",
      "Train inference error (RMSE): ±0.10393571138408292\n",
      "Test MSE: 0.015\n",
      "Test inference error (RMSE): ±0.12284113846648717\n",
      "##### GradientBoostingRegressor - Lasso #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.3675820320776039\n",
      "Test MSE: 0.639\n",
      "Test inference error (RMSE): ±0.7996033347561522\n",
      "##### GradientBoostingRegressor - LassoCV #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.36678440036983795\n",
      "Test MSE: 0.638\n",
      "Test inference error (RMSE): ±0.7986047544136868\n",
      "##### GradientBoostingRegressor - LassoLars #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.367777621241635\n",
      "Test MSE: 0.641\n",
      "Test inference error (RMSE): ±0.8006482843933775\n",
      "##### GradientBoostingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.242309412491018e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017708969159163586\n",
      "##### GradientBoostingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.228045408443187e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017703370765747282\n",
      "##### GradientBoostingRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.236701309561165e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017699396109693787\n",
      "##### GradientBoostingRegressor - LinearSVR #####\n",
      "Train MSE: 0.137\n",
      "Train inference error (RMSE): ±0.36976698220076964\n",
      "Test MSE: 0.633\n",
      "Test inference error (RMSE): ±0.7958384519364567\n",
      "##### GradientBoostingRegressor - MLPRegressor #####\n",
      "Train MSE: 0.137\n",
      "Train inference error (RMSE): ±0.36997606356018675\n",
      "Test MSE: 0.635\n",
      "Test inference error (RMSE): ±0.796948087368065\n",
      "##### GradientBoostingRegressor - MultiTaskElasticNet #####\n",
      "Error (GradientBoostingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### GradientBoostingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (GradientBoostingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### GradientBoostingRegressor - MultiTaskLasso #####\n",
      "Error (GradientBoostingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### GradientBoostingRegressor - MultiTaskLassoCV #####\n",
      "Error (GradientBoostingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### GradientBoostingRegressor - NuSVR #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.36704335762478824\n",
      "Test MSE: 0.634\n",
      "Test inference error (RMSE): ±0.796041584914814\n",
      "##### GradientBoostingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.3670317797057185\n",
      "Test MSE: 0.628\n",
      "Test inference error (RMSE): ±0.792712407810117\n",
      "##### GradientBoostingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.170\n",
      "Train inference error (RMSE): ±0.412008404682746\n",
      "Test MSE: 0.582\n",
      "Test inference error (RMSE): ±0.762610474666031\n",
      "##### GradientBoostingRegressor - PLSCanonical #####\n",
      "Error (GradientBoostingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### GradientBoostingRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.039567958043097005\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04080699371771891\n",
      "##### GradientBoostingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.137\n",
      "Train inference error (RMSE): ±0.37056647705414203\n",
      "Test MSE: 0.630\n",
      "Test inference error (RMSE): ±0.7937269968511714\n",
      "##### GradientBoostingRegressor - PoissonRegressor #####\n",
      "Error (GradientBoostingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### GradientBoostingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.3671798633268544\n",
      "Test MSE: 0.627\n",
      "Test inference error (RMSE): ±0.7917494914386972\n",
      "##### GradientBoostingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.216689633726369e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017673097412748153\n",
      "##### GradientBoostingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (GradientBoostingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### GradientBoostingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.134\n",
      "Train inference error (RMSE): ±0.3659063383795668\n",
      "Test MSE: 0.609\n",
      "Test inference error (RMSE): ±0.7804709863603316\n",
      "##### GradientBoostingRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016078984740462371\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016475318455665274\n",
      "##### GradientBoostingRegressor - RidgeCV #####\n",
      "Train MSE: 0.187\n",
      "Train inference error (RMSE): ±0.4319811600126418\n",
      "Test MSE: 0.867\n",
      "Test inference error (RMSE): ±0.9313418074264643\n",
      "##### GradientBoostingRegressor - SGDRegressor #####\n",
      "Train MSE: 1137868484697036822682150774687795125940246011622333543997698958007444643889807360.000\n",
      "Train inference error (RMSE): ±3.373230624634249e+40\n",
      "Test MSE: 961866145437916762233510383963126640810356956714763533581826959178483316446724096.000\n",
      "Test inference error (RMSE): ±3.1013966941330107e+40\n",
      "##### GradientBoostingRegressor - SVR #####\n",
      "Train MSE: 0.135\n",
      "Train inference error (RMSE): ±0.3667516584503224\n",
      "Test MSE: 0.633\n",
      "Test inference error (RMSE): ±0.7958073945034941\n",
      "##### GradientBoostingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.221091654483753e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017668664534424772\n",
      "##### GradientBoostingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.26320943303204e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00017734256650557727\n",
      "##### GradientBoostingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.134\n",
      "Train inference error (RMSE): ±0.3665649272501301\n",
      "Test MSE: 0.634\n",
      "Test inference error (RMSE): ±0.7965389242658285\n",
      "##### HistGradientBoostingRegressor - HuberRegressor #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.2509253184733759\n",
      "Test MSE: 0.658\n",
      "Test inference error (RMSE): ±0.8109295866573933\n",
      "##### HistGradientBoostingRegressor - IsotonicRegression #####\n",
      "Error (HistGradientBoostingRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### HistGradientBoostingRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 0.108\n",
      "Train inference error (RMSE): ±0.32795039797249326\n",
      "Test MSE: 0.712\n",
      "Test inference error (RMSE): ±0.8436929603065401\n",
      "##### HistGradientBoostingRegressor - KernelRidge #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.2502876458307033\n",
      "Test MSE: 0.667\n",
      "Test inference error (RMSE): ±0.8164337384463074\n",
      "##### HistGradientBoostingRegressor - Lars #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06301791075164058\n",
      "Test MSE: 0.003\n",
      "Test inference error (RMSE): ±0.05130964673549445\n",
      "##### HistGradientBoostingRegressor - LarsCV #####\n",
      "Train MSE: 0.011\n",
      "Train inference error (RMSE): ±0.10476881280288039\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.11991684909471209\n",
      "##### HistGradientBoostingRegressor - Lasso #####\n",
      "Train MSE: 0.062\n",
      "Train inference error (RMSE): ±0.24975448214582466\n",
      "Test MSE: 0.671\n",
      "Test inference error (RMSE): ±0.8192911464256636\n",
      "##### HistGradientBoostingRegressor - LassoCV #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.2518229644525971\n",
      "Test MSE: 0.681\n",
      "Test inference error (RMSE): ±0.8253840783147669\n",
      "##### HistGradientBoostingRegressor - LassoLars #####\n",
      "Train MSE: 0.062\n",
      "Train inference error (RMSE): ±0.24975447893921932\n",
      "Test MSE: 0.671\n",
      "Test inference error (RMSE): ±0.8192911485362409\n",
      "##### HistGradientBoostingRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.03636070579109e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019346841835919768\n",
      "##### HistGradientBoostingRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.03636070579109e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019346841835919768\n",
      "##### HistGradientBoostingRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.036389074821379e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001934668486885431\n",
      "##### HistGradientBoostingRegressor - LinearSVR #####\n",
      "Train MSE: 0.065\n",
      "Train inference error (RMSE): ±0.25451196918444946\n",
      "Test MSE: 0.665\n",
      "Test inference error (RMSE): ±0.8157150249102275\n",
      "##### HistGradientBoostingRegressor - MLPRegressor #####\n",
      "Train MSE: 0.065\n",
      "Train inference error (RMSE): ±0.25556202464676564\n",
      "Test MSE: 0.667\n",
      "Test inference error (RMSE): ±0.8169899866437553\n",
      "##### HistGradientBoostingRegressor - MultiTaskElasticNet #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### HistGradientBoostingRegressor - MultiTaskElasticNetCV #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### HistGradientBoostingRegressor - MultiTaskLasso #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### HistGradientBoostingRegressor - MultiTaskLassoCV #####\n",
      "Error (HistGradientBoostingRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### HistGradientBoostingRegressor - NuSVR #####\n",
      "Train MSE: 0.065\n",
      "Train inference error (RMSE): ±0.2558758325279868\n",
      "Test MSE: 0.668\n",
      "Test inference error (RMSE): ±0.8172760323640401\n",
      "##### HistGradientBoostingRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.25018950022342973\n",
      "Test MSE: 0.666\n",
      "Test inference error (RMSE): ±0.816004041076433\n",
      "##### HistGradientBoostingRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.098\n",
      "Train inference error (RMSE): ±0.3124733162290344\n",
      "Test MSE: 0.611\n",
      "Test inference error (RMSE): ±0.7818554716430811\n",
      "##### HistGradientBoostingRegressor - PLSCanonical #####\n",
      "Error (HistGradientBoostingRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### HistGradientBoostingRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04037593913528546\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.040981583653604846\n",
      "##### HistGradientBoostingRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.075\n",
      "Train inference error (RMSE): ±0.2743040166403413\n",
      "Test MSE: 0.711\n",
      "Test inference error (RMSE): ±0.8434707635345237\n",
      "##### HistGradientBoostingRegressor - PoissonRegressor #####\n",
      "Error (HistGradientBoostingRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### HistGradientBoostingRegressor - QuantileRegressor #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.25023559124447864\n",
      "Test MSE: 0.660\n",
      "Test inference error (RMSE): ±0.8124829851910298\n",
      "##### HistGradientBoostingRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.036389074821379e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001934668486885431\n",
      "##### HistGradientBoostingRegressor - RadiusNeighborsRegressor #####\n",
      "Error (HistGradientBoostingRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### HistGradientBoostingRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.056\n",
      "Train inference error (RMSE): ±0.23634682153115968\n",
      "Test MSE: 0.615\n",
      "Test inference error (RMSE): ±0.7840045566733054\n",
      "##### HistGradientBoostingRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0016063374946855373\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016528416330106692\n",
      "##### HistGradientBoostingRegressor - RidgeCV #####\n",
      "Train MSE: 0.073\n",
      "Train inference error (RMSE): ±0.2698257675020192\n",
      "Test MSE: 0.643\n",
      "Test inference error (RMSE): ±0.8018618616397859\n",
      "##### HistGradientBoostingRegressor - SGDRegressor #####\n",
      "Train MSE: 6632953382641615846617341448600746165790514298668692064198565516136357294904442880.000\n",
      "Train inference error (RMSE): ±8.144294556707546e+40\n",
      "Test MSE: 7020747236749091198568644806988193020573887792385223275152236167123958700435308544.000\n",
      "Test inference error (RMSE): ±8.378989937187591e+40\n",
      "##### HistGradientBoostingRegressor - SVR #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.25064500690629665\n",
      "Test MSE: 0.667\n",
      "Test inference error (RMSE): ±0.8165207083586431\n",
      "##### HistGradientBoostingRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.037246495296163e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00019346960200549874\n",
      "##### HistGradientBoostingRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±6.036389074821379e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001934668486885431\n",
      "##### HistGradientBoostingRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.063\n",
      "Train inference error (RMSE): ±0.2504772476694222\n",
      "Test MSE: 0.666\n",
      "Test inference error (RMSE): ±0.8159877744600433\n",
      "##### HuberRegressor - IsotonicRegression #####\n",
      "Error (HuberRegressor-IsotonicRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### HuberRegressor - KNeighborsRegressor #####\n",
      "Train MSE: 5.567\n",
      "Train inference error (RMSE): ±2.3593635362592993\n",
      "Test MSE: 34.144\n",
      "Test inference error (RMSE): ±5.843262154281569\n",
      "##### HuberRegressor - KernelRidge #####\n",
      "Train MSE: 14.012\n",
      "Train inference error (RMSE): ±3.7432498354178674\n",
      "Test MSE: 15.118\n",
      "Test inference error (RMSE): ±3.8882494650742667\n",
      "##### HuberRegressor - Lars #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06706413800630437\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06199535696284023\n",
      "##### HuberRegressor - LarsCV #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11931805322498276\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.1176751046338083\n",
      "##### HuberRegressor - Lasso #####\n",
      "Train MSE: 2.339\n",
      "Train inference error (RMSE): ±1.5292168609467052\n",
      "Test MSE: 2.638\n",
      "Test inference error (RMSE): ±1.6242069253424198\n",
      "##### HuberRegressor - LassoCV #####\n",
      "Train MSE: 14.022\n",
      "Train inference error (RMSE): ±3.7446491387186422\n",
      "Test MSE: 15.175\n",
      "Test inference error (RMSE): ±3.8954797520415716\n",
      "##### HuberRegressor - LassoLars #####\n",
      "Train MSE: 2.339\n",
      "Train inference error (RMSE): ±1.5292168627454175\n",
      "Test MSE: 2.638\n",
      "Test inference error (RMSE): ±1.6242069232258605\n",
      "##### HuberRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8441773819730156e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.997129860576826e-05\n",
      "##### HuberRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8441773819730156e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.997129860576826e-05\n",
      "##### HuberRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844146726034822e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.997068514189778e-05\n",
      "##### HuberRegressor - LinearSVR #####\n",
      "Train MSE: 14.012\n",
      "Train inference error (RMSE): ±3.743235432450679\n",
      "Test MSE: 15.119\n",
      "Test inference error (RMSE): ±3.888304347045328\n",
      "##### HuberRegressor - MLPRegressor #####\n",
      "Train MSE: 14.014\n",
      "Train inference error (RMSE): ±3.7435634761147476\n",
      "Test MSE: 15.128\n",
      "Test inference error (RMSE): ±3.8895237804564124\n",
      "##### HuberRegressor - MultiTaskElasticNet #####\n",
      "Error (HuberRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### HuberRegressor - MultiTaskElasticNetCV #####\n",
      "Error (HuberRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### HuberRegressor - MultiTaskLasso #####\n",
      "Error (HuberRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### HuberRegressor - MultiTaskLassoCV #####\n",
      "Error (HuberRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### HuberRegressor - NuSVR #####\n",
      "Train MSE: 14.012\n",
      "Train inference error (RMSE): ±3.74331192749913\n",
      "Test MSE: 15.122\n",
      "Test inference error (RMSE): ±3.888675891166577\n",
      "##### HuberRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.014\n",
      "Train inference error (RMSE): ±3.743472580173076\n",
      "Test MSE: 15.127\n",
      "Test inference error (RMSE): ±3.8893697992901104\n",
      "##### HuberRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1035196004632029\n",
      "Test MSE: 1.162\n",
      "Test inference error (RMSE): ±1.0778243679049424\n",
      "##### HuberRegressor - PLSCanonical #####\n",
      "Error (HuberRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### HuberRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.041761208279670885\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04564848458331186\n",
      "##### HuberRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.017\n",
      "Train inference error (RMSE): ±3.7439944337227864\n",
      "Test MSE: 15.142\n",
      "Test inference error (RMSE): ±3.8913106408855582\n",
      "##### HuberRegressor - PoissonRegressor #####\n",
      "Error (HuberRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### HuberRegressor - QuantileRegressor #####\n",
      "Train MSE: 14.010\n",
      "Train inference error (RMSE): ±3.7430116987848896\n",
      "Test MSE: 15.112\n",
      "Test inference error (RMSE): ±3.887446330206448\n",
      "##### HuberRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844146726034822e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.997068514189778e-05\n",
      "##### HuberRegressor - RadiusNeighborsRegressor #####\n",
      "Error (HuberRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### HuberRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.210\n",
      "Train inference error (RMSE): ±0.45798901846134155\n",
      "Test MSE: 1.462\n",
      "Test inference error (RMSE): ±1.209307838269019\n",
      "##### HuberRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014963142462326023\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001548162584150472\n",
      "##### HuberRegressor - RidgeCV #####\n",
      "Train MSE: 14.205\n",
      "Train inference error (RMSE): ±3.768996633378965\n",
      "Test MSE: 16.291\n",
      "Test inference error (RMSE): ±4.036207612242599\n",
      "##### HuberRegressor - SGDRegressor #####\n",
      "Train MSE: 465517853287230180057646458577328261249307159420772034382896361339485415108771840.000\n",
      "Train inference error (RMSE): ±2.1575862747228213e+40\n",
      "Test MSE: 480326935083844657078546647841145813245364076196615837148353398619185774514405376.000\n",
      "Test inference error (RMSE): ±2.191636226849348e+40\n",
      "##### HuberRegressor - SVR #####\n",
      "Train MSE: 14.013\n",
      "Train inference error (RMSE): ±3.7434143836541036\n",
      "Test MSE: 15.126\n",
      "Test inference error (RMSE): ±3.8892723963582405\n",
      "##### HuberRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8441118024832475e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.997089769079164e-05\n",
      "##### HuberRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844146726034822e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.997068514189778e-05\n",
      "##### HuberRegressor - TweedieRegressor #####\n",
      "Train MSE: 14.012\n",
      "Train inference error (RMSE): ±3.7433063019715145\n",
      "Test MSE: 15.121\n",
      "Test inference error (RMSE): ±3.8886093132509107\n",
      "##### IsotonicRegression - KNeighborsRegressor #####\n",
      "Error (IsotonicRegression-KNeighborsRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - KernelRidge #####\n",
      "Error (IsotonicRegression-KernelRidge): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Lars #####\n",
      "Error (IsotonicRegression-Lars): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LarsCV #####\n",
      "Error (IsotonicRegression-LarsCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Lasso #####\n",
      "Error (IsotonicRegression-Lasso): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoCV #####\n",
      "Error (IsotonicRegression-LassoCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLars #####\n",
      "Error (IsotonicRegression-LassoLars): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLarsCV #####\n",
      "Error (IsotonicRegression-LassoLarsCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LassoLarsIC #####\n",
      "Error (IsotonicRegression-LassoLarsIC): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LinearRegression #####\n",
      "Error (IsotonicRegression-LinearRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - LinearSVR #####\n",
      "Error (IsotonicRegression-LinearSVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MLPRegressor #####\n",
      "Error (IsotonicRegression-MLPRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskElasticNet #####\n",
      "Error (IsotonicRegression-MultiTaskElasticNet): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskElasticNetCV #####\n",
      "Error (IsotonicRegression-MultiTaskElasticNetCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskLasso #####\n",
      "Error (IsotonicRegression-MultiTaskLasso): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - MultiTaskLassoCV #####\n",
      "Error (IsotonicRegression-MultiTaskLassoCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - NuSVR #####\n",
      "Error (IsotonicRegression-NuSVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - OrthogonalMatchingPursuit #####\n",
      "Error (IsotonicRegression-OrthogonalMatchingPursuit): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - OrthogonalMatchingPursuitCV #####\n",
      "Error (IsotonicRegression-OrthogonalMatchingPursuitCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PLSCanonical #####\n",
      "Error (IsotonicRegression-PLSCanonical): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PLSRegression #####\n",
      "Error (IsotonicRegression-PLSRegression): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PassiveAggressiveRegressor #####\n",
      "Error (IsotonicRegression-PassiveAggressiveRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - PoissonRegressor #####\n",
      "Error (IsotonicRegression-PoissonRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - QuantileRegressor #####\n",
      "Error (IsotonicRegression-QuantileRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RANSACRegressor #####\n",
      "Error (IsotonicRegression-RANSACRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RadiusNeighborsRegressor #####\n",
      "Error (IsotonicRegression-RadiusNeighborsRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RandomForestRegressor #####\n",
      "Error (IsotonicRegression-RandomForestRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - Ridge #####\n",
      "Error (IsotonicRegression-Ridge): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - RidgeCV #####\n",
      "Error (IsotonicRegression-RidgeCV): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - SGDRegressor #####\n",
      "Error (IsotonicRegression-SGDRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - SVR #####\n",
      "Error (IsotonicRegression-SVR): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TheilSenRegressor #####\n",
      "Error (IsotonicRegression-TheilSenRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TransformedTargetRegressor #####\n",
      "Error (IsotonicRegression-TransformedTargetRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### IsotonicRegression - TweedieRegressor #####\n",
      "Error (IsotonicRegression-TweedieRegressor): Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "##### KNeighborsRegressor - KernelRidge #####\n",
      "Train MSE: 5.545\n",
      "Train inference error (RMSE): ±2.354786552180981\n",
      "Test MSE: 34.623\n",
      "Test inference error (RMSE): ±5.884153319730678\n",
      "##### KNeighborsRegressor - Lars #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.06716866115611177\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06099934422777372\n",
      "##### KNeighborsRegressor - LarsCV #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.1192804277851682\n",
      "Test MSE: 0.012\n",
      "Test inference error (RMSE): ±0.1114920577070457\n",
      "##### KNeighborsRegressor - Lasso #####\n",
      "Train MSE: 1.616\n",
      "Train inference error (RMSE): ±1.271382334416922\n",
      "Test MSE: 3.788\n",
      "Test inference error (RMSE): ±1.9463411400863753\n",
      "##### KNeighborsRegressor - LassoCV #####\n",
      "Train MSE: 5.573\n",
      "Train inference error (RMSE): ±2.360637746283447\n",
      "Test MSE: 36.646\n",
      "Test inference error (RMSE): ±6.053622140108929\n",
      "##### KNeighborsRegressor - LassoLars #####\n",
      "Train MSE: 1.616\n",
      "Train inference error (RMSE): ±1.2713823578967887\n",
      "Test MSE: 3.788\n",
      "Test inference error (RMSE): ±1.9463410406434631\n",
      "##### KNeighborsRegressor - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.3877130206472036e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±8.484047718507159e-05\n",
      "##### KNeighborsRegressor - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.3877130206472036e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±8.484047718507159e-05\n",
      "##### KNeighborsRegressor - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.3876926996995996e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±8.484372826881029e-05\n",
      "##### KNeighborsRegressor - LinearSVR #####\n",
      "Train MSE: 5.563\n",
      "Train inference error (RMSE): ±2.358553898557417\n",
      "Test MSE: 34.749\n",
      "Test inference error (RMSE): ±5.894848504064035\n",
      "##### KNeighborsRegressor - MLPRegressor #####\n",
      "Train MSE: 5.559\n",
      "Train inference error (RMSE): ±2.3576944696004705\n",
      "Test MSE: 35.960\n",
      "Test inference error (RMSE): ±5.996657119354343\n",
      "##### KNeighborsRegressor - MultiTaskElasticNet #####\n",
      "Error (KNeighborsRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### KNeighborsRegressor - MultiTaskElasticNetCV #####\n",
      "Error (KNeighborsRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### KNeighborsRegressor - MultiTaskLasso #####\n",
      "Error (KNeighborsRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### KNeighborsRegressor - MultiTaskLassoCV #####\n",
      "Error (KNeighborsRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### KNeighborsRegressor - NuSVR #####\n",
      "Train MSE: 5.564\n",
      "Train inference error (RMSE): ±2.3588444737823924\n",
      "Test MSE: 34.782\n",
      "Test inference error (RMSE): ±5.897661616066866\n",
      "##### KNeighborsRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 5.561\n",
      "Train inference error (RMSE): ±2.3582250649993104\n",
      "Test MSE: 36.352\n",
      "Test inference error (RMSE): ±6.0292316967719914\n",
      "##### KNeighborsRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.009\n",
      "Train inference error (RMSE): ±1.004466120952777\n",
      "Test MSE: 1.725\n",
      "Test inference error (RMSE): ±1.3132698129736355\n",
      "##### KNeighborsRegressor - PLSCanonical #####\n",
      "Error (KNeighborsRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### KNeighborsRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.0415906386351671\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04220016163851001\n",
      "##### KNeighborsRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 5.688\n",
      "Train inference error (RMSE): ±2.3850020106821703\n",
      "Test MSE: 38.499\n",
      "Test inference error (RMSE): ±6.204735152378143\n",
      "##### KNeighborsRegressor - PoissonRegressor #####\n",
      "Error (KNeighborsRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### KNeighborsRegressor - QuantileRegressor #####\n",
      "Train MSE: 5.561\n",
      "Train inference error (RMSE): ±2.3581578111616843\n",
      "Test MSE: 36.174\n",
      "Test inference error (RMSE): ±6.0144615365488105\n",
      "##### KNeighborsRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.3876926996995996e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±8.484372826881029e-05\n",
      "##### KNeighborsRegressor - RadiusNeighborsRegressor #####\n",
      "Error (KNeighborsRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### KNeighborsRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.322\n",
      "Train inference error (RMSE): ±0.5672596852846533\n",
      "Test MSE: 2.001\n",
      "Test inference error (RMSE): ±1.4146865210057649\n",
      "##### KNeighborsRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014709995297976983\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0017718556052154426\n",
      "##### KNeighborsRegressor - RidgeCV #####\n",
      "Train MSE: 5.766\n",
      "Train inference error (RMSE): ±2.401295029334138\n",
      "Test MSE: 45.148\n",
      "Test inference error (RMSE): ±6.719207435483874\n",
      "##### KNeighborsRegressor - SGDRegressor #####\n",
      "Train MSE: 1446386019559562387596428653932672512427763796112539108797050269688638695698071552.000\n",
      "Train inference error (RMSE): ±3.803138203588666e+40\n",
      "Test MSE: 1536659795218930304445968416917192535186201279008612439812788390170558237457252352.000\n",
      "Test inference error (RMSE): ±3.9200252489224227e+40\n",
      "##### KNeighborsRegressor - SVR #####\n",
      "Train MSE: 5.565\n",
      "Train inference error (RMSE): ±2.359044852720268\n",
      "Test MSE: 34.879\n",
      "Test inference error (RMSE): ±5.9058174633766995\n",
      "##### KNeighborsRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.387624841558495e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±8.481122480157968e-05\n",
      "##### KNeighborsRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.3876926996995996e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±8.484372826881029e-05\n",
      "##### KNeighborsRegressor - TweedieRegressor #####\n",
      "Train MSE: 5.564\n",
      "Train inference error (RMSE): ±2.358866133360148\n",
      "Test MSE: 34.736\n",
      "Test inference error (RMSE): ±5.893684838382072\n",
      "##### KernelRidge - Lars #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.06710813274563941\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06383068579651816\n",
      "##### KernelRidge - LarsCV #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.1169670560564665\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.11515888082448889\n",
      "##### KernelRidge - Lasso #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.531023957938013\n",
      "Test MSE: 2.695\n",
      "Test inference error (RMSE): ±1.6415931667196466\n",
      "##### KernelRidge - LassoCV #####\n",
      "Train MSE: 14.049\n",
      "Train inference error (RMSE): ±3.7482107700248077\n",
      "Test MSE: 15.328\n",
      "Test inference error (RMSE): ±3.9150742176426494\n",
      "##### KernelRidge - LassoLars #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5310239585488548\n",
      "Test MSE: 2.695\n",
      "Test inference error (RMSE): ±1.6415931543970268\n",
      "##### KernelRidge - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830771082484723e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987756099928063e-05\n",
      "##### KernelRidge - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830771082484723e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987756099928063e-05\n",
      "##### KernelRidge - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830647134498569e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987654120401099e-05\n",
      "##### KernelRidge - LinearSVR #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.7453171493353374\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.898797542749157\n",
      "##### KernelRidge - MLPRegressor #####\n",
      "Train MSE: 14.029\n",
      "Train inference error (RMSE): ±3.7455312629340547\n",
      "Test MSE: 15.182\n",
      "Test inference error (RMSE): ±3.89642702573701\n",
      "##### KernelRidge - MultiTaskElasticNet #####\n",
      "Error (KernelRidge-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### KernelRidge - MultiTaskElasticNetCV #####\n",
      "Error (KernelRidge-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### KernelRidge - MultiTaskLasso #####\n",
      "Error (KernelRidge-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### KernelRidge - MultiTaskLassoCV #####\n",
      "Error (KernelRidge-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### KernelRidge - NuSVR #####\n",
      "Train MSE: 14.028\n",
      "Train inference error (RMSE): ±3.7453940847077067\n",
      "Test MSE: 15.205\n",
      "Test inference error (RMSE): ±3.8994137237432187\n",
      "##### KernelRidge - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.025\n",
      "Train inference error (RMSE): ±3.744986861363756\n",
      "Test MSE: 15.187\n",
      "Test inference error (RMSE): ±3.8970050724411607\n",
      "##### KernelRidge - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.103489274454164\n",
      "Test MSE: 1.167\n",
      "Test inference error (RMSE): ±1.0803799121689708\n",
      "##### KernelRidge - PLSCanonical #####\n",
      "Error (KernelRidge-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### KernelRidge - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04135892520963577\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.043738530761310776\n",
      "##### KernelRidge - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.035\n",
      "Train inference error (RMSE): ±3.7463520176932747\n",
      "Test MSE: 15.159\n",
      "Test inference error (RMSE): ±3.8934410946014317\n",
      "##### KernelRidge - PoissonRegressor #####\n",
      "Error (KernelRidge-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### KernelRidge - QuantileRegressor #####\n",
      "Train MSE: 14.013\n",
      "Train inference error (RMSE): ±3.743386639074784\n",
      "Test MSE: 15.122\n",
      "Test inference error (RMSE): ±3.8886555061292167\n",
      "##### KernelRidge - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830647134498569e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987654120401099e-05\n",
      "##### KernelRidge - RadiusNeighborsRegressor #####\n",
      "Error (KernelRidge-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### KernelRidge - RandomForestRegressor #####\n",
      "Train MSE: 0.211\n",
      "Train inference error (RMSE): ±0.45888476657619004\n",
      "Test MSE: 1.475\n",
      "Test inference error (RMSE): ±1.2143145348834625\n",
      "##### KernelRidge - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001500923627550146\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016395324470335913\n",
      "##### KernelRidge - RidgeCV #####\n",
      "Train MSE: 14.423\n",
      "Train inference error (RMSE): ±3.7977372225104933\n",
      "Test MSE: 17.631\n",
      "Test inference error (RMSE): ±4.198895095638528\n",
      "##### KernelRidge - SGDRegressor #####\n",
      "Train MSE: 15090866048746995973106561817389790578861140976961547991667293991689214681415680.000\n",
      "Train inference error (RMSE): ±3.884696390806751e+39\n",
      "Test MSE: 15949430563197535813607221361294722804924499984967828340902009027913785981009920.000\n",
      "Test inference error (RMSE): ±3.9936738178270816e+39\n",
      "##### KernelRidge - SVR #####\n",
      "Train MSE: 14.028\n",
      "Train inference error (RMSE): ±3.745460902031209\n",
      "Test MSE: 15.213\n",
      "Test inference error (RMSE): ±3.900340289420247\n",
      "##### KernelRidge - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830322971753278e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987497792637593e-05\n",
      "##### KernelRidge - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830647134498569e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987654120401099e-05\n",
      "##### KernelRidge - TweedieRegressor #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.7452760950858166\n",
      "Test MSE: 15.200\n",
      "Test inference error (RMSE): ±3.89871901507764\n",
      "##### Lars - LarsCV #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.07321549790371926\n",
      "Test MSE: 0.005\n",
      "Test inference error (RMSE): ±0.07070157939698418\n",
      "##### Lars - Lasso #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04697376793687459\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04368330205298064\n",
      "##### Lars - LassoCV #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.06779850049056621\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06480781953754094\n",
      "##### Lars - LassoLars #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04697376905669229\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.043683303659988446\n",
      "##### Lars - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.000706429285655728\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006762038741820191\n",
      "##### Lars - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.000706429285655728\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006762038741820191\n",
      "##### Lars - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007064301346651509\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006762060438234274\n",
      "##### Lars - LinearSVR #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06704575303596379\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06417712268183003\n",
      "##### Lars - MLPRegressor #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06702842613508765\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.0641888162995128\n",
      "##### Lars - MultiTaskElasticNet #####\n",
      "Error (Lars-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### Lars - MultiTaskElasticNetCV #####\n",
      "Error (Lars-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### Lars - MultiTaskLasso #####\n",
      "Error (Lars-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### Lars - MultiTaskLassoCV #####\n",
      "Error (Lars-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### Lars - NuSVR #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.06712624596269944\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06434001614880748\n",
      "##### Lars - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06700546300313193\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.062138386424662156\n",
      "##### Lars - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04684560151288094\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04341074630106204\n",
      "##### Lars - PLSCanonical #####\n",
      "Error (Lars-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### Lars - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.041499829511912646\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.043360185054011395\n",
      "##### Lars - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.06701667901834392\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06398794935715266\n",
      "##### Lars - PoissonRegressor #####\n",
      "Error (Lars-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### Lars - QuantileRegressor #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.0670485130829396\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06148852874900385\n",
      "##### Lars - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007064301346651509\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006762060438234274\n",
      "##### Lars - RadiusNeighborsRegressor #####\n",
      "Error (Lars-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### Lars - RandomForestRegressor #####\n",
      "Train MSE: 0.003\n",
      "Train inference error (RMSE): ±0.058888390764602803\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.049683900814999384\n",
      "##### Lars - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015721279993857582\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016422650845637086\n",
      "##### Lars - RidgeCV #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.07252678591437889\n",
      "Test MSE: 0.010\n",
      "Test inference error (RMSE): ±0.10052506359538835\n",
      "##### Lars - SGDRegressor #####\n",
      "Train MSE: 3857210170977023112939794752368192729371758821962538154840275868113966215774028693504.000\n",
      "Train inference error (RMSE): ±1.963978149312518e+42\n",
      "Test MSE: 3992391001445315150629616847731602903854570990823526841878984470462111410980952997888.000\n",
      "Test inference error (RMSE): ±1.9980968448614585e+42\n",
      "##### Lars - SVR #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.06779928041147346\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06484907526807904\n",
      "##### Lars - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007064341158417633\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006762434720938902\n",
      "##### Lars - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007064301346651509\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006762060438234274\n",
      "##### Lars - TweedieRegressor #####\n",
      "Train MSE: 0.005\n",
      "Train inference error (RMSE): ±0.06780660190095651\n",
      "Test MSE: 0.004\n",
      "Test inference error (RMSE): ±0.06487812158077538\n",
      "##### LarsCV - Lasso #####\n",
      "Train MSE: 0.015\n",
      "Train inference error (RMSE): ±0.12194547099915604\n",
      "Test MSE: 0.015\n",
      "Test inference error (RMSE): ±0.12156353276144569\n",
      "##### LarsCV - LassoCV #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.1169118960869866\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.11488516101041236\n",
      "##### LarsCV - LassoLars #####\n",
      "Train MSE: 0.015\n",
      "Train inference error (RMSE): ±0.12194547383786061\n",
      "Test MSE: 0.015\n",
      "Test inference error (RMSE): ±0.12156353604818823\n",
      "##### LarsCV - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007090710732501194\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.000698831839437606\n",
      "##### LarsCV - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007090710732501194\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.000698831839437606\n",
      "##### LarsCV - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007090709856614091\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006988321220146772\n",
      "##### LarsCV - LinearSVR #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11674689263703804\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.1150610164212779\n",
      "##### LarsCV - MLPRegressor #####\n",
      "Train MSE: 9.713\n",
      "Train inference error (RMSE): ±3.1166191692310456\n",
      "Test MSE: 10.234\n",
      "Test inference error (RMSE): ±3.1991232309220914\n",
      "##### LarsCV - MultiTaskElasticNet #####\n",
      "Error (LarsCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LarsCV - MultiTaskElasticNetCV #####\n",
      "Error (LarsCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LarsCV - MultiTaskLasso #####\n",
      "Error (LarsCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LarsCV - MultiTaskLassoCV #####\n",
      "Error (LarsCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LarsCV - NuSVR #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11703009149466845\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.1154109181691811\n",
      "##### LarsCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11926945089512726\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.11773587012296839\n",
      "##### LarsCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.015\n",
      "Train inference error (RMSE): ±0.12302299464055877\n",
      "Test MSE: 0.015\n",
      "Test inference error (RMSE): ±0.12142773581447588\n",
      "##### LarsCV - PLSCanonical #####\n",
      "Error (LarsCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LarsCV - PLSRegression #####\n",
      "Train MSE: 0.001\n",
      "Train inference error (RMSE): ±0.034220778637615426\n",
      "Test MSE: 0.001\n",
      "Test inference error (RMSE): ±0.037618594743007265\n",
      "##### LarsCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11676944076878565\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.11515243476701009\n",
      "##### LarsCV - PoissonRegressor #####\n",
      "Error (LarsCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LarsCV - QuantileRegressor #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11927858014651767\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.11761670268435431\n",
      "##### LarsCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007090709856614091\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006988321220146772\n",
      "##### LarsCV - RadiusNeighborsRegressor #####\n",
      "Error (LarsCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LarsCV - RandomForestRegressor #####\n",
      "Train MSE: 0.012\n",
      "Train inference error (RMSE): ±0.10793667661580612\n",
      "Test MSE: 0.015\n",
      "Test inference error (RMSE): ±0.12045088131324012\n",
      "##### LarsCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0011324897889199066\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001239780239893618\n",
      "##### LarsCV - RidgeCV #####\n",
      "Train MSE: 0.017\n",
      "Train inference error (RMSE): ±0.1291062583096702\n",
      "Test MSE: 0.034\n",
      "Test inference error (RMSE): ±0.1836021679933807\n",
      "##### LarsCV - SGDRegressor #####\n",
      "Train MSE: 17721428182762037580860878577598464237303537325503504964716234683644866004902739968.000\n",
      "Train inference error (RMSE): ±1.3312185463988262e+41\n",
      "Test MSE: 18555632694341553720363220236685972481784361230695812530918827145387940444349923328.000\n",
      "Test inference error (RMSE): ±1.3621906142071877e+41\n",
      "##### LarsCV - SVR #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11927799157737252\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.11784718742521919\n",
      "##### LarsCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007090701135143082\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006988331422458319\n",
      "##### LarsCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007090709856614091\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0006988321220146772\n",
      "##### LarsCV - TweedieRegressor #####\n",
      "Train MSE: 0.014\n",
      "Train inference error (RMSE): ±0.11928936395159032\n",
      "Test MSE: 0.014\n",
      "Test inference error (RMSE): ±0.11785832393558378\n",
      "##### Lasso - LassoCV #####\n",
      "Train MSE: 2.329\n",
      "Train inference error (RMSE): ±1.5260559183555538\n",
      "Test MSE: 2.472\n",
      "Test inference error (RMSE): ±1.572169417509485\n",
      "##### Lasso - LassoLars #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5310504633873492\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.6414372391003693\n",
      "##### Lasso - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966874042931047e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.613388737607858e-05\n",
      "##### Lasso - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966874042931047e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.613388737607858e-05\n",
      "##### Lasso - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966795524496315e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.61318038136298e-05\n",
      "##### Lasso - LinearSVR #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.531050342935013\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.6414398680727569\n",
      "##### Lasso - MLPRegressor #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.531076337108371\n",
      "Test MSE: 2.699\n",
      "Test inference error (RMSE): ±1.6428379239636184\n",
      "##### Lasso - MultiTaskElasticNet #####\n",
      "Error (Lasso-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### Lasso - MultiTaskElasticNetCV #####\n",
      "Error (Lasso-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### Lasso - MultiTaskLasso #####\n",
      "Error (Lasso-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### Lasso - MultiTaskLassoCV #####\n",
      "Error (Lasso-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### Lasso - NuSVR #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5310380963039547\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.641208507748703\n",
      "##### Lasso - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 2.328\n",
      "Train inference error (RMSE): ±1.5258982117893687\n",
      "Test MSE: 2.489\n",
      "Test inference error (RMSE): ±1.5777287429679407\n",
      "##### Lasso - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.10359697592209\n",
      "Test MSE: 1.174\n",
      "Test inference error (RMSE): ±1.0834259719640207\n",
      "##### Lasso - PLSCanonical #####\n",
      "Error (Lasso-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### Lasso - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.039139264048449925\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.040359437198527984\n",
      "##### Lasso - PassiveAggressiveRegressor #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.530868383701867\n",
      "Test MSE: 2.696\n",
      "Test inference error (RMSE): ±1.6420922766244213\n",
      "##### Lasso - PoissonRegressor #####\n",
      "Error (Lasso-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### Lasso - QuantileRegressor #####\n",
      "Train MSE: 2.329\n",
      "Train inference error (RMSE): ±1.5260205518427516\n",
      "Test MSE: 2.499\n",
      "Test inference error (RMSE): ±1.58097306672793\n",
      "##### Lasso - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966795524496315e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.61318038136298e-05\n",
      "##### Lasso - RadiusNeighborsRegressor #####\n",
      "Error (Lasso-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### Lasso - RandomForestRegressor #####\n",
      "Train MSE: 0.268\n",
      "Train inference error (RMSE): ±0.5179207712090708\n",
      "Test MSE: 1.583\n",
      "Test inference error (RMSE): ±1.2581343007488655\n",
      "##### Lasso - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015026716285671277\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016499739272812545\n",
      "##### Lasso - RidgeCV #####\n",
      "Train MSE: 2.643\n",
      "Train inference error (RMSE): ±1.625657834842651\n",
      "Test MSE: 4.932\n",
      "Test inference error (RMSE): ±2.2208960478507973\n",
      "##### Lasso - SGDRegressor #####\n",
      "Train MSE: 1193037389080533414075270073091688977479264060289872873298061417397917251753253797888.000\n",
      "Train inference error (RMSE): ±1.0922625092350892e+42\n",
      "Test MSE: 1238641046859193322308021649324914045320319091740641588544973056481917679595394433024.000\n",
      "Test inference error (RMSE): ±1.1129425173202762e+42\n",
      "##### Lasso - SVR #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.530950308214624\n",
      "Test MSE: 2.688\n",
      "Test inference error (RMSE): ±1.6396643144129093\n",
      "##### Lasso - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966707651206198e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.611516095819856e-05\n",
      "##### Lasso - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966795524496315e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.61318038136298e-05\n",
      "##### Lasso - TweedieRegressor #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5311100016260766\n",
      "Test MSE: 2.696\n",
      "Test inference error (RMSE): ±1.6420491816394536\n",
      "##### LassoCV - LassoLars #####\n",
      "Train MSE: 2.329\n",
      "Train inference error (RMSE): ±1.526055917486543\n",
      "Test MSE: 2.472\n",
      "Test inference error (RMSE): ±1.5721694429638842\n",
      "##### LassoCV - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8443240763608084e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.0441381593996705e-05\n",
      "##### LassoCV - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8443240763608084e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.0441381593996705e-05\n",
      "##### LassoCV - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844194706449542e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.044063835397534e-05\n",
      "##### LassoCV - LinearSVR #####\n",
      "Train MSE: 14.049\n",
      "Train inference error (RMSE): ±3.7482128354421036\n",
      "Test MSE: 15.328\n",
      "Test inference error (RMSE): ±3.915079978114077\n",
      "##### LassoCV - MLPRegressor #####\n",
      "Train MSE: 14.143\n",
      "Train inference error (RMSE): ±3.7607336229080626\n",
      "Test MSE: 15.129\n",
      "Test inference error (RMSE): ±3.8896514141649483\n",
      "##### LassoCV - MultiTaskElasticNet #####\n",
      "Error (LassoCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoCV - MultiTaskElasticNetCV #####\n",
      "Error (LassoCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoCV - MultiTaskLasso #####\n",
      "Error (LassoCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoCV - MultiTaskLassoCV #####\n",
      "Error (LassoCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoCV - NuSVR #####\n",
      "Train MSE: 14.047\n",
      "Train inference error (RMSE): ±3.7479407684933204\n",
      "Test MSE: 15.317\n",
      "Test inference error (RMSE): ±3.913712374523293\n",
      "##### LassoCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.041\n",
      "Train inference error (RMSE): ±3.7471900314686\n",
      "Test MSE: 15.283\n",
      "Test inference error (RMSE): ±3.9093847777222464\n",
      "##### LassoCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.225\n",
      "Train inference error (RMSE): ±1.1066839558670991\n",
      "Test MSE: 1.271\n",
      "Test inference error (RMSE): ±1.1273776890345537\n",
      "##### LassoCV - PLSCanonical #####\n",
      "Error (LassoCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoCV - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04611425600256673\n",
      "Test MSE: 0.005\n",
      "Test inference error (RMSE): ±0.06718173295338735\n",
      "##### LassoCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.093\n",
      "Train inference error (RMSE): ±3.754076773141816\n",
      "Test MSE: 15.146\n",
      "Test inference error (RMSE): ±3.891752221716001\n",
      "##### LassoCV - PoissonRegressor #####\n",
      "Error (LassoCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoCV - QuantileRegressor #####\n",
      "Train MSE: 14.024\n",
      "Train inference error (RMSE): ±3.744869906254591\n",
      "Test MSE: 15.180\n",
      "Test inference error (RMSE): ±3.896189225480012\n",
      "##### LassoCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844194706449542e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.044063835397534e-05\n",
      "##### LassoCV - RadiusNeighborsRegressor #####\n",
      "Error (LassoCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoCV - RandomForestRegressor #####\n",
      "Train MSE: 0.204\n",
      "Train inference error (RMSE): ±0.4519603243130134\n",
      "Test MSE: 1.500\n",
      "Test inference error (RMSE): ±1.2248915342568134\n",
      "##### LassoCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014772262808441026\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001500507877116797\n",
      "##### LassoCV - RidgeCV #####\n",
      "Train MSE: 14.847\n",
      "Train inference error (RMSE): ±3.8531597352715585\n",
      "Test MSE: 20.276\n",
      "Test inference error (RMSE): ±4.502935555908963\n",
      "##### LassoCV - SGDRegressor #####\n",
      "Train MSE: 611868357728625334364278260923820431891223715100382969202650721852590932579319808.000\n",
      "Train inference error (RMSE): ±2.4735972948898235e+40\n",
      "Test MSE: 612595998693662979862762793686289875316385404508587390238443141300100938583769088.000\n",
      "Test inference error (RMSE): ±2.475067673203428e+40\n",
      "##### LassoCV - SVR #####\n",
      "Train MSE: 14.045\n",
      "Train inference error (RMSE): ±3.7476245252918488\n",
      "Test MSE: 15.307\n",
      "Test inference error (RMSE): ±3.912471858973769\n",
      "##### LassoCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844137520870237e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.045250570117971e-05\n",
      "##### LassoCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.844194706449542e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.044063835397534e-05\n",
      "##### LassoCV - TweedieRegressor #####\n",
      "Train MSE: 14.045\n",
      "Train inference error (RMSE): ±3.7477259828937783\n",
      "Test MSE: 15.306\n",
      "Test inference error (RMSE): ±3.91230237265051\n",
      "##### LassoLars - LassoLarsCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966872814622864e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.61338703450176e-05\n",
      "##### LassoLars - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966872814622864e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.61338703450176e-05\n",
      "##### LassoLars - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966789300184385e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.613172868249862e-05\n",
      "##### LassoLars - LinearSVR #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5310503444317105\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.6414398584295795\n",
      "##### LassoLars - MLPRegressor #####\n",
      "Train MSE: 2.347\n",
      "Train inference error (RMSE): ±1.5319909282955173\n",
      "Test MSE: 2.743\n",
      "Test inference error (RMSE): ±1.6561349098965277\n",
      "##### LassoLars - MultiTaskElasticNet #####\n",
      "Error (LassoLars-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLars - MultiTaskElasticNetCV #####\n",
      "Error (LassoLars-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLars - MultiTaskLasso #####\n",
      "Error (LassoLars-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLars - MultiTaskLassoCV #####\n",
      "Error (LassoLars-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLars - NuSVR #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.53103809744201\n",
      "Test MSE: 2.694\n",
      "Test inference error (RMSE): ±1.6412084984673438\n",
      "##### LassoLars - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 2.328\n",
      "Train inference error (RMSE): ±1.5258982134506969\n",
      "Test MSE: 2.489\n",
      "Test inference error (RMSE): ±1.5777287624352394\n",
      "##### LassoLars - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1035969755239823\n",
      "Test MSE: 1.174\n",
      "Test inference error (RMSE): ±1.0834259690167134\n",
      "##### LassoLars - PLSCanonical #####\n",
      "Error (LassoLars-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLars - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.03913926428445823\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.040359437094334934\n",
      "##### LassoLars - PassiveAggressiveRegressor #####\n",
      "Train MSE: 2.375\n",
      "Train inference error (RMSE): ±1.5411864886165965\n",
      "Test MSE: 2.880\n",
      "Test inference error (RMSE): ±1.6972033768412154\n",
      "##### LassoLars - PoissonRegressor #####\n",
      "Error (LassoLars-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLars - QuantileRegressor #####\n",
      "Train MSE: 2.329\n",
      "Train inference error (RMSE): ±1.5260205536395968\n",
      "Test MSE: 2.499\n",
      "Test inference error (RMSE): ±1.580973079620107\n",
      "##### LassoLars - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966789300184385e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.613172868249862e-05\n",
      "##### LassoLars - RadiusNeighborsRegressor #####\n",
      "Error (LassoLars-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLars - RandomForestRegressor #####\n",
      "Train MSE: 0.245\n",
      "Train inference error (RMSE): ±0.49509496457965263\n",
      "Test MSE: 1.515\n",
      "Test inference error (RMSE): ±1.2309235404801597\n",
      "##### LassoLars - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015026717042954487\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016499740024247351\n",
      "##### LassoLars - RidgeCV #####\n",
      "Train MSE: 2.643\n",
      "Train inference error (RMSE): ±1.625657624208803\n",
      "Test MSE: 4.932\n",
      "Test inference error (RMSE): ±2.220894934152257\n",
      "##### LassoLars - SGDRegressor #####\n",
      "Train MSE: 117435873618023743172883822541988335042854300352727920221767603811013998997820932096.000\n",
      "Train inference error (RMSE): ±3.4268917931271734e+41\n",
      "Test MSE: 126336435631186185850037431368034725989795957495399290579685636307170377015396139008.000\n",
      "Test inference error (RMSE): ±3.55438371073223e+41\n",
      "##### LassoLars - SVR #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.530950309447411\n",
      "Test MSE: 2.688\n",
      "Test inference error (RMSE): ±1.6396643060889435\n",
      "##### LassoLars - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966678497946621e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.611655237656471e-05\n",
      "##### LassoLars - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±8.966789300184385e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±9.613172868249862e-05\n",
      "##### LassoLars - TweedieRegressor #####\n",
      "Train MSE: 2.344\n",
      "Train inference error (RMSE): ±1.5311100026936033\n",
      "Test MSE: 2.696\n",
      "Test inference error (RMSE): ±1.642049171701374\n",
      "##### LassoLarsCV - LassoLarsIC #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9154406871527125e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993937487545266e-05\n",
      "##### LassoLarsCV - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153444492721348e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850790022907e-05\n",
      "##### LassoLarsCV - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830748791812251e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987734077992223e-05\n",
      "##### LassoLarsCV - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00013310193441310638\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00013629667334387154\n",
      "##### LassoLarsCV - MultiTaskElasticNet #####\n",
      "Error (LassoLarsCV-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsCV - MultiTaskElasticNetCV #####\n",
      "Error (LassoLarsCV-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLarsCV - MultiTaskLasso #####\n",
      "Error (LassoLarsCV-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsCV - MultiTaskLassoCV #####\n",
      "Error (LassoLarsCV-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLarsCV - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.840817713412031e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.002065962725687e-05\n",
      "##### LassoLarsCV - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830311036227951e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.985003537312199e-05\n",
      "##### LassoLarsCV - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012775292987254313\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012515517890234352\n",
      "##### LassoLarsCV - PLSCanonical #####\n",
      "Error (LassoLarsCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLarsCV - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014550239249996137\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015445412112022293\n",
      "##### LassoLarsCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.843629220842461e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.018876325763527e-05\n",
      "##### LassoLarsCV - PoissonRegressor #####\n",
      "Error (LassoLarsCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLarsCV - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8309459575962784e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.978858846430949e-05\n",
      "##### LassoLarsCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153444492721348e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850790022907e-05\n",
      "##### LassoLarsCV - RadiusNeighborsRegressor #####\n",
      "Error (LassoLarsCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLarsCV - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±5.011034082637544e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00013386115574446833\n",
      "##### LassoLarsCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007474544855922025\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0008174765934823763\n",
      "##### LassoLarsCV - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.892169386290682e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.3301852584035094e-05\n",
      "##### LassoLarsCV - SGDRegressor #####\n",
      "Train MSE: 3574073006344171135856792657648507917458867597628480686635485397688249553778638848.000\n",
      "Train inference error (RMSE): ±5.978355130254618e+40\n",
      "Test MSE: 4046937334886471928577721650732036494648874577838037744702398374612258241059487744.000\n",
      "Test inference error (RMSE): ±6.361554318628798e+40\n",
      "##### LassoLarsCV - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8416630381027894e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.004226525972585e-05\n",
      "##### LassoLarsCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9154507387812595e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9943327003068065e-05\n",
      "##### LassoLarsCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153444492721348e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850790022907e-05\n",
      "##### LassoLarsCV - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842571857899664e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000065364803111e-05\n",
      "##### LassoLarsIC - LinearRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153444492721348e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850790022907e-05\n",
      "##### LassoLarsIC - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830748791812251e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987734077992223e-05\n",
      "##### LassoLarsIC - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8330561509588074e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.993484536128661e-05\n",
      "##### LassoLarsIC - MultiTaskElasticNet #####\n",
      "Error (LassoLarsIC-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsIC - MultiTaskElasticNetCV #####\n",
      "Error (LassoLarsIC-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LassoLarsIC - MultiTaskLasso #####\n",
      "Error (LassoLarsIC-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LassoLarsIC - MultiTaskLassoCV #####\n",
      "Error (LassoLarsIC-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LassoLarsIC - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.840817713412031e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.002065962725687e-05\n",
      "##### LassoLarsIC - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830311036227951e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.985003537312199e-05\n",
      "##### LassoLarsIC - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012775292987254313\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012515517890234352\n",
      "##### LassoLarsIC - PLSCanonical #####\n",
      "Error (LassoLarsIC-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LassoLarsIC - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014550239249996137\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015445412112022293\n",
      "##### LassoLarsIC - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.832286411173011e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987622720227653e-05\n",
      "##### LassoLarsIC - PoissonRegressor #####\n",
      "Error (LassoLarsIC-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LassoLarsIC - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8309459575962784e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.978858846430949e-05\n",
      "##### LassoLarsIC - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153444492721348e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850790022907e-05\n",
      "##### LassoLarsIC - RadiusNeighborsRegressor #####\n",
      "Error (LassoLarsIC-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LassoLarsIC - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.614009673476945e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001243732027497808\n",
      "##### LassoLarsIC - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007474544855922025\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0008174765934823763\n",
      "##### LassoLarsIC - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.892169386290682e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.3301852584035094e-05\n",
      "##### LassoLarsIC - SGDRegressor #####\n",
      "Train MSE: 19633281748620095503158266777655819842214299202624515767933077493780220310422814720.000\n",
      "Train inference error (RMSE): ±1.4011881297177798e+41\n",
      "Test MSE: 21031387156603310440684762926841564212808268799823543719432729404973171152603054080.000\n",
      "Test inference error (RMSE): ±1.4502202300548461e+41\n",
      "##### LassoLarsIC - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8416630381027894e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.004226525972585e-05\n",
      "##### LassoLarsIC - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153906045129535e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9939919553414272e-05\n",
      "##### LassoLarsIC - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153444492721348e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993850790022907e-05\n",
      "##### LassoLarsIC - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842571857899664e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000065364803111e-05\n",
      "##### LinearRegression - LinearSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8306761242874525e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987685402011418e-05\n",
      "##### LinearRegression - MLPRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.916268009539071e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.011763969604182e-05\n",
      "##### LinearRegression - MultiTaskElasticNet #####\n",
      "Error (LinearRegression-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LinearRegression - MultiTaskElasticNetCV #####\n",
      "Error (LinearRegression-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LinearRegression - MultiTaskLasso #####\n",
      "Error (LinearRegression-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LinearRegression - MultiTaskLassoCV #####\n",
      "Error (LinearRegression-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LinearRegression - NuSVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8407837823761825e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.002063366598894e-05\n",
      "##### LinearRegression - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830242206663296e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.984957237094016e-05\n",
      "##### LinearRegression - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012775214806003894\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012515373151950263\n",
      "##### LinearRegression - PLSCanonical #####\n",
      "Error (LinearRegression-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LinearRegression - PLSRegression #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014550247115451057\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015445437439192491\n",
      "##### LinearRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8317317428195924e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.983044948729328e-05\n",
      "##### LinearRegression - PoissonRegressor #####\n",
      "Error (LinearRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LinearRegression - QuantileRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8308531917464495e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.978763636021368e-05\n",
      "##### LinearRegression - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.915368081375861e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9938889004952374e-05\n",
      "##### LinearRegression - RadiusNeighborsRegressor #####\n",
      "Error (LinearRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LinearRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.592037935737719e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012700932430801025\n",
      "##### LinearRegression - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00074745439254676\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0008174756697928903\n",
      "##### LinearRegression - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.883287188998849e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.280763048493746e-05\n",
      "##### LinearRegression - SGDRegressor #####\n",
      "Train MSE: 677967623571854628981186237807760875954491871530379467322647718408056933572637884416.000\n",
      "Train inference error (RMSE): ±8.2338789374866e+41\n",
      "Test MSE: 692936158943090306640334591197954205888738416225558389928563390764297764473250250752.000\n",
      "Test inference error (RMSE): ±8.324278701143362e+41\n",
      "##### LinearRegression - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.841575317211714e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.004169811805276e-05\n",
      "##### LinearRegression - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9154936484243644e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.993572553165872e-05\n",
      "##### LinearRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.915368081375861e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9938889004952374e-05\n",
      "##### LinearRegression - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842506423697025e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000024256480227e-05\n",
      "##### LinearSVR - MLPRegressor #####\n",
      "Train MSE: 14.043\n",
      "Train inference error (RMSE): ±3.7474027675083232\n",
      "Test MSE: 15.141\n",
      "Test inference error (RMSE): ±3.8911547561440414\n",
      "##### LinearSVR - MultiTaskElasticNet #####\n",
      "Error (LinearSVR-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### LinearSVR - MultiTaskElasticNetCV #####\n",
      "Error (LinearSVR-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### LinearSVR - MultiTaskLasso #####\n",
      "Error (LinearSVR-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### LinearSVR - MultiTaskLassoCV #####\n",
      "Error (LinearSVR-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### LinearSVR - NuSVR #####\n",
      "Train MSE: 14.030\n",
      "Train inference error (RMSE): ±3.745720136160786\n",
      "Test MSE: 15.223\n",
      "Test inference error (RMSE): ±3.9016792457867977\n",
      "##### LinearSVR - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.025\n",
      "Train inference error (RMSE): ±3.744983426437943\n",
      "Test MSE: 15.187\n",
      "Test inference error (RMSE): ±3.897005903710494\n",
      "##### LinearSVR - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1034179868535814\n",
      "Test MSE: 1.169\n",
      "Test inference error (RMSE): ±1.081008609848041\n",
      "##### LinearSVR - PLSCanonical #####\n",
      "Error (LinearSVR-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### LinearSVR - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04143971688335196\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.0439892056911056\n",
      "##### LinearSVR - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.745217631764169\n",
      "Test MSE: 15.173\n",
      "Test inference error (RMSE): ±3.895192259092857\n",
      "##### LinearSVR - PoissonRegressor #####\n",
      "Error (LinearSVR-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### LinearSVR - QuantileRegressor #####\n",
      "Train MSE: 14.013\n",
      "Train inference error (RMSE): ±3.7433801855392304\n",
      "Test MSE: 15.122\n",
      "Test inference error (RMSE): ±3.8887433344507527\n",
      "##### LinearSVR - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830680996167425e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987690473549088e-05\n",
      "##### LinearSVR - RadiusNeighborsRegressor #####\n",
      "Error (LinearSVR-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### LinearSVR - RandomForestRegressor #####\n",
      "Train MSE: 0.207\n",
      "Train inference error (RMSE): ±0.45504543372737105\n",
      "Test MSE: 1.476\n",
      "Test inference error (RMSE): ±1.2151032166950029\n",
      "##### LinearSVR - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015015978790626533\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001642268641756241\n",
      "##### LinearSVR - RidgeCV #####\n",
      "Train MSE: 14.422\n",
      "Train inference error (RMSE): ±3.7976181137276255\n",
      "Test MSE: 17.623\n",
      "Test inference error (RMSE): ±4.197922506880719\n",
      "##### LinearSVR - SGDRegressor #####\n",
      "Train MSE: 2085480458407835682269865510644664577653098701343987139183927737535512736583122944.000\n",
      "Train inference error (RMSE): ±4.56670609784321e+40\n",
      "Test MSE: 2176738725480430411357511432902752392676582103072829469347195947808203940611227648.000\n",
      "Test inference error (RMSE): ±4.665553263526664e+40\n",
      "##### LinearSVR - SVR #####\n",
      "Train MSE: 14.029\n",
      "Train inference error (RMSE): ±3.7455038604277218\n",
      "Test MSE: 15.213\n",
      "Test inference error (RMSE): ±3.9004449286964955\n",
      "##### LinearSVR - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8306944336002796e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987570686629506e-05\n",
      "##### LinearSVR - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830680996167425e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.987690473549088e-05\n",
      "##### LinearSVR - TweedieRegressor #####\n",
      "Train MSE: 14.027\n",
      "Train inference error (RMSE): ±3.745319279659386\n",
      "Test MSE: 15.201\n",
      "Test inference error (RMSE): ±3.8988169334417084\n",
      "##### MLPRegressor - MultiTaskElasticNet #####\n",
      "Error (MLPRegressor-MultiTaskElasticNet): For mono-task outputs, use ElasticNet\n",
      "##### MLPRegressor - MultiTaskElasticNetCV #####\n",
      "Error (MLPRegressor-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MLPRegressor - MultiTaskLasso #####\n",
      "Error (MLPRegressor-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### MLPRegressor - MultiTaskLassoCV #####\n",
      "Error (MLPRegressor-MultiTaskLassoCV): For mono-task outputs, use LassoCVCV\n",
      "##### MLPRegressor - NuSVR #####\n",
      "Train MSE: 14.033\n",
      "Train inference error (RMSE): ±3.746069625780403\n",
      "Test MSE: 15.187\n",
      "Test inference error (RMSE): ±3.897058283461791\n",
      "##### MLPRegressor - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.028\n",
      "Train inference error (RMSE): ±3.7454155654175323\n",
      "Test MSE: 15.120\n",
      "Test inference error (RMSE): ±3.888409507475253\n",
      "##### MLPRegressor - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.978\n",
      "Train inference error (RMSE): ±1.4063597009144395\n",
      "Test MSE: 1.707\n",
      "Test inference error (RMSE): ±1.306706161570659\n",
      "##### MLPRegressor - PLSCanonical #####\n",
      "Error (MLPRegressor-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### MLPRegressor - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.041448746528109745\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04390599182683387\n",
      "##### MLPRegressor - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.108\n",
      "Train inference error (RMSE): ±3.7561100078742267\n",
      "Test MSE: 15.448\n",
      "Test inference error (RMSE): ±3.9303717764897903\n",
      "##### MLPRegressor - PoissonRegressor #####\n",
      "Error (MLPRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### MLPRegressor - QuantileRegressor #####\n",
      "Train MSE: 463982402.001\n",
      "Train inference error (RMSE): ±21540.250741378677\n",
      "Test MSE: 486833334.018\n",
      "Test inference error (RMSE): ±22064.2999893068\n",
      "##### MLPRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.870807359880483e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.067579186497056e-05\n",
      "##### MLPRegressor - RadiusNeighborsRegressor #####\n",
      "Error (MLPRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### MLPRegressor - RandomForestRegressor #####\n",
      "Train MSE: 4.809\n",
      "Train inference error (RMSE): ±2.1929992468429242\n",
      "Test MSE: 6.878\n",
      "Test inference error (RMSE): ±2.6225334877788544\n",
      "##### MLPRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015228041263905447\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0017596721096746221\n",
      "##### MLPRegressor - RidgeCV #####\n",
      "Train MSE: 14.474\n",
      "Train inference error (RMSE): ±3.804502979912884\n",
      "Test MSE: 18.024\n",
      "Test inference error (RMSE): ±4.2454561672764894\n",
      "##### MLPRegressor - SGDRegressor #####\n",
      "Train MSE: 43987399941689182126908198828924880174234657675066015268346394906422992829415424.000\n",
      "Train inference error (RMSE): ±6.632299747575435e+39\n",
      "Test MSE: 47428512886234007939724395082853409749210878844309490539767972539651908222058496.000\n",
      "Test inference error (RMSE): ±6.886836202947912e+39\n",
      "##### MLPRegressor - SVR #####\n",
      "Train MSE: 14.033\n",
      "Train inference error (RMSE): ±3.7461252449640057\n",
      "Test MSE: 15.255\n",
      "Test inference error (RMSE): ±3.90571288089376\n",
      "##### MLPRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8311475210830416e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.9896875822227966e-05\n",
      "##### MLPRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.837471142063115e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.999071659398209e-05\n",
      "##### MLPRegressor - TweedieRegressor #####\n",
      "Train MSE: 14.034\n",
      "Train inference error (RMSE): ±3.746215296095841\n",
      "Test MSE: 15.159\n",
      "Test inference error (RMSE): ±3.893400697328986\n",
      "##### MultiTaskElasticNet - MultiTaskElasticNetCV #####\n",
      "Error (MultiTaskElasticNet-MultiTaskElasticNetCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - MultiTaskLasso #####\n",
      "Error (MultiTaskElasticNet-MultiTaskLasso): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - MultiTaskLassoCV #####\n",
      "Error (MultiTaskElasticNet-MultiTaskLassoCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - NuSVR #####\n",
      "Error (MultiTaskElasticNet-NuSVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskElasticNet-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskElasticNet-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PLSCanonical #####\n",
      "Error (MultiTaskElasticNet-PLSCanonical): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PLSRegression #####\n",
      "Error (MultiTaskElasticNet-PLSRegression): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskElasticNet-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - PoissonRegressor #####\n",
      "Error (MultiTaskElasticNet-PoissonRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - QuantileRegressor #####\n",
      "Error (MultiTaskElasticNet-QuantileRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RANSACRegressor #####\n",
      "Error (MultiTaskElasticNet-RANSACRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskElasticNet-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RandomForestRegressor #####\n",
      "Error (MultiTaskElasticNet-RandomForestRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - Ridge #####\n",
      "Error (MultiTaskElasticNet-Ridge): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - RidgeCV #####\n",
      "Error (MultiTaskElasticNet-RidgeCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - SGDRegressor #####\n",
      "Error (MultiTaskElasticNet-SGDRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - SVR #####\n",
      "Error (MultiTaskElasticNet-SVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TheilSenRegressor #####\n",
      "Error (MultiTaskElasticNet-TheilSenRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TransformedTargetRegressor #####\n",
      "Error (MultiTaskElasticNet-TransformedTargetRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNet - TweedieRegressor #####\n",
      "Error (MultiTaskElasticNet-TweedieRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskElasticNetCV - MultiTaskLasso #####\n",
      "Error (MultiTaskElasticNetCV-MultiTaskLasso): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - MultiTaskLassoCV #####\n",
      "Error (MultiTaskElasticNetCV-MultiTaskLassoCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - NuSVR #####\n",
      "Error (MultiTaskElasticNetCV-NuSVR): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskElasticNetCV-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskElasticNetCV-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PLSCanonical #####\n",
      "Error (MultiTaskElasticNetCV-PLSCanonical): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PLSRegression #####\n",
      "Error (MultiTaskElasticNetCV-PLSRegression): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskElasticNetCV-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - PoissonRegressor #####\n",
      "Error (MultiTaskElasticNetCV-PoissonRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - QuantileRegressor #####\n",
      "Error (MultiTaskElasticNetCV-QuantileRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RANSACRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RANSACRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RandomForestRegressor #####\n",
      "Error (MultiTaskElasticNetCV-RandomForestRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - Ridge #####\n",
      "Error (MultiTaskElasticNetCV-Ridge): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - RidgeCV #####\n",
      "Error (MultiTaskElasticNetCV-RidgeCV): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - SGDRegressor #####\n",
      "Error (MultiTaskElasticNetCV-SGDRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - SVR #####\n",
      "Error (MultiTaskElasticNetCV-SVR): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TheilSenRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TheilSenRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TransformedTargetRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TransformedTargetRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskElasticNetCV - TweedieRegressor #####\n",
      "Error (MultiTaskElasticNetCV-TweedieRegressor): For mono-task outputs, use ElasticNetCVCV\n",
      "##### MultiTaskLasso - MultiTaskLassoCV #####\n",
      "Error (MultiTaskLasso-MultiTaskLassoCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - NuSVR #####\n",
      "Error (MultiTaskLasso-NuSVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskLasso-OrthogonalMatchingPursuit): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskLasso-OrthogonalMatchingPursuitCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PLSCanonical #####\n",
      "Error (MultiTaskLasso-PLSCanonical): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PLSRegression #####\n",
      "Error (MultiTaskLasso-PLSRegression): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskLasso-PassiveAggressiveRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - PoissonRegressor #####\n",
      "Error (MultiTaskLasso-PoissonRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - QuantileRegressor #####\n",
      "Error (MultiTaskLasso-QuantileRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RANSACRegressor #####\n",
      "Error (MultiTaskLasso-RANSACRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskLasso-RadiusNeighborsRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RandomForestRegressor #####\n",
      "Error (MultiTaskLasso-RandomForestRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - Ridge #####\n",
      "Error (MultiTaskLasso-Ridge): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - RidgeCV #####\n",
      "Error (MultiTaskLasso-RidgeCV): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - SGDRegressor #####\n",
      "Error (MultiTaskLasso-SGDRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - SVR #####\n",
      "Error (MultiTaskLasso-SVR): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TheilSenRegressor #####\n",
      "Error (MultiTaskLasso-TheilSenRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TransformedTargetRegressor #####\n",
      "Error (MultiTaskLasso-TransformedTargetRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLasso - TweedieRegressor #####\n",
      "Error (MultiTaskLasso-TweedieRegressor): For mono-task outputs, use ElasticNet\n",
      "##### MultiTaskLassoCV - NuSVR #####\n",
      "Error (MultiTaskLassoCV-NuSVR): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - OrthogonalMatchingPursuit #####\n",
      "Error (MultiTaskLassoCV-OrthogonalMatchingPursuit): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - OrthogonalMatchingPursuitCV #####\n",
      "Error (MultiTaskLassoCV-OrthogonalMatchingPursuitCV): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PLSCanonical #####\n",
      "Error (MultiTaskLassoCV-PLSCanonical): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PLSRegression #####\n",
      "Error (MultiTaskLassoCV-PLSRegression): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PassiveAggressiveRegressor #####\n",
      "Error (MultiTaskLassoCV-PassiveAggressiveRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - PoissonRegressor #####\n",
      "Error (MultiTaskLassoCV-PoissonRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - QuantileRegressor #####\n",
      "Error (MultiTaskLassoCV-QuantileRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RANSACRegressor #####\n",
      "Error (MultiTaskLassoCV-RANSACRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RadiusNeighborsRegressor #####\n",
      "Error (MultiTaskLassoCV-RadiusNeighborsRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RandomForestRegressor #####\n",
      "Error (MultiTaskLassoCV-RandomForestRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - Ridge #####\n",
      "Error (MultiTaskLassoCV-Ridge): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - RidgeCV #####\n",
      "Error (MultiTaskLassoCV-RidgeCV): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - SGDRegressor #####\n",
      "Error (MultiTaskLassoCV-SGDRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - SVR #####\n",
      "Error (MultiTaskLassoCV-SVR): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TheilSenRegressor #####\n",
      "Error (MultiTaskLassoCV-TheilSenRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TransformedTargetRegressor #####\n",
      "Error (MultiTaskLassoCV-TransformedTargetRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### MultiTaskLassoCV - TweedieRegressor #####\n",
      "Error (MultiTaskLassoCV-TweedieRegressor): For mono-task outputs, use LassoCVCV\n",
      "##### NuSVR - OrthogonalMatchingPursuit #####\n",
      "Train MSE: 14.024\n",
      "Train inference error (RMSE): ±3.7448112041416146\n",
      "Test MSE: 15.181\n",
      "Test inference error (RMSE): ±3.8962376251358632\n",
      "##### NuSVR - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1034408112662126\n",
      "Test MSE: 1.170\n",
      "Test inference error (RMSE): ±1.0814744218497934\n",
      "##### NuSVR - PLSCanonical #####\n",
      "Error (NuSVR-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### NuSVR - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.041483963129627814\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.044061127940477715\n",
      "##### NuSVR - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.031\n",
      "Train inference error (RMSE): ±3.7457632556024927\n",
      "Test MSE: 15.228\n",
      "Test inference error (RMSE): ±3.9023222176320234\n",
      "##### NuSVR - PoissonRegressor #####\n",
      "Error (NuSVR-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### NuSVR - QuantileRegressor #####\n",
      "Train MSE: 14.009\n",
      "Train inference error (RMSE): ±3.742900770184341\n",
      "Test MSE: 15.111\n",
      "Test inference error (RMSE): ±3.8873238290325545\n",
      "##### NuSVR - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.840794442260117e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.002074462469415e-05\n",
      "##### NuSVR - RadiusNeighborsRegressor #####\n",
      "Error (NuSVR-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### NuSVR - RandomForestRegressor #####\n",
      "Train MSE: 0.211\n",
      "Train inference error (RMSE): ±0.4598694340016435\n",
      "Test MSE: 1.518\n",
      "Test inference error (RMSE): ±1.2320106339656072\n",
      "##### NuSVR - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014945780185625706\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016235520784801118\n",
      "##### NuSVR - RidgeCV #####\n",
      "Train MSE: 14.455\n",
      "Train inference error (RMSE): ±3.8019924127303333\n",
      "Test MSE: 17.858\n",
      "Test inference error (RMSE): ±4.225926649289289\n",
      "##### NuSVR - SGDRegressor #####\n",
      "Train MSE: 110493207105316931698335078557856244369188525820008803110758115636466709889548288.000\n",
      "Train inference error (RMSE): ±1.051157491079795e+40\n",
      "Test MSE: 111081373494714534475801213325333376151451921796114694268239372999222818284503040.000\n",
      "Test inference error (RMSE): ±1.0539514860500673e+40\n",
      "##### NuSVR - SVR #####\n",
      "Train MSE: 14.029\n",
      "Train inference error (RMSE): ±3.7455573790220336\n",
      "Test MSE: 15.216\n",
      "Test inference error (RMSE): ±3.9007947682065773\n",
      "##### NuSVR - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.840804505042036e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.002507167253367e-05\n",
      "##### NuSVR - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.840794442260117e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.002074462469415e-05\n",
      "##### NuSVR - TweedieRegressor #####\n",
      "Train MSE: 14.028\n",
      "Train inference error (RMSE): ±3.745393724787505\n",
      "Test MSE: 15.205\n",
      "Test inference error (RMSE): ±3.8993477955384077\n",
      "##### OrthogonalMatchingPursuit - OrthogonalMatchingPursuitCV #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1034690694995755\n",
      "Test MSE: 1.175\n",
      "Test inference error (RMSE): ±1.083766167510313\n",
      "##### OrthogonalMatchingPursuit - PLSCanonical #####\n",
      "Error (OrthogonalMatchingPursuit-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### OrthogonalMatchingPursuit - PLSRegression #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.042291511362895794\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04851184822386144\n",
      "##### OrthogonalMatchingPursuit - PassiveAggressiveRegressor #####\n",
      "Train MSE: 14.024\n",
      "Train inference error (RMSE): ±3.7448437518179527\n",
      "Test MSE: 15.141\n",
      "Test inference error (RMSE): ±3.891128832087316\n",
      "##### OrthogonalMatchingPursuit - PoissonRegressor #####\n",
      "Error (OrthogonalMatchingPursuit-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### OrthogonalMatchingPursuit - QuantileRegressor #####\n",
      "Train MSE: 14.010\n",
      "Train inference error (RMSE): ±3.7430416736680177\n",
      "Test MSE: 15.112\n",
      "Test inference error (RMSE): ±3.8873953671098787\n",
      "##### OrthogonalMatchingPursuit - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830247815825525e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.9849630769381264e-05\n",
      "##### OrthogonalMatchingPursuit - RadiusNeighborsRegressor #####\n",
      "Error (OrthogonalMatchingPursuit-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### OrthogonalMatchingPursuit - RandomForestRegressor #####\n",
      "Train MSE: 0.211\n",
      "Train inference error (RMSE): ±0.45959252903737324\n",
      "Test MSE: 1.586\n",
      "Test inference error (RMSE): ±1.2592299701474403\n",
      "##### OrthogonalMatchingPursuit - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014853245307978823\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001508710421976814\n",
      "##### OrthogonalMatchingPursuit - RidgeCV #####\n",
      "Train MSE: 14.421\n",
      "Train inference error (RMSE): ±3.7975176652174\n",
      "Test MSE: 17.618\n",
      "Test inference error (RMSE): ±4.197360283873274\n",
      "##### OrthogonalMatchingPursuit - SGDRegressor #####\n",
      "Train MSE: 189777378453660132941545724935084599910006037831762981995216937026233755555069952.000\n",
      "Train inference error (RMSE): ±1.377597105302055e+40\n",
      "Test MSE: 192527632153116874659933530166741576674002342333680154910801328571888717057228800.000\n",
      "Test inference error (RMSE): ±1.3875432683455924e+40\n",
      "##### OrthogonalMatchingPursuit - SVR #####\n",
      "Train MSE: 14.022\n",
      "Train inference error (RMSE): ±3.744636795996777\n",
      "Test MSE: 15.177\n",
      "Test inference error (RMSE): ±3.8957094006233084\n",
      "##### OrthogonalMatchingPursuit - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8303083565643685e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.985389232392255e-05\n",
      "##### OrthogonalMatchingPursuit - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830247815825525e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.9849630769381264e-05\n",
      "##### OrthogonalMatchingPursuit - TweedieRegressor #####\n",
      "Train MSE: 14.013\n",
      "Train inference error (RMSE): ±3.743400254407096\n",
      "Test MSE: 15.124\n",
      "Test inference error (RMSE): ±3.888993678969799\n",
      "##### OrthogonalMatchingPursuitCV - PLSCanonical #####\n",
      "Error (OrthogonalMatchingPursuitCV-PLSCanonical): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### OrthogonalMatchingPursuitCV - PLSRegression #####\n",
      "Train MSE: 0.001\n",
      "Train inference error (RMSE): ±0.03211704760531494\n",
      "Test MSE: 0.001\n",
      "Test inference error (RMSE): ±0.03499306737369095\n",
      "##### OrthogonalMatchingPursuitCV - PassiveAggressiveRegressor #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1034424675993166\n",
      "Test MSE: 1.167\n",
      "Test inference error (RMSE): ±1.0802852521005022\n",
      "##### OrthogonalMatchingPursuitCV - PoissonRegressor #####\n",
      "Error (OrthogonalMatchingPursuitCV-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### OrthogonalMatchingPursuitCV - QuantileRegressor #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.103451866760137\n",
      "Test MSE: 1.172\n",
      "Test inference error (RMSE): ±1.0826755587855492\n",
      "##### OrthogonalMatchingPursuitCV - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012775212994565566\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012515370407002784\n",
      "##### OrthogonalMatchingPursuitCV - RadiusNeighborsRegressor #####\n",
      "Error (OrthogonalMatchingPursuitCV-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### OrthogonalMatchingPursuitCV - RandomForestRegressor #####\n",
      "Train MSE: 0.486\n",
      "Train inference error (RMSE): ±0.697068951054365\n",
      "Test MSE: 1.037\n",
      "Test inference error (RMSE): ±1.0185351723371672\n",
      "##### OrthogonalMatchingPursuitCV - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015029210323836606\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001641691530796797\n",
      "##### OrthogonalMatchingPursuitCV - RidgeCV #####\n",
      "Train MSE: 1.394\n",
      "Train inference error (RMSE): ±1.1805718820203301\n",
      "Test MSE: 2.011\n",
      "Test inference error (RMSE): ±1.4180249684858852\n",
      "##### OrthogonalMatchingPursuitCV - SGDRegressor #####\n",
      "Train MSE: 274824535622589738477932460355488087777240183568225403068789441414052594585564086272.000\n",
      "Train inference error (RMSE): ±5.242370986706203e+41\n",
      "Test MSE: 287195247475931162522343697873786512449857567948327439805385740648135109270254387200.000\n",
      "Test inference error (RMSE): ±5.359060061950521e+41\n",
      "##### OrthogonalMatchingPursuitCV - SVR #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1034322719809353\n",
      "Test MSE: 1.171\n",
      "Test inference error (RMSE): ±1.0819693000060309\n",
      "##### OrthogonalMatchingPursuitCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012775133206857335\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012515221710762353\n",
      "##### OrthogonalMatchingPursuitCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00012775212994565566\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012515370407002784\n",
      "##### OrthogonalMatchingPursuitCV - TweedieRegressor #####\n",
      "Train MSE: 1.218\n",
      "Train inference error (RMSE): ±1.1034050051736022\n",
      "Test MSE: 1.168\n",
      "Test inference error (RMSE): ±1.080775701551866\n",
      "##### PLSCanonical - PLSRegression #####\n",
      "Error (PLSCanonical-PLSRegression): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - PassiveAggressiveRegressor #####\n",
      "Error (PLSCanonical-PassiveAggressiveRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - PoissonRegressor #####\n",
      "Error (PLSCanonical-PoissonRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - QuantileRegressor #####\n",
      "Error (PLSCanonical-QuantileRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RANSACRegressor #####\n",
      "Error (PLSCanonical-RANSACRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RadiusNeighborsRegressor #####\n",
      "Error (PLSCanonical-RadiusNeighborsRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RandomForestRegressor #####\n",
      "Error (PLSCanonical-RandomForestRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - Ridge #####\n",
      "Error (PLSCanonical-Ridge): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - RidgeCV #####\n",
      "Error (PLSCanonical-RidgeCV): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - SGDRegressor #####\n",
      "Error (PLSCanonical-SGDRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - SVR #####\n",
      "Error (PLSCanonical-SVR): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TheilSenRegressor #####\n",
      "Error (PLSCanonical-TheilSenRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TransformedTargetRegressor #####\n",
      "Error (PLSCanonical-TransformedTargetRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSCanonical - TweedieRegressor #####\n",
      "Error (PLSCanonical-TweedieRegressor): `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\n",
      "##### PLSRegression - PassiveAggressiveRegressor #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04234096738849266\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.041360317773423444\n",
      "##### PLSRegression - PoissonRegressor #####\n",
      "Error (PLSRegression-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PLSRegression - QuantileRegressor #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04180618970204635\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.045957267076745516\n",
      "##### PLSRegression - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014550247072741952\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015445437381694524\n",
      "##### PLSRegression - RadiusNeighborsRegressor #####\n",
      "Error (PLSRegression-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### PLSRegression - RandomForestRegressor #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.039372698410299965\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04045855628681459\n",
      "##### PLSRegression - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0019243392714228204\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0019379847674628433\n",
      "##### PLSRegression - RidgeCV #####\n",
      "Train MSE: 0.004\n",
      "Train inference error (RMSE): ±0.05925830319404502\n",
      "Test MSE: 0.013\n",
      "Test inference error (RMSE): ±0.11614290812798618\n",
      "##### PLSRegression - SGDRegressor #####\n",
      "Train MSE: 915260417436462628409159838565770547738771653905532835098740572341462976273045258240.000\n",
      "Train inference error (RMSE): ±9.566924361760486e+41\n",
      "Test MSE: 960511481948942273286000963507856960977688457423649490995733609510303611005003890688.000\n",
      "Test inference error (RMSE): ±9.800568768948782e+41\n",
      "##### PLSRegression - SVR #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04148999452209771\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.04413077981851264\n",
      "##### PLSRegression - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014550234678385003\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015445584365446898\n",
      "##### PLSRegression - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014550247072741952\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015445437381694524\n",
      "##### PLSRegression - TweedieRegressor #####\n",
      "Train MSE: 0.002\n",
      "Train inference error (RMSE): ±0.04148521192233007\n",
      "Test MSE: 0.002\n",
      "Test inference error (RMSE): ±0.044050844113428037\n",
      "##### PassiveAggressiveRegressor - PoissonRegressor #####\n",
      "Error (PassiveAggressiveRegressor-PoissonRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PassiveAggressiveRegressor - QuantileRegressor #####\n",
      "Train MSE: 14.012\n",
      "Train inference error (RMSE): ±3.7432620907076406\n",
      "Test MSE: 15.121\n",
      "Test inference error (RMSE): ±3.8885303730361764\n",
      "##### PassiveAggressiveRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.831114647193286e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.98968774241301e-05\n",
      "##### PassiveAggressiveRegressor - RadiusNeighborsRegressor #####\n",
      "Error (PassiveAggressiveRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### PassiveAggressiveRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.213\n",
      "Train inference error (RMSE): ±0.46185865199538345\n",
      "Test MSE: 1.524\n",
      "Test inference error (RMSE): ±1.2343839904737144\n",
      "##### PassiveAggressiveRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015060602537540562\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016984013577122767\n",
      "##### PassiveAggressiveRegressor - RidgeCV #####\n",
      "Train MSE: 14.472\n",
      "Train inference error (RMSE): ±3.8042059159081036\n",
      "Test MSE: 18.111\n",
      "Test inference error (RMSE): ±4.255751916256659\n",
      "##### PassiveAggressiveRegressor - SGDRegressor #####\n",
      "Train MSE: 181145076687976354132317461440305296241851620645106189860371857620408379644051456.000\n",
      "Train inference error (RMSE): ±1.3459014699745906e+40\n",
      "Test MSE: 187023120565426187399166620895524365522399235747498854860657734361310036756529152.000\n",
      "Test inference error (RMSE): ±1.3675639676644973e+40\n",
      "##### PassiveAggressiveRegressor - SVR #####\n",
      "Train MSE: 14.101\n",
      "Train inference error (RMSE): ±3.755195293169928\n",
      "Test MSE: 15.115\n",
      "Test inference error (RMSE): ±3.887852807628686\n",
      "##### PassiveAggressiveRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.845690291542044e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.977384107925131e-05\n",
      "##### PassiveAggressiveRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.83381685076354e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.9878869126325346e-05\n",
      "##### PassiveAggressiveRegressor - TweedieRegressor #####\n",
      "Train MSE: 14.028\n",
      "Train inference error (RMSE): ±3.745390759548945\n",
      "Test MSE: 15.190\n",
      "Test inference error (RMSE): ±3.897376930193054\n",
      "##### PoissonRegressor - QuantileRegressor #####\n",
      "Error (PoissonRegressor-QuantileRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RANSACRegressor #####\n",
      "Error (PoissonRegressor-RANSACRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RadiusNeighborsRegressor #####\n",
      "Error (PoissonRegressor-RadiusNeighborsRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RandomForestRegressor #####\n",
      "Error (PoissonRegressor-RandomForestRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - Ridge #####\n",
      "Error (PoissonRegressor-Ridge): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - RidgeCV #####\n",
      "Error (PoissonRegressor-RidgeCV): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - SGDRegressor #####\n",
      "Error (PoissonRegressor-SGDRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - SVR #####\n",
      "Error (PoissonRegressor-SVR): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TheilSenRegressor #####\n",
      "Error (PoissonRegressor-TheilSenRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TransformedTargetRegressor #####\n",
      "Error (PoissonRegressor-TransformedTargetRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### PoissonRegressor - TweedieRegressor #####\n",
      "Error (PoissonRegressor-TweedieRegressor): Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "##### QuantileRegressor - RANSACRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830846339941456e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.978756515425062e-05\n",
      "##### QuantileRegressor - RadiusNeighborsRegressor #####\n",
      "Error (QuantileRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### QuantileRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.215\n",
      "Train inference error (RMSE): ±0.4638861312608926\n",
      "Test MSE: 1.534\n",
      "Test inference error (RMSE): ±1.2383528878294954\n",
      "##### QuantileRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014913155472793668\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0015159507094416073\n",
      "##### QuantileRegressor - RidgeCV #####\n",
      "Train MSE: 14.280\n",
      "Train inference error (RMSE): ±3.778912435270973\n",
      "Test MSE: 16.737\n",
      "Test inference error (RMSE): ±4.091057679649319\n",
      "##### QuantileRegressor - SGDRegressor #####\n",
      "Train MSE: 6952800264984810875806448553257928315115664619023995520672926701359322361623478272.000\n",
      "Train inference error (RMSE): ±8.33834531845786e+40\n",
      "Test MSE: 7214277155169928941787257242488285685305269381903475990752983185794562719110660096.000\n",
      "Test inference error (RMSE): ±8.493690102169922e+40\n",
      "##### QuantileRegressor - SVR #####\n",
      "Train MSE: 14.012\n",
      "Train inference error (RMSE): ±3.7431999774767526\n",
      "Test MSE: 15.118\n",
      "Test inference error (RMSE): ±3.8882056483316476\n",
      "##### QuantileRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8305360393280994e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.978427911181662e-05\n",
      "##### QuantileRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.830846339941456e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±3.978756515425062e-05\n",
      "##### QuantileRegressor - TweedieRegressor #####\n",
      "Train MSE: 14.009\n",
      "Train inference error (RMSE): ±3.7429046134473403\n",
      "Test MSE: 15.114\n",
      "Test inference error (RMSE): ±3.887664930101749\n",
      "##### RANSACRegressor - RadiusNeighborsRegressor #####\n",
      "Error (RANSACRegressor-RadiusNeighborsRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RANSACRegressor - RandomForestRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.853902255100985e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012827677975633717\n",
      "##### RANSACRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.00074745439254676\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0008174756697928903\n",
      "##### RANSACRegressor - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.883287188998849e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.280763048493746e-05\n",
      "##### RANSACRegressor - SGDRegressor #####\n",
      "Train MSE: 4681580280328847379184351376173786500735974160682814511179338282872117932243025920.000\n",
      "Train inference error (RMSE): ±6.842207451056163e+40\n",
      "Test MSE: 4130003011846933738508963856701409071021674478784334484737988988181490458005864448.000\n",
      "Test inference error (RMSE): ±6.42650994852333e+40\n",
      "##### RANSACRegressor - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.841575317211714e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.004169811805276e-05\n",
      "##### RANSACRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.915666653140612e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9943242589135278e-05\n",
      "##### RANSACRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.915368081375861e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9938889004952374e-05\n",
      "##### RANSACRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842506423697025e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000024256480227e-05\n",
      "##### RadiusNeighborsRegressor - RandomForestRegressor #####\n",
      "Error (RadiusNeighborsRegressor-RandomForestRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - Ridge #####\n",
      "Error (RadiusNeighborsRegressor-Ridge): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - RidgeCV #####\n",
      "Error (RadiusNeighborsRegressor-RidgeCV): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - SGDRegressor #####\n",
      "Error (RadiusNeighborsRegressor-SGDRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - SVR #####\n",
      "Error (RadiusNeighborsRegressor-SVR): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TheilSenRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TheilSenRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TransformedTargetRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TransformedTargetRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RadiusNeighborsRegressor - TweedieRegressor #####\n",
      "Error (RadiusNeighborsRegressor-TweedieRegressor): Input X contains NaN.\n",
      "_RidgeGCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "##### RandomForestRegressor - Ridge #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0015748586344709453\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016451702204245823\n",
      "##### RandomForestRegressor - RidgeCV #####\n",
      "Train MSE: 0.223\n",
      "Train inference error (RMSE): ±0.4718854178070255\n",
      "Test MSE: 1.420\n",
      "Test inference error (RMSE): ±1.1914896575738199\n",
      "##### RandomForestRegressor - SGDRegressor #####\n",
      "Train MSE: 259597040545765201714704538811283042811462971877365715450573245326356710257508483072.000\n",
      "Train inference error (RMSE): ±5.095066638874954e+41\n",
      "Test MSE: 267152266572068963789368896884644599448497149433968990820698788311358967915330142208.000\n",
      "Test inference error (RMSE): ±5.168677457261857e+41\n",
      "##### RandomForestRegressor - SVR #####\n",
      "Train MSE: 0.204\n",
      "Train inference error (RMSE): ±0.45119695845443797\n",
      "Test MSE: 1.497\n",
      "Test inference error (RMSE): ±1.2234338181885398\n",
      "##### RandomForestRegressor - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.807262123249003e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0001294146190235328\n",
      "##### RandomForestRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±4.702101803926537e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.00012668655790812499\n",
      "##### RandomForestRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.219\n",
      "Train inference error (RMSE): ±0.46751370581733054\n",
      "Test MSE: 1.484\n",
      "Test inference error (RMSE): ±1.2181435510707292\n",
      "##### Ridge - RidgeCV #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001647533406690656\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.002398459576835671\n",
      "##### Ridge - SGDRegressor #####\n",
      "Train MSE: 4005325478499620197508613932191747037773399424374771055308424445608960080028226289664.000\n",
      "Train inference error (RMSE): ±2.0013309267833793e+42\n",
      "Test MSE: 4161486826504019939420257149567471563885738067086368091849028438258760808061424631808.000\n",
      "Test inference error (RMSE): ±2.0399722612094557e+42\n",
      "##### Ridge - SVR #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0014944807677811985\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.001620316781604981\n",
      "##### Ridge - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007474544814895\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0008174677959055713\n",
      "##### Ridge - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.0007474543766196437\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0008174756542404718\n",
      "##### Ridge - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±0.001495977481397325\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±0.0016367170558851444\n",
      "##### RidgeCV - SGDRegressor #####\n",
      "Train MSE: 581107823173466623183035140460723333469721280987938517225211890360667980431360.000\n",
      "Train inference error (RMSE): ±7.623042851601102e+38\n",
      "Test MSE: 590517953103318104190055050420819790942498177002968947765559704477118314315776.000\n",
      "Test inference error (RMSE): ±7.68451659574835e+38\n",
      "##### RidgeCV - SVR #####\n",
      "Train MSE: 14.436\n",
      "Train inference error (RMSE): ±3.799486734120981\n",
      "Test MSE: 17.738\n",
      "Test inference error (RMSE): ±4.211704364984501\n",
      "##### RidgeCV - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.88497831379744e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.293458010348492e-05\n",
      "##### RidgeCV - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.8999366857946484e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.373637172626664e-05\n",
      "##### RidgeCV - TweedieRegressor #####\n",
      "Train MSE: 14.437\n",
      "Train inference error (RMSE): ±3.7995718268314786\n",
      "Test MSE: 17.715\n",
      "Test inference error (RMSE): ±4.208910476064284\n",
      "##### SGDRegressor - SVR #####\n",
      "Train MSE: 64861931953551647305213005806620278158283797824491577223277895201546807845847040.000\n",
      "Train inference error (RMSE): ±8.053690579700194e+39\n",
      "Test MSE: 67755483678879971317222516278126673384691487149326716983399006183145130021617664.000\n",
      "Test inference error (RMSE): ±8.23137191960611e+39\n",
      "##### SGDRegressor - TheilSenRegressor #####\n",
      "Train MSE: 711117792700245391361842872819964664962106945478425997009273635893723934603870208.000\n",
      "Train inference error (RMSE): ±2.6666791946168654e+40\n",
      "Test MSE: 339062755004158526324432383290550883574543717036873149922999281092728208073162752.000\n",
      "Test inference error (RMSE): ±1.841365675264309e+40\n",
      "##### SGDRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 105086411960049781290491654537899738927608404126960151521180081244133251548935356416.000\n",
      "Train inference error (RMSE): ±3.2417034404777032e+41\n",
      "Test MSE: 107704395888053834626914609141158093543275802216925417109522662776353355624892858368.000\n",
      "Test inference error (RMSE): ±3.281834789992541e+41\n",
      "##### SGDRegressor - TweedieRegressor #####\n",
      "Train MSE: 10051188432633551351517158445306075137584576197511691843218093636705796641989328896.000\n",
      "Train inference error (RMSE): ±1.0025561546683334e+41\n",
      "Test MSE: 10512767374230237616674736227452469667267100568633689540432770329627798929970036736.000\n",
      "Test inference error (RMSE): ±1.025317871405265e+41\n",
      "##### SVR - TheilSenRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.841586900222071e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.0038067866099884e-05\n",
      "##### SVR - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.841559735108071e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.0041535930164835e-05\n",
      "##### SVR - TweedieRegressor #####\n",
      "Train MSE: 14.029\n",
      "Train inference error (RMSE): ±3.7454776876649873\n",
      "Test MSE: 15.212\n",
      "Test inference error (RMSE): ±3.9002214812464504\n",
      "##### TheilSenRegressor - TransformedTargetRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±1.9153141705222546e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±1.9934203377083247e-05\n",
      "##### TheilSenRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842584713714041e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000537147036678e-05\n",
      "##### TransformedTargetRegressor - TweedieRegressor #####\n",
      "Train MSE: 0.000\n",
      "Train inference error (RMSE): ±3.842506423697025e-05\n",
      "Test MSE: 0.000\n",
      "Test inference error (RMSE): ±4.000024256480227e-05\n",
      "########## Best Estimator ##########\n",
      "['BayesianRidge-TheilSenRegressor', 3.9735505302514424e-10, 1.9933766654226296e-05]\n",
      "Total time: 368.59308886528015\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimators_stacked_trained, best_staked_estimator_name = run_sklearn_estimators_with_stacking(\n",
    "    all_estimators,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    model_type\n",
    ")\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b0d684-33bf-419b-b59d-4c171e29b1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;BayesianRidge&#x27;, BayesianRidge()),\n",
       "                              (&#x27;TheilSenRegressor&#x27;, TheilSenRegressor())],\n",
       "                  final_estimator=RidgeCV())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingRegressor.html\">?<span>Documentation for StackingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingRegressor(estimators=[(&#x27;BayesianRidge&#x27;, BayesianRidge()),\n",
       "                              (&#x27;TheilSenRegressor&#x27;, TheilSenRegressor())],\n",
       "                  final_estimator=RidgeCV())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>BayesianRidge</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesianRidge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.BayesianRidge.html\">?<span>Documentation for BayesianRidge</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>BayesianRidge()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>TheilSenRegressor</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TheilSenRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.TheilSenRegressor.html\">?<span>Documentation for TheilSenRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TheilSenRegressor()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RidgeCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.RidgeCV.html\">?<span>Documentation for RidgeCV</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RidgeCV()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('BayesianRidge', BayesianRidge()),\n",
       "                              ('TheilSenRegressor', TheilSenRegressor())],\n",
       "                  final_estimator=RidgeCV())"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_stacked_trained[best_staked_estimator_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a42d4-3bad-4a1c-a8c9-dee86bc52bb5",
   "metadata": {},
   "source": [
    "### Save Estimator staked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32120e1f-2db5-41c8-b53f-2dc4588c3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(estimators_trained[best_estimator_name], open('results/estimator_sklearn_stacked.sav', 'wb'))\n",
    "\n",
    "# Scaler\n",
    "pickle.dump(scaler, open('results/scaler.pkl','wb'))\n",
    "\n",
    "# Save columns names and informations\n",
    "data_to_save = {\n",
    "    'col_names_order': col_names_order,\n",
    "    'num_col_names': num_col_names,\n",
    "    'cat_col_names': cat_col_names,\n",
    "    'date_col_names': date_col_names,\n",
    "    'target_cols': target_cols,\n",
    "    'category_mappings': category_mappings,\n",
    "    'window_size': window_size\n",
    "}\n",
    "with open('results/columns_metadata_sklearn_stacked.json', 'w') as json_file:\n",
    "    json.dump(data_to_save, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538ba71-15e3-42db-a526-cb376135a073",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c843071-fc93-45c4-bca3-a1fd36a7fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43724cc0-8d03-4e8e-a4d4-4a0eefb8a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "loaded_estimator = pickle.load(open('results/estimator_sklearn_stacked.sav', 'rb'))\n",
    "# Scaler\n",
    "loaded_scaler = pickle.load(open('results/scaler.pkl','rb'))\n",
    "# columns_metadata\n",
    "columns_metadata = json.load(open('results/columns_metadata_sklearn_stacked.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1ef45e9-aa23-4ce3-819f-d6e4081582c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inference_data(new_input, columns_metadata, scaler=None):\n",
    "    \"\"\"\n",
    "    Preprocess the input data for inference based on metadata and scaler for numeric normalization.\n",
    "\n",
    "    Args:\n",
    "        new_input (list of list): Data to preprocess (each inner list is a row).\n",
    "        columns_metadata (dict): Metadata defining column names, types, mappings, and order.\n",
    "        scaler (StandardScaler): Trained scaler for numerical columns.\n",
    "    \n",
    "    Returns:\n",
    "        list: Preprocessed data ready for inference.\n",
    "    \"\"\"\n",
    "    # Exclude target columns from col_names_order for inference\n",
    "    target_cols = columns_metadata['target_cols']\n",
    "    col_names_order = [col for col in columns_metadata['col_names_order'] if col not in target_cols]\n",
    "    # Transform the new_input into a DataFrame with the correct column order\n",
    "    df_input = pd.DataFrame(new_input, columns=col_names_order)\n",
    "\n",
    "    # Convert categorical columns based on category_mappings\n",
    "    category_mappings = columns_metadata['category_mappings']\n",
    "    for col in columns_metadata['cat_col_names']:\n",
    "        if col in df_input.columns and col in category_mappings:\n",
    "            # Replace string categories with mapped integer IDs\n",
    "            df_input[col] = df_input[col].map(category_mappings[col])\n",
    "            if df_input[col].isnull().any():\n",
    "                raise ValueError(f'Invalid value found in column \"{col}\" that is not in the category mappings.')\n",
    "\n",
    "    # Normalize numeric columns using the trained scaler\n",
    "    num_col_names = columns_metadata['num_col_names']\n",
    "    if num_col_names and scaler:\n",
    "        df_input[num_col_names] = scaler.transform(df_input[num_col_names])\n",
    "\n",
    "    # Ensure date columns are in the correct datetime format\n",
    "    for col in columns_metadata['date_col_names']:\n",
    "        if col in df_input.columns:\n",
    "            df_input[col] = pd.to_datetime(df_input[col], errors='coerce').astype(int) // 10**9\n",
    "            if df_input[col].isnull().any():\n",
    "                raise ValueError(f'Invalid date value found in column \"{col}\".')\n",
    "\n",
    "    # Drop target columns if they exist in the input (not used in inference)\n",
    "    target_cols = columns_metadata['target_cols']\n",
    "    df_input = df_input.drop(columns=target_cols, errors='ignore')\n",
    "\n",
    "    # Convert DataFrame to list of rows for model inference\n",
    "    processed_data = df_input.values.tolist()\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db28f2-6ac1-4d60-9dd3-eb40e4fb3d43",
   "metadata": {},
   "source": [
    "**ATENÇÃO:** Modifique a variável \"new_input\" conforme o seu dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "297367d2-2bb1-41be-a3bc-f05b8811222e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.6566259610493973,\n",
       "  -1.0020325387672895,\n",
       "  -1.54018511120959,\n",
       "  -0.8012900629047318,\n",
       "  1.0386334016719143,\n",
       "  -0.9145317195800292,\n",
       "  -0.06338586865109594,\n",
       "  1.0853784867264844,\n",
       "  1796601600.0,\n",
       "  -0.7109761886219765,\n",
       "  -0.5609894513544795,\n",
       "  1.5263017672739743,\n",
       "  -1.5620218399366994]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "new_input = [\n",
    "    [16.104017, 991.702137, 33.491679, 5.722285, 26.064810, 992.934297, 58.463331, 16.400403, '2026-12-07', 15.764825, 997.960562, 85.419949, 1.430146]\n",
    "]\n",
    "new_input_preprocessed = preprocess_inference_data(new_input, columns_metadata, loaded_scaler)\n",
    "new_input_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1adcc30-d10d-42f6-b7a6-4332800409c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.3786154]\n",
      "Total time: 0.0002663135528564453\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "print(loaded_estimator.predict(new_input_preprocessed))\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbf7e0df-f497-4ebd-9cfa-5118cbce826e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Temporal graph result\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test['data'], test['target'], marker='o', linestyle='-')\n",
    "plt.plot(test['data'], loaded_estimator.predict(x_test), marker='^', linestyle='-', label='Inferência', color='orange')\n",
    "plt.title('Real vs Predict')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Target')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
