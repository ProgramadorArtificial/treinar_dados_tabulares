{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3489c1bc-d70b-4089-a6fc-9428e959dfc3",
   "metadata": {},
   "source": [
    "# Sklearn\n",
    "Notebook pensando para facilitar e agiliar o treinamento de Machine Learning, sendo necessário, em grande parte das vezes, somente alterar o caminho do dataset e o tipo (classificador ou regressão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7227abb5-2f27-4fc4-be31-afe3a4a093ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0be3e-6a93-41aa-9ec8-0ceb6ffece8c",
   "metadata": {},
   "source": [
    "## Preparar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a81160e-461d-440f-a3ac-7869034ff805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_cols, max_unique_values=10, window_size=1):\n",
    "    \"\"\"\n",
    "    Preprocess dataset, converting string columns to number and identifying numeric, categorical, and date columns.\n",
    "    Adds a window of historical rows to the data.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame with data to analyze.\n",
    "        target_cols (list): All target columns to not add in numeric, categorical, or date feature lists.\n",
    "        max_unique_values (int): Maximum number of unique values to consider a numeric column as categorical.\n",
    "        window_size (int): Number of previous rows to include for each row.\n",
    "\n",
    "    Returns:\n",
    "        df_copy (DataFrame): Processed DataFrame with transformations applied.\n",
    "        num_col_names (list): List of numeric feature column names.\n",
    "        cat_col_names (list): List of categorical feature column names.\n",
    "        date_col_names (list): List of date feature column names.\n",
    "        mappings (dict): Mapping of original categorical values (or target columns) to transformed numeric values.\n",
    "    \"\"\"\n",
    "    # Create a copy so as not to alter the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Remove lines with null values\n",
    "    df_copy = df_copy.dropna()\n",
    "    \n",
    "    # Identify categorical and numeric columns\n",
    "    cat_col_names = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_col_names = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    date_col_names = []\n",
    "\n",
    "    # Identify columns that are dates\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['object', 'string']:  # Only check object/string columns\n",
    "            try:\n",
    "                # Attempt to convert the column to datetime\n",
    "                pd.to_datetime(df[col], errors='raise')\n",
    "                if col not in target_cols:  # Avoid considering target columns as date columns\n",
    "                    date_col_names.append(col)\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "    # Identify numeric columns that are categorical\n",
    "    potential_categorical = []\n",
    "    for col in num_col_names:\n",
    "        if col not in target_cols and df_copy[col].nunique() <= max_unique_values:\n",
    "            potential_categorical.append(col)\n",
    "\n",
    "    cat_col_names += potential_categorical\n",
    "\n",
    "    # Remove target columns from the lists\n",
    "    num_col_names = [col for col in num_col_names if col not in potential_categorical + target_cols]\n",
    "    cat_col_names = [col for col in cat_col_names if col not in target_cols]\n",
    "    \n",
    "    mappings = {}\n",
    "    label_encoders = {}\n",
    "\n",
    "    # Convert string columns to category and create a mapping (old value -> new value)\n",
    "    for col in cat_col_names + target_cols:\n",
    "        if df_copy[col].dtype not in ['int64', 'float64']:\n",
    "            le = LabelEncoder()\n",
    "            df_copy[col] = le.fit_transform(df_copy[col])\n",
    "            mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            label_encoders[col] = le\n",
    "            # Convert values to int (otherwise will raise error if save as json)\n",
    "            for key, value in mappings[col].items():\n",
    "                mappings[col][key] = int(value)\n",
    "        #else:\n",
    "        #    mappings[col] = {int(val): int(val) for val in df_copy[col].unique()}\n",
    "\n",
    "    # Add historical data based on window_size\n",
    "    if window_size > 1:\n",
    "        historical_features = []\n",
    "        for i in range(window_size - 1, 0, -1):  # Criar features lag, do mais antigo ao mais recente\n",
    "            shifted = df_copy.drop(columns=target_cols, errors='ignore').shift(i).add_suffix(f'_lag_{i}')\n",
    "            historical_features.append(shifted)\n",
    "        \n",
    "        # Concatenate the lags to the left and keep the current values\n",
    "        df_copy = pd.concat(historical_features + [df_copy], axis=1)\n",
    "    \n",
    "        # Remove NaNs columns created by shifts\n",
    "        df_copy = df_copy.dropna()\n",
    "    \n",
    "        # Add lags\n",
    "        num_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in num_col_names]\n",
    "        cat_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in cat_col_names]\n",
    "        date_col_lags = [f'{col}_lag_{i}' for i in range(window_size - 1, 0, -1) for col in date_col_names]\n",
    "        mappings_lags = {}\n",
    "        for col, value in mappings.items():\n",
    "            for i in range(window_size - 1, 0, -1):\n",
    "                mappings_lags[f'{col}_lag_{i}'] = value\n",
    "    \n",
    "        # Update main columns + lags columns\n",
    "        num_col_names = num_col_lags + num_col_names\n",
    "        cat_col_names = cat_col_lags + cat_col_names\n",
    "        date_col_names = date_col_lags + date_col_names\n",
    "        mappings = {**mappings_lags, **mappings}\n",
    "    \n",
    "    return df_copy, num_col_names, cat_col_names, date_col_names, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6dda78a0-630b-4947-8e10-a24019cf98d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.7707742797</td>\n",
       "      <td>A</td>\n",
       "      <td>129.5194433721</td>\n",
       "      <td>157.6498256906</td>\n",
       "      <td>6.2554953619</td>\n",
       "      <td>0.8285228515</td>\n",
       "      <td>1.1000000000</td>\n",
       "      <td>0.6562278492</td>\n",
       "      <td>type_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.2215353721</td>\n",
       "      <td>E</td>\n",
       "      <td>140.3040905876</td>\n",
       "      <td>216.7446469595</td>\n",
       "      <td>5.7139137854</td>\n",
       "      <td>0.3557319672</td>\n",
       "      <td>1.2000000000</td>\n",
       "      <td>0.6981205515</td>\n",
       "      <td>type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.4881898661</td>\n",
       "      <td>A</td>\n",
       "      <td>166.9523993970</td>\n",
       "      <td>312.9389445534</td>\n",
       "      <td>5.2672387340</td>\n",
       "      <td>0.9604111071</td>\n",
       "      <td>1.1000000000</td>\n",
       "      <td>0.9570049098</td>\n",
       "      <td>type_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.3211134057</td>\n",
       "      <td>E</td>\n",
       "      <td>88.3652979602</td>\n",
       "      <td>89.7272340679</td>\n",
       "      <td>6.7063765270</td>\n",
       "      <td>-0.8954943008</td>\n",
       "      <td>1.2000000000</td>\n",
       "      <td>0.7573366916</td>\n",
       "      <td>type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.5691906326</td>\n",
       "      <td>D</td>\n",
       "      <td>143.3793556875</td>\n",
       "      <td>118.9111152596</td>\n",
       "      <td>6.2425756631</td>\n",
       "      <td>1.5253087636</td>\n",
       "      <td>0.9500000000</td>\n",
       "      <td>0.9654732117</td>\n",
       "      <td>type_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>103.3689379687</td>\n",
       "      <td>B</td>\n",
       "      <td>186.3485993257</td>\n",
       "      <td>86.9300120510</td>\n",
       "      <td>5.3045163994</td>\n",
       "      <td>1.6363046648</td>\n",
       "      <td>0.9000000000</td>\n",
       "      <td>0.8372406745</td>\n",
       "      <td>type_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>90.7240623224</td>\n",
       "      <td>C</td>\n",
       "      <td>105.8582061089</td>\n",
       "      <td>332.8729377064</td>\n",
       "      <td>7.2544016853</td>\n",
       "      <td>-0.1414448793</td>\n",
       "      <td>1.0500000000</td>\n",
       "      <td>0.6630705647</td>\n",
       "      <td>type_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>93.9450816212</td>\n",
       "      <td>C</td>\n",
       "      <td>96.9209632656</td>\n",
       "      <td>134.3396033225</td>\n",
       "      <td>6.6794296726</td>\n",
       "      <td>-0.1931349811</td>\n",
       "      <td>1.0500000000</td>\n",
       "      <td>0.9851832500</td>\n",
       "      <td>type_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>49.0225508182</td>\n",
       "      <td>C</td>\n",
       "      <td>141.1951253555</td>\n",
       "      <td>138.9560400100</td>\n",
       "      <td>6.6230235483</td>\n",
       "      <td>-1.8472118518</td>\n",
       "      <td>1.0500000000</td>\n",
       "      <td>0.7187352285</td>\n",
       "      <td>type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>65.3968538022</td>\n",
       "      <td>C</td>\n",
       "      <td>169.8954135169</td>\n",
       "      <td>205.8410594826</td>\n",
       "      <td>4.3121141005</td>\n",
       "      <td>-0.0402629006</td>\n",
       "      <td>1.0500000000</td>\n",
       "      <td>0.9999621311</td>\n",
       "      <td>type_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_1 feature_2      feature_3      feature_4    feature_5  \\\n",
       "0    66.7707742797         A 129.5194433721 157.6498256906 6.2554953619   \n",
       "1    -2.2215353721         E 140.3040905876 216.7446469595 5.7139137854   \n",
       "2    77.4881898661         A 166.9523993970 312.9389445534 5.2672387340   \n",
       "3    57.3211134057         E  88.3652979602  89.7272340679 6.7063765270   \n",
       "4    36.5691906326         D 143.3793556875 118.9111152596 6.2425756631   \n",
       "..             ...       ...            ...            ...          ...   \n",
       "995 103.3689379687         B 186.3485993257  86.9300120510 5.3045163994   \n",
       "996  90.7240623224         C 105.8582061089 332.8729377064 7.2544016853   \n",
       "997  93.9450816212         C  96.9209632656 134.3396033225 6.6794296726   \n",
       "998  49.0225508182         C 141.1951253555 138.9560400100 6.6230235483   \n",
       "999  65.3968538022         C 169.8954135169 205.8410594826 4.3121141005   \n",
       "\n",
       "        feature_6    feature_7    feature_8  target  \n",
       "0    0.8285228515 1.1000000000 0.6562278492  type_4  \n",
       "1    0.3557319672 1.2000000000 0.6981205515  type_3  \n",
       "2    0.9604111071 1.1000000000 0.9570049098  type_5  \n",
       "3   -0.8954943008 1.2000000000 0.7573366916  type_3  \n",
       "4    1.5253087636 0.9500000000 0.9654732117  type_4  \n",
       "..            ...          ...          ...     ...  \n",
       "995  1.6363046648 0.9000000000 0.8372406745  type_5  \n",
       "996 -0.1414448793 1.0500000000 0.6630705647  type_5  \n",
       "997 -0.1931349811 1.0500000000 0.9851832500  type_5  \n",
       "998 -1.8472118518 1.0500000000 0.7187352285  type_3  \n",
       "999 -0.0402629006 1.0500000000 0.9999621311  type_5  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/synthetic_dataset_cat_1000.csv')\n",
    "model_type = 'classifier'  # classifier or regressor\n",
    "window_size = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "502d6196-e3f8-4683-8d12-73fcf834d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['target']\n",
    "# Aplicar o pré-processamento\n",
    "df, num_col_names, cat_col_names, date_col_names, category_mappings = preprocess_data(df, target_cols, max_unique_values=10, window_size=window_size)\n",
    "col_names_order = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a60931f8-4c85-41bc-ad1d-0ac0443fb35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.7707742797</td>\n",
       "      <td>0</td>\n",
       "      <td>129.5194433721</td>\n",
       "      <td>157.6498256906</td>\n",
       "      <td>6.2554953619</td>\n",
       "      <td>0.8285228515</td>\n",
       "      <td>1.1000000000</td>\n",
       "      <td>0.6562278492</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.2215353721</td>\n",
       "      <td>4</td>\n",
       "      <td>140.3040905876</td>\n",
       "      <td>216.7446469595</td>\n",
       "      <td>5.7139137854</td>\n",
       "      <td>0.3557319672</td>\n",
       "      <td>1.2000000000</td>\n",
       "      <td>0.6981205515</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.4881898661</td>\n",
       "      <td>0</td>\n",
       "      <td>166.9523993970</td>\n",
       "      <td>312.9389445534</td>\n",
       "      <td>5.2672387340</td>\n",
       "      <td>0.9604111071</td>\n",
       "      <td>1.1000000000</td>\n",
       "      <td>0.9570049098</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.3211134057</td>\n",
       "      <td>4</td>\n",
       "      <td>88.3652979602</td>\n",
       "      <td>89.7272340679</td>\n",
       "      <td>6.7063765270</td>\n",
       "      <td>-0.8954943008</td>\n",
       "      <td>1.2000000000</td>\n",
       "      <td>0.7573366916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.5691906326</td>\n",
       "      <td>3</td>\n",
       "      <td>143.3793556875</td>\n",
       "      <td>118.9111152596</td>\n",
       "      <td>6.2425756631</td>\n",
       "      <td>1.5253087636</td>\n",
       "      <td>0.9500000000</td>\n",
       "      <td>0.9654732117</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>103.3689379687</td>\n",
       "      <td>1</td>\n",
       "      <td>186.3485993257</td>\n",
       "      <td>86.9300120510</td>\n",
       "      <td>5.3045163994</td>\n",
       "      <td>1.6363046648</td>\n",
       "      <td>0.9000000000</td>\n",
       "      <td>0.8372406745</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>90.7240623224</td>\n",
       "      <td>2</td>\n",
       "      <td>105.8582061089</td>\n",
       "      <td>332.8729377064</td>\n",
       "      <td>7.2544016853</td>\n",
       "      <td>-0.1414448793</td>\n",
       "      <td>1.0500000000</td>\n",
       "      <td>0.6630705647</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>93.9450816212</td>\n",
       "      <td>2</td>\n",
       "      <td>96.9209632656</td>\n",
       "      <td>134.3396033225</td>\n",
       "      <td>6.6794296726</td>\n",
       "      <td>-0.1931349811</td>\n",
       "      <td>1.0500000000</td>\n",
       "      <td>0.9851832500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>49.0225508182</td>\n",
       "      <td>2</td>\n",
       "      <td>141.1951253555</td>\n",
       "      <td>138.9560400100</td>\n",
       "      <td>6.6230235483</td>\n",
       "      <td>-1.8472118518</td>\n",
       "      <td>1.0500000000</td>\n",
       "      <td>0.7187352285</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>65.3968538022</td>\n",
       "      <td>2</td>\n",
       "      <td>169.8954135169</td>\n",
       "      <td>205.8410594826</td>\n",
       "      <td>4.3121141005</td>\n",
       "      <td>-0.0402629006</td>\n",
       "      <td>1.0500000000</td>\n",
       "      <td>0.9999621311</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_1  feature_2      feature_3      feature_4    feature_5  \\\n",
       "0    66.7707742797          0 129.5194433721 157.6498256906 6.2554953619   \n",
       "1    -2.2215353721          4 140.3040905876 216.7446469595 5.7139137854   \n",
       "2    77.4881898661          0 166.9523993970 312.9389445534 5.2672387340   \n",
       "3    57.3211134057          4  88.3652979602  89.7272340679 6.7063765270   \n",
       "4    36.5691906326          3 143.3793556875 118.9111152596 6.2425756631   \n",
       "..             ...        ...            ...            ...          ...   \n",
       "995 103.3689379687          1 186.3485993257  86.9300120510 5.3045163994   \n",
       "996  90.7240623224          2 105.8582061089 332.8729377064 7.2544016853   \n",
       "997  93.9450816212          2  96.9209632656 134.3396033225 6.6794296726   \n",
       "998  49.0225508182          2 141.1951253555 138.9560400100 6.6230235483   \n",
       "999  65.3968538022          2 169.8954135169 205.8410594826 4.3121141005   \n",
       "\n",
       "        feature_6    feature_7    feature_8  target  \n",
       "0    0.8285228515 1.1000000000 0.6562278492       3  \n",
       "1    0.3557319672 1.2000000000 0.6981205515       2  \n",
       "2    0.9604111071 1.1000000000 0.9570049098       4  \n",
       "3   -0.8954943008 1.2000000000 0.7573366916       2  \n",
       "4    1.5253087636 0.9500000000 0.9654732117       3  \n",
       "..            ...          ...          ...     ...  \n",
       "995  1.6363046648 0.9000000000 0.8372406745       4  \n",
       "996 -0.1414448793 1.0500000000 0.6630705647       4  \n",
       "997 -0.1931349811 1.0500000000 0.9851832500       4  \n",
       "998 -1.8472118518 1.0500000000 0.7187352285       2  \n",
       "999 -0.0402629006 1.0500000000 0.9999621311       4  \n",
       "\n",
       "[999 rows x 9 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6911e8e8-d77e-497e-a8bc-134fdcd791fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_names_order: ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'target']\n",
      "num_col_names: ['feature_1', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_8']\n",
      "cat_col_names: ['feature_2', 'feature_7']\n",
      "date_col_names: []\n",
      "target_cols: ['target']\n",
      "category_mappings: {'feature_2': {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}, 'target': {'type_1': 0, 'type_2': 1, 'type_3': 2, 'type_4': 3, 'type_5': 4}}\n"
     ]
    }
   ],
   "source": [
    "print(f'''col_names_order: {col_names_order}\n",
    "num_col_names: {num_col_names}\n",
    "cat_col_names: {cat_col_names}\n",
    "date_col_names: {date_col_names}\n",
    "target_cols: {target_cols}\n",
    "category_mappings: {category_mappings}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed57e737-f6d9-4fe3-b38c-038d44e280bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 999 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature_1  999 non-null    float64\n",
      " 1   feature_2  999 non-null    int64  \n",
      " 2   feature_3  999 non-null    float64\n",
      " 3   feature_4  999 non-null    float64\n",
      " 4   feature_5  999 non-null    float64\n",
      " 5   feature_6  999 non-null    float64\n",
      " 6   feature_7  999 non-null    float64\n",
      " 7   feature_8  999 non-null    float64\n",
      " 8   target     999 non-null    int64  \n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 78.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eacf642-fe7f-465c-8f74-fea497c7453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0         200\n",
      "1         200\n",
      "2         200\n",
      "3         200\n",
      "4         199\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if model_type == 'classifier':\n",
    "    print(df[target_cols].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fffec-dfee-49f8-815d-3fc5c94a51c1",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8adfa6d0-8dee-468c-8c3b-b00ab8a204a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e972c845-197d-4055-bfb0-641a680b9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[target_cols]\n",
    "x_train = train.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4b2e59-7601-42ad-bf06-f2a4982a7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[target_cols]\n",
    "x_test = test.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee0910a-7f2d-4009-9b66-67bdd31fc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7ec3c7-e375-40d3-8a2c-663157d552e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skelarn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeca4cce-663a-43b1-8539-37ccc4f433ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>77.315169</td>\n",
       "      <td>2</td>\n",
       "      <td>88.579018</td>\n",
       "      <td>319.710140</td>\n",
       "      <td>5.962173</td>\n",
       "      <td>-1.541202</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.080516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>76.385535</td>\n",
       "      <td>4</td>\n",
       "      <td>199.757113</td>\n",
       "      <td>260.694707</td>\n",
       "      <td>6.565209</td>\n",
       "      <td>-0.026903</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.999432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15.731042</td>\n",
       "      <td>2</td>\n",
       "      <td>56.875552</td>\n",
       "      <td>124.204462</td>\n",
       "      <td>6.695920</td>\n",
       "      <td>1.932574</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.283560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>10.050194</td>\n",
       "      <td>4</td>\n",
       "      <td>96.372959</td>\n",
       "      <td>76.846148</td>\n",
       "      <td>5.796292</td>\n",
       "      <td>1.889467</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.937108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>93.095994</td>\n",
       "      <td>4</td>\n",
       "      <td>81.020364</td>\n",
       "      <td>351.416083</td>\n",
       "      <td>7.221696</td>\n",
       "      <td>1.911871</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.994299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>17.257347</td>\n",
       "      <td>2</td>\n",
       "      <td>169.329248</td>\n",
       "      <td>84.846722</td>\n",
       "      <td>6.611299</td>\n",
       "      <td>-1.463970</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.502549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>88.104266</td>\n",
       "      <td>2</td>\n",
       "      <td>185.927139</td>\n",
       "      <td>149.604856</td>\n",
       "      <td>6.335173</td>\n",
       "      <td>-1.190243</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.320141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>34.302048</td>\n",
       "      <td>5</td>\n",
       "      <td>110.786530</td>\n",
       "      <td>202.335930</td>\n",
       "      <td>6.480678</td>\n",
       "      <td>-1.631086</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.305090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>72.366015</td>\n",
       "      <td>4</td>\n",
       "      <td>187.903474</td>\n",
       "      <td>138.212407</td>\n",
       "      <td>6.465393</td>\n",
       "      <td>-0.848563</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.007499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>23.207490</td>\n",
       "      <td>4</td>\n",
       "      <td>122.077783</td>\n",
       "      <td>98.748634</td>\n",
       "      <td>6.148170</td>\n",
       "      <td>-0.032532</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.288537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_1  feature_2   feature_3   feature_4  feature_5  feature_6  \\\n",
       "729  77.315169          2   88.579018  319.710140   5.962173  -1.541202   \n",
       "631  76.385535          4  199.757113  260.694707   6.565209  -0.026903   \n",
       "395  15.731042          2   56.875552  124.204462   6.695920   1.932574   \n",
       "778  10.050194          4   96.372959   76.846148   5.796292   1.889467   \n",
       "599  93.095994          4   81.020364  351.416083   7.221696   1.911871   \n",
       "..         ...        ...         ...         ...        ...        ...   \n",
       "106  17.257347          2  169.329248   84.846722   6.611299  -1.463970   \n",
       "270  88.104266          2  185.927139  149.604856   6.335173  -1.190243   \n",
       "861  34.302048          5  110.786530  202.335930   6.480678  -1.631086   \n",
       "436  72.366015          4  187.903474  138.212407   6.465393  -0.848563   \n",
       "102  23.207490          4  122.077783   98.748634   6.148170  -0.032532   \n",
       "\n",
       "     feature_7  feature_8  \n",
       "729       1.05   0.080516  \n",
       "631       1.20   0.999432  \n",
       "395       1.05   1.283560  \n",
       "778       1.20   0.937108  \n",
       "599       1.20   0.994299  \n",
       "..         ...        ...  \n",
       "106       1.05   0.502549  \n",
       "270       1.05   0.320141  \n",
       "861       0.85   0.305090  \n",
       "436       1.20   0.007499  \n",
       "102       1.20   0.288537  \n",
       "\n",
       "[699 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bddd440-aac8-4616-94fa-22e859de77ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9137412366505652,\n",
       "  2.0,\n",
       "  -0.3442244422028869,\n",
       "  1.6170950170689913,\n",
       "  -0.07154072695582632,\n",
       "  -1.5466467378205833,\n",
       "  1.05,\n",
       "  -1.73008077310345],\n",
       " [0.8821999533148237,\n",
       "  4.0,\n",
       "  1.6373368534551567,\n",
       "  1.0265886204199564,\n",
       "  0.5767544485776073,\n",
       "  -0.035046213212481865,\n",
       "  1.2,\n",
       "  1.0767357448652082],\n",
       " [-1.175729614208871,\n",
       "  2.0,\n",
       "  -0.9092850511921601,\n",
       "  -0.3391281043259055,\n",
       "  0.7172762681361885,\n",
       "  1.9209380476851483,\n",
       "  1.05,\n",
       "  1.9446006842976316],\n",
       " [-1.3684735128810557,\n",
       "  4.0,\n",
       "  -0.2053106413705183,\n",
       "  -0.8129937742181641,\n",
       "  -0.2498708095289632,\n",
       "  1.877908521770101,\n",
       "  1.2,\n",
       "  0.8863692185763542],\n",
       " [1.4491644891918491,\n",
       "  4.0,\n",
       "  -0.47894465235372086,\n",
       "  1.934343604432471,\n",
       "  1.2825124220724713,\n",
       "  1.9002719200668665,\n",
       "  1.2,\n",
       "  1.0610568868699743],\n",
       " [0.09627214936025551,\n",
       "  5.0,\n",
       "  0.33783680513179704,\n",
       "  -1.117308792853592,\n",
       "  -0.49997994753399383,\n",
       "  0.06732065420646137,\n",
       "  0.85,\n",
       "  0.021880567054821075],\n",
       " [-1.1074177522664461,\n",
       "  5.0,\n",
       "  -0.4288590256987593,\n",
       "  1.8293287908728304,\n",
       "  0.7600581459673539,\n",
       "  -0.18232669260597742,\n",
       "  0.85,\n",
       "  1.0682932187773269],\n",
       " [0.08959575785173825,\n",
       "  0.0,\n",
       "  -1.6593877283231517,\n",
       "  -0.4688888168361159,\n",
       "  -0.23132570051016157,\n",
       "  1.4881086027549735,\n",
       "  1.1,\n",
       "  0.9337249375939641],\n",
       " [-0.46449171395425376,\n",
       "  4.0,\n",
       "  -1.1103897238328935,\n",
       "  0.2940658209869411,\n",
       "  0.4273447205939432,\n",
       "  -1.6883268112430274,\n",
       "  1.2,\n",
       "  1.0792432984712694],\n",
       " [0.672098538420208,\n",
       "  4.0,\n",
       "  -0.45058107811546805,\n",
       "  -1.2140536170121639,\n",
       "  -0.4364210507843172,\n",
       "  0.6743296743163686,\n",
       "  1.2,\n",
       "  0.5595736650264734],\n",
       " [-1.9737839131025336,\n",
       "  5.0,\n",
       "  1.3423713093024903,\n",
       "  -0.2721296570640724,\n",
       "  0.9683145243295308,\n",
       "  1.2887894766490773,\n",
       "  0.85,\n",
       "  0.9745755234021829],\n",
       " [1.2792335624060112,\n",
       "  2.0,\n",
       "  1.4615240440670798,\n",
       "  -1.145568628466744,\n",
       "  -0.1473450263870815,\n",
       "  0.38734374975577057,\n",
       "  1.05,\n",
       "  -1.5352810790874423],\n",
       " [-0.16574662480023658,\n",
       "  1.0,\n",
       "  0.5582890953089988,\n",
       "  -0.7731201497082457,\n",
       "  0.4164246740869885,\n",
       "  0.8569522478381996,\n",
       "  0.9,\n",
       "  -1.2487780627754184],\n",
       " [-1.330315278519935,\n",
       "  0.0,\n",
       "  -0.8387328728906739,\n",
       "  -1.1486196357496032,\n",
       "  0.22123107509445533,\n",
       "  0.6573071849799718,\n",
       "  1.1,\n",
       "  -0.29366481810527517],\n",
       " [0.5084246927643555,\n",
       "  2.0,\n",
       "  -1.5735735335786114,\n",
       "  -1.101104350195127,\n",
       "  0.6809344349359907,\n",
       "  0.008504872392572768,\n",
       "  1.05,\n",
       "  1.0192462354644487],\n",
       " [1.0836380278207849,\n",
       "  1.0,\n",
       "  1.3761285971417987,\n",
       "  -0.6193473761286766,\n",
       "  -0.4049586164444352,\n",
       "  0.12203291135155996,\n",
       "  0.9,\n",
       "  0.7958955661449982],\n",
       " [0.41033647754984287,\n",
       "  5.0,\n",
       "  -0.27902381339643073,\n",
       "  1.186623495785399,\n",
       "  -0.46980626455116276,\n",
       "  0.2414829550479856,\n",
       "  0.85,\n",
       "  -0.714181770965138],\n",
       " [-1.4280921409135154,\n",
       "  0.0,\n",
       "  0.32393442522313337,\n",
       "  0.46896872702443415,\n",
       "  -2.4627746459480626,\n",
       "  -1.2958149615377352,\n",
       "  1.1,\n",
       "  -1.6797518669574312],\n",
       " [0.6611529604398276,\n",
       "  0.0,\n",
       "  -0.5986682873775213,\n",
       "  0.06697263765299932,\n",
       "  -0.3526618226059912,\n",
       "  -0.8103693732755973,\n",
       "  1.1,\n",
       "  0.8701361389550432],\n",
       " [0.04882627824969364,\n",
       "  1.0,\n",
       "  0.27517597748292905,\n",
       "  -0.3014343957179335,\n",
       "  -1.4683824357740376,\n",
       "  1.9305596891458734,\n",
       "  0.9,\n",
       "  -0.505212553322674],\n",
       " [-1.476904474703974,\n",
       "  3.0,\n",
       "  0.5418771972337414,\n",
       "  -1.2944643270789769,\n",
       "  0.44130026123072696,\n",
       "  -0.6349399626707752,\n",
       "  0.95,\n",
       "  1.0047753848669505],\n",
       " [-1.4691891189277069,\n",
       "  1.0,\n",
       "  0.6448953433219715,\n",
       "  -0.8492979688363642,\n",
       "  0.612005637972608,\n",
       "  -1.575086806316091,\n",
       "  0.9,\n",
       "  -1.2762256577684508],\n",
       " [1.5231739923894183,\n",
       "  0.0,\n",
       "  -0.8815479640429722,\n",
       "  0.5150113558394277,\n",
       "  0.49313852190699925,\n",
       "  -1.7210182865061767,\n",
       "  1.1,\n",
       "  -0.05276049546931884],\n",
       " [-0.4440754620758188,\n",
       "  4.0,\n",
       "  1.651229205289116,\n",
       "  -0.9125800820148035,\n",
       "  0.07710650523079114,\n",
       "  0.08442391455198553,\n",
       "  1.2,\n",
       "  -1.861443611037119],\n",
       " [1.246900866161923,\n",
       "  1.0,\n",
       "  1.6121836033764343,\n",
       "  -1.3749867247902008,\n",
       "  -0.12037304737234232,\n",
       "  -1.295765148303235,\n",
       "  0.9,\n",
       "  0.852989497258276],\n",
       " [0.724513144096668,\n",
       "  5.0,\n",
       "  -0.33080101285551206,\n",
       "  -0.973605322611055,\n",
       "  0.7743983499599185,\n",
       "  -0.1686508434043631,\n",
       "  0.85,\n",
       "  -0.5661060434659534],\n",
       " [-1.1610339281374686,\n",
       "  5.0,\n",
       "  -1.5357653430238278,\n",
       "  -0.46428794038995796,\n",
       "  0.36684765068761904,\n",
       "  1.0310129967933002,\n",
       "  0.85,\n",
       "  1.0771212195144209],\n",
       " [-0.13277286915941777,\n",
       "  2.0,\n",
       "  0.3619437737709778,\n",
       "  -1.1819348419797229,\n",
       "  1.7067296436671935,\n",
       "  0.5964749248734417,\n",
       "  1.05,\n",
       "  -1.102726697189817],\n",
       " [1.1085695260927557,\n",
       "  0.0,\n",
       "  0.3520945398945642,\n",
       "  -0.051278754281094144,\n",
       "  0.6009354933705249,\n",
       "  -2.0006450419401283,\n",
       "  1.1,\n",
       "  -1.8209257684643958],\n",
       " [0.49391888452997573,\n",
       "  4.0,\n",
       "  0.9404094756806431,\n",
       "  0.8372426867280569,\n",
       "  -0.03286348968543126,\n",
       "  -0.2597191913808718,\n",
       "  1.2,\n",
       "  -0.24544760125773424],\n",
       " [-0.22869288128302995,\n",
       "  3.0,\n",
       "  1.398773542220222,\n",
       "  -0.9861209390868803,\n",
       "  0.5632259181182753,\n",
       "  1.4274097179708745,\n",
       "  0.95,\n",
       "  -1.3631497890616746],\n",
       " [1.4036661004480138,\n",
       "  5.0,\n",
       "  -1.4816475498488157,\n",
       "  -1.397842132951729,\n",
       "  0.4840786026841606,\n",
       "  0.09551262701175835,\n",
       "  0.85,\n",
       "  1.0708858638228544],\n",
       " [0.6462343147582885,\n",
       "  5.0,\n",
       "  -0.8732419847642424,\n",
       "  -1.3163675181981735,\n",
       "  0.4777044675720742,\n",
       "  0.6627270202812077,\n",
       "  0.85,\n",
       "  -0.8439797566279512],\n",
       " [0.555983388436235,\n",
       "  0.0,\n",
       "  0.38546931379899774,\n",
       "  -0.00447494210135393,\n",
       "  0.24379653604104753,\n",
       "  0.8188548825019959,\n",
       "  1.1,\n",
       "  0.028423225822376812],\n",
       " [0.32126740663355696,\n",
       "  5.0,\n",
       "  -1.2817902743250889,\n",
       "  0.12400276893418362,\n",
       "  -1.0524743116013722,\n",
       "  -0.9595011885187522,\n",
       "  0.85,\n",
       "  -0.8090628890938729],\n",
       " [1.2394850787256613,\n",
       "  5.0,\n",
       "  1.0891340697126695,\n",
       "  -0.44021219077058393,\n",
       "  0.6714239628840044,\n",
       "  -0.6738839624066753,\n",
       "  0.85,\n",
       "  -0.6428109449949239],\n",
       " [-1.423717737003462,\n",
       "  5.0,\n",
       "  -0.7919228275285531,\n",
       "  -1.4008539738776706,\n",
       "  0.9230824707646125,\n",
       "  -0.18249284599346074,\n",
       "  0.85,\n",
       "  1.0764694249622653],\n",
       " [0.3072099665574349,\n",
       "  2.0,\n",
       "  -0.3101705906296058,\n",
       "  -1.3080084298855477,\n",
       "  0.32967824410810276,\n",
       "  1.845189327558485,\n",
       "  1.05,\n",
       "  1.031031744027838],\n",
       " [-1.0194068365902649,\n",
       "  0.0,\n",
       "  1.0439636218198547,\n",
       "  0.5610589987876476,\n",
       "  -3.7400046876494866,\n",
       "  0.05246503742274216,\n",
       "  1.1,\n",
       "  1.052817284105164],\n",
       " [-1.7039668529459526,\n",
       "  1.0,\n",
       "  0.06662731255986883,\n",
       "  0.35403251168854155,\n",
       "  0.5244978348973957,\n",
       "  -1.6287487493654955,\n",
       "  0.9,\n",
       "  -1.6405981720941805],\n",
       " [1.1798188313908315,\n",
       "  5.0,\n",
       "  0.6253749999303398,\n",
       "  -0.0023415569765508374,\n",
       "  0.10478147841365903,\n",
       "  0.006860297381187414,\n",
       "  0.85,\n",
       "  -1.2781249355780282],\n",
       " [-0.08386509438357026,\n",
       "  5.0,\n",
       "  0.7125582918918966,\n",
       "  1.4487618882996218,\n",
       "  0.8786640970573456,\n",
       "  0.07376676897207318,\n",
       "  0.85,\n",
       "  0.6329113700224247],\n",
       " [0.1470296241281361,\n",
       "  2.0,\n",
       "  1.3651541585052367,\n",
       "  1.5962837794107627,\n",
       "  0.2600309441879816,\n",
       "  0.0058919603337493,\n",
       "  1.05,\n",
       "  -0.44921464838932396],\n",
       " [-1.2051233046636518,\n",
       "  4.0,\n",
       "  1.0147857467075638,\n",
       "  -1.3885268658615093,\n",
       "  0.4537793525090859,\n",
       "  0.4935817054074883,\n",
       "  1.2,\n",
       "  -1.0895261009870136],\n",
       " [-0.6526357655888877,\n",
       "  5.0,\n",
       "  1.396784806684171,\n",
       "  -1.0739329633602386,\n",
       "  0.20205561019318538,\n",
       "  0.8538472777322685,\n",
       "  0.85,\n",
       "  -1.9554120695411505],\n",
       " [-0.46869525128310907,\n",
       "  3.0,\n",
       "  -1.4892672740631279,\n",
       "  1.7011108757456004,\n",
       "  -2.2669549656869665,\n",
       "  0.5532160299765674,\n",
       "  0.95,\n",
       "  0.561363581680767],\n",
       " [-0.44911103591704254,\n",
       "  5.0,\n",
       "  1.5051017502270003,\n",
       "  0.9569838707603486,\n",
       "  0.9489072628624072,\n",
       "  -0.2696685201185964,\n",
       "  0.85,\n",
       "  -1.0825927245724305],\n",
       " [-0.4187968164375134,\n",
       "  1.0,\n",
       "  -0.44699858706930184,\n",
       "  -0.08290598922598201,\n",
       "  0.6405996454384607,\n",
       "  -1.1241287545005085,\n",
       "  0.9,\n",
       "  0.9172443768081703],\n",
       " [-1.2242958338807557,\n",
       "  2.0,\n",
       "  -0.36040162194692366,\n",
       "  -1.1314674059171563,\n",
       "  0.6392395488771875,\n",
       "  -1.519610278336342,\n",
       "  1.05,\n",
       "  1.8739867019145156],\n",
       " [0.3383885028346739,\n",
       "  1.0,\n",
       "  0.8255424848215535,\n",
       "  -0.7265073670184241,\n",
       "  -0.20081173186311696,\n",
       "  -0.29455644624225646,\n",
       "  0.9,\n",
       "  0.9848845062365903],\n",
       " [0.06416142604550375,\n",
       "  0.0,\n",
       "  0.11129689836876093,\n",
       "  1.263556268662071,\n",
       "  -3.664432906952229,\n",
       "  -1.8402373260294698,\n",
       "  1.1,\n",
       "  -0.1953117173261173],\n",
       " [-0.5339139850139143,\n",
       "  5.0,\n",
       "  0.48228795885497044,\n",
       "  -1.3098525245699817,\n",
       "  -2.765114799348028,\n",
       "  0.837323971464104,\n",
       "  0.85,\n",
       "  0.9664944492079265],\n",
       " [-1.1902188194047043,\n",
       "  1.0,\n",
       "  -0.16319068848165616,\n",
       "  -0.42349476510453854,\n",
       "  -3.3220357196972183,\n",
       "  0.2017034473675778,\n",
       "  0.9,\n",
       "  -1.6328232461442918],\n",
       " [-1.4552426385265407,\n",
       "  1.0,\n",
       "  1.1086518174653304,\n",
       "  1.6410120796080514,\n",
       "  -0.5747077827468478,\n",
       "  1.85053329810967,\n",
       "  0.9,\n",
       "  -1.853270474845453],\n",
       " [-0.10961330404338673,\n",
       "  1.0,\n",
       "  -0.27284489498575876,\n",
       "  1.649450547543893,\n",
       "  0.0044649414575226075,\n",
       "  1.8069573768137717,\n",
       "  0.9,\n",
       "  0.7819097276489435],\n",
       " [0.10141126338530712,\n",
       "  2.0,\n",
       "  0.7136044757410572,\n",
       "  -0.579798898216382,\n",
       "  -0.12612301770845685,\n",
       "  0.35516588318333253,\n",
       "  1.05,\n",
       "  1.077992608620683],\n",
       " [1.014829351656104,\n",
       "  4.0,\n",
       "  -1.0521866135019677,\n",
       "  0.617581281181125,\n",
       "  0.9598320708410634,\n",
       "  0.28951812094890383,\n",
       "  1.2,\n",
       "  -1.149102046510322],\n",
       " [-0.8862182357948051,\n",
       "  5.0,\n",
       "  1.3139316228572075,\n",
       "  1.9311788796420954,\n",
       "  -0.4441479253184046,\n",
       "  1.8930111909752816,\n",
       "  0.85,\n",
       "  -0.8813342833531637],\n",
       " [-1.5246887683169277,\n",
       "  0.0,\n",
       "  -1.3149596017109724,\n",
       "  -0.1413385408054084,\n",
       "  1.230079430961817,\n",
       "  -0.18005059875638268,\n",
       "  1.1,\n",
       "  -0.3256167921037531],\n",
       " [0.848095452246249,\n",
       "  2.0,\n",
       "  1.483760885990563,\n",
       "  1.1239469318907487,\n",
       "  0.2902551778009579,\n",
       "  0.39948534425679544,\n",
       "  1.05,\n",
       "  -0.2602874099784045],\n",
       " [0.3298336992409684,\n",
       "  5.0,\n",
       "  -0.6488236936349513,\n",
       "  0.4608749502124453,\n",
       "  0.7122754475695663,\n",
       "  -0.5962294266197492,\n",
       "  0.85,\n",
       "  -0.12254330449099902],\n",
       " [-1.415972070152212,\n",
       "  5.0,\n",
       "  -1.1272886584059583,\n",
       "  0.22538462849076601,\n",
       "  0.08444450064800647,\n",
       "  -1.0114772821809213,\n",
       "  0.85,\n",
       "  -1.867949246890612],\n",
       " [0.5439563212954759,\n",
       "  4.0,\n",
       "  -0.5736619805769837,\n",
       "  0.520309412516964,\n",
       "  0.2708581804844216,\n",
       "  -1.1996554716936372,\n",
       "  1.2,\n",
       "  1.0376141856397871],\n",
       " [1.171658730396189,\n",
       "  1.0,\n",
       "  1.027828554485245,\n",
       "  -0.010916677608134013,\n",
       "  -0.23248341447880677,\n",
       "  0.13643055039335744,\n",
       "  0.9,\n",
       "  -1.585167848010533],\n",
       " [1.413503402828726,\n",
       "  5.0,\n",
       "  1.5448690176621538,\n",
       "  -1.2846116810069679,\n",
       "  0.6795726343883566,\n",
       "  1.61700804593103,\n",
       "  0.85,\n",
       "  0.9377960227659734],\n",
       " [-0.9688129931839011,\n",
       "  2.0,\n",
       "  0.0933008320675316,\n",
       "  -0.8677974127824982,\n",
       "  -0.590633037467101,\n",
       "  1.6228331478252174,\n",
       "  1.05,\n",
       "  0.9360299401065055],\n",
       " [-1.1821212265014325,\n",
       "  2.0,\n",
       "  1.561334546533372,\n",
       "  -1.370265759058946,\n",
       "  -0.33231604730809405,\n",
       "  0.46473982096574923,\n",
       "  1.05,\n",
       "  1.0460692557729998],\n",
       " [0.19417020642002614,\n",
       "  4.0,\n",
       "  -0.7751348592755178,\n",
       "  -0.9386195299969164,\n",
       "  -0.42501374391514773,\n",
       "  -1.31663819231765,\n",
       "  1.2,\n",
       "  0.009925985908232085],\n",
       " [0.2802408019266237,\n",
       "  0.0,\n",
       "  1.2865533222895544,\n",
       "  0.329016961297437,\n",
       "  -1.6544246556442042,\n",
       "  0.21420803103665134,\n",
       "  1.1,\n",
       "  0.9709371000729387],\n",
       " [-1.6756045053398616,\n",
       "  1.0,\n",
       "  -1.121110559794297,\n",
       "  -1.3774485104945702,\n",
       "  0.18069311842516622,\n",
       "  0.16471357350330207,\n",
       "  0.9,\n",
       "  0.9648970180014859],\n",
       " [-0.4558000814965976,\n",
       "  1.0,\n",
       "  -0.13636996330711512,\n",
       "  1.4647781377898923,\n",
       "  0.19994175445054124,\n",
       "  -1.4260173275823156,\n",
       "  0.9,\n",
       "  1.065591340640984],\n",
       " [1.7620153680454065,\n",
       "  2.0,\n",
       "  0.5044867394550826,\n",
       "  -1.0147955615945123,\n",
       "  0.5066636716314684,\n",
       "  -0.2922448090719679,\n",
       "  1.05,\n",
       "  -0.8055654833206077],\n",
       " [-1.8273403007566171,\n",
       "  2.0,\n",
       "  0.116632566926735,\n",
       "  0.6189849290076562,\n",
       "  -0.5588145951657435,\n",
       "  -1.7026324000610633,\n",
       "  1.05,\n",
       "  -1.8026385915087526],\n",
       " [0.0009356797986962752,\n",
       "  5.0,\n",
       "  1.2409340193090048,\n",
       "  -1.266798195114252,\n",
       "  0.9066383228961667,\n",
       "  0.1013112233690656,\n",
       "  0.85,\n",
       "  0.7957753363589651],\n",
       " [-0.4639189234189285,\n",
       "  5.0,\n",
       "  -1.2112856628318844,\n",
       "  0.37492767823676626,\n",
       "  0.19731084822588263,\n",
       "  1.1785623762076989,\n",
       "  0.85,\n",
       "  1.0095429267396034],\n",
       " [1.0307976072116272,\n",
       "  2.0,\n",
       "  -1.5346466097253366,\n",
       "  1.7263227626579039,\n",
       "  0.8558168574616006,\n",
       "  0.3366101345072206,\n",
       "  1.05,\n",
       "  0.7502597464898738],\n",
       " [-0.07154743312519408,\n",
       "  2.0,\n",
       "  -0.8030441210782013,\n",
       "  0.9447636168017655,\n",
       "  0.4689435985989676,\n",
       "  0.023115867924624688,\n",
       "  1.05,\n",
       "  -1.4642448245131465],\n",
       " [-1.5494632261151158,\n",
       "  4.0,\n",
       "  0.27986915656485206,\n",
       "  -0.5354302012266579,\n",
       "  0.44765355245393684,\n",
       "  0.15957242460200424,\n",
       "  1.2,\n",
       "  1.0501197135003844],\n",
       " [1.1711613855453207,\n",
       "  2.0,\n",
       "  -0.8019210348749443,\n",
       "  -0.982250809491076,\n",
       "  -0.18032265624266242,\n",
       "  0.39132972006803657,\n",
       "  1.05,\n",
       "  -1.7885743787355424],\n",
       " [1.1046004783938057,\n",
       "  2.0,\n",
       "  -0.25309625445221584,\n",
       "  1.4186678936830404,\n",
       "  -1.1214440263500471,\n",
       "  -0.7890002859196019,\n",
       "  1.05,\n",
       "  -1.7427514981946308],\n",
       " [-1.3126005835470027,\n",
       "  5.0,\n",
       "  -0.5392717154082143,\n",
       "  -0.07496529037765313,\n",
       "  0.941119031138274,\n",
       "  0.4952721851785658,\n",
       "  0.85,\n",
       "  -0.19361771600378375],\n",
       " [-1.221305718347086,\n",
       "  4.0,\n",
       "  0.27375564804692887,\n",
       "  -0.256069030039627,\n",
       "  1.2613007332327275,\n",
       "  -0.036430339940922034,\n",
       "  1.2,\n",
       "  0.8402221656626498],\n",
       " [-1.2337739116204276,\n",
       "  2.0,\n",
       "  0.2958138539645977,\n",
       "  -0.06692291930304418,\n",
       "  0.6466281078248823,\n",
       "  -0.2226817017935078,\n",
       "  1.05,\n",
       "  -0.2901968463475223],\n",
       " [-1.2286875704773974,\n",
       "  3.0,\n",
       "  -1.6380661248031123,\n",
       "  -0.0957133328873393,\n",
       "  0.1818382626879103,\n",
       "  -1.3095261378991345,\n",
       "  0.95,\n",
       "  1.077578462240611],\n",
       " [0.3170773760018178,\n",
       "  3.0,\n",
       "  1.0181718949079372,\n",
       "  -0.9891236882138269,\n",
       "  0.3144492972510705,\n",
       "  -0.2057450615484498,\n",
       "  0.95,\n",
       "  0.9154184829156478],\n",
       " [-0.30269411806508,\n",
       "  4.0,\n",
       "  -0.5235659951381635,\n",
       "  -0.3507778472726069,\n",
       "  0.2009546628505892,\n",
       "  1.9059576330159742,\n",
       "  1.2,\n",
       "  -0.7665319813722444],\n",
       " [0.9510362791362714,\n",
       "  4.0,\n",
       "  1.0785116925503508,\n",
       "  0.6040808276662442,\n",
       "  -0.24466862533125663,\n",
       "  0.10023066874375718,\n",
       "  1.2,\n",
       "  0.17923630242100133],\n",
       " [0.04202340169190226,\n",
       "  3.0,\n",
       "  -1.603564031597639,\n",
       "  -0.9820020352432289,\n",
       "  0.2506968955848423,\n",
       "  1.1915749470849135,\n",
       "  0.95,\n",
       "  -0.10617096023109127],\n",
       " [-0.21869960755371762,\n",
       "  5.0,\n",
       "  -0.48440138948131073,\n",
       "  0.5487525210031695,\n",
       "  -0.7994214222540859,\n",
       "  -0.008577933572347938,\n",
       "  0.85,\n",
       "  1.0737420808932496],\n",
       " [0.965319313842642,\n",
       "  3.0,\n",
       "  -0.8047228030944608,\n",
       "  -0.35225431851747613,\n",
       "  0.42979720316673836,\n",
       "  -1.156170214952602,\n",
       "  0.95,\n",
       "  -0.14653951275992483],\n",
       " [-1.637659925772088,\n",
       "  5.0,\n",
       "  -0.7228866641816255,\n",
       "  -1.1775893438696383,\n",
       "  -2.044005158016481,\n",
       "  -0.5455200994149709,\n",
       "  0.85,\n",
       "  -0.9377729525762777],\n",
       " [0.30903225191045935,\n",
       "  4.0,\n",
       "  -0.4574894177130901,\n",
       "  1.7970410313797078,\n",
       "  -0.43318747589332507,\n",
       "  0.9866945097901104,\n",
       "  1.2,\n",
       "  1.0089513240745296],\n",
       " [-1.3997902063910121,\n",
       "  5.0,\n",
       "  0.3301520092773556,\n",
       "  -1.1172946607733016,\n",
       "  -0.731477255745512,\n",
       "  0.6130669472166745,\n",
       "  0.85,\n",
       "  -1.0208880499287156],\n",
       " [-0.9822418316388112,\n",
       "  4.0,\n",
       "  0.15520299447458522,\n",
       "  0.08348390650990638,\n",
       "  0.8460641251370968,\n",
       "  -1.6767268392922587,\n",
       "  1.2,\n",
       "  1.0679675881877315],\n",
       " [1.5425543510690185,\n",
       "  5.0,\n",
       "  1.1877243607653896,\n",
       "  0.7858151528314717,\n",
       "  0.0642596480246921,\n",
       "  1.3608623849378243,\n",
       "  0.85,\n",
       "  -1.512139272147306],\n",
       " [0.1361862547742014,\n",
       "  3.0,\n",
       "  1.6082299429015219,\n",
       "  1.6513103723446247,\n",
       "  -0.4642871454561819,\n",
       "  -0.1450787833374195,\n",
       "  0.95,\n",
       "  0.29927429233778063],\n",
       " [0.6767511084226371,\n",
       "  1.0,\n",
       "  0.836520520062323,\n",
       "  -0.5985222912382945,\n",
       "  0.923177806660869,\n",
       "  0.06153488659774145,\n",
       "  0.9,\n",
       "  0.4455801721130471],\n",
       " [1.1030103894751435,\n",
       "  2.0,\n",
       "  0.9581253468946075,\n",
       "  -0.9281098775464106,\n",
       "  0.4460224167268978,\n",
       "  -1.7791020590045894,\n",
       "  1.05,\n",
       "  0.15050047945339787],\n",
       " [-0.3834829766343692,\n",
       "  0.0,\n",
       "  1.1366940326582997,\n",
       "  0.9885866456664901,\n",
       "  0.31712808353841515,\n",
       "  1.0363335008393906,\n",
       "  1.1,\n",
       "  0.6700558179066356],\n",
       " [-1.2848182373085333,\n",
       "  2.0,\n",
       "  -1.3328668727854152,\n",
       "  1.3889162238208674,\n",
       "  0.7000577247185857,\n",
       "  -0.15393594610616318,\n",
       "  1.05,\n",
       "  0.4431177997624655],\n",
       " [-0.9308118677459701,\n",
       "  2.0,\n",
       "  -0.2774119686976973,\n",
       "  -1.2922255703787133,\n",
       "  -1.2564353876270682,\n",
       "  1.7069794935243343,\n",
       "  1.05,\n",
       "  -1.7140001574234538],\n",
       " [0.1468820439605759,\n",
       "  5.0,\n",
       "  -0.9660051574953313,\n",
       "  1.4165224553693987,\n",
       "  0.8587088221417342,\n",
       "  0.7155596676809595,\n",
       "  0.85,\n",
       "  0.7108510038846101],\n",
       " [-0.6999879456714243,\n",
       "  4.0,\n",
       "  -1.0634589537182195,\n",
       "  -1.1905401532187714,\n",
       "  0.5792545789536252,\n",
       "  -0.3871581275218967,\n",
       "  1.2,\n",
       "  0.09966569348994297],\n",
       " [-1.563307437997377,\n",
       "  0.0,\n",
       "  1.182041424788491,\n",
       "  -1.3278956644506386,\n",
       "  0.9328115325254295,\n",
       "  -1.118026401103118,\n",
       "  1.1,\n",
       "  0.7896565234602257],\n",
       " [-0.1481293312587568,\n",
       "  3.0,\n",
       "  0.44405216897227034,\n",
       "  -0.3905884980857261,\n",
       "  -0.17339477884388602,\n",
       "  -1.0537029778432085,\n",
       "  0.95,\n",
       "  -1.3819547203762093],\n",
       " [-0.7092596694200632,\n",
       "  0.0,\n",
       "  -0.25361972312490016,\n",
       "  0.3728116657456288,\n",
       "  0.8128632883753519,\n",
       "  1.4618186969511955,\n",
       "  1.1,\n",
       "  0.2887496780678603],\n",
       " [0.44751985691945323,\n",
       "  3.0,\n",
       "  0.887729878507719,\n",
       "  0.4316899715449821,\n",
       "  0.9377327215170419,\n",
       "  -1.7943365105946,\n",
       "  0.95,\n",
       "  0.9116514932455123],\n",
       " [-0.872453080812735,\n",
       "  2.0,\n",
       "  1.5600580689173356,\n",
       "  0.8098129725093663,\n",
       "  -0.25687881638590043,\n",
       "  -1.2186480241924857,\n",
       "  1.05,\n",
       "  -1.598848294306059],\n",
       " [1.4288751060897433,\n",
       "  4.0,\n",
       "  -0.13017108385283097,\n",
       "  0.42156515170326364,\n",
       "  -0.20671525506617522,\n",
       "  -0.026001648365977105,\n",
       "  1.2,\n",
       "  0.03741617602802749],\n",
       " [1.3626037246640728,\n",
       "  1.0,\n",
       "  0.3862906068505094,\n",
       "  0.1996676982327598,\n",
       "  1.7975662608939642,\n",
       "  1.8557110063619164,\n",
       "  0.9,\n",
       "  0.691212861980438],\n",
       " [-0.5666261858436757,\n",
       "  1.0,\n",
       "  0.22396738636777605,\n",
       "  1.848352358051828,\n",
       "  -0.9992908863820856,\n",
       "  -0.24684835581313672,\n",
       "  0.9,\n",
       "  -0.7794212684623762],\n",
       " [0.8093448514026622,\n",
       "  3.0,\n",
       "  0.3609057583234236,\n",
       "  -0.9786783008072716,\n",
       "  -0.5596611756233572,\n",
       "  0.7162170116357062,\n",
       "  0.95,\n",
       "  -0.5946571892672051],\n",
       " [0.4870873886009884,\n",
       "  0.0,\n",
       "  -0.6475877449244042,\n",
       "  -1.3355543349916374,\n",
       "  -0.4422639630203807,\n",
       "  -0.030342112405477583,\n",
       "  1.1,\n",
       "  1.0512258528019953],\n",
       " [-0.25438556703698345,\n",
       "  3.0,\n",
       "  0.0672032104119151,\n",
       "  0.6360079235606654,\n",
       "  -0.1521300340917861,\n",
       "  -0.2472337193353931,\n",
       "  0.95,\n",
       "  -0.5024255608625474],\n",
       " [-1.8784999706079868,\n",
       "  0.0,\n",
       "  -0.12909991515836566,\n",
       "  0.7465874101704083,\n",
       "  0.9351496535332251,\n",
       "  0.4243082328598836,\n",
       "  1.1,\n",
       "  1.0764262895830663],\n",
       " [0.6272409829340628,\n",
       "  3.0,\n",
       "  1.6243966916948838,\n",
       "  0.47211155393790366,\n",
       "  0.6782306952771603,\n",
       "  0.8380283450755145,\n",
       "  0.95,\n",
       "  0.4156785705931175],\n",
       " [-0.033513974091420165,\n",
       "  5.0,\n",
       "  -1.154379423057615,\n",
       "  -0.16934569822211212,\n",
       "  0.055942235027659,\n",
       "  -1.522472806013124,\n",
       "  0.85,\n",
       "  -1.9702074693954874],\n",
       " [0.844186289397972,\n",
       "  5.0,\n",
       "  1.4506719540857362,\n",
       "  -1.0149089002251632,\n",
       "  0.2692780987822806,\n",
       "  -1.8175738509641965,\n",
       "  0.85,\n",
       "  -0.8192114380019789],\n",
       " [1.4746549025824303,\n",
       "  2.0,\n",
       "  -0.003935263673711373,\n",
       "  1.6137733357063206,\n",
       "  0.8679960237154782,\n",
       "  -0.10034726769406696,\n",
       "  1.05,\n",
       "  0.46039555222031564],\n",
       " [-0.8803140997913201,\n",
       "  2.0,\n",
       "  0.6630503449013144,\n",
       "  -1.281994158332698,\n",
       "  -1.2687733004390458,\n",
       "  -1.3546817864004632,\n",
       "  1.05,\n",
       "  -0.6036403930603732],\n",
       " [-0.9933923171293791,\n",
       "  5.0,\n",
       "  0.09774877057532806,\n",
       "  0.5177913257325885,\n",
       "  0.5897283173823301,\n",
       "  -0.36303585839333324,\n",
       "  0.85,\n",
       "  -1.5752071371482617],\n",
       " [0.7740561038505376,\n",
       "  1.0,\n",
       "  1.1172512555289185,\n",
       "  0.32757614656774214,\n",
       "  0.8106312966371616,\n",
       "  0.9699234336452203,\n",
       "  0.9,\n",
       "  1.0621098741367572],\n",
       " [0.49712973799780263,\n",
       "  0.0,\n",
       "  -1.4254340710996138,\n",
       "  -0.5355607126249037,\n",
       "  0.2505425188347793,\n",
       "  -0.6991730778654991,\n",
       "  1.1,\n",
       "  0.020234647694566447],\n",
       " [-1.3215219851566844,\n",
       "  0.0,\n",
       "  -1.5237500616410524,\n",
       "  -0.2668588845730072,\n",
       "  0.5566309861801236,\n",
       "  -1.8934150635501064,\n",
       "  1.1,\n",
       "  0.52190557519658],\n",
       " [-0.8435396702983912,\n",
       "  1.0,\n",
       "  -1.2183961640722285,\n",
       "  -1.2142507963562785,\n",
       "  0.8269435459903477,\n",
       "  1.2065609839836349,\n",
       "  0.9,\n",
       "  -0.6222127181837693],\n",
       " [-0.42989711355605764,\n",
       "  5.0,\n",
       "  1.5787257215469452,\n",
       "  -1.2099884785366077,\n",
       "  0.17513867593397758,\n",
       "  0.9978483176794837,\n",
       "  0.85,\n",
       "  0.22600918336231016],\n",
       " [-0.04619118789529664,\n",
       "  2.0,\n",
       "  0.5935685766413664,\n",
       "  -0.1915243222077322,\n",
       "  0.6389085799694756,\n",
       "  -1.8521113938814417,\n",
       "  1.05,\n",
       "  0.219351276000792],\n",
       " [-0.7940810527956595,\n",
       "  4.0,\n",
       "  -1.1685411869016802,\n",
       "  -0.9944047814142034,\n",
       "  0.7897661293552377,\n",
       "  -1.511926847501815,\n",
       "  1.2,\n",
       "  0.15681123044342085],\n",
       " [1.0212522136182363,\n",
       "  2.0,\n",
       "  0.835353058756487,\n",
       "  1.9583863829007353,\n",
       "  -1.316563784860599,\n",
       "  -0.2932719861220628,\n",
       "  1.05,\n",
       "  0.7362248158583701],\n",
       " [0.6065604908996783,\n",
       "  4.0,\n",
       "  0.21034315017354857,\n",
       "  1.7019074810796684,\n",
       "  1.0597656755464844,\n",
       "  0.6651929405167691,\n",
       "  1.2,\n",
       "  -0.1527797596547537],\n",
       " [0.6436849143027004,\n",
       "  0.0,\n",
       "  -0.5486149490209451,\n",
       "  0.7905670408695399,\n",
       "  0.4772424693165382,\n",
       "  -0.9974423854921729,\n",
       "  1.1,\n",
       "  0.6256938724134182],\n",
       " [0.08270817078197067,\n",
       "  1.0,\n",
       "  0.08344194263895793,\n",
       "  0.4709178371030767,\n",
       "  0.558934977158081,\n",
       "  -0.8615580084383928,\n",
       "  0.9,\n",
       "  1.063425294614293],\n",
       " [0.671914801384699,\n",
       "  3.0,\n",
       "  -1.5917184841750127,\n",
       "  1.5391269678702624,\n",
       "  1.03686330588168,\n",
       "  -0.3944244833948405,\n",
       "  0.95,\n",
       "  0.10661542295941512],\n",
       " [1.3986907319015385,\n",
       "  5.0,\n",
       "  -1.4094634828692343,\n",
       "  0.14298803840755575,\n",
       "  0.6906029303889211,\n",
       "  -1.8458605534391381,\n",
       "  0.85,\n",
       "  -1.6557575055440992],\n",
       " [-0.7544748474229103,\n",
       "  3.0,\n",
       "  -0.5025732327110629,\n",
       "  1.1459926646538032,\n",
       "  -0.06337424481151345,\n",
       "  -1.9815686194233813,\n",
       "  0.95,\n",
       "  -1.7150907295614424],\n",
       " [-1.0753012844495544,\n",
       "  3.0,\n",
       "  0.3799756522989643,\n",
       "  1.8398614931901933,\n",
       "  -0.2548016032598356,\n",
       "  0.9212029575268414,\n",
       "  0.95,\n",
       "  0.10229906410964561],\n",
       " [0.6864111697216703,\n",
       "  3.0,\n",
       "  0.4881388069598436,\n",
       "  1.5822529285022882,\n",
       "  0.9222690283924929,\n",
       "  -1.4285684718444707,\n",
       "  0.95,\n",
       "  -1.2403159556783172],\n",
       " [1.2165403104220334,\n",
       "  5.0,\n",
       "  0.41553862837078054,\n",
       "  1.0331085340064825,\n",
       "  0.7661342256771131,\n",
       "  0.17806697200359245,\n",
       "  0.85,\n",
       "  0.12599911226024757],\n",
       " [1.1705604092691893,\n",
       "  0.0,\n",
       "  1.228686829317889,\n",
       "  -0.673958357691396,\n",
       "  0.9036589893245268,\n",
       "  0.5091152990632611,\n",
       "  1.1,\n",
       "  -0.9017330789561985],\n",
       " [1.462704272762099,\n",
       "  3.0,\n",
       "  0.32800731481502116,\n",
       "  0.7175621162253764,\n",
       "  -0.061102016032076725,\n",
       "  -1.7184772203811227,\n",
       "  0.95,\n",
       "  -0.39050948310996136],\n",
       " [0.7929366777786272,\n",
       "  3.0,\n",
       "  0.702222771057703,\n",
       "  1.9148529695354943,\n",
       "  -1.1010074879125367,\n",
       "  -1.5872022909576322,\n",
       "  0.95,\n",
       "  -0.7409357879304712],\n",
       " [-0.2369982541454059,\n",
       "  2.0,\n",
       "  -0.3669435527418866,\n",
       "  0.2763486129644338,\n",
       "  0.8162803650504596,\n",
       "  -0.04565534941615651,\n",
       "  1.05,\n",
       "  0.7284551931206376],\n",
       " [1.0280751362972331,\n",
       "  1.0,\n",
       "  -0.14165367911374574,\n",
       "  0.9112105617480503,\n",
       "  0.6970856980791461,\n",
       "  0.9387897734720922,\n",
       "  0.9,\n",
       "  -1.467510016643396],\n",
       " [-1.0080047616473082,\n",
       "  2.0,\n",
       "  1.0007960823805668,\n",
       "  -0.05620376972600951,\n",
       "  -0.4418837139654368,\n",
       "  0.2325417285180199,\n",
       "  1.05,\n",
       "  0.05693307100837796],\n",
       " [1.1249983760001852,\n",
       "  3.0,\n",
       "  -1.4701537465955536,\n",
       "  -1.3336118366811611,\n",
       "  0.07698793486019516,\n",
       "  0.5560166545208264,\n",
       "  0.95,\n",
       "  1.0130724408046745],\n",
       " [-0.6439433776262273,\n",
       "  1.0,\n",
       "  1.7086384982214047,\n",
       "  -0.641758717671456,\n",
       "  0.8143007701659333,\n",
       "  0.5465954145485328,\n",
       "  0.9,\n",
       "  0.10322046785186449],\n",
       " [0.5089642938858767,\n",
       "  3.0,\n",
       "  -0.9999977219103138,\n",
       "  0.411101886500002,\n",
       "  -0.29385514630125104,\n",
       "  -1.450997831033482,\n",
       "  0.95,\n",
       "  -0.8581713550470005],\n",
       " [-0.37114454302475997,\n",
       "  2.0,\n",
       "  0.747351965318727,\n",
       "  -0.8053524535312746,\n",
       "  -2.9383158853306592,\n",
       "  -0.2541733287723661,\n",
       "  1.05,\n",
       "  1.0552295572781327],\n",
       " [-1.3215164910545723,\n",
       "  4.0,\n",
       "  0.31524897048102546,\n",
       "  -0.9698109036282547,\n",
       "  -2.1561290442774457,\n",
       "  -1.5183863316444424,\n",
       "  1.2,\n",
       "  -1.7538411453533231],\n",
       " [-1.5934170163550596,\n",
       "  5.0,\n",
       "  -0.6742243718346563,\n",
       "  0.2525886059379406,\n",
       "  0.4673782981652215,\n",
       "  0.4034893657087136,\n",
       "  0.85,\n",
       "  1.0128762088230663],\n",
       " [0.1891179695233423,\n",
       "  3.0,\n",
       "  -0.5134258158625794,\n",
       "  -0.3217071706148385,\n",
       "  0.6356586714857374,\n",
       "  -0.017148429401839384,\n",
       "  0.95,\n",
       "  1.048202425115092],\n",
       " [1.1511326964490318,\n",
       "  1.0,\n",
       "  1.2545625048028315,\n",
       "  -0.9917411133500779,\n",
       "  0.34065447818739636,\n",
       "  -0.26132638124615837,\n",
       "  0.9,\n",
       "  -0.4525300044320201],\n",
       " [-0.9601571341632051,\n",
       "  4.0,\n",
       "  -1.335658712708541,\n",
       "  1.2363874921285334,\n",
       "  -3.315562353348856,\n",
       "  -0.2560099210537576,\n",
       "  1.2,\n",
       "  0.877455327777267],\n",
       " [-1.2112179035505386,\n",
       "  3.0,\n",
       "  1.2883803913604643,\n",
       "  -0.7236772985917075,\n",
       "  0.6819916571362268,\n",
       "  -0.6571149145177931,\n",
       "  0.95,\n",
       "  3.026573784832258],\n",
       " [-1.7091130510807606,\n",
       "  4.0,\n",
       "  -0.4260949967691639,\n",
       "  -1.1640606620073803,\n",
       "  0.7605145510595475,\n",
       "  0.20962284477042512,\n",
       "  1.2,\n",
       "  0.6362890404959244],\n",
       " [-0.27962072285215134,\n",
       "  5.0,\n",
       "  0.05801431085939296,\n",
       "  -1.149714750746335,\n",
       "  0.842055034551563,\n",
       "  -1.520384302996027,\n",
       "  0.85,\n",
       "  -1.0038519781362185],\n",
       " [0.6564138766303009,\n",
       "  1.0,\n",
       "  1.4206635455558418,\n",
       "  -0.4268076087997072,\n",
       "  -0.2577679925197256,\n",
       "  -1.56588570288241,\n",
       "  0.9,\n",
       "  -0.016318941107668038],\n",
       " [0.2982998957238449,\n",
       "  5.0,\n",
       "  1.4419707722505637,\n",
       "  0.22991560895579335,\n",
       "  0.2702839085162456,\n",
       "  0.6124228915774543,\n",
       "  0.85,\n",
       "  0.8965209575562378],\n",
       " [1.6129902351307237,\n",
       "  0.0,\n",
       "  -0.6664345101438217,\n",
       "  -0.2630769904401699,\n",
       "  0.32518289259694694,\n",
       "  0.7517343680994156,\n",
       "  1.1,\n",
       "  -1.9381634812592918],\n",
       " [0.5647032707526967,\n",
       "  4.0,\n",
       "  -1.3636199287821729,\n",
       "  0.18411323912569813,\n",
       "  -1.5405519422093221,\n",
       "  -0.41429502523064354,\n",
       "  1.2,\n",
       "  -0.09227791851306955],\n",
       " [-1.5778427375525153,\n",
       "  4.0,\n",
       "  1.048674558534086,\n",
       "  0.6958409920956069,\n",
       "  0.6183940262655724,\n",
       "  1.3261457930481841,\n",
       "  1.2,\n",
       "  0.10347389519256227],\n",
       " [1.2234165358607108,\n",
       "  5.0,\n",
       "  -0.7803109948477874,\n",
       "  -0.09300692398818625,\n",
       "  -0.014381014647828191,\n",
       "  1.413930304867016,\n",
       "  0.85,\n",
       "  -0.20464851027643002],\n",
       " [0.08305833510555101,\n",
       "  5.0,\n",
       "  0.7956322726705782,\n",
       "  -0.8277445963967183,\n",
       "  -0.32671825659713266,\n",
       "  0.2068790664652657,\n",
       "  0.85,\n",
       "  -0.6365871945631216],\n",
       " [-1.3543718624421588,\n",
       "  1.0,\n",
       "  0.2805697582351046,\n",
       "  0.3112842384042054,\n",
       "  -1.1492642626237417,\n",
       "  -1.0438162842308074,\n",
       "  0.9,\n",
       "  0.8394547221281904],\n",
       " [-0.5241748684375996,\n",
       "  3.0,\n",
       "  -1.3004772014450041,\n",
       "  0.8678984851912538,\n",
       "  -0.3984339356808121,\n",
       "  -0.1807017600600625,\n",
       "  0.95,\n",
       "  -1.5872725906205294],\n",
       " [-0.9591877308883956,\n",
       "  4.0,\n",
       "  -1.3737176219152367,\n",
       "  -0.17806210905588832,\n",
       "  0.2674693232108977,\n",
       "  0.46675491293616495,\n",
       "  1.2,\n",
       "  -1.7379938057405575],\n",
       " [-1.378788304141558,\n",
       "  5.0,\n",
       "  1.0318953418984167,\n",
       "  0.6302179330432405,\n",
       "  -0.9765107584982999,\n",
       "  0.5521241931815365,\n",
       "  0.85,\n",
       "  -0.3130791784605133],\n",
       " [-1.2083013155424762,\n",
       "  2.0,\n",
       "  -0.7997781688254539,\n",
       "  0.7891858379734351,\n",
       "  0.01080167059204323,\n",
       "  -1.2986786272195694,\n",
       "  1.05,\n",
       "  1.0420844525592454],\n",
       " [-1.1599450363034318,\n",
       "  2.0,\n",
       "  1.379123111598265,\n",
       "  0.2731343183482402,\n",
       "  0.5873296891209365,\n",
       "  -0.5829106798638626,\n",
       "  1.05,\n",
       "  0.14649289260644296],\n",
       " [-1.4168954164431333,\n",
       "  1.0,\n",
       "  -1.5697571937754229,\n",
       "  0.3903921719599766,\n",
       "  -0.4316951281838859,\n",
       "  -0.460328965100997,\n",
       "  0.9,\n",
       "  -0.5079085455948842],\n",
       " [1.4411687391055614,\n",
       "  3.0,\n",
       "  1.0272531121379147,\n",
       "  1.4878695606754473,\n",
       "  -0.027187330979601913,\n",
       "  0.5729508789624134,\n",
       "  0.95,\n",
       "  1.077100372284018],\n",
       " [-0.9298707542706608,\n",
       "  3.0,\n",
       "  -0.8697671262620088,\n",
       "  0.7302185660313539,\n",
       "  0.27835568046370984,\n",
       "  1.8937298901271,\n",
       "  0.95,\n",
       "  -0.18501774498525989],\n",
       " [1.197589715167593,\n",
       "  2.0,\n",
       "  -0.7282067326971623,\n",
       "  -1.3127035172785713,\n",
       "  0.3199134568401196,\n",
       "  -0.7348814454707713,\n",
       "  1.05,\n",
       "  -0.8721701823749597],\n",
       " [0.30762319011880623,\n",
       "  2.0,\n",
       "  -0.9135806195321617,\n",
       "  -1.218061033778143,\n",
       "  -1.9587887787694618,\n",
       "  -1.2461482642506538,\n",
       "  1.05,\n",
       "  -1.1597879032948812],\n",
       " [-0.05945745937292159,\n",
       "  1.0,\n",
       "  0.291040885088998,\n",
       "  0.0746752716019522,\n",
       "  -0.07207846243653579,\n",
       "  0.916864247390104,\n",
       "  0.9,\n",
       "  1.0250876224144043],\n",
       " [-1.14108016387535,\n",
       "  2.0,\n",
       "  0.0817701262008738,\n",
       "  -0.7502144978560105,\n",
       "  0.896225495878548,\n",
       "  0.5702959277432033,\n",
       "  1.05,\n",
       "  0.35461584733570256],\n",
       " [1.5611970576930456,\n",
       "  2.0,\n",
       "  0.6036406194000393,\n",
       "  -1.3824894414957798,\n",
       "  0.29131792923547073,\n",
       "  -0.08517646638055443,\n",
       "  1.05,\n",
       "  -1.1027410224910608],\n",
       " [-1.2641375844849196,\n",
       "  2.0,\n",
       "  -1.1403135868654268,\n",
       "  0.38154439543704166,\n",
       "  0.6375014826982119,\n",
       "  1.9091402638699988,\n",
       "  1.05,\n",
       "  0.6076820222251831],\n",
       " [0.11840075716902225,\n",
       "  5.0,\n",
       "  1.530820995821322,\n",
       "  1.002720894223994,\n",
       "  0.5924651413883872,\n",
       "  -0.4530615527481811,\n",
       "  0.85,\n",
       "  0.9800460229955592],\n",
       " [-0.6376873590502546,\n",
       "  4.0,\n",
       "  -1.4307538039414234,\n",
       "  0.5574671704311587,\n",
       "  0.9791209346443897,\n",
       "  1.808609355934382,\n",
       "  1.2,\n",
       "  0.5569141681865482],\n",
       " [-0.4252694330930354,\n",
       "  2.0,\n",
       "  0.8690653836952802,\n",
       "  1.9292466158556145,\n",
       "  0.47814573114166964,\n",
       "  0.754195977090456,\n",
       "  1.05,\n",
       "  0.010452227686932334],\n",
       " [-0.8380762442680099,\n",
       "  2.0,\n",
       "  1.3282330234645867,\n",
       "  -0.5441882895821759,\n",
       "  0.8490984257526969,\n",
       "  1.9586566937257237,\n",
       "  1.05,\n",
       "  0.045653712672824524],\n",
       " [1.0538709852707233,\n",
       "  1.0,\n",
       "  0.5401851802687577,\n",
       "  -1.338611118716299,\n",
       "  0.15542119631374618,\n",
       "  -1.4550915588385547,\n",
       "  0.9,\n",
       "  0.8726819470051906],\n",
       " [0.5530885281930012,\n",
       "  3.0,\n",
       "  0.9113517556849592,\n",
       "  -1.0652561730808863,\n",
       "  0.630766084521995,\n",
       "  1.4204428876485733,\n",
       "  0.95,\n",
       "  0.03575180303280613],\n",
       " [-1.5109856050592023,\n",
       "  3.0,\n",
       "  -1.1913636247716752,\n",
       "  -0.15866969054528982,\n",
       "  0.7550630219780536,\n",
       "  0.9872610806557139,\n",
       "  0.95,\n",
       "  0.7644922218209593],\n",
       " [-0.2917514584605587,\n",
       "  1.0,\n",
       "  0.8863541145759039,\n",
       "  -0.07577528179197203,\n",
       "  -1.6664064164959576,\n",
       "  -1.5543136750651105,\n",
       "  0.9,\n",
       "  0.9761526720471392],\n",
       " [-1.2588515893063479,\n",
       "  5.0,\n",
       "  0.4111976646566106,\n",
       "  1.2139620950030239,\n",
       "  0.9197251327894365,\n",
       "  -0.11655757492644946,\n",
       "  0.85,\n",
       "  1.0196112472310364],\n",
       " [1.0781792785188533,\n",
       "  1.0,\n",
       "  0.7380274027488432,\n",
       "  -1.2054192300175037,\n",
       "  0.7700797581684937,\n",
       "  -1.1296947513239144,\n",
       "  0.9,\n",
       "  -0.5938599183716979],\n",
       " [-0.6516137631916679,\n",
       "  4.0,\n",
       "  0.40725718262296196,\n",
       "  -1.0970403807454836,\n",
       "  0.3104306004430558,\n",
       "  0.0356751779339136,\n",
       "  1.2,\n",
       "  -1.7577975235824224],\n",
       " [0.8048501784543975,\n",
       "  0.0,\n",
       "  0.8571327257293332,\n",
       "  -0.13353516278848196,\n",
       "  -0.9058199705191062,\n",
       "  -0.22216355873224128,\n",
       "  1.1,\n",
       "  1.07377713812563],\n",
       " [1.1997918677957802,\n",
       "  0.0,\n",
       "  0.10499811335452053,\n",
       "  -1.1704574040033406,\n",
       "  -0.8548913039619384,\n",
       "  -1.0235286027894044,\n",
       "  1.1,\n",
       "  -0.009657333079430197],\n",
       " [-0.3367091350368873,\n",
       "  0.0,\n",
       "  -0.9095631654758646,\n",
       "  -0.4894276643737732,\n",
       "  0.4442957874066869,\n",
       "  0.9510566258879265,\n",
       "  1.1,\n",
       "  1.0762403073621087],\n",
       " [0.21623659304664353,\n",
       "  3.0,\n",
       "  0.17939225458142508,\n",
       "  -0.9677029245218924,\n",
       "  0.9692458802325639,\n",
       "  0.01821667682253653,\n",
       "  0.95,\n",
       "  1.0733363525587853],\n",
       " [0.9299631608702947,\n",
       "  1.0,\n",
       "  -0.8728425913963217,\n",
       "  1.2517666729142087,\n",
       "  -1.0050045138073969,\n",
       "  -0.02055423865312273,\n",
       "  0.9,\n",
       "  0.9731064924756203],\n",
       " [-0.76962564828528,\n",
       "  1.0,\n",
       "  -1.270311086393843,\n",
       "  1.8351754593566356,\n",
       "  -0.3059090666615122,\n",
       "  -0.2921192832840494,\n",
       "  0.9,\n",
       "  -0.5258071879034216],\n",
       " [1.3651523627986881,\n",
       "  1.0,\n",
       "  -0.8717980182215909,\n",
       "  -0.7443124484338338,\n",
       "  -3.2624352262883685,\n",
       "  -0.22258679823483318,\n",
       "  0.9,\n",
       "  -1.6859555711849923],\n",
       " [1.2729883574658292,\n",
       "  5.0,\n",
       "  -0.7328538557282397,\n",
       "  -0.7171377643429886,\n",
       "  -2.4845225083022195,\n",
       "  1.0179746769517937,\n",
       "  0.85,\n",
       "  -1.6295844328774234],\n",
       " [-0.5408359945156157,\n",
       "  1.0,\n",
       "  -0.1601029841541287,\n",
       "  -0.283689909702601,\n",
       "  -0.6352889828855177,\n",
       "  0.4860073635192404,\n",
       "  0.9,\n",
       "  0.8259857177985657],\n",
       " [-0.6728623548428955,\n",
       "  0.0,\n",
       "  0.5036194605266954,\n",
       "  1.3673731880106919,\n",
       "  0.4813444333131068,\n",
       "  -0.183565858813667,\n",
       "  1.1,\n",
       "  0.7364186244868923],\n",
       " [-1.5313943005279267,\n",
       "  3.0,\n",
       "  0.9377135378939526,\n",
       "  0.4828365946078167,\n",
       "  0.8155331539147407,\n",
       "  -1.5042309761523776,\n",
       "  0.95,\n",
       "  0.5926970146442533],\n",
       " [-0.7273469668245637,\n",
       "  3.0,\n",
       "  -0.11680748907089153,\n",
       "  0.5702035455398198,\n",
       "  0.3048377005773388,\n",
       "  -0.7561946322664205,\n",
       "  0.95,\n",
       "  0.24949050504600329],\n",
       " [1.482368077101653,\n",
       "  1.0,\n",
       "  0.027317106062186958,\n",
       "  -1.260251587475733,\n",
       "  -3.4249109449147292,\n",
       "  0.06021512413480991,\n",
       "  0.9,\n",
       "  0.6425721801753658],\n",
       " [1.2904039594127976,\n",
       "  0.0,\n",
       "  1.4382920801639918,\n",
       "  -1.3456250619639143,\n",
       "  1.4537982895051924,\n",
       "  0.23493992103494205,\n",
       "  1.1,\n",
       "  1.0674043614652144],\n",
       " [-0.6757869861882547,\n",
       "  3.0,\n",
       "  -0.926173289311016,\n",
       "  0.7098678246882083,\n",
       "  0.7388465977229541,\n",
       "  0.7287756186364818,\n",
       "  0.95,\n",
       "  0.2879783005904472],\n",
       " [-1.8256245254095012,\n",
       "  0.0,\n",
       "  1.5326415829710114,\n",
       "  0.436855520396545,\n",
       "  -2.253051312233323,\n",
       "  1.923780392565429,\n",
       "  1.1,\n",
       "  -0.1755267110334461],\n",
       " [1.825034011774134,\n",
       "  3.0,\n",
       "  -1.1254389540161,\n",
       "  -0.8251355257433092,\n",
       "  -0.12678274289221725,\n",
       "  1.4679968642686512,\n",
       "  0.95,\n",
       "  0.43219340000609796],\n",
       " [-0.16433991607053058,\n",
       "  5.0,\n",
       "  1.5807698138797237,\n",
       "  -0.5168596940061649,\n",
       "  0.9071112299962821,\n",
       "  -0.3172213253038055,\n",
       "  0.85,\n",
       "  0.9067327981991051],\n",
       " [-1.8297019137506638,\n",
       "  1.0,\n",
       "  -1.1550858462491431,\n",
       "  -0.23451068284318133,\n",
       "  -0.011203785424742914,\n",
       "  -0.14685035069895935,\n",
       "  0.9,\n",
       "  0.7399534647644387],\n",
       " [0.6327064057055113,\n",
       "  5.0,\n",
       "  -0.6455168107324282,\n",
       "  -0.4796639529465781,\n",
       "  -0.33259135002128454,\n",
       "  -0.12718150783662688,\n",
       "  0.85,\n",
       "  1.0372925264323927],\n",
       " [0.9258986239529815,\n",
       "  5.0,\n",
       "  1.5031036477547761,\n",
       "  0.5869151116998286,\n",
       "  0.37760128206183285,\n",
       "  -0.3751818749722765,\n",
       "  0.85,\n",
       "  -0.5891682310484743],\n",
       " [1.2795414918076604,\n",
       "  0.0,\n",
       "  -1.6343699320506542,\n",
       "  -0.9752088788221825,\n",
       "  0.6962405009732436,\n",
       "  -0.18036003357101446,\n",
       "  1.1,\n",
       "  -1.0278608723415483],\n",
       " [-0.879285809775961,\n",
       "  4.0,\n",
       "  -1.3448870347284165,\n",
       "  -1.24100462339001,\n",
       "  -0.4093241245097501,\n",
       "  0.8485765830727946,\n",
       "  1.2,\n",
       "  -1.2939498117933061],\n",
       " [0.8699924383701373,\n",
       "  4.0,\n",
       "  -0.5054500990602501,\n",
       "  0.6477373062838314,\n",
       "  -1.7882451483971633,\n",
       "  -0.09254728689221203,\n",
       "  1.2,\n",
       "  1.0763091038129158],\n",
       " [-0.2985742645937006,\n",
       "  2.0,\n",
       "  -1.1235352528318354,\n",
       "  -1.1771704216116912,\n",
       "  -1.870908522962854,\n",
       "  1.5087796153901136,\n",
       "  1.05,\n",
       "  -1.7857637247212292],\n",
       " [0.6058383184264856,\n",
       "  4.0,\n",
       "  -0.7071289560504089,\n",
       "  -0.3788208980763592,\n",
       "  0.12162952855400735,\n",
       "  0.6304368055316908,\n",
       "  1.2,\n",
       "  0.7390669653669046],\n",
       " [0.5788788705058326,\n",
       "  4.0,\n",
       "  -0.25495062269853935,\n",
       "  0.9763682212903643,\n",
       "  0.16063787182927353,\n",
       "  -0.11967606331275261,\n",
       "  1.2,\n",
       "  0.6143685600271803],\n",
       " [-0.11894345810197832,\n",
       "  4.0,\n",
       "  0.5553198750979893,\n",
       "  -0.9783499252324321,\n",
       "  0.9311396409912744,\n",
       "  -0.329931456457243,\n",
       "  1.2,\n",
       "  -0.37921891691054344],\n",
       " [1.2312549468439826,\n",
       "  5.0,\n",
       "  1.4206903911928532,\n",
       "  1.8789811506994838,\n",
       "  -0.35841094951165603,\n",
       "  -0.004187754929885454,\n",
       "  0.85,\n",
       "  0.41221300768065683],\n",
       " [1.0778838998883518,\n",
       "  0.0,\n",
       "  -0.9329002571728217,\n",
       "  -0.6884736370647833,\n",
       "  0.9202949879179322,\n",
       "  -1.065636414738091,\n",
       "  1.1,\n",
       "  0.9590721481284223],\n",
       " [-1.476699852529069,\n",
       "  2.0,\n",
       "  -1.6412843568439275,\n",
       "  0.5008494671094502,\n",
       "  0.6072116050421397,\n",
       "  -0.4176524462827955,\n",
       "  1.05,\n",
       "  -1.7216267887852128],\n",
       " [1.577133309092914,\n",
       "  5.0,\n",
       "  -0.6994489372915784,\n",
       "  -0.5851996016748222,\n",
       "  0.5683970967382698,\n",
       "  1.387757183176363,\n",
       "  0.85,\n",
       "  1.4641832519428037],\n",
       " [1.477972963674257,\n",
       "  2.0,\n",
       "  -0.1955434004573437,\n",
       "  -0.23771622979950102,\n",
       "  0.6995481170820267,\n",
       "  -0.2009822536785122,\n",
       "  1.05,\n",
       "  1.0332136027034635],\n",
       " [0.32269637458241773,\n",
       "  4.0,\n",
       "  -0.16908947840506633,\n",
       "  -0.7180076651481964,\n",
       "  1.043843303783887,\n",
       "  0.68957819357209,\n",
       "  1.2,\n",
       "  -0.5682603319214125],\n",
       " [-0.8045551058826427,\n",
       "  0.0,\n",
       "  0.9930178081770505,\n",
       "  1.4224979321107754,\n",
       "  -0.2535497694311737,\n",
       "  -0.2927459178777026,\n",
       "  1.1,\n",
       "  0.5679036803118105],\n",
       " [0.2832467406235647,\n",
       "  2.0,\n",
       "  -0.8100630613322393,\n",
       "  -0.2899111158259387,\n",
       "  -0.9122115124871587,\n",
       "  0.009669143292776851,\n",
       "  1.05,\n",
       "  0.5290614655531299],\n",
       " [-0.34468159322659503,\n",
       "  1.0,\n",
       "  -0.7450082945695511,\n",
       "  0.6224211490257645,\n",
       "  -1.4366545800863486,\n",
       "  0.45176128984958663,\n",
       "  0.9,\n",
       "  -0.16322655822718088],\n",
       " [-0.790705622215447,\n",
       "  3.0,\n",
       "  -1.180522811190725,\n",
       "  -0.9916000093057441,\n",
       "  0.3309143162510476,\n",
       "  1.9365636563564046,\n",
       "  0.95,\n",
       "  -0.2843609171485976],\n",
       " [1.0117901095207174,\n",
       "  5.0,\n",
       "  -0.3252028142102689,\n",
       "  -1.300598289479838,\n",
       "  -0.32801523719615494,\n",
       "  -0.01188092368089909,\n",
       "  0.85,\n",
       "  1.0487925628052501],\n",
       " [-1.2024144273750323,\n",
       "  3.0,\n",
       "  1.5232236414634501,\n",
       "  -0.6321032275225279,\n",
       "  0.4770355110403369,\n",
       "  1.5199659427798884,\n",
       "  0.95,\n",
       "  0.9342247153782923],\n",
       " [-1.4619968704984847,\n",
       "  0.0,\n",
       "  -1.577488252845861,\n",
       "  0.2667914737599432,\n",
       "  -0.9438449273645901,\n",
       "  0.5552081254343547,\n",
       "  1.1,\n",
       "  -0.9885507848709087],\n",
       " [-0.29440550519423364,\n",
       "  4.0,\n",
       "  -1.3511588210873153,\n",
       "  -0.17911486768787735,\n",
       "  0.4630697414245962,\n",
       "  1.3990925705342128,\n",
       "  1.2,\n",
       "  -0.8632143032117696],\n",
       " [0.7587750051141342,\n",
       "  4.0,\n",
       "  -1.6230633729837283,\n",
       "  -1.067075630386733,\n",
       "  -1.019078716835124,\n",
       "  1.0699067773678603,\n",
       "  1.2,\n",
       "  1.0362480858927132],\n",
       " [1.1891199604189888,\n",
       "  2.0,\n",
       "  1.157485414142751,\n",
       "  0.019157114039232558,\n",
       "  0.7955819904594398,\n",
       "  0.6063787354194223,\n",
       "  1.05,\n",
       "  0.9995391002483691],\n",
       " [1.3668822640918092,\n",
       "  0.0,\n",
       "  1.3976895959909135,\n",
       "  -0.24615319828431106,\n",
       "  0.4011872320978036,\n",
       "  0.6566556720357641,\n",
       "  1.1,\n",
       "  -0.9616826694865166],\n",
       " [1.2942530966436616,\n",
       "  2.0,\n",
       "  -0.5348524668067506,\n",
       "  1.805599638704695,\n",
       "  1.259596492312412,\n",
       "  1.3221308722633798,\n",
       "  1.05,\n",
       "  0.7298041947081401],\n",
       " [-1.1248938176044314,\n",
       "  3.0,\n",
       "  1.0185072488376452,\n",
       "  -0.8568042277180314,\n",
       "  0.5341750179805613,\n",
       "  -0.6967331498848212,\n",
       "  0.95,\n",
       "  -0.3009748663707718],\n",
       " [-0.9528991254058536,\n",
       "  1.0,\n",
       "  0.44675511243361804,\n",
       "  -1.4096004382490663,\n",
       "  -2.945682936096161,\n",
       "  0.1340884542948143,\n",
       "  0.9,\n",
       "  1.0768762164265724],\n",
       " [1.3559186608896343,\n",
       "  3.0,\n",
       "  -0.9042127715171344,\n",
       "  -1.141224147861729,\n",
       "  -1.5131090921641546,\n",
       "  0.5306652293897735,\n",
       "  0.95,\n",
       "  -1.2983702992908528],\n",
       " [-0.0016940203511596223,\n",
       "  4.0,\n",
       "  -0.4382181294795304,\n",
       "  1.2568358002313276,\n",
       "  -2.977964875399165,\n",
       "  -1.4532769627698696,\n",
       "  1.2,\n",
       "  0.3553108207158811],\n",
       " [0.030685783667292386,\n",
       "  5.0,\n",
       "  1.002336103914457,\n",
       "  -0.4672919820404412,\n",
       "  -0.04308091408302813,\n",
       "  1.4612225747118455,\n",
       "  0.85,\n",
       "  0.5262530032174325],\n",
       " [1.5749283117946167,\n",
       "  0.0,\n",
       "  0.4614770085308783,\n",
       "  -1.031606212528177,\n",
       "  -0.1480443465050062,\n",
       "  -0.3271986405406178,\n",
       "  1.1,\n",
       "  1.0517843309234816],\n",
       " [1.671940415688028,\n",
       "  4.0,\n",
       "  1.1595421553827654,\n",
       "  1.8689172775236833,\n",
       "  -0.12845650670137185,\n",
       "  -1.6076641108415621,\n",
       "  1.2,\n",
       "  1.0365047407314836],\n",
       " [-1.3569895426976235,\n",
       "  3.0,\n",
       "  1.5532645771856142,\n",
       "  -0.3228284182323843,\n",
       "  -0.8250757328946806,\n",
       "  0.29881700922767573,\n",
       "  0.95,\n",
       "  0.7128608160725436],\n",
       " [-0.6008818857719115,\n",
       "  0.0,\n",
       "  0.9777697227606105,\n",
       "  -1.0571779300606219,\n",
       "  0.7952123168083748,\n",
       "  -1.1052001190642702,\n",
       "  1.1,\n",
       "  0.3954983001924356],\n",
       " [0.3418639419900231,\n",
       "  1.0,\n",
       "  1.1601658497122305,\n",
       "  -0.878305240146176,\n",
       "  0.29180477445680697,\n",
       "  -0.5088938416633271,\n",
       "  0.9,\n",
       "  0.2743650232380261],\n",
       " [-0.004743359544250955,\n",
       "  3.0,\n",
       "  1.3172651165812779,\n",
       "  1.9266845353423823,\n",
       "  -0.7628186601434715,\n",
       "  -0.06699613319700723,\n",
       "  0.95,\n",
       "  2.400751597774951],\n",
       " [-0.03836759543969655,\n",
       "  0.0,\n",
       "  -1.2833149975525524,\n",
       "  0.5892273263291148,\n",
       "  -0.0856620856951942,\n",
       "  -0.2110148453220713,\n",
       "  1.1,\n",
       "  0.5301091770953666],\n",
       " [0.08582887276351854,\n",
       "  1.0,\n",
       "  0.320922881171138,\n",
       "  1.363082530510514,\n",
       "  0.4045943776547412,\n",
       "  0.04940334170220239,\n",
       "  0.9,\n",
       "  0.13740708617059214],\n",
       " [0.860560587865524,\n",
       "  2.0,\n",
       "  -0.2894717612931817,\n",
       "  -1.3735423520145795,\n",
       "  1.544756065248776,\n",
       "  1.5682314377394244,\n",
       "  1.05,\n",
       "  0.8931099476274683],\n",
       " [-1.0111695640509017,\n",
       "  5.0,\n",
       "  1.2506930699267091,\n",
       "  -0.5616004536105191,\n",
       "  1.0903926948853104,\n",
       "  0.44586701799860684,\n",
       "  0.85,\n",
       "  -0.41105220238959306],\n",
       " [-0.1892708926369184,\n",
       "  1.0,\n",
       "  -0.9467561324544157,\n",
       "  -0.06566291480584005,\n",
       "  -0.6147387746681765,\n",
       "  0.8936596370602995,\n",
       "  0.9,\n",
       "  0.829679640791923],\n",
       " [-1.5303986487036094,\n",
       "  0.0,\n",
       "  -1.1324115603284772,\n",
       "  1.8843209955340108,\n",
       "  0.22542067217753936,\n",
       "  -0.938009472433829,\n",
       "  1.1,\n",
       "  1.0348375949493618],\n",
       " [1.460346253328607,\n",
       "  1.0,\n",
       "  -0.9878400232018317,\n",
       "  1.9009305843155506,\n",
       "  -1.23977286292964,\n",
       "  -1.2625226155604747,\n",
       "  0.9,\n",
       "  0.8336979646952102],\n",
       " [-0.28492819946800113,\n",
       "  5.0,\n",
       "  1.244814899519155,\n",
       "  1.7400901187546896,\n",
       "  -3.543257653749672,\n",
       "  -1.6134019806943645,\n",
       "  0.85,\n",
       "  -1.898798043448027],\n",
       " [-1.3868555216119445,\n",
       "  5.0,\n",
       "  1.2031038615681338,\n",
       "  -0.7495184625436702,\n",
       "  -0.13510697019163084,\n",
       "  0.7343955652682509,\n",
       "  0.85,\n",
       "  1.0436318008529022],\n",
       " [1.541561650318658,\n",
       "  5.0,\n",
       "  0.17426200721322319,\n",
       "  -1.0775819062700025,\n",
       "  0.5849215410135444,\n",
       "  -0.2890166106634571,\n",
       "  0.85,\n",
       "  1.058745410510895],\n",
       " [-0.41061669375593146,\n",
       "  1.0,\n",
       "  1.5060795351031468,\n",
       "  0.036466617441066135,\n",
       "  0.2042097794381814,\n",
       "  -1.5603479891001464,\n",
       "  0.9,\n",
       "  -0.9537790981510409],\n",
       " [0.0920985205382231,\n",
       "  3.0,\n",
       "  1.0735461557386454,\n",
       "  -1.4025569963684656,\n",
       "  -0.49351393331603155,\n",
       "  -1.0078171859691183,\n",
       "  0.95,\n",
       "  1.0747809685875167],\n",
       " [0.9584874312294371,\n",
       "  1.0,\n",
       "  -0.7433733364793242,\n",
       "  -1.0033324263112366,\n",
       "  0.9516562584646894,\n",
       "  -1.7448201472428049,\n",
       "  0.9,\n",
       "  -0.30820685246180934],\n",
       " [1.3858165269477245,\n",
       "  2.0,\n",
       "  1.5652779542794368,\n",
       "  -0.9222705839457608,\n",
       "  0.5926381201262819,\n",
       "  -1.1230143095518543,\n",
       "  1.05,\n",
       "  0.3792154759476991],\n",
       " [0.5093680196799834,\n",
       "  2.0,\n",
       "  1.1051026196427098,\n",
       "  0.4777248948563776,\n",
       "  -1.8454400748135054,\n",
       "  -0.04838260650832776,\n",
       "  1.05,\n",
       "  1.0783555200553803],\n",
       " [-0.6499231402893145,\n",
       "  2.0,\n",
       "  -0.6378517547594821,\n",
       "  -1.1421314784455878,\n",
       "  0.5467281225827143,\n",
       "  0.20447770465179224,\n",
       "  1.05,\n",
       "  -1.3183310570483537],\n",
       " [0.5780234552699338,\n",
       "  4.0,\n",
       "  0.5317665670935503,\n",
       "  0.20240709446524818,\n",
       "  -0.21647619046930255,\n",
       "  1.4121437371020462,\n",
       "  1.2,\n",
       "  0.4223675929211294],\n",
       " [0.23810750447727205,\n",
       "  2.0,\n",
       "  -0.19420293096018285,\n",
       "  -1.1194859325995363,\n",
       "  -0.9664067294789668,\n",
       "  -0.15779669137110214,\n",
       "  1.05,\n",
       "  -1.5783246017645],\n",
       " [0.399448995053497,\n",
       "  0.0,\n",
       "  -1.6864839505931593,\n",
       "  -1.4002995410457533,\n",
       "  0.8021728919614479,\n",
       "  -1.7767939301755538,\n",
       "  1.1,\n",
       "  0.7463390731941323],\n",
       " [1.9061120256582675,\n",
       "  3.0,\n",
       "  1.3400323388069388,\n",
       "  0.22327728954409812,\n",
       "  -3.434399398335105,\n",
       "  0.13325454772953,\n",
       "  0.95,\n",
       "  -1.7563040452614869],\n",
       " [0.3322053906802775,\n",
       "  3.0,\n",
       "  0.5552361042913699,\n",
       "  -1.2791313251336296,\n",
       "  0.5995714515289952,\n",
       "  1.1787734576942446,\n",
       "  0.95,\n",
       "  0.11466348002571772],\n",
       " [-0.1345868380661445,\n",
       "  5.0,\n",
       "  -1.4618606362339717,\n",
       "  -0.9130434641973193,\n",
       "  -0.7526283149115731,\n",
       "  0.8119667157819656,\n",
       "  0.85,\n",
       "  0.8730522860362894],\n",
       " [-1.4794046360001116,\n",
       "  5.0,\n",
       "  -0.48515314493403233,\n",
       "  1.8743163036216928,\n",
       "  1.0427779371604589,\n",
       "  0.7112138985153339,\n",
       "  0.85,\n",
       "  -1.2766939827270989],\n",
       " [-0.20446266721615702,\n",
       "  0.0,\n",
       "  -1.519250601598511,\n",
       "  0.04992207070210008,\n",
       "  -1.0321816307209002,\n",
       "  0.15448887621955093,\n",
       "  1.1,\n",
       "  0.9533486873909596],\n",
       " [0.9913530866921777,\n",
       "  3.0,\n",
       "  -1.5957159774998304,\n",
       "  1.3292971846792954,\n",
       "  -1.6343231423948388,\n",
       "  -0.6179263105257546,\n",
       "  0.95,\n",
       "  1.0678739475502759],\n",
       " [1.5157871230731916,\n",
       "  0.0,\n",
       "  -1.4215040783164508,\n",
       "  -1.4064247420742317,\n",
       "  -0.47220824331264,\n",
       "  -0.18755417771910235,\n",
       "  1.1,\n",
       "  0.6000677777017953],\n",
       " [1.5142070043039944,\n",
       "  3.0,\n",
       "  0.29228924133958467,\n",
       "  1.2391630699724903,\n",
       "  0.8519912745002274,\n",
       "  1.91201794433197,\n",
       "  0.95,\n",
       "  0.5214700932009333],\n",
       " [-1.450461972761438,\n",
       "  5.0,\n",
       "  -0.371856523944398,\n",
       "  1.3694609595887008,\n",
       "  -0.043228822596816895,\n",
       "  0.382132779188599,\n",
       "  0.85,\n",
       "  0.31573781859748196],\n",
       " [0.617485616766966,\n",
       "  1.0,\n",
       "  -0.35410240979229046,\n",
       "  -0.8141729277272323,\n",
       "  0.171508572531635,\n",
       "  -0.062163878307211734,\n",
       "  0.9,\n",
       "  0.35399030101668394],\n",
       " [0.8490899571637159,\n",
       "  2.0,\n",
       "  0.7422822253409651,\n",
       "  1.4299779048468562,\n",
       "  -0.8296483267651542,\n",
       "  -0.30850030654918226,\n",
       "  1.05,\n",
       "  -0.19598423300911538],\n",
       " [0.3817452629816614,\n",
       "  4.0,\n",
       "  -1.6794874780968667,\n",
       "  0.24858667485554056,\n",
       "  -1.0234499616358252,\n",
       "  -0.2693309920190241,\n",
       "  1.2,\n",
       "  0.5750855689221146],\n",
       " [-1.4177520926651421,\n",
       "  0.0,\n",
       "  -0.43253977033730684,\n",
       "  0.808846439138493,\n",
       "  1.2069793874937078,\n",
       "  -0.7179654546859783,\n",
       "  1.1,\n",
       "  -0.02454057516229803],\n",
       " [-0.14436676755504893,\n",
       "  0.0,\n",
       "  1.180514577762954,\n",
       "  -1.071064897374709,\n",
       "  0.2548867130073018,\n",
       "  0.7154980786436258,\n",
       "  1.1,\n",
       "  0.9804694198376992],\n",
       " [0.745919171434873,\n",
       "  0.0,\n",
       "  0.8479421360211908,\n",
       "  0.29052459950142007,\n",
       "  -2.4140532161771078,\n",
       "  -0.3633170144271932,\n",
       "  1.1,\n",
       "  0.43128620130019246],\n",
       " [1.3344376621248442,\n",
       "  2.0,\n",
       "  0.2716680373908659,\n",
       "  -0.9295227245456346,\n",
       "  0.29485119794944264,\n",
       "  0.1523352340400379,\n",
       "  1.05,\n",
       "  -0.6730272584819367],\n",
       " [-1.0132805006836887,\n",
       "  1.0,\n",
       "  -0.2563256310571705,\n",
       "  1.6881178071965854,\n",
       "  0.6481492854540287,\n",
       "  -1.262828311133707,\n",
       "  0.9,\n",
       "  0.998666232061044],\n",
       " [-0.6757641652725298,\n",
       "  1.0,\n",
       "  0.3410606680702615,\n",
       "  1.2667702194959065,\n",
       "  0.018697056933464355,\n",
       "  0.4422796802445921,\n",
       "  0.9,\n",
       "  3.4710131446455894],\n",
       " [0.3655608775426249,\n",
       "  3.0,\n",
       "  1.3688519711551272,\n",
       "  -0.7125105459026191,\n",
       "  0.6169209473969925,\n",
       "  0.44400068764315764,\n",
       "  0.95,\n",
       "  0.4492004581819145],\n",
       " [1.034798261531911,\n",
       "  0.0,\n",
       "  -0.6648287546524695,\n",
       "  1.0171192673203573,\n",
       "  -0.12123079610723775,\n",
       "  0.6976805045901044,\n",
       "  1.1,\n",
       "  -0.582134970002704],\n",
       " [0.014315089213426087,\n",
       "  3.0,\n",
       "  0.9514996358378457,\n",
       "  -0.6078487889553784,\n",
       "  0.8962343810367872,\n",
       "  -1.5730564455956988,\n",
       "  0.95,\n",
       "  0.2029728942184475],\n",
       " [1.3217675566838663,\n",
       "  5.0,\n",
       "  0.6887907023475943,\n",
       "  -1.135771274555396,\n",
       "  1.3808542584307033,\n",
       "  -1.2381170430313424,\n",
       "  0.85,\n",
       "  -1.2049863601618394],\n",
       " [-1.0236840192677008,\n",
       "  3.0,\n",
       "  -0.6671644875801647,\n",
       "  1.420569616113791,\n",
       "  0.8232720219143596,\n",
       "  -0.2517187946610591,\n",
       "  0.95,\n",
       "  0.9655802060448596],\n",
       " [-0.15327426448639087,\n",
       "  2.0,\n",
       "  -0.03291050795667173,\n",
       "  -0.8262760652392922,\n",
       "  0.2905269422097333,\n",
       "  0.21507897914035579,\n",
       "  1.05,\n",
       "  -1.1337797001601255],\n",
       " [-1.1158879003310178,\n",
       "  5.0,\n",
       "  -1.3241943949717119,\n",
       "  -0.2999388013091843,\n",
       "  -0.02209176582014453,\n",
       "  1.0340660452991237,\n",
       "  0.85,\n",
       "  -0.10450176532951709],\n",
       " [-0.7661787257876704,\n",
       "  2.0,\n",
       "  -0.06377309395753218,\n",
       "  1.4134866235315424,\n",
       "  -0.9434530537745308,\n",
       "  -1.1728403274016355,\n",
       "  1.05,\n",
       "  0.059674387318228835],\n",
       " [0.0158953532771706,\n",
       "  0.0,\n",
       "  -0.41613183729430675,\n",
       "  -1.1134221243191829,\n",
       "  0.8939707518978885,\n",
       "  -0.2782632948104488,\n",
       "  1.1,\n",
       "  1.072263395247152],\n",
       " [1.6123439947461562,\n",
       "  4.0,\n",
       "  0.9180991039617317,\n",
       "  -0.31791497924551804,\n",
       "  0.7640484723669824,\n",
       "  -1.2336706148434504,\n",
       "  1.2,\n",
       "  1.0590685486304654],\n",
       " [-1.3842494845296505,\n",
       "  0.0,\n",
       "  -0.06899662119314691,\n",
       "  0.0918659022026079,\n",
       "  0.09542898636357351,\n",
       "  -1.657073186148609,\n",
       "  1.1,\n",
       "  0.05331836683259055],\n",
       " [-0.20921683897959514,\n",
       "  5.0,\n",
       "  0.8550470093052723,\n",
       "  -1.1191185536901846,\n",
       "  0.28211217160328045,\n",
       "  0.2878997257181707,\n",
       "  0.85,\n",
       "  -1.6384188872531171],\n",
       " [-0.4719239137719031,\n",
       "  1.0,\n",
       "  -1.5838371780616225,\n",
       "  0.2957919217392531,\n",
       "  1.1010098251215987,\n",
       "  1.8781975913204059,\n",
       "  0.9,\n",
       "  -0.5998706514979693],\n",
       " [0.7354997347562567,\n",
       "  4.0,\n",
       "  -1.147221419502142,\n",
       "  1.662229687003242,\n",
       "  1.229430356698436,\n",
       "  1.3183354615074152,\n",
       "  1.2,\n",
       "  -1.4966395615786279],\n",
       " [-0.9166056217655464,\n",
       "  1.0,\n",
       "  0.9258323347772925,\n",
       "  -1.1100678963601958,\n",
       "  1.2805483348192879,\n",
       "  1.9709116945578236,\n",
       "  0.9,\n",
       "  0.5286672171165908],\n",
       " [1.907998193472365,\n",
       "  4.0,\n",
       "  1.5029777596056,\n",
       "  -0.8494973593330458,\n",
       "  0.9167329323364084,\n",
       "  0.34232582935972905,\n",
       "  1.2,\n",
       "  0.24586198108687915],\n",
       " [0.5107127189415064,\n",
       "  1.0,\n",
       "  -0.6010050419440124,\n",
       "  -0.7612718393713005,\n",
       "  0.4760869588144875,\n",
       "  -0.5395736256307505,\n",
       "  0.9,\n",
       "  0.550097730194678],\n",
       " [-0.5843154015813175,\n",
       "  5.0,\n",
       "  -0.6429638726372165,\n",
       "  -0.7623095509375223,\n",
       "  0.8147346986012272,\n",
       "  1.1386822629356141,\n",
       "  0.85,\n",
       "  0.33571739345829654],\n",
       " [0.1623164983676165,\n",
       "  0.0,\n",
       "  -1.2047050662492633,\n",
       "  0.5143251566646617,\n",
       "  0.4592608620770788,\n",
       "  0.7386538077718549,\n",
       "  1.1,\n",
       "  0.7240469943567381],\n",
       " [-1.757336459006101,\n",
       "  1.0,\n",
       "  -0.3040261786141629,\n",
       "  0.9353146023784683,\n",
       "  0.5848612470549621,\n",
       "  0.8907129938440438,\n",
       "  0.9,\n",
       "  2.171572651631037],\n",
       " [0.633376394730878,\n",
       "  0.0,\n",
       "  -1.5491235677901292,\n",
       "  0.6614358080701463,\n",
       "  0.9014728768029969,\n",
       "  0.508536723500615,\n",
       "  1.1,\n",
       "  0.9886149532781454],\n",
       " [0.23364013858707408,\n",
       "  4.0,\n",
       "  1.3845338606133273,\n",
       "  1.3552791635384995,\n",
       "  -2.5213494197188773,\n",
       "  -1.5917001995701767,\n",
       "  1.2,\n",
       "  0.7181581325618348],\n",
       " [0.6779492113094756,\n",
       "  5.0,\n",
       "  1.5130669758086748,\n",
       "  -0.7598985839716348,\n",
       "  -0.6282289806299403,\n",
       "  0.3496097801351096,\n",
       "  0.85,\n",
       "  -0.2960598343855559],\n",
       " [1.2442527356435453,\n",
       "  5.0,\n",
       "  1.2054625499497191,\n",
       "  -0.0289123347691015,\n",
       "  -1.843039810893386,\n",
       "  0.27258191407314697,\n",
       "  0.85,\n",
       "  0.7643156354589451],\n",
       " [0.04107888283006731,\n",
       "  2.0,\n",
       "  -0.9229575511539504,\n",
       "  -1.1267021288038408,\n",
       "  1.0629349046062373,\n",
       "  0.48237964062070954,\n",
       "  1.05,\n",
       "  1.4455960907611114],\n",
       " [0.9077464902893119,\n",
       "  1.0,\n",
       "  -0.4989876904913857,\n",
       "  -1.1249453501970132,\n",
       "  -0.339634829216903,\n",
       "  0.13262372563823888,\n",
       "  0.9,\n",
       "  1.0774612803747918],\n",
       " [-1.1942158951642559,\n",
       "  3.0,\n",
       "  0.7147962929637376,\n",
       "  0.07421294560953416,\n",
       "  -1.6319533170544078,\n",
       "  -1.7035696685183335,\n",
       "  0.95,\n",
       "  -1.7726872057599246],\n",
       " [-1.674611477013626,\n",
       "  3.0,\n",
       "  -0.19547163051419159,\n",
       "  0.11737553795946265,\n",
       "  0.8077000775067904,\n",
       "  -0.32216045835070567,\n",
       "  0.95,\n",
       "  -0.455781170656705],\n",
       " [-1.059675782852503,\n",
       "  4.0,\n",
       "  1.4768067633921016,\n",
       "  -1.036339807525879,\n",
       "  -1.3122500978491103,\n",
       "  1.8973075929275818,\n",
       "  1.2,\n",
       "  0.9917569710105677],\n",
       " [0.3273602446973689,\n",
       "  4.0,\n",
       "  -0.09061925125060791,\n",
       "  -0.47938275679532183,\n",
       "  0.936552387643215,\n",
       "  -0.5066384429564708,\n",
       "  1.2,\n",
       "  0.9461243689723057],\n",
       " [-0.40749304854391394,\n",
       "  1.0,\n",
       "  1.625483766870871,\n",
       "  -0.9270524998276578,\n",
       "  -0.5278305094075731,\n",
       "  -0.6644929511494277,\n",
       "  0.9,\n",
       "  1.0291972004515524],\n",
       " [1.4892073740955065,\n",
       "  0.0,\n",
       "  -1.0812576132122202,\n",
       "  1.856108389210927,\n",
       "  -1.4685317310698849,\n",
       "  -0.629294341485035,\n",
       "  1.1,\n",
       "  -0.18314854856060261],\n",
       " [1.0538366079569859,\n",
       "  5.0,\n",
       "  -0.9949607213483804,\n",
       "  0.05847414566233637,\n",
       "  0.877158074937541,\n",
       "  0.5914974986171139,\n",
       "  0.85,\n",
       "  -0.3993992236981173],\n",
       " [0.14060012868713612,\n",
       "  0.0,\n",
       "  -0.9522921095569333,\n",
       "  -1.2989949667273615,\n",
       "  0.8428417107582719,\n",
       "  1.0251004709738272,\n",
       "  1.1,\n",
       "  2.4781950525477234],\n",
       " [-0.31366730258551756,\n",
       "  2.0,\n",
       "  0.7851750847133511,\n",
       "  -0.01999198429414133,\n",
       "  0.7729402955360274,\n",
       "  0.5732594748799509,\n",
       "  1.05,\n",
       "  1.0418080589374432],\n",
       " [-0.8591476423015473,\n",
       "  1.0,\n",
       "  0.15009666093868965,\n",
       "  -0.9264102593840592,\n",
       "  0.4839136705317054,\n",
       "  0.7279879665454789,\n",
       "  0.9,\n",
       "  0.7043192435071286],\n",
       " [-0.5309785135721434,\n",
       "  0.0,\n",
       "  0.46346225643687183,\n",
       "  -1.212586036711458,\n",
       "  0.35850695221995305,\n",
       "  -1.7883456751837008,\n",
       "  1.1,\n",
       "  1.0577674717340957],\n",
       " [0.6594967875483845,\n",
       "  5.0,\n",
       "  1.5307126745017676,\n",
       "  -0.49287869858147476,\n",
       "  0.7615957195750077,\n",
       "  0.18662909849487977,\n",
       "  0.85,\n",
       "  -1.2561322369448338],\n",
       " [0.5093257931137843,\n",
       "  0.0,\n",
       "  0.9976229705419296,\n",
       "  0.05040212136202482,\n",
       "  -0.9589112945207734,\n",
       "  -1.1030712238476883,\n",
       "  1.1,\n",
       "  -1.228491970318356],\n",
       " [-1.9398120007142778,\n",
       "  5.0,\n",
       "  -1.558240365613379,\n",
       "  0.9144347862001935,\n",
       "  -0.37705979558211966,\n",
       "  -0.9014873290649017,\n",
       "  0.85,\n",
       "  -1.5465039124407287],\n",
       " [1.5907343005424361,\n",
       "  3.0,\n",
       "  1.6002804869896643,\n",
       "  0.08007749527078686,\n",
       "  0.7695637905086993,\n",
       "  0.08055301842425396,\n",
       "  0.95,\n",
       "  0.9214930803413783],\n",
       " [0.7197239660320761,\n",
       "  0.0,\n",
       "  -1.0344706877990908,\n",
       "  -0.7441960312843134,\n",
       "  0.4413728681283639,\n",
       "  -1.736888962103894,\n",
       "  1.1,\n",
       "  0.6771879823428965],\n",
       " [0.17896681879993767,\n",
       "  1.0,\n",
       "  0.768845549384445,\n",
       "  1.5991738859127715,\n",
       "  -0.5953049590874882,\n",
       "  0.8805994276024163,\n",
       "  0.9,\n",
       "  -1.170758584411314],\n",
       " [1.3349916202707945,\n",
       "  5.0,\n",
       "  0.22864884844351677,\n",
       "  1.0790115163489393,\n",
       "  0.8256065829842569,\n",
       "  -0.32450153139930216,\n",
       "  0.85,\n",
       "  -0.541358379854505],\n",
       " [-0.9025424397895756,\n",
       "  4.0,\n",
       "  -0.8953435521570536,\n",
       "  -1.0690525589630737,\n",
       "  -0.07025830792449761,\n",
       "  0.012351365708635337,\n",
       "  1.2,\n",
       "  -0.9069081432581273],\n",
       " [-0.11951144554330428,\n",
       "  2.0,\n",
       "  0.534625919127375,\n",
       "  1.891914633929264,\n",
       "  -0.1703023408923482,\n",
       "  1.3799504898447756,\n",
       "  1.05,\n",
       "  0.477232956154654],\n",
       " [0.6029393285135503,\n",
       "  4.0,\n",
       "  1.6152565801300922,\n",
       "  -0.3638489943738758,\n",
       "  -0.4159813178882935,\n",
       "  1.4984814738997971,\n",
       "  1.2,\n",
       "  -1.5596039591803252],\n",
       " [-0.9298591626074045,\n",
       "  3.0,\n",
       "  1.0900094743970168,\n",
       "  1.1455026907291694,\n",
       "  -2.8178470325514122,\n",
       "  -0.17358634746556953,\n",
       "  0.95,\n",
       "  -0.5993126014221487],\n",
       " [-1.309596691558404,\n",
       "  2.0,\n",
       "  -0.2693985453862257,\n",
       "  0.6788896333373547,\n",
       "  0.8286787853056976,\n",
       "  -0.3518754997369144,\n",
       "  1.05,\n",
       "  -1.1502657991495522],\n",
       " [-1.0816083412070585,\n",
       "  4.0,\n",
       "  0.6351019330324753,\n",
       "  1.8878822869653014,\n",
       "  -0.04860658931995947,\n",
       "  -0.07826785660153608,\n",
       "  1.2,\n",
       "  -1.2097287458550696],\n",
       " [0.33411943736197075,\n",
       "  1.0,\n",
       "  -0.46625671000945673,\n",
       "  -0.8738330652457522,\n",
       "  -1.0362671609214444,\n",
       "  -0.7632775638347936,\n",
       "  0.9,\n",
       "  -1.707332285018128],\n",
       " [0.8576417992994496,\n",
       "  2.0,\n",
       "  -1.6127162602792058,\n",
       "  -0.7432182199121794,\n",
       "  -2.9097626165205783,\n",
       "  1.6782261231357058,\n",
       "  1.05,\n",
       "  0.013193729065518106],\n",
       " [-1.0130904117479984,\n",
       "  2.0,\n",
       "  1.5920233605610927,\n",
       "  0.3143212245846135,\n",
       "  0.25117372989850756,\n",
       "  -0.08800182238566669,\n",
       "  1.05,\n",
       "  -0.4252866847718806],\n",
       " [1.682550815041334,\n",
       "  5.0,\n",
       "  0.927358413040275,\n",
       "  1.2295200631268404,\n",
       "  0.8959182829530467,\n",
       "  1.3495336758551628,\n",
       "  0.85,\n",
       "  -0.7055803008608528],\n",
       " [-0.7496617222352403,\n",
       "  3.0,\n",
       "  -0.32842031460832805,\n",
       "  -0.947656541773418,\n",
       "  -0.19080755646318018,\n",
       "  0.7092650895424997,\n",
       "  0.95,\n",
       "  1.0076383574962076],\n",
       " [-1.2756127866296376,\n",
       "  0.0,\n",
       "  -1.0173456800566498,\n",
       "  0.3909906668573729,\n",
       "  0.8020836095804437,\n",
       "  0.5857906825837537,\n",
       "  1.1,\n",
       "  -1.696066384136054],\n",
       " [0.24952941152043628,\n",
       "  3.0,\n",
       "  -0.9397863676820395,\n",
       "  1.0981704074363141,\n",
       "  0.04700733213248275,\n",
       "  -0.9391640733085593,\n",
       "  0.95,\n",
       "  1.5155860292596102],\n",
       " [0.32514791494552975,\n",
       "  2.0,\n",
       "  -0.19937382501241735,\n",
       "  0.81585132246792,\n",
       "  0.4755182958218163,\n",
       "  1.0314590441168194,\n",
       "  1.05,\n",
       "  0.6482162148743396],\n",
       " [-1.236754971778172,\n",
       "  0.0,\n",
       "  1.2368929725573803,\n",
       "  1.897347829337808,\n",
       "  -1.9454971801464769,\n",
       "  0.21668505456455586,\n",
       "  1.1,\n",
       "  0.48254164159895296],\n",
       " [0.3326859730094775,\n",
       "  5.0,\n",
       "  0.022965778800583685,\n",
       "  0.8972536461560473,\n",
       "  0.6974479584143457,\n",
       "  -0.7923122780392187,\n",
       "  0.85,\n",
       "  1.0392733141874437],\n",
       " [1.155459939588917,\n",
       "  1.0,\n",
       "  -0.35470773189904337,\n",
       "  1.5845410878845643,\n",
       "  0.2622675406704056,\n",
       "  0.7302001437202009,\n",
       "  0.9,\n",
       "  -1.2799379482263504],\n",
       " [-0.24814330162294362,\n",
       "  5.0,\n",
       "  1.42203195297041,\n",
       "  -0.0011748868428581689,\n",
       "  -1.7916839397393514,\n",
       "  0.49340793251104154,\n",
       "  0.85,\n",
       "  -0.6871645904689819],\n",
       " [-0.5245809302088121,\n",
       "  4.0,\n",
       "  -1.2306605473081935,\n",
       "  -1.3757487374511168,\n",
       "  0.8970849624065895,\n",
       "  -0.9128404181265614,\n",
       "  1.2,\n",
       "  1.2431261842309895],\n",
       " [1.4231771813696816,\n",
       "  3.0,\n",
       "  -0.587539654784539,\n",
       "  -1.4285998352735276,\n",
       "  1.1125657244754608,\n",
       "  -0.03193462308145814,\n",
       "  0.95,\n",
       "  -0.4400528375345449],\n",
       " [0.5885459005291579,\n",
       "  1.0,\n",
       "  -0.8889126454041323,\n",
       "  1.9359995569086175,\n",
       "  0.0029756095085494436,\n",
       "  0.6345095208455073,\n",
       "  0.9,\n",
       "  0.9881877320404876],\n",
       " [0.5753684382980409,\n",
       "  4.0,\n",
       "  0.8591271673137382,\n",
       "  -1.1453703047260297,\n",
       "  0.39847666306399554,\n",
       "  -0.5948190886627466,\n",
       "  1.2,\n",
       "  -0.10480818837408566],\n",
       " [-1.7372051762125422,\n",
       "  2.0,\n",
       "  -1.3319585432148613,\n",
       "  -1.347932425611451,\n",
       "  -0.46306989886709293,\n",
       "  -0.7264877258832408,\n",
       "  1.05,\n",
       "  1.3582044546704535],\n",
       " [-1.6891209576391342,\n",
       "  3.0,\n",
       "  -0.8393333031012599,\n",
       "  0.6928870238818339,\n",
       "  0.8495732997498702,\n",
       "  -0.8943276326165628,\n",
       "  0.95,\n",
       "  -1.7985409351041548],\n",
       " [-1.7532092062706301,\n",
       "  3.0,\n",
       "  -0.557169724676007,\n",
       "  -1.4449759110530345,\n",
       "  0.9221983884937598,\n",
       "  0.9645563093012383,\n",
       "  0.95,\n",
       "  0.5599110654328568],\n",
       " [1.2608661568839123,\n",
       "  1.0,\n",
       "  -1.086516662257214,\n",
       "  -0.48024444004605576,\n",
       "  -2.813905520146256,\n",
       "  -0.08211790831676777,\n",
       "  0.9,\n",
       "  0.9133573063855228],\n",
       " [-0.017717911247085195,\n",
       "  5.0,\n",
       "  1.1469598641604217,\n",
       "  -0.8826837002984251,\n",
       "  0.3279049658539417,\n",
       "  -0.11165341950940957,\n",
       "  0.85,\n",
       "  -0.49128226258179947],\n",
       " [-1.7303918860773089,\n",
       "  0.0,\n",
       "  0.45210542256282243,\n",
       "  -1.3597914919894145,\n",
       "  0.5859348317774595,\n",
       "  -0.8727087587584629,\n",
       "  1.1,\n",
       "  -0.8418875173897039],\n",
       " [-0.661463628698826,\n",
       "  2.0,\n",
       "  -1.573300151816224,\n",
       "  -0.1603946975248914,\n",
       "  -0.38362568993141843,\n",
       "  0.6459115880094617,\n",
       "  1.05,\n",
       "  1.7551687519772912],\n",
       " [1.7205989258322458,\n",
       "  1.0,\n",
       "  -1.5477674317847845,\n",
       "  -0.022390899607297593,\n",
       "  -1.9086662685296887,\n",
       "  1.5579076784790518,\n",
       "  0.9,\n",
       "  -1.6405662393628204],\n",
       " [1.2344248678095648,\n",
       "  4.0,\n",
       "  -1.2629558700602934,\n",
       "  -1.1880841711403995,\n",
       "  0.1658018383649378,\n",
       "  -0.1669274725672088,\n",
       "  1.2,\n",
       "  0.038372805528960705],\n",
       " [1.8549317111119965,\n",
       "  5.0,\n",
       "  -1.3583995278552046,\n",
       "  1.197343579313307,\n",
       "  -0.025042475390191856,\n",
       "  0.4121535952899552,\n",
       "  0.85,\n",
       "  1.3361467406128722],\n",
       " [0.39635402889512916,\n",
       "  5.0,\n",
       "  0.8731733988027228,\n",
       "  0.17320473507447628,\n",
       "  0.9425482372706223,\n",
       "  -1.99209966690182,\n",
       "  0.85,\n",
       "  0.38880663844967317],\n",
       " [0.8125594365412013,\n",
       "  1.0,\n",
       "  0.3093078384818514,\n",
       "  0.876729541116542,\n",
       "  0.883411908950286,\n",
       "  -1.8801436222895969,\n",
       "  0.9,\n",
       "  0.5839151395356611],\n",
       " [-1.1348745388272672,\n",
       "  4.0,\n",
       "  1.3126901133662552,\n",
       "  -0.5160705626144624,\n",
       "  -0.6608602377185293,\n",
       "  1.6551906599627126,\n",
       "  1.2,\n",
       "  -0.7131885613743242],\n",
       " [-1.49851301524153,\n",
       "  0.0,\n",
       "  -0.7634580779517993,\n",
       "  -0.9106259923369592,\n",
       "  0.9127955990543218,\n",
       "  1.4554784872409394,\n",
       "  1.1,\n",
       "  -1.453120464517031],\n",
       " [0.08217113842416947,\n",
       "  0.0,\n",
       "  -1.247447252116229,\n",
       "  0.06887498807070218,\n",
       "  0.5277649919028482,\n",
       "  1.3780200951956252,\n",
       "  1.1,\n",
       "  -1.263683140925153],\n",
       " [1.3729970749317815,\n",
       "  0.0,\n",
       "  1.2577795435033572,\n",
       "  -0.8623437566645004,\n",
       "  -1.3473732294838887,\n",
       "  -0.8589351014822826,\n",
       "  1.1,\n",
       "  -0.1198405447241977],\n",
       " [0.7600935505309826,\n",
       "  0.0,\n",
       "  1.3167136819842293,\n",
       "  -1.1974686487080748,\n",
       "  0.7877816126521022,\n",
       "  0.5144309928366751,\n",
       "  1.1,\n",
       "  -1.6464726094431466],\n",
       " [-0.36931683666181375,\n",
       "  2.0,\n",
       "  -1.2713863689154787,\n",
       "  -0.22256270261455038,\n",
       "  0.5617547008273445,\n",
       "  0.040094822564593034,\n",
       "  1.05,\n",
       "  1.0342826684734987],\n",
       " [-1.0395933245466265,\n",
       "  4.0,\n",
       "  0.9688958686952105,\n",
       "  1.1295635087004041,\n",
       "  -0.5556159187864436,\n",
       "  0.6835029956744361,\n",
       "  1.2,\n",
       "  -0.3533253061536642],\n",
       " [0.17476305834751252,\n",
       "  5.0,\n",
       "  0.9101288558601119,\n",
       "  0.3886877945560834,\n",
       "  0.6275018177500834,\n",
       "  0.31712403569771763,\n",
       "  0.85,\n",
       "  0.40883644275757564],\n",
       " [1.1739945008161026,\n",
       "  2.0,\n",
       "  -1.599393730430036,\n",
       "  -0.0869845225503957,\n",
       "  -0.11889300607285846,\n",
       "  -1.1736927069048686,\n",
       "  1.05,\n",
       "  0.3206156749443904],\n",
       " [0.3823836123548832,\n",
       "  5.0,\n",
       "  0.47853568014137743,\n",
       "  -1.0881113229839403,\n",
       "  0.1964094967892818,\n",
       "  -1.5785059566781743,\n",
       "  0.85,\n",
       "  0.5341335779010423],\n",
       " [0.6996035090138691,\n",
       "  4.0,\n",
       "  1.089173687566379,\n",
       "  -0.7333928385860502,\n",
       "  0.41885781161441066,\n",
       "  -1.149433815396919,\n",
       "  1.2,\n",
       "  0.6669216345229968],\n",
       " [-0.3429355310361028,\n",
       "  1.0,\n",
       "  0.4776779302293436,\n",
       "  1.6854728129090972,\n",
       "  0.9046823547444018,\n",
       "  0.6386455025280733,\n",
       "  0.9,\n",
       "  0.12235868510740379],\n",
       " [0.7757892442719229,\n",
       "  0.0,\n",
       "  0.04057450497410473,\n",
       "  -1.2289250900854016,\n",
       "  -1.1970686593933104,\n",
       "  -0.5367062926991178,\n",
       "  1.1,\n",
       "  -1.670409613122743],\n",
       " [0.12894794926958053,\n",
       "  3.0,\n",
       "  0.5065362407003628,\n",
       "  0.33954199266012564,\n",
       "  -0.45831897789356346,\n",
       "  -1.3448160122564694,\n",
       "  0.95,\n",
       "  1.0728601492613679],\n",
       " [0.23664203783207077,\n",
       "  5.0,\n",
       "  1.4647989657827587,\n",
       "  1.8971314864756346,\n",
       "  -1.1835649292358357,\n",
       "  1.7722230394227663,\n",
       "  0.85,\n",
       "  -0.747435638685733],\n",
       " [-0.9343915850728455,\n",
       "  1.0,\n",
       "  1.5958810151333611,\n",
       "  -0.7922734177319284,\n",
       "  -0.1913082221559818,\n",
       "  -0.37498284779535995,\n",
       "  0.9,\n",
       "  -0.903553502305243],\n",
       " [-0.8869705268380998,\n",
       "  3.0,\n",
       "  -1.556901777446702,\n",
       "  -1.3254789112075132,\n",
       "  0.4057132171417363,\n",
       "  -0.10875705495906235,\n",
       "  0.95,\n",
       "  0.9594221550643367],\n",
       " [-0.6764346599162598,\n",
       "  4.0,\n",
       "  -0.1085347799662742,\n",
       "  -0.5595221476998798,\n",
       "  0.5122108600715172,\n",
       "  -0.5244407235949019,\n",
       "  1.2,\n",
       "  -0.005420202656126515],\n",
       " [-0.6078041225117959,\n",
       "  5.0,\n",
       "  -1.5296763784876326,\n",
       "  -0.6579017591648485,\n",
       "  -0.7761173397499815,\n",
       "  -0.533251286464985,\n",
       "  0.85,\n",
       "  -0.2370078788557342],\n",
       " [0.29444243644668405,\n",
       "  3.0,\n",
       "  1.577307254363651,\n",
       "  -0.8300701802049635,\n",
       "  -1.0350297773552737,\n",
       "  -1.4878002747394885,\n",
       "  0.95,\n",
       "  -1.3525965541641294],\n",
       " [0.0011977691293724455,\n",
       "  4.0,\n",
       "  1.3382796156511312,\n",
       "  0.2730916463024957,\n",
       "  0.6990403670353262,\n",
       "  1.0415763086416294,\n",
       "  1.2,\n",
       "  0.3394743613216802],\n",
       " [-0.9473893073804628,\n",
       "  3.0,\n",
       "  1.551755307847825,\n",
       "  1.7319332105814862,\n",
       "  0.28065922819306544,\n",
       "  -0.6636960273567662,\n",
       "  0.95,\n",
       "  -0.08326090779493783],\n",
       " [-1.0233853315355939,\n",
       "  3.0,\n",
       "  -0.7888324721649215,\n",
       "  0.01103059804274061,\n",
       "  -0.43150165776949895,\n",
       "  -0.7979777924058427,\n",
       "  0.95,\n",
       "  0.13481553244620204],\n",
       " [0.7001654322103302,\n",
       "  3.0,\n",
       "  -0.9830046359754363,\n",
       "  1.923608230236372,\n",
       "  -1.7539314788387406,\n",
       "  -0.35486663507111765,\n",
       "  0.95,\n",
       "  -0.9600448063288676],\n",
       " [-0.6038509417970034,\n",
       "  1.0,\n",
       "  1.6956204688731096,\n",
       "  0.9094188609158674,\n",
       "  -0.5105106631675426,\n",
       "  0.19532220060650501,\n",
       "  0.9,\n",
       "  0.8206463125148483],\n",
       " [-1.5551157063234466,\n",
       "  3.0,\n",
       "  -0.8123542438463658,\n",
       "  0.994588685321697,\n",
       "  -0.9613549418039762,\n",
       "  -0.6832997562387633,\n",
       "  0.95,\n",
       "  0.7372011611745432],\n",
       " [-0.7939791030715522,\n",
       "  4.0,\n",
       "  1.5704219298666395,\n",
       "  -1.074148924131085,\n",
       "  -2.427889894387259,\n",
       "  0.09154394285991337,\n",
       "  1.2,\n",
       "  0.5384266314684119],\n",
       " [-0.39338319256976995,\n",
       "  5.0,\n",
       "  -0.291755092219387,\n",
       "  1.7263518245086071,\n",
       "  0.7196406920766403,\n",
       "  1.7023102411795725,\n",
       "  0.85,\n",
       "  0.7592656379812148],\n",
       " [0.2118107179215814,\n",
       "  2.0,\n",
       "  -1.5662392283166915,\n",
       "  -1.3802534091555017,\n",
       "  0.8162810753821775,\n",
       "  -0.3803227454640198,\n",
       "  1.05,\n",
       "  -0.7411090054526936],\n",
       " [1.3030832531806238,\n",
       "  1.0,\n",
       "  0.3938764780843887,\n",
       "  -1.1656669908469302,\n",
       "  -3.1947032493263205,\n",
       "  -0.007783293299557116,\n",
       "  0.9,\n",
       "  1.0683697980643927],\n",
       " [1.2008401997115983,\n",
       "  4.0,\n",
       "  0.26001150241631743,\n",
       "  -0.9039450903848129,\n",
       "  -2.579563427697369,\n",
       "  0.8828500028734263,\n",
       "  1.2,\n",
       "  1.050948177671414],\n",
       " [-1.0434165989939033,\n",
       "  0.0,\n",
       "  0.16994093199334165,\n",
       "  0.10428492919368937,\n",
       "  0.7094437507570192,\n",
       "  0.03876220228529674,\n",
       "  1.1,\n",
       "  -0.5072218794495768],\n",
       " [0.4358483259839263,\n",
       "  5.0,\n",
       "  -0.36815235820845665,\n",
       "  -1.0343730351993374,\n",
       "  -0.09893899886334535,\n",
       "  -1.0887336244741903,\n",
       "  0.85,\n",
       "  -1.9511197914112184],\n",
       " [-0.030474552021470317,\n",
       "  3.0,\n",
       "  1.4854307949170578,\n",
       "  -0.6023508423758943,\n",
       "  -1.3160455752444937,\n",
       "  0.7271885354980251,\n",
       "  0.95,\n",
       "  -0.830324750581396],\n",
       " [1.1281276669362021,\n",
       "  5.0,\n",
       "  1.2295828932299502,\n",
       "  0.6800816257401145,\n",
       "  -0.6323268705531252,\n",
       "  -0.5225396241240589,\n",
       "  0.85,\n",
       "  0.7034910062141293],\n",
       " [-0.4005348790599719,\n",
       "  0.0,\n",
       "  -0.34864491456075963,\n",
       "  1.2303826469393533,\n",
       "  -0.15942931383836814,\n",
       "  1.942377014124244,\n",
       "  1.1,\n",
       "  0.7975275596662261],\n",
       " [0.7268689448777852,\n",
       "  1.0,\n",
       "  0.3567686704874869,\n",
       "  1.9434391305490522,\n",
       "  -1.2554977315861986,\n",
       "  -1.0023284673804214,\n",
       "  0.9,\n",
       "  -1.2246806535946397],\n",
       " [-0.3383509701104985,\n",
       "  3.0,\n",
       "  -0.5032361461964432,\n",
       "  -0.8665063464389439,\n",
       "  0.5733090061838934,\n",
       "  0.1997865931357121,\n",
       "  0.95,\n",
       "  0.5358502518672027],\n",
       " [-0.2722372992568216,\n",
       "  4.0,\n",
       "  -0.6226674863445111,\n",
       "  0.18229318527063557,\n",
       "  0.06320589193438038,\n",
       "  0.1299830403425622,\n",
       "  1.2,\n",
       "  -0.43305176238704063],\n",
       " [0.6532113252178375,\n",
       "  3.0,\n",
       "  -1.6044932110287893,\n",
       "  -0.85078758903563,\n",
       "  0.9360760039089971,\n",
       "  0.26106779879593495,\n",
       "  0.95,\n",
       "  -0.6236513400174656],\n",
       " [-1.4705255266981492,\n",
       "  3.0,\n",
       "  1.4582228858539432,\n",
       "  -0.8659267563132572,\n",
       "  -0.15102155855286092,\n",
       "  -1.3195730886760204,\n",
       "  0.95,\n",
       "  -0.10190892199011463],\n",
       " [1.5637785823320378,\n",
       "  3.0,\n",
       "  1.503743631035786,\n",
       "  -1.1584815790492367,\n",
       "  0.5780785170207272,\n",
       "  -1.7026511232921424,\n",
       "  0.95,\n",
       "  0.6117851216610507],\n",
       " [-0.4861039000514497,\n",
       "  0.0,\n",
       "  1.1341896985109536,\n",
       "  -1.0220541564344847,\n",
       "  0.7249711263087375,\n",
       "  -0.5367689896570076,\n",
       "  1.1,\n",
       "  0.27951658147440017],\n",
       " [-1.6370001033298656,\n",
       "  0.0,\n",
       "  0.7944721095198913,\n",
       "  -0.5902280744946629,\n",
       "  -1.3431158216081893,\n",
       "  1.1643264456722724,\n",
       "  1.1,\n",
       "  0.2227785751917272],\n",
       " [1.0520471272391279,\n",
       "  5.0,\n",
       "  0.515122497045904,\n",
       "  -1.2973140371603775,\n",
       "  0.769214764858121,\n",
       "  -0.17561298011503068,\n",
       "  0.85,\n",
       "  -0.9947190808669809],\n",
       " [1.3532477916025236,\n",
       "  3.0,\n",
       "  0.9307035970239252,\n",
       "  1.0806599305681928,\n",
       "  0.8203926085170021,\n",
       "  -1.214799570139988,\n",
       "  0.95,\n",
       "  1.0530247599193108],\n",
       " [-0.5882560943557049,\n",
       "  1.0,\n",
       "  -1.0948529826680675,\n",
       "  -0.5394799539704342,\n",
       "  -0.017556896751396385,\n",
       "  -0.08720463875256894,\n",
       "  0.9,\n",
       "  -1.9663700374739603],\n",
       " [1.4884682469775958,\n",
       "  0.0,\n",
       "  -0.9783990029152219,\n",
       "  -0.7523808041209105,\n",
       "  0.6147574301155535,\n",
       "  -0.40945494530602783,\n",
       "  1.1,\n",
       "  -0.5033483791224028],\n",
       " [-1.1801844860949622,\n",
       "  0.0,\n",
       "  -0.2528064038096131,\n",
       "  1.8181817253549128,\n",
       "  -0.5026448501374231,\n",
       "  1.1987018215885186,\n",
       "  1.1,\n",
       "  -1.7401864939303628],\n",
       " [-0.3859658431678435,\n",
       "  3.0,\n",
       "  1.0615051014039825,\n",
       "  1.698588369308899,\n",
       "  0.939871507129009,\n",
       "  1.0124930455449224,\n",
       "  0.95,\n",
       "  0.43833423912226793],\n",
       " [-0.6899851260893112,\n",
       "  0.0,\n",
       "  1.1945252431579956,\n",
       "  -0.924668243342511,\n",
       "  -0.9826461612138455,\n",
       "  1.459787964727708,\n",
       "  1.1,\n",
       "  0.188354344172973],\n",
       " [0.9367876913389654,\n",
       "  1.0,\n",
       "  0.6840310628695824,\n",
       "  -0.22719005430384517,\n",
       "  0.3510051851233566,\n",
       "  0.6648078932762362,\n",
       "  0.9,\n",
       "  0.5352004749225094],\n",
       " [-0.9624174885208824,\n",
       "  4.0,\n",
       "  -0.7325729940572294,\n",
       "  1.246843144795606,\n",
       "  0.7305743085203977,\n",
       "  0.6330857521457721,\n",
       "  1.2,\n",
       "  1.243073770707833],\n",
       " [-1.546232424597115,\n",
       "  5.0,\n",
       "  -0.913148145133518,\n",
       "  0.6045214923982287,\n",
       "  -2.875319763030491,\n",
       "  -0.04978747105703209,\n",
       "  0.85,\n",
       "  -0.11785407734820944],\n",
       " [1.2127149124774905,\n",
       "  4.0,\n",
       "  -1.1353283391499127,\n",
       "  0.5755600065568309,\n",
       "  0.7264303281461911,\n",
       "  0.31720211787113256,\n",
       "  1.2,\n",
       "  -0.7007847163285539],\n",
       " [0.5331565134722984,\n",
       "  3.0,\n",
       "  1.3565465329224413,\n",
       "  -0.6729859233247752,\n",
       "  1.0844943782196588,\n",
       "  1.3818684718115837,\n",
       "  0.95,\n",
       "  0.6752459492679955],\n",
       " [-1.4629447599783705,\n",
       "  2.0,\n",
       "  -0.9135695286812746,\n",
       "  0.18242142254328753,\n",
       "  0.46061525536258063,\n",
       "  0.30508635706957926,\n",
       "  1.05,\n",
       "  1.078470530828251],\n",
       " [-1.0344676261856955,\n",
       "  1.0,\n",
       "  0.30465818269646033,\n",
       "  1.731221516222393,\n",
       "  -0.10676492220377576,\n",
       "  -0.873789472370461,\n",
       "  0.9,\n",
       "  0.0479064712997809],\n",
       " [1.2136919954453198,\n",
       "  4.0,\n",
       "  -0.7006847361697327,\n",
       "  -0.11394181248852729,\n",
       "  0.16093086869890963,\n",
       "  -1.1729440750448594,\n",
       "  1.2,\n",
       "  0.39866284447708644],\n",
       " [1.6133559733770964,\n",
       "  3.0,\n",
       "  0.24585144165747524,\n",
       "  -1.0826126560043965,\n",
       "  0.729708237578029,\n",
       "  1.1216905384794016,\n",
       "  0.95,\n",
       "  -0.21413880698495316],\n",
       " [0.19718537892958996,\n",
       "  4.0,\n",
       "  -1.3593433817123945,\n",
       "  1.0936437240169534,\n",
       "  -1.1137872761792837,\n",
       "  0.32252048505397946,\n",
       "  1.2,\n",
       "  -0.1701612053150725],\n",
       " [1.4081961433147656,\n",
       "  5.0,\n",
       "  -1.5755715958771843,\n",
       "  -0.34720471459796737,\n",
       "  0.4039753689725637,\n",
       "  0.33843864895735976,\n",
       "  0.85,\n",
       "  0.3350323240909937],\n",
       " [-0.9341169709419239,\n",
       "  1.0,\n",
       "  -0.8969450738192952,\n",
       "  1.6665527687207151,\n",
       "  0.8124146248241948,\n",
       "  0.21127636000918107,\n",
       "  0.9,\n",
       "  0.9159730520649783],\n",
       " [0.9699119612350577,\n",
       "  0.0,\n",
       "  0.8989233548888408,\n",
       "  0.2978987341709649,\n",
       "  0.8123658925624275,\n",
       "  -1.0928866768119512,\n",
       "  1.1,\n",
       "  -0.050466460390162185],\n",
       " [1.5437158741336048,\n",
       "  2.0,\n",
       "  0.20461179358277898,\n",
       "  -1.0868462868800124,\n",
       "  0.20978087638866155,\n",
       "  1.3796693891982519,\n",
       "  1.05,\n",
       "  -1.2385300721155235],\n",
       " [-1.1235234500396523,\n",
       "  2.0,\n",
       "  0.1569822049905231,\n",
       "  1.720742756308075,\n",
       "  0.34139897942396424,\n",
       "  1.372419297002514,\n",
       "  1.05,\n",
       "  -0.571005465010331],\n",
       " [-1.5167698270182535,\n",
       "  3.0,\n",
       "  0.6342235597408943,\n",
       "  0.02312153348094938,\n",
       "  0.22285238262955806,\n",
       "  1.5238374298311566,\n",
       "  0.95,\n",
       "  0.9448013108146042],\n",
       " [1.0067934502089968,\n",
       "  4.0,\n",
       "  -0.9890436540617078,\n",
       "  -0.5785700349116768,\n",
       "  0.5438557432755926,\n",
       "  -0.3370968814996338,\n",
       "  1.2,\n",
       "  -0.7999202427361273],\n",
       " [-0.2681944959474241,\n",
       "  2.0,\n",
       "  0.3925391440184432,\n",
       "  1.329447953307364,\n",
       "  -0.47168869806328506,\n",
       "  0.00732260245280424,\n",
       "  1.05,\n",
       "  -0.6859674244172597],\n",
       " [0.42700351546956666,\n",
       "  0.0,\n",
       "  -1.3597503379028935,\n",
       "  -0.7045632173632544,\n",
       "  0.46094906294885923,\n",
       "  -0.716236654176586,\n",
       "  1.1,\n",
       "  1.0784674460406514],\n",
       " [-0.910224545187423,\n",
       "  5.0,\n",
       "  -0.8427684270651775,\n",
       "  -0.02153874618002862,\n",
       "  0.3040131168366606,\n",
       "  1.6435130780932292,\n",
       "  0.85,\n",
       "  -0.4400902982287818],\n",
       " [-1.6596688685875223,\n",
       "  3.0,\n",
       "  -0.8117716000486956,\n",
       "  1.0874192931981743,\n",
       "  0.8257913216270978,\n",
       "  0.5600495453798492,\n",
       "  0.95,\n",
       "  -0.4724774275786721],\n",
       " [-0.4953839092261141,\n",
       "  4.0,\n",
       "  0.1210983685468731,\n",
       "  -1.4257046133741123,\n",
       "  -1.5512837248774556,\n",
       "  1.3961473535031659,\n",
       "  1.2,\n",
       "  -1.1500999178755182],\n",
       " [-1.278035105106311,\n",
       "  4.0,\n",
       "  1.2519626355799203,\n",
       "  -0.6059732057620812,\n",
       "  0.11593058849695137,\n",
       "  0.2297057900873805,\n",
       "  1.2,\n",
       "  -0.8415527122642862],\n",
       " [-1.4315972789059397,\n",
       "  5.0,\n",
       "  -0.009290458854328925,\n",
       "  -1.2475830519491995,\n",
       "  0.41413342357070504,\n",
       "  -0.45272565187557573,\n",
       "  0.85,\n",
       "  0.17875455445209476],\n",
       " [-1.1364606378896889,\n",
       "  4.0,\n",
       "  0.7207552422763941,\n",
       "  0.4060815552052462,\n",
       "  0.8224617202074785,\n",
       "  -1.8584960902991192,\n",
       "  1.2,\n",
       "  0.9871865201342619],\n",
       " [0.9788178125766727,\n",
       "  2.0,\n",
       "  -1.4785477329594767,\n",
       "  -1.2368226778486047,\n",
       "  1.2777659149977583,\n",
       "  1.9513416180145182,\n",
       "  1.05,\n",
       "  -0.9643549785948778],\n",
       " [-0.19258316544139328,\n",
       "  3.0,\n",
       "  1.314663630912722,\n",
       "  -0.04455422021260602,\n",
       "  0.7102863027757848,\n",
       "  0.0048955606856688145,\n",
       "  0.95,\n",
       "  -0.14028259348676517],\n",
       " [0.5000899944553665,\n",
       "  4.0,\n",
       "  0.6652433704781638,\n",
       "  1.4440840487020388,\n",
       "  0.657715684931335,\n",
       "  1.2678811383919693,\n",
       "  1.2,\n",
       "  -1.8694372031923736],\n",
       " [-0.27142459368682426,\n",
       "  3.0,\n",
       "  -1.2870763780063452,\n",
       "  -0.1694714067598026,\n",
       "  -2.8555756488788364,\n",
       "  1.2628376826837766,\n",
       "  0.95,\n",
       "  0.8712370240551427],\n",
       " [-0.16095810191673174,\n",
       "  1.0,\n",
       "  -1.0227919669193664,\n",
       "  -0.9806804670243353,\n",
       "  -1.4829235803190948,\n",
       "  0.06601674881966409,\n",
       "  0.9,\n",
       "  0.47630463760458425],\n",
       " [1.0098736413305538,\n",
       "  5.0,\n",
       "  -1.3548401462187625,\n",
       "  -0.11545297904485265,\n",
       "  0.5450096483980769,\n",
       "  0.32665854336450834,\n",
       "  0.85,\n",
       "  -0.07866876810753408],\n",
       " [1.429319273242321,\n",
       "  4.0,\n",
       "  1.6506438534796126,\n",
       "  -0.4350785517294609,\n",
       "  -0.6704124019601734,\n",
       "  -0.8971686259754557,\n",
       "  1.2,\n",
       "  -0.8555800893065623],\n",
       " [-0.3629096910790013,\n",
       "  4.0,\n",
       "  -1.044054941345638,\n",
       "  -1.061375649382321,\n",
       "  0.5398843450004376,\n",
       "  0.7614603701983461,\n",
       "  1.2,\n",
       "  0.7956049355420902],\n",
       " [-1.5900384787972015,\n",
       "  0.0,\n",
       "  -0.9864558682613133,\n",
       "  1.1182178807130894,\n",
       "  -0.5638599845641324,\n",
       "  1.1889467550068582,\n",
       "  1.1,\n",
       "  0.40373331075177576],\n",
       " [0.40514237434724815,\n",
       "  4.0,\n",
       "  -0.18722086162473034,\n",
       "  -0.46165918501553543,\n",
       "  1.3516653942065715,\n",
       "  -0.3409444194952286,\n",
       "  1.2,\n",
       "  -0.013212936992328363],\n",
       " [-1.148825515461133,\n",
       "  0.0,\n",
       "  -1.0291186059849415,\n",
       "  0.3828278042496906,\n",
       "  -1.379770186961225,\n",
       "  0.5057022847048407,\n",
       "  1.1,\n",
       "  1.0775408551792884],\n",
       " [0.23788485482925523,\n",
       "  1.0,\n",
       "  0.308594811075183,\n",
       "  -0.2909113150699548,\n",
       "  0.5308330249263419,\n",
       "  -0.27769306827062473,\n",
       "  0.9,\n",
       "  -1.903714502634072],\n",
       " [-0.1427649852552275,\n",
       "  3.0,\n",
       "  1.1839112222752504,\n",
       "  -0.04441193547823121,\n",
       "  0.9235296189922402,\n",
       "  1.909286533936902,\n",
       "  0.95,\n",
       "  0.5712694297401417],\n",
       " [0.5084922132747024,\n",
       "  5.0,\n",
       "  -1.4610425411687464,\n",
       "  -1.3454753254734173,\n",
       "  -1.8071313416638812,\n",
       "  0.4964407396698454,\n",
       "  0.85,\n",
       "  -1.257812062271886],\n",
       " [0.8580731644551988,\n",
       "  4.0,\n",
       "  -0.10575213226799067,\n",
       "  1.593480852672083,\n",
       "  0.1367333399480433,\n",
       "  -0.3236276016481693,\n",
       "  1.2,\n",
       "  0.827371511312109],\n",
       " [-0.6101245863373211,\n",
       "  4.0,\n",
       "  0.5293236955410773,\n",
       "  -1.230647084061575,\n",
       "  0.3100345560621379,\n",
       "  1.2092625624509483,\n",
       "  1.2,\n",
       "  -1.3197068725165872],\n",
       " [-1.5931237367416138,\n",
       "  1.0,\n",
       "  0.15228673160183412,\n",
       "  0.8713221521421675,\n",
       "  0.44017219230951643,\n",
       "  0.22843262507606907,\n",
       "  0.9,\n",
       "  3.0664844875285766],\n",
       " [0.38875805971383837,\n",
       "  0.0,\n",
       "  0.8779423474050481,\n",
       "  1.457503024992371,\n",
       "  1.0708004728217104,\n",
       "  -0.5211371785987614,\n",
       "  1.1,\n",
       "  0.2397158346543198],\n",
       " [0.5006664360485423,\n",
       "  4.0,\n",
       "  -0.10039600137066228,\n",
       "  0.9453089574637297,\n",
       "  0.856142967176578,\n",
       "  1.4127138026520083,\n",
       "  1.2,\n",
       "  0.9341894899696138],\n",
       " [1.1120256989388988,\n",
       "  3.0,\n",
       "  -0.27188283441701894,\n",
       "  -0.2737487964570653,\n",
       "  0.41520553793847814,\n",
       "  -1.0818658441301454,\n",
       "  0.95,\n",
       "  0.33013055969106647],\n",
       " [1.289094768724023,\n",
       "  1.0,\n",
       "  -0.3443992802552242,\n",
       "  0.8963769321796724,\n",
       "  -2.470909600721082,\n",
       "  -1.8688761267604208,\n",
       "  0.9,\n",
       "  -1.9367968653908922],\n",
       " [-1.8777167625036886,\n",
       "  0.0,\n",
       "  1.6278993280110163,\n",
       "  0.5250122668993994,\n",
       "  0.546993672458467,\n",
       "  0.48644782511395035,\n",
       "  1.1,\n",
       "  0.8020299662711774],\n",
       " [1.2931846392402446,\n",
       "  1.0,\n",
       "  -1.33204687794151,\n",
       "  0.3647950869437133,\n",
       "  0.5804461994611605,\n",
       "  -0.6136440563967919,\n",
       "  0.9,\n",
       "  0.5948140374364902],\n",
       " [-1.812680976259264,\n",
       "  3.0,\n",
       "  1.256135589099121,\n",
       "  -0.7228750039344204,\n",
       "  -0.6649064845867235,\n",
       "  -0.9430204366743498,\n",
       "  0.95,\n",
       "  -1.003718596606179],\n",
       " [-0.7651326668966727,\n",
       "  3.0,\n",
       "  1.0712443232398532,\n",
       "  0.4323825092032897,\n",
       "  0.6306814482463143,\n",
       "  -1.9128454061840134,\n",
       "  0.95,\n",
       "  1.0733846384804555],\n",
       " [0.2709588196617225,\n",
       "  2.0,\n",
       "  0.8535409160231877,\n",
       "  0.9256877765199364,\n",
       "  -0.033610511270617975,\n",
       "  -0.9578542324757652,\n",
       "  1.05,\n",
       "  0.5893680573876497],\n",
       " [1.4636045612902997,\n",
       "  5.0,\n",
       "  1.479997324625148,\n",
       "  1.7364913127161077,\n",
       "  0.25166914992189143,\n",
       "  1.3311433880235162,\n",
       "  0.85,\n",
       "  0.6029688811180633],\n",
       " [-1.072239434786948,\n",
       "  4.0,\n",
       "  -1.548145975311335,\n",
       "  -1.2083580225332373,\n",
       "  0.008799071787768382,\n",
       "  -0.687473698054781,\n",
       "  1.2,\n",
       "  -0.2733464633928666],\n",
       " [0.8584355988450788,\n",
       "  5.0,\n",
       "  0.35149997384991855,\n",
       "  -0.3015133505186339,\n",
       "  0.4707752199477612,\n",
       "  1.0095998964018558,\n",
       "  0.85,\n",
       "  1.27162835390699],\n",
       " [1.0352293711744667,\n",
       "  2.0,\n",
       "  -1.1537538258414353,\n",
       "  1.203249155092777,\n",
       "  0.644700249927463,\n",
       "  1.674411451079587,\n",
       "  1.05,\n",
       "  -0.8948862228591693],\n",
       " [-0.691301115364922,\n",
       "  5.0,\n",
       "  -1.5850370459529763,\n",
       "  -1.1167125881755995,\n",
       "  0.005522120216149617,\n",
       "  -0.42877477336558806,\n",
       "  0.85,\n",
       "  0.6087306363522546],\n",
       " [-1.5125797033535542,\n",
       "  4.0,\n",
       "  -1.3709451282144252,\n",
       "  -0.9625389939812907,\n",
       "  1.0129521928355714,\n",
       "  -1.9231068414541665,\n",
       "  1.2,\n",
       "  -1.0110316886024335],\n",
       " [-1.3173938025642493,\n",
       "  4.0,\n",
       "  1.5935605681711742,\n",
       "  -0.883962562940356,\n",
       "  -0.5296155882778912,\n",
       "  -1.1405284107078026,\n",
       "  1.2,\n",
       "  -0.9176894325861876],\n",
       " [-0.09794597522724817,\n",
       "  0.0,\n",
       "  -1.3661133923614166,\n",
       "  -1.3922532342850584,\n",
       "  0.5744012539953377,\n",
       "  0.604089487605378,\n",
       "  1.1,\n",
       "  1.3256328583233352],\n",
       " [-0.6314015444452512,\n",
       "  3.0,\n",
       "  -0.19888390967805336,\n",
       "  1.0497026962610387,\n",
       "  0.09904900005467965,\n",
       "  -0.35181600729352225,\n",
       "  0.95,\n",
       "  0.7277836255242828],\n",
       " [-1.5697130324567967,\n",
       "  2.0,\n",
       "  -0.7208747451044408,\n",
       "  -0.4292428078045188,\n",
       "  0.8957215372596389,\n",
       "  -1.4426069178344252,\n",
       "  1.05,\n",
       "  0.5459744989587371],\n",
       " [-0.49071251144735956,\n",
       "  0.0,\n",
       "  0.3699011947850361,\n",
       "  1.5848323788211687,\n",
       "  0.08670007760280264,\n",
       "  -1.2595892046159987,\n",
       "  1.1,\n",
       "  0.8051780301374607],\n",
       " [0.6573969802320877,\n",
       "  2.0,\n",
       "  0.7362122597203089,\n",
       "  1.391757675720824,\n",
       "  0.04222619693586958,\n",
       "  1.557987348083009,\n",
       "  1.05,\n",
       "  -1.9619841023544506],\n",
       " [-0.8982585927657915,\n",
       "  3.0,\n",
       "  -1.3702962734186634,\n",
       "  -0.6918086528573646,\n",
       "  0.9084240148520519,\n",
       "  0.05899690996948848,\n",
       "  0.95,\n",
       "  -1.8879969084816592],\n",
       " [1.170393240051556,\n",
       "  4.0,\n",
       "  -0.10488149254016703,\n",
       "  -1.0389921647874243,\n",
       "  -0.02754660660355175,\n",
       "  1.5372044986852067,\n",
       "  1.2,\n",
       "  0.8148181829895793],\n",
       " [-0.2965694792636505,\n",
       "  3.0,\n",
       "  -1.2485801617746706,\n",
       "  0.6317979965388648,\n",
       "  -0.4848747716848663,\n",
       "  0.32759201039242103,\n",
       "  0.95,\n",
       "  -0.17554457911293242],\n",
       " [-1.1137835097103825,\n",
       "  4.0,\n",
       "  1.6625556861650908,\n",
       "  1.139797665819819,\n",
       "  0.6725746091217722,\n",
       "  -0.9386901769466673,\n",
       "  1.2,\n",
       "  -1.0281444537114024],\n",
       " [1.2867562532202905,\n",
       "  0.0,\n",
       "  1.485904520763476,\n",
       "  -0.24850264295039287,\n",
       "  -3.5887281868542216,\n",
       "  -1.7404966975380514,\n",
       "  1.1,\n",
       "  1.0324994863141068],\n",
       " [-0.0774775487750847,\n",
       "  1.0,\n",
       "  1.1241689537191242,\n",
       "  -0.3704117260699308,\n",
       "  -0.08389721420091065,\n",
       "  1.348888051022927,\n",
       "  0.9,\n",
       "  -0.19503459631393763],\n",
       " [0.006439071718635466,\n",
       "  3.0,\n",
       "  -0.46989979147651295,\n",
       "  0.7374581612102901,\n",
       "  0.0891769857258024,\n",
       "  1.2437104536654329,\n",
       "  0.95,\n",
       "  0.4298855039088863],\n",
       " [1.506606863292154,\n",
       "  1.0,\n",
       "  0.5719787374214994,\n",
       "  1.5108544554599739,\n",
       "  0.9013250205826085,\n",
       "  1.5798906168311873,\n",
       "  0.9,\n",
       "  -1.9142310449204174],\n",
       " [-1.103971687994777,\n",
       "  1.0,\n",
       "  -0.01957537420537268,\n",
       "  -0.0440857701921307,\n",
       "  0.3811530498414751,\n",
       "  -0.07454739149553491,\n",
       "  0.9,\n",
       "  0.9865250984475842],\n",
       " [-0.9938812264019338,\n",
       "  2.0,\n",
       "  0.021548715392627097,\n",
       "  -0.7856968867950634,\n",
       "  0.6876200677126625,\n",
       "  -0.7258736249885891,\n",
       "  1.05,\n",
       "  1.1110269790325658],\n",
       " [-0.3290612143337145,\n",
       "  0.0,\n",
       "  -1.0850680620560065,\n",
       "  -1.1576409907706946,\n",
       "  -0.2603328634133218,\n",
       "  0.15145936660492232,\n",
       "  1.1,\n",
       "  0.6014146848754204],\n",
       " [-1.573314019999963,\n",
       "  0.0,\n",
       "  1.3909391139083462,\n",
       "  0.116402716310899,\n",
       "  -2.3133073791653453,\n",
       "  0.9958663603552577,\n",
       "  1.1,\n",
       "  -1.0728516801764685],\n",
       " [0.8266514239925501,\n",
       "  3.0,\n",
       "  -0.5848028998761232,\n",
       "  -0.6337866597377542,\n",
       "  0.6470270593822298,\n",
       "  0.0885814295431164,\n",
       "  0.95,\n",
       "  -1.807200400219414],\n",
       " [0.18535923602219273,\n",
       "  1.0,\n",
       "  -1.2954412949750984,\n",
       "  1.209373617433484,\n",
       "  -0.8579177023364598,\n",
       "  -0.004884615156411953,\n",
       "  0.9,\n",
       "  -1.542324861295352],\n",
       " [0.8067710877872795,\n",
       "  1.0,\n",
       "  0.2823274959557701,\n",
       "  -1.2724397140576547,\n",
       "  0.797668780394921,\n",
       "  -0.7736148135232497,\n",
       "  0.9,\n",
       "  -0.6027163411636492],\n",
       " [1.6815847664177148,\n",
       "  4.0,\n",
       "  -0.9514648011161307,\n",
       "  -0.6401479565670619,\n",
       "  -0.6977179271290612,\n",
       "  -0.2645672965001214,\n",
       "  1.2,\n",
       "  -0.24183774377107478],\n",
       " [-1.108993507131546,\n",
       "  1.0,\n",
       "  -0.9566227538140674,\n",
       "  1.3742927421519595,\n",
       "  -0.5541612210571228,\n",
       "  0.09722979012289534,\n",
       "  0.9,\n",
       "  -0.7423718309154215],\n",
       " [0.5036326605408152,\n",
       "  2.0,\n",
       "  0.19972289252770078,\n",
       "  0.5134836049337085,\n",
       "  -0.9358896555158214,\n",
       "  0.19798627171677485,\n",
       "  1.05,\n",
       "  0.8950629996074966],\n",
       " [1.585942550045258,\n",
       "  2.0,\n",
       "  -0.938871345651653,\n",
       "  0.950373435191731,\n",
       "  0.6402947947572516,\n",
       "  -0.44873720120370114,\n",
       "  1.05,\n",
       "  -0.9712265078354342],\n",
       " [-1.502190540537329,\n",
       "  4.0,\n",
       "  -0.5324722103511041,\n",
       "  0.7291358304319522,\n",
       "  0.2586933125505875,\n",
       "  -0.7281043677081948,\n",
       "  1.2,\n",
       "  -1.436043004867653],\n",
       " [0.25677274486688845,\n",
       "  2.0,\n",
       "  -0.20656400869359082,\n",
       "  1.047206524584854,\n",
       "  0.7100760596823849,\n",
       "  0.5331681438788556,\n",
       "  1.05,\n",
       "  -0.25495782120155824],\n",
       " [-1.4664268820690745,\n",
       "  0.0,\n",
       "  0.9182045286972497,\n",
       "  -0.6063490092737794,\n",
       "  1.2566991856083045,\n",
       "  -0.7311754100376843,\n",
       "  1.1,\n",
       "  1.308952991397025],\n",
       " [1.7592382770842874,\n",
       "  0.0,\n",
       "  0.6067504517937767,\n",
       "  1.705841799076983,\n",
       "  -0.08098935863832839,\n",
       "  0.18026010935875514,\n",
       "  1.1,\n",
       "  -1.1004174629846981],\n",
       " [-1.6297704746113537,\n",
       "  2.0,\n",
       "  -0.41642219496748134,\n",
       "  0.212183137943208,\n",
       "  -0.7007069472778413,\n",
       "  -1.0943812381846418,\n",
       "  1.05,\n",
       "  -0.9545549419080742],\n",
       " [0.9918885034324554,\n",
       "  3.0,\n",
       "  0.718334343873962,\n",
       "  1.4926011989045689,\n",
       "  -1.1906161601767282,\n",
       "  -1.931447237302342,\n",
       "  0.95,\n",
       "  0.41516125220781624],\n",
       " [-1.4489104289020351,\n",
       "  4.0,\n",
       "  -0.7839259444098066,\n",
       "  0.7803725518637625,\n",
       "  1.322042252710903,\n",
       "  -0.9469490826086426,\n",
       "  1.2,\n",
       "  0.5805785249772103],\n",
       " [1.708586538857594,\n",
       "  1.0,\n",
       "  -0.17584933735408365,\n",
       "  -1.2582324009890766,\n",
       "  0.7047556262589708,\n",
       "  1.724427577173166,\n",
       "  0.9,\n",
       "  -1.3601824554627113],\n",
       " [1.235733971070719,\n",
       "  0.0,\n",
       "  0.23423678857756558,\n",
       "  -8.060176988209331e-05,\n",
       "  0.34701919779576335,\n",
       "  -0.06605577053408951,\n",
       "  1.1,\n",
       "  -1.1269279150819422],\n",
       " [-0.6936443206292625,\n",
       "  1.0,\n",
       "  1.005862345492687,\n",
       "  -1.4302521021002852,\n",
       "  -0.5975978083360383,\n",
       "  1.481574887042414,\n",
       "  0.9,\n",
       "  0.6378163686086078],\n",
       " [-1.4062603780589098,\n",
       "  4.0,\n",
       "  -0.38317964893961365,\n",
       "  -0.6981486619169964,\n",
       "  0.586772169414293,\n",
       "  0.09733804696310157,\n",
       "  1.2,\n",
       "  0.2636866950196522],\n",
       " [1.7108618676065706,\n",
       "  0.0,\n",
       "  -1.4965593519596219,\n",
       "  -1.4355045158450672,\n",
       "  -0.3262407698136446,\n",
       "  1.1615980515913589,\n",
       "  1.1,\n",
       "  0.6506398031810615],\n",
       " [0.7284428071889661,\n",
       "  4.0,\n",
       "  -0.05851850481690782,\n",
       "  -1.1027799438507366,\n",
       "  -2.2397759527406462,\n",
       "  -1.0122133269997926,\n",
       "  1.2,\n",
       "  -0.7565796307999679],\n",
       " [1.4534581096197274,\n",
       "  5.0,\n",
       "  1.0049270213532646,\n",
       "  -0.5768058575081059,\n",
       "  -0.14226415603296982,\n",
       "  0.9397646583036495,\n",
       "  0.85,\n",
       "  -0.647842590123798],\n",
       " [-0.5263286789066334,\n",
       "  4.0,\n",
       "  -1.6879775040769587,\n",
       "  -0.046057595642315464,\n",
       "  0.05258816042914744,\n",
       "  -0.4814428078354286,\n",
       "  1.2,\n",
       "  0.19125799188644382],\n",
       " [0.3697827229144364,\n",
       "  2.0,\n",
       "  -0.3950565873851421,\n",
       "  0.5560749040100752,\n",
       "  1.054223527468399,\n",
       "  -0.379236315600207,\n",
       "  1.05,\n",
       "  -0.14456414416604565],\n",
       " [0.24629159097845799,\n",
       "  4.0,\n",
       "  -0.6207999017849793,\n",
       "  -1.2161568799067934,\n",
       "  -1.2342764485534383,\n",
       "  -0.029732532122528788,\n",
       "  1.2,\n",
       "  -0.9532957437484285],\n",
       " [-0.7134059308356814,\n",
       "  3.0,\n",
       "  1.6738893694113686,\n",
       "  0.956532332289581,\n",
       "  -2.333602018496248,\n",
       "  -1.2420520564730653,\n",
       "  0.95,\n",
       "  0.8683513632147587],\n",
       " [-1.3293289974278142,\n",
       "  3.0,\n",
       "  -0.24206445284289294,\n",
       "  -0.7499344809318438,\n",
       "  0.09539211180059946,\n",
       "  -0.8597979307395759,\n",
       "  0.95,\n",
       "  0.15904237782081646],\n",
       " [0.9454606420193491,\n",
       "  4.0,\n",
       "  -1.6518380678182514,\n",
       "  1.7298962849247688,\n",
       "  0.670958053659361,\n",
       "  -0.24688660994151035,\n",
       "  1.2,\n",
       "  0.3995751006749614],\n",
       " [0.4004320624778799,\n",
       "  0.0,\n",
       "  -1.164788368882226,\n",
       "  -1.0835234683959014,\n",
       "  0.7409165686704444,\n",
       "  0.7478296031386984,\n",
       "  1.1,\n",
       "  -0.4526694312178314],\n",
       " [0.3779264290246198,\n",
       "  0.0,\n",
       "  -0.8756776877104423,\n",
       "  1.1809364267859672,\n",
       "  1.078490286235516,\n",
       "  -1.9333579765322877,\n",
       "  1.1,\n",
       "  -1.3504269089276146],\n",
       " [0.27864952047453423,\n",
       "  5.0,\n",
       "  -0.484012608228664,\n",
       "  0.9235685133025444,\n",
       "  0.7072646062436936,\n",
       "  -1.5031285838541937,\n",
       "  0.85,\n",
       "  0.7484851204776317],\n",
       " [0.7302959508027466,\n",
       "  4.0,\n",
       "  0.9708497691421588,\n",
       "  -1.3388490862819258,\n",
       "  0.5371816790212265,\n",
       "  -1.2697466829869892,\n",
       "  1.2,\n",
       "  -0.7638942172571214],\n",
       " [0.9660754098070836,\n",
       "  2.0,\n",
       "  -0.8847695497288061,\n",
       "  -1.0261880059648172,\n",
       "  0.7309861657098098,\n",
       "  0.013616827304879734,\n",
       "  1.05,\n",
       "  0.9303729174718371],\n",
       " [0.758876020549187,\n",
       "  4.0,\n",
       "  -1.0152627891795252,\n",
       "  -0.8438804718459111,\n",
       "  -0.19447610609745475,\n",
       "  -1.9277279055621277,\n",
       "  1.2,\n",
       "  0.35545077677169373],\n",
       " [-1.1044079391342936,\n",
       "  2.0,\n",
       "  0.96027829996178,\n",
       "  1.5138649949187117,\n",
       "  0.2927237317466399,\n",
       "  0.4754640620692001,\n",
       "  1.05,\n",
       "  1.071190820105849],\n",
       " [0.7186265535445687,\n",
       "  3.0,\n",
       "  0.10421095300182123,\n",
       "  -0.7124404410177135,\n",
       "  0.9010454697448578,\n",
       "  0.9024585602942088,\n",
       "  0.95,\n",
       "  1.0586573864245332],\n",
       " [-0.17265805045369043,\n",
       "  1.0,\n",
       "  -0.7648589652228658,\n",
       "  -1.1745601406246944,\n",
       "  0.9089933357899975,\n",
       "  -1.0673862879884306,\n",
       "  0.9,\n",
       "  0.8938517687885112],\n",
       " [0.3994737141099948,\n",
       "  0.0,\n",
       "  0.29493417209883827,\n",
       "  0.16751191813549196,\n",
       "  0.059524606469465474,\n",
       "  1.1936828934581547,\n",
       "  1.1,\n",
       "  -0.8056009216427288],\n",
       " [0.6151054366931783,\n",
       "  0.0,\n",
       "  1.1555724525063127,\n",
       "  -0.3946001296104163,\n",
       "  0.2362963735483651,\n",
       "  1.1052471441186869,\n",
       "  1.1,\n",
       "  -0.8368748192151968],\n",
       " [-1.1631865386589715,\n",
       "  3.0,\n",
       "  -0.8245988957739961,\n",
       "  -0.8151189939630882,\n",
       "  -0.42747845392607026,\n",
       "  -0.29048641394847285,\n",
       "  0.95,\n",
       "  -1.3918950038528397],\n",
       " [0.14067743651776463,\n",
       "  4.0,\n",
       "  -0.032895648634348705,\n",
       "  -1.1170690684961204,\n",
       "  0.4284555234083932,\n",
       "  0.5764664809178109,\n",
       "  1.2,\n",
       "  1.0509141308694487],\n",
       " [-0.6055720540590417,\n",
       "  0.0,\n",
       "  1.5478370723190071,\n",
       "  1.0866505282717867,\n",
       "  0.5172705398970384,\n",
       "  1.8745902875494629,\n",
       "  1.1,\n",
       "  -0.983744609016658],\n",
       " [0.8754236255775959,\n",
       "  4.0,\n",
       "  1.1188309479528937,\n",
       "  -0.7514778075489357,\n",
       "  -0.13286427880697313,\n",
       "  0.2541437511731184,\n",
       "  1.2,\n",
       "  -0.7070883738237644],\n",
       " [1.061916262521639,\n",
       "  5.0,\n",
       "  -0.3969545328105017,\n",
       "  0.9643347533475513,\n",
       "  -1.6948232454931378,\n",
       "  -0.6416320151662891,\n",
       "  0.85,\n",
       "  -0.7654888093919368],\n",
       " [0.5820464130515114,\n",
       "  2.0,\n",
       "  -1.6091849049866966,\n",
       "  -0.09002712499018115,\n",
       "  -0.24796667134264583,\n",
       "  -1.1575070925863113,\n",
       "  1.05,\n",
       "  0.12358999975579316],\n",
       " [0.8814568840594823,\n",
       "  0.0,\n",
       "  0.22006755620538374,\n",
       "  0.45358358217411476,\n",
       "  1.0666102589111244,\n",
       "  0.3475145916031086,\n",
       "  1.1,\n",
       "  0.8716442351435769],\n",
       " [0.27223916154381184,\n",
       "  5.0,\n",
       "  -1.5666583685354192,\n",
       "  -0.44640371945131824,\n",
       "  0.9637158024017091,\n",
       "  -1.176573483293919,\n",
       "  0.85,\n",
       "  0.7932953820915296],\n",
       " [-0.4687178092169578,\n",
       "  3.0,\n",
       "  0.6324987841114426,\n",
       "  -0.39209315363018843,\n",
       "  0.22990718328394047,\n",
       "  1.5143990523520114,\n",
       "  0.95,\n",
       "  0.9730095240225123],\n",
       " [1.1851990487330888,\n",
       "  4.0,\n",
       "  0.8631612823186592,\n",
       "  -1.1968006146345025,\n",
       "  -1.7918715972045984,\n",
       "  0.25262577929463276,\n",
       "  1.2,\n",
       "  0.9033082054356332],\n",
       " [-0.08088932128502938,\n",
       "  0.0,\n",
       "  -0.1440831146978411,\n",
       "  -0.5404232709736619,\n",
       "  -0.8961860986845899,\n",
       "  -1.4605689146684186,\n",
       "  1.1,\n",
       "  1.0780151001602367],\n",
       " [0.9296273214729911,\n",
       "  1.0,\n",
       "  1.2751168026026543,\n",
       "  0.23116330943962204,\n",
       "  -2.0769132345362102,\n",
       "  -0.7989697912385106,\n",
       "  0.9,\n",
       "  -1.792451621127633],\n",
       " [0.13698299306448053,\n",
       "  1.0,\n",
       "  -0.360627436199269,\n",
       "  1.4872259550218738,\n",
       "  -0.3349996327947926,\n",
       "  -0.004923448485653179,\n",
       "  0.9,\n",
       "  0.3916310793647896],\n",
       " [0.25755457849484753,\n",
       "  5.0,\n",
       "  -0.533230134352415,\n",
       "  1.606528727620085,\n",
       "  0.44234326296957793,\n",
       "  0.36287670418054635,\n",
       "  0.85,\n",
       "  -0.7622170427193645],\n",
       " [0.6967662248748284,\n",
       "  5.0,\n",
       "  1.032223857007615,\n",
       "  -0.8781996901226088,\n",
       "  -3.770026519018165,\n",
       "  0.04621742742292279,\n",
       "  0.85,\n",
       "  -1.946244404311597],\n",
       " [-1.7728969674181225,\n",
       "  1.0,\n",
       "  -0.581958134067689,\n",
       "  -0.6211995807477828,\n",
       "  -0.6270396186678617,\n",
       "  -0.13021716918831835,\n",
       "  0.9,\n",
       "  -1.9681469421667854],\n",
       " [-0.33268121671439216,\n",
       "  3.0,\n",
       "  -1.3566012671490797,\n",
       "  -1.1821683460838088,\n",
       "  1.0417940717678014,\n",
       "  0.6198259748674497,\n",
       "  0.95,\n",
       "  -0.49449386972509274],\n",
       " [-0.6905292132977012,\n",
       "  4.0,\n",
       "  -0.12848750133681033,\n",
       "  0.12521584425607077,\n",
       "  -0.5212106164464078,\n",
       "  0.4671867274891554,\n",
       "  1.2,\n",
       "  0.4357706188906945],\n",
       " [0.9869997000545803,\n",
       "  2.0,\n",
       "  -0.03724523974324487,\n",
       "  1.3420944241259463,\n",
       "  0.322825509110751,\n",
       "  -0.5400539044187479,\n",
       "  1.05,\n",
       "  -1.303190765026431],\n",
       " [-0.9077872406690514,\n",
       "  3.0,\n",
       "  -1.12209194502759,\n",
       "  0.5320006239016013,\n",
       "  0.7888031076205003,\n",
       "  0.22910083942407955,\n",
       "  0.95,\n",
       "  -0.9223815505364434],\n",
       " [-1.6175418990105104,\n",
       "  5.0,\n",
       "  -1.6248430246120298,\n",
       "  0.9383687510445973,\n",
       "  0.6433271493514493,\n",
       "  1.8152081760530445,\n",
       "  0.85,\n",
       "  -0.5564225208919243],\n",
       " [0.995721864779181,\n",
       "  4.0,\n",
       "  -0.4732753322632044,\n",
       "  0.09782015011440841,\n",
       "  0.8218634133866076,\n",
       "  0.0943609775982142,\n",
       "  1.2,\n",
       "  0.3267929069491691],\n",
       " [0.6811561368248099,\n",
       "  4.0,\n",
       "  0.8500009817243831,\n",
       "  1.5083956088137047,\n",
       "  0.5661889486106553,\n",
       "  0.035702055907271275,\n",
       "  1.2,\n",
       "  1.077096796569865],\n",
       " [1.4840407217255531,\n",
       "  2.0,\n",
       "  -1.0923913993673169,\n",
       "  -0.833878963045275,\n",
       "  0.8685413530292572,\n",
       "  -0.019950859781297226,\n",
       "  1.05,\n",
       "  0.43313703768088585],\n",
       " [0.7788623098017464,\n",
       "  3.0,\n",
       "  -0.4489573791838145,\n",
       "  0.04832254552140042,\n",
       "  0.8092445744167782,\n",
       "  1.830695680114283,\n",
       "  0.95,\n",
       "  0.85070466777047],\n",
       " [-0.0772229057698672,\n",
       "  0.0,\n",
       "  -1.0766196897077092,\n",
       "  -0.9837758837784794,\n",
       "  0.3953419129580992,\n",
       "  0.8128056945713377,\n",
       "  1.1,\n",
       "  -1.0420597468619546],\n",
       " [-0.28785419276654606,\n",
       "  3.0,\n",
       "  -0.7103220046529094,\n",
       "  0.09624726806659482,\n",
       "  0.651244753480385,\n",
       "  0.050889347914916325,\n",
       "  0.95,\n",
       "  -0.031036367150494255],\n",
       " [1.1495566667973691,\n",
       "  3.0,\n",
       "  0.6173045699204207,\n",
       "  0.8003322042103935,\n",
       "  -0.8872344200265404,\n",
       "  -0.2051216549418083,\n",
       "  0.95,\n",
       "  1.0717274116416815],\n",
       " [-1.683014970406138,\n",
       "  1.0,\n",
       "  1.4366869492553438,\n",
       "  -1.3394677867479012,\n",
       "  -0.1406885552871929,\n",
       "  1.5069689292182658,\n",
       "  0.9,\n",
       "  -1.367237941699353],\n",
       " [0.27305031104464816,\n",
       "  2.0,\n",
       "  -0.024474409993004903,\n",
       "  1.012383598118449,\n",
       "  -0.024422183564293685,\n",
       "  -1.0861897586847449,\n",
       "  1.05,\n",
       "  -0.25177533201913527],\n",
       " [-0.2959956763257084,\n",
       "  2.0,\n",
       "  1.6592786375469126,\n",
       "  -0.7067666828061072,\n",
       "  0.5962810719498963,\n",
       "  -0.7804109594622389,\n",
       "  1.05,\n",
       "  -0.8266610858202874],\n",
       " [0.4689082581104156,\n",
       "  4.0,\n",
       "  0.9141600440916762,\n",
       "  -0.831715987911445,\n",
       "  -0.1325771463317001,\n",
       "  0.35175403393139965,\n",
       "  1.2,\n",
       "  0.9671777938892662],\n",
       " [1.6466815304426254,\n",
       "  3.0,\n",
       "  -1.0537896906505664,\n",
       "  1.2639163997595946,\n",
       "  0.6620398077053178,\n",
       "  1.103075527687954,\n",
       "  0.95,\n",
       "  -0.055068171351008936],\n",
       " [0.7458568366586651,\n",
       "  5.0,\n",
       "  1.410955312356907,\n",
       "  -1.3348965887063262,\n",
       "  0.7520838558418729,\n",
       "  -1.791878181777878,\n",
       "  0.85,\n",
       "  0.7458220622076601],\n",
       " [-1.0191923227202855,\n",
       "  0.0,\n",
       "  -0.7270991699704109,\n",
       "  -1.3046010709471,\n",
       "  0.8505454177631447,\n",
       "  -0.5569212180300892,\n",
       "  1.1,\n",
       "  -0.4563144251805243],\n",
       " [1.3130658199626282,\n",
       "  2.0,\n",
       "  1.2056241968466466,\n",
       "  1.4863660977825304,\n",
       "  -3.1474032546931596,\n",
       "  -0.08954727796531688,\n",
       "  1.05,\n",
       "  0.9742876935405038],\n",
       " [-1.16151476351455,\n",
       "  4.0,\n",
       "  0.9025741262227958,\n",
       "  1.290820273632623,\n",
       "  0.4015846038434724,\n",
       "  -0.720837224410974,\n",
       "  1.2,\n",
       "  0.7169757118084318],\n",
       " [-0.19859711381206283,\n",
       "  4.0,\n",
       "  1.642566283022034,\n",
       "  0.5439590489158779,\n",
       "  -3.70460273985139,\n",
       "  -0.46844540876140506,\n",
       "  1.2,\n",
       "  -0.9500316653468238],\n",
       " [0.9977370455595278,\n",
       "  5.0,\n",
       "  0.7937666036322131,\n",
       "  0.14708675286814368,\n",
       "  0.4192719251373116,\n",
       "  -0.4010956828715916,\n",
       "  0.85,\n",
       "  -0.8582137048998763],\n",
       " [1.7517995407618185,\n",
       "  3.0,\n",
       "  1.2692087692665348,\n",
       "  -0.4481792162755167,\n",
       "  0.7448375665005993,\n",
       "  -0.831244718868598,\n",
       "  0.95,\n",
       "  -1.5600206232182094],\n",
       " [-0.3867671375154484,\n",
       "  1.0,\n",
       "  0.31155830704775545,\n",
       "  -0.3069111905797378,\n",
       "  0.8210784152816702,\n",
       "  0.7786394255255455,\n",
       "  0.9,\n",
       "  0.5536368603663107],\n",
       " [1.1784731591249484,\n",
       "  1.0,\n",
       "  1.6283979570886629,\n",
       "  1.5202314866549231,\n",
       "  0.769412570000365,\n",
       "  -1.6093479920100568,\n",
       "  0.9,\n",
       "  -1.0559564038680973],\n",
       " [-0.9965495656746444,\n",
       "  5.0,\n",
       "  1.261116857660168,\n",
       "  1.4840686280427897,\n",
       "  -0.09294876794700967,\n",
       "  -0.01065037382221062,\n",
       "  0.85,\n",
       "  -0.7184604475528005],\n",
       " [-0.9342687432384671,\n",
       "  2.0,\n",
       "  -1.5113094968588947,\n",
       "  0.30384018902006016,\n",
       "  0.9055584180156293,\n",
       "  -0.6870502610892016,\n",
       "  1.05,\n",
       "  1.0782510595793109],\n",
       " [-0.7751622908164811,\n",
       "  5.0,\n",
       "  -1.60369691482077,\n",
       "  1.763222309969993,\n",
       "  0.34447137470143946,\n",
       "  0.6241220838950011,\n",
       "  0.85,\n",
       "  -0.4286576247359768],\n",
       " [-0.38914434389446745,\n",
       "  3.0,\n",
       "  -0.4217247266809739,\n",
       "  -0.9872078638070746,\n",
       "  0.49559933147539215,\n",
       "  -0.6050757348837419,\n",
       "  0.95,\n",
       "  -0.09977927075546933],\n",
       " [-1.5465361904482955,\n",
       "  5.0,\n",
       "  -0.9602356591127181,\n",
       "  -0.8753073188688416,\n",
       "  0.8352423801604117,\n",
       "  1.6780302890937207,\n",
       "  0.85,\n",
       "  -1.7935056512531782],\n",
       " [1.8368574972770018,\n",
       "  2.0,\n",
       "  1.689343846577013,\n",
       "  1.068468096194783,\n",
       "  -0.4216487993383032,\n",
       "  -0.08600244259536535,\n",
       "  1.05,\n",
       "  0.8865823779346215],\n",
       " [0.9150211830449926,\n",
       "  4.0,\n",
       "  -1.0921577391302093,\n",
       "  1.2541062622496202,\n",
       "  0.8845270809573739,\n",
       "  0.0063935996280661735,\n",
       "  1.2,\n",
       "  0.857900134872234],\n",
       " [-0.643242870348327,\n",
       "  5.0,\n",
       "  1.116563462607916,\n",
       "  -1.1161081000426276,\n",
       "  0.11056447302302075,\n",
       "  0.01851543666601142,\n",
       "  0.85,\n",
       "  0.9648147307789922],\n",
       " [-0.047436513041356966,\n",
       "  1.0,\n",
       "  -1.5150414698525554,\n",
       "  1.219533876074622,\n",
       "  -0.32913445610036324,\n",
       "  1.151512613210282,\n",
       "  0.9,\n",
       "  1.072733727892675],\n",
       " [0.5176572223508348,\n",
       "  2.0,\n",
       "  1.1652996467227856,\n",
       "  0.5999009617534693,\n",
       "  0.896092167987039,\n",
       "  1.1897347781051955,\n",
       "  1.05,\n",
       "  -0.02385806990848519],\n",
       " [-0.99192997915999,\n",
       "  0.0,\n",
       "  0.6701514005304114,\n",
       "  -0.8200508244123668,\n",
       "  0.6702360130678853,\n",
       "  1.408996703611624,\n",
       "  1.1,\n",
       "  -1.8536164619630784],\n",
       " [-0.31983016307480466,\n",
       "  0.0,\n",
       "  -1.0917095268807087,\n",
       "  -1.039670377437188,\n",
       "  0.5372650364773045,\n",
       "  -0.02158611298868459,\n",
       "  1.1,\n",
       "  -0.26584157695678395],\n",
       " [1.3851612115378797,\n",
       "  5.0,\n",
       "  0.44763956096806345,\n",
       "  1.596185572264648,\n",
       "  -0.18282148671867898,\n",
       "  0.15002883348004828,\n",
       "  0.85,\n",
       "  -1.5413233473621717],\n",
       " [-0.20110355963398338,\n",
       "  1.0,\n",
       "  1.2475751168672933,\n",
       "  0.14372918423662254,\n",
       "  0.6701865653930885,\n",
       "  0.355173272410203,\n",
       "  0.9,\n",
       "  -0.6516668684807441],\n",
       " [0.656893313264343,\n",
       "  2.0,\n",
       "  1.1307975810375994,\n",
       "  -0.906566263204924,\n",
       "  0.4633218854302641,\n",
       "  1.9150409839902578,\n",
       "  1.05,\n",
       "  -0.32638389493952624],\n",
       " [-0.33465412014855184,\n",
       "  4.0,\n",
       "  -0.039242969946156336,\n",
       "  -0.6003299291193586,\n",
       "  0.7869963288530699,\n",
       "  1.7164135308300708,\n",
       "  1.2,\n",
       "  -0.6478072794345571],\n",
       " [1.1202867298124166,\n",
       "  2.0,\n",
       "  -1.6607981775405745,\n",
       "  -0.9228048322945872,\n",
       "  -0.7067047866482643,\n",
       "  -0.6226959533396876,\n",
       "  1.05,\n",
       "  1.0445299043231537],\n",
       " [-0.8461817673692659,\n",
       "  3.0,\n",
       "  -0.3788294362618966,\n",
       "  -1.4024744240926026,\n",
       "  0.8071611626120685,\n",
       "  0.40658703037552163,\n",
       "  0.95,\n",
       "  0.21607464086357145],\n",
       " [0.5301183429945218,\n",
       "  0.0,\n",
       "  -0.9140021683945533,\n",
       "  0.08926051673598372,\n",
       "  -1.6321033569496055,\n",
       "  1.6562102219323334,\n",
       "  1.1,\n",
       "  0.8856602708873098],\n",
       " [-0.9764925590597026,\n",
       "  4.0,\n",
       "  -0.16288213926794698,\n",
       "  0.615458707239353,\n",
       "  -0.1020020809880277,\n",
       "  1.224662806345093,\n",
       "  1.2,\n",
       "  -0.08454623465767626],\n",
       " [-1.4506492335532661,\n",
       "  4.0,\n",
       "  -1.071203543755227,\n",
       "  0.16599107463826515,\n",
       "  -0.18229357259092227,\n",
       "  -0.45677660659570174,\n",
       "  1.2,\n",
       "  -0.9969502967054246],\n",
       " [1.2483936230378716,\n",
       "  0.0,\n",
       "  0.0291818149537501,\n",
       "  -1.0575669404541772,\n",
       "  0.22862297438867615,\n",
       "  0.02818293980618774,\n",
       "  1.1,\n",
       "  0.7415990244253113],\n",
       " [-0.10463791606095284,\n",
       "  1.0,\n",
       "  -0.6337707692369647,\n",
       "  -1.2362108780421974,\n",
       "  -1.425420431855817,\n",
       "  -1.867602062928786,\n",
       "  0.9,\n",
       "  -0.9357705071640158],\n",
       " [-0.3482354984311135,\n",
       "  3.0,\n",
       "  -1.153462348732518,\n",
       "  1.1917264821117486,\n",
       "  0.18203723497511806,\n",
       "  -0.07986102090231031,\n",
       "  0.95,\n",
       "  -0.3666329340357872],\n",
       " [-0.06521983857587606,\n",
       "  5.0,\n",
       "  -1.3714095467097105,\n",
       "  -1.2249676893979207,\n",
       "  -2.1261557250670866,\n",
       "  -0.6746709716685622,\n",
       "  0.85,\n",
       "  -0.9735311515048338],\n",
       " [1.323101511162291,\n",
       "  3.0,\n",
       "  0.5654763263780112,\n",
       "  -1.0069432552562925,\n",
       "  -0.2494272492417127,\n",
       "  -0.5363004848529932,\n",
       "  0.95,\n",
       "  0.282115985038191],\n",
       " [-1.3468920364738863,\n",
       "  1.0,\n",
       "  -1.1006503588662058,\n",
       "  1.954708256342054,\n",
       "  -0.09408209795420135,\n",
       "  -1.2058530307475426,\n",
       "  0.9,\n",
       "  0.5330062829585601],\n",
       " [-0.49413726095495236,\n",
       "  1.0,\n",
       "  -0.38064988576212516,\n",
       "  -0.9784473103124167,\n",
       "  0.7200719032369971,\n",
       "  0.1675197661752684,\n",
       "  0.9,\n",
       "  0.6269883340863326],\n",
       " [-1.008571201823698,\n",
       "  5.0,\n",
       "  0.7694423694568909,\n",
       "  0.9370365486284217,\n",
       "  0.32247312296570013,\n",
       "  -0.00033859298892862066,\n",
       "  0.85,\n",
       "  -1.2237003265312694],\n",
       " [1.5824929582184297,\n",
       "  4.0,\n",
       "  -0.5843079482106116,\n",
       "  -0.7956768934221781,\n",
       "  0.7265336521642559,\n",
       "  -0.6231014357202107,\n",
       "  1.2,\n",
       "  1.0010325506897415],\n",
       " [0.7937946642873901,\n",
       "  5.0,\n",
       "  0.8266835349119777,\n",
       "  1.7675462845725212,\n",
       "  0.4543767910775935,\n",
       "  -1.1795796908617973,\n",
       "  0.85,\n",
       "  -0.07551271527182706],\n",
       " [1.3686878887028977,\n",
       "  2.0,\n",
       "  -0.03625217873706787,\n",
       "  1.7488015232831486,\n",
       "  1.3176731360376526,\n",
       "  -0.14938426884616438,\n",
       "  1.05,\n",
       "  0.049324219292192266],\n",
       " [-1.0164170326655297,\n",
       "  5.0,\n",
       "  -1.2047629912930038,\n",
       "  0.28525487467692423,\n",
       "  0.8535479066439481,\n",
       "  -1.0656775163474292,\n",
       "  0.85,\n",
       "  3.2374983732456197],\n",
       " [-0.7243847544019554,\n",
       "  1.0,\n",
       "  -1.0096488320085721,\n",
       "  0.5333227553495031,\n",
       "  1.0949306615290648,\n",
       "  -0.5916766457428049,\n",
       "  0.9,\n",
       "  1.0380267080125856],\n",
       " [0.9861469648336926,\n",
       "  5.0,\n",
       "  0.21330466730550687,\n",
       "  -0.7521968939559912,\n",
       "  -0.3620628959498997,\n",
       "  0.9870626484642345,\n",
       "  0.85,\n",
       "  1.0430075072544656],\n",
       " [1.452699573274461,\n",
       "  4.0,\n",
       "  -0.7751946302779669,\n",
       "  1.612298632786985,\n",
       "  -0.8005924462065763,\n",
       "  -0.2455746200876539,\n",
       "  1.2,\n",
       "  0.2870857598168703],\n",
       " [-1.3920329525022395,\n",
       "  0.0,\n",
       "  0.3898499166190117,\n",
       "  -0.4620290550480929,\n",
       "  0.9594423449407286,\n",
       "  -1.6895172520029285,\n",
       "  1.1,\n",
       "  0.2151970993106291],\n",
       " [-0.1537465087532126,\n",
       "  0.0,\n",
       "  0.44828637389519715,\n",
       "  0.3623169717777053,\n",
       "  -0.9041329221883012,\n",
       "  -1.4576266488243752,\n",
       "  1.1,\n",
       "  1.0179106801813262],\n",
       " [0.5300764747454905,\n",
       "  0.0,\n",
       "  1.4269706556434576,\n",
       "  -0.9465912684754183,\n",
       "  0.3319951406488036,\n",
       "  -0.593291027632801,\n",
       "  1.1,\n",
       "  -0.3556452716509492],\n",
       " [0.32648497873416316,\n",
       "  4.0,\n",
       "  0.054298451611333454,\n",
       "  -0.6424896031960979,\n",
       "  0.43659834450158264,\n",
       "  -0.014590549149127347,\n",
       "  1.2,\n",
       "  -1.5624776754630318],\n",
       " [0.6666123944839856,\n",
       "  2.0,\n",
       "  -1.1172210562619533,\n",
       "  -0.34131384707909634,\n",
       "  -1.8648368947605602,\n",
       "  1.6999052075772432,\n",
       "  1.05,\n",
       "  0.954797208048266],\n",
       " [0.8392915758482336,\n",
       "  1.0,\n",
       "  -0.43454308333507713,\n",
       "  0.6454781005798735,\n",
       "  0.16263345992214293,\n",
       "  1.3213929531708144,\n",
       "  0.9,\n",
       "  0.47848226166606994],\n",
       " [-1.4228046247855728,\n",
       "  4.0,\n",
       "  -0.16091832172459355,\n",
       "  1.7982632133364536,\n",
       "  1.076401982384526,\n",
       "  -1.2792087847637068,\n",
       "  1.2,\n",
       "  0.6437914475116943],\n",
       " [-1.4951776338092486,\n",
       "  4.0,\n",
       "  -0.7413053551881291,\n",
       "  0.6431415860995894,\n",
       "  0.7658447453400786,\n",
       "  0.7634768741398283,\n",
       "  1.2,\n",
       "  -1.3720378183081983],\n",
       " [-0.0213028902857841,\n",
       "  1.0,\n",
       "  1.587432753960329,\n",
       "  -0.6856201937758297,\n",
       "  0.933481048910758,\n",
       "  0.3575652845507393,\n",
       "  0.9,\n",
       "  -0.9908804688541496],\n",
       " [0.2844550224820325,\n",
       "  5.0,\n",
       "  -1.4489223246358158,\n",
       "  -1.4029119720951893,\n",
       "  0.18446294827615195,\n",
       "  -0.009110834972009292,\n",
       "  0.85,\n",
       "  -0.9410037004512803],\n",
       " [-1.5326479175570227,\n",
       "  5.0,\n",
       "  0.1162655414954112,\n",
       "  -0.771261826491047,\n",
       "  1.3243300119066959,\n",
       "  -0.40820245402769917,\n",
       "  0.85,\n",
       "  0.4321223493265299],\n",
       " [-1.7848376478123194,\n",
       "  4.0,\n",
       "  0.5776873905456812,\n",
       "  0.5868258181974979,\n",
       "  -0.3384320157303054,\n",
       "  0.3469065587753063,\n",
       "  1.2,\n",
       "  0.15638398903690337],\n",
       " [0.05904234432144646,\n",
       "  1.0,\n",
       "  0.19179563973706493,\n",
       "  1.104258442360453,\n",
       "  0.5784135095335929,\n",
       "  -1.8856494515200792,\n",
       "  0.9,\n",
       "  -1.5755936343826193],\n",
       " [-0.4402110072180424,\n",
       "  4.0,\n",
       "  -1.1309660300416338,\n",
       "  0.06932358234977497,\n",
       "  0.87641069382582,\n",
       "  0.7553625250205647,\n",
       "  1.2,\n",
       "  0.6546037478439192],\n",
       " [0.16385373366697017,\n",
       "  5.0,\n",
       "  -0.14298288205197468,\n",
       "  0.988821679212671,\n",
       "  -0.5685089124598967,\n",
       "  1.0931389675507046,\n",
       "  0.85,\n",
       "  0.9954207396234652],\n",
       " [-0.066151444982766,\n",
       "  2.0,\n",
       "  0.365896088062884,\n",
       "  -0.7088520493059047,\n",
       "  0.32495182756609675,\n",
       "  -0.9901482875905244,\n",
       "  1.05,\n",
       "  -1.4647335593440112],\n",
       " [-1.5307747849414635,\n",
       "  4.0,\n",
       "  1.6057396378269533,\n",
       "  0.8423263167032986,\n",
       "  0.84659154103495,\n",
       "  -1.5344169282472924,\n",
       "  1.2,\n",
       "  1.0340952107266292],\n",
       " [-0.9910080112860904,\n",
       "  3.0,\n",
       "  -0.40552098018915045,\n",
       "  0.006891830241841245,\n",
       "  0.4894094642039506,\n",
       "  -1.6028180797832672,\n",
       "  0.95,\n",
       "  0.9228989811520596],\n",
       " [1.097463159286492,\n",
       "  2.0,\n",
       "  0.7921273995652898,\n",
       "  1.7098974578074648,\n",
       "  -0.7524862072497569,\n",
       "  -0.5785688864253704,\n",
       "  1.05,\n",
       "  0.5232424523199573],\n",
       " [0.14595628609433095,\n",
       "  3.0,\n",
       "  -1.498044322697234,\n",
       "  -0.5565488042525563,\n",
       "  0.5811563213191271,\n",
       "  -0.14041207467025188,\n",
       "  0.95,\n",
       "  1.0564627495164758],\n",
       " [-0.5992110838440825,\n",
       "  2.0,\n",
       "  -0.9652792464208713,\n",
       "  -0.29951460163982363,\n",
       "  1.2737929293415338,\n",
       "  0.283476714147447,\n",
       "  1.05,\n",
       "  -0.052279386243106116],\n",
       " [-1.3850049225994616,\n",
       "  0.0,\n",
       "  -0.18449208525457506,\n",
       "  -1.0288211556127407,\n",
       "  -0.21686124652273298,\n",
       "  -0.04863209570889533,\n",
       "  1.1,\n",
       "  0.8511705763756521],\n",
       " [-0.8711190182620946,\n",
       "  4.0,\n",
       "  0.38089133159974525,\n",
       "  1.5205420217682826,\n",
       "  -0.20523830744160318,\n",
       "  1.9642841337176107,\n",
       "  1.2,\n",
       "  -0.11503491606993779],\n",
       " [1.6678822902024144,\n",
       "  4.0,\n",
       "  -1.5329840505063155,\n",
       "  0.21599604764849392,\n",
       "  0.9672043240887594,\n",
       "  0.3556301669526292,\n",
       "  1.2,\n",
       "  -0.15089463571430728],\n",
       " [-1.4645503581785875,\n",
       "  3.0,\n",
       "  -1.5024666848980162,\n",
       "  -1.3821043268761146,\n",
       "  1.111747023197321,\n",
       "  0.17865566962942447,\n",
       "  0.95,\n",
       "  -0.08559074978860645],\n",
       " [-0.3837475486305221,\n",
       "  3.0,\n",
       "  1.5973829118219895,\n",
       "  -1.0496428650124061,\n",
       "  0.7289169485368018,\n",
       "  1.304227026588307,\n",
       "  0.95,\n",
       "  -1.9409178245871244],\n",
       " [0.4767536279247199,\n",
       "  3.0,\n",
       "  -0.9210636621091073,\n",
       "  0.9614733225663382,\n",
       "  0.003075746658187078,\n",
       "  0.7362279349125307,\n",
       "  0.95,\n",
       "  -0.6867704911292194],\n",
       " [1.4268058956036729,\n",
       "  0.0,\n",
       "  1.2987221654119572,\n",
       "  -0.06185173979379229,\n",
       "  1.107955367575002,\n",
       "  -0.5116939124493897,\n",
       "  1.1,\n",
       "  -1.6667878572037977],\n",
       " [1.5091798340684075,\n",
       "  2.0,\n",
       "  -1.097003788526811,\n",
       "  -1.3306896498304828,\n",
       "  -0.5076907673974667,\n",
       "  -0.5784644480045691,\n",
       "  1.05,\n",
       "  0.6580368325111378],\n",
       " [1.656673768428342,\n",
       "  0.0,\n",
       "  1.3585292563180398,\n",
       "  -0.204339596677908,\n",
       "  -0.27449598200694686,\n",
       "  0.4049605219727094,\n",
       "  1.1,\n",
       "  -1.664384211550588],\n",
       " [-0.6358038081413608,\n",
       "  4.0,\n",
       "  0.850454301628219,\n",
       "  -1.4327581666261877,\n",
       "  0.9255505324591025,\n",
       "  -0.2469857401167768,\n",
       "  1.2,\n",
       "  1.0781105795072783],\n",
       " [1.0247918727734207,\n",
       "  5.0,\n",
       "  0.9251776993476469,\n",
       "  1.3843518588167467,\n",
       "  -0.7399268365571406,\n",
       "  0.6277428521959333,\n",
       "  0.85,\n",
       "  1.0492761744181132],\n",
       " [1.106790326540148,\n",
       "  0.0,\n",
       "  -0.20966448053114,\n",
       "  0.07006692680654505,\n",
       "  -0.7456440321602782,\n",
       "  0.037499479620904885,\n",
       "  1.1,\n",
       "  3.3363101716605805],\n",
       " [1.0830787114296558,\n",
       "  1.0,\n",
       "  -0.0532028482537131,\n",
       "  0.642346863615634,\n",
       "  0.434786769660008,\n",
       "  1.5041694343340726,\n",
       "  0.9,\n",
       "  0.9563262319911989],\n",
       " [0.4936837558196985,\n",
       "  3.0,\n",
       "  -1.2247258792268472,\n",
       "  0.9664790930995204,\n",
       "  0.8544948942136342,\n",
       "  -0.02671082552865526,\n",
       "  0.95,\n",
       "  -1.118226788484295],\n",
       " [0.7366395008583498,\n",
       "  3.0,\n",
       "  -0.4769407036051555,\n",
       "  -0.1597681019003517,\n",
       "  -1.3954994594823142,\n",
       "  -1.5487996117919491,\n",
       "  0.95,\n",
       "  1.0193567740301313],\n",
       " [0.9340128479162155,\n",
       "  5.0,\n",
       "  0.9292549586253871,\n",
       "  1.3432002272826378,\n",
       "  0.7358684779543495,\n",
       "  -0.8693595145662723,\n",
       "  0.85,\n",
       "  -1.698281948511637],\n",
       " [-1.4275154267976986,\n",
       "  0.0,\n",
       "  -1.2182465822499957,\n",
       "  -1.2561258928622172,\n",
       "  0.35839123976985393,\n",
       "  -0.19857787336432425,\n",
       "  1.1,\n",
       "  -0.05777947484054313],\n",
       " [1.2672738517810056,\n",
       "  4.0,\n",
       "  1.3485198490731611,\n",
       "  1.020766503681872,\n",
       "  -0.08585586270353023,\n",
       "  0.15401219555598292,\n",
       "  1.2,\n",
       "  0.7715162896589708],\n",
       " [-0.1566094855822813,\n",
       "  1.0,\n",
       "  0.30853708444556527,\n",
       "  -0.7950279044720334,\n",
       "  0.7160000859212439,\n",
       "  -1.8621061678303292,\n",
       "  0.9,\n",
       "  0.7592603377309004],\n",
       " [-0.6710954664117611,\n",
       "  5.0,\n",
       "  -0.9172592802855748,\n",
       "  -0.911529727832437,\n",
       "  -0.04113657142189101,\n",
       "  0.18308076115512212,\n",
       "  0.85,\n",
       "  0.8136600828166514],\n",
       " [0.1661345113224881,\n",
       "  2.0,\n",
       "  1.224392757279129,\n",
       "  0.6332184768284581,\n",
       "  0.9448853319874599,\n",
       "  0.3225215596461391,\n",
       "  1.05,\n",
       "  1.0065645020376148],\n",
       " [0.6283122059426383,\n",
       "  3.0,\n",
       "  -1.4524526226383094,\n",
       "  -0.4270049677999914,\n",
       "  0.3793784472489756,\n",
       "  1.3688290209688045,\n",
       "  0.95,\n",
       "  0.9283981210732508],\n",
       " [1.2146830138025695,\n",
       "  4.0,\n",
       "  -1.29002501288627,\n",
       "  -0.8046027732372526,\n",
       "  -2.3960614679996772,\n",
       "  0.023714495072895945,\n",
       "  1.2,\n",
       "  0.5257278173003398],\n",
       " [-0.7999108592427536,\n",
       "  2.0,\n",
       "  -1.6755768934433581,\n",
       "  -0.7601933997015573,\n",
       "  -2.615955212821008,\n",
       "  -0.1320636645673933,\n",
       "  1.05,\n",
       "  -0.412012660792846],\n",
       " [0.8146940185966215,\n",
       "  0.0,\n",
       "  0.45727493281561166,\n",
       "  1.8314631242428778,\n",
       "  1.5489187522172634,\n",
       "  -1.4151726713111172,\n",
       "  1.1,\n",
       "  -0.8605325853858531],\n",
       " [-0.3215184160886255,\n",
       "  5.0,\n",
       "  0.4999826084247405,\n",
       "  -1.0206369403849958,\n",
       "  0.3354568985026549,\n",
       "  1.0664720797418303,\n",
       "  0.85,\n",
       "  0.6679892180729358],\n",
       " [-1.998998062798949,\n",
       "  1.0,\n",
       "  -0.874456285415416,\n",
       "  -0.3136026277960519,\n",
       "  0.7395966486170099,\n",
       "  -0.1970501935502529,\n",
       "  0.9,\n",
       "  -0.9308710910576186],\n",
       " [1.3565124612236903,\n",
       "  0.0,\n",
       "  0.9230089227501614,\n",
       "  -0.5679549329497542,\n",
       "  1.0069595337780983,\n",
       "  -1.884777769808441,\n",
       "  1.1,\n",
       "  1.0070740094670905],\n",
       " [1.6414776256279036,\n",
       "  2.0,\n",
       "  0.3539364531166121,\n",
       "  0.9974086368250848,\n",
       "  0.7462310452643823,\n",
       "  1.717049654624127,\n",
       "  1.05,\n",
       "  -0.4107614562100785],\n",
       " [-1.2442132073273533,\n",
       "  0.0,\n",
       "  0.8027405457927886,\n",
       "  -0.8790102187916198,\n",
       "  0.5015504036936027,\n",
       "  0.8376795271186732,\n",
       "  1.1,\n",
       "  0.3238753454133878],\n",
       " [-0.4985736093976945,\n",
       "  0.0,\n",
       "  1.560009623788737,\n",
       "  0.5489026047325384,\n",
       "  0.4681656864099348,\n",
       "  -0.9023140504813653,\n",
       "  1.1,\n",
       "  -1.9290551615656255],\n",
       " [-1.1713063175651455,\n",
       "  5.0,\n",
       "  0.45425895480507067,\n",
       "  -0.31938490730302443,\n",
       "  0.8479731646486086,\n",
       "  0.036318981503085025,\n",
       "  0.85,\n",
       "  -0.20958633355185044],\n",
       " [0.8469563119581422,\n",
       "  2.0,\n",
       "  -1.328464150605159,\n",
       "  -0.1553123458316128,\n",
       "  -0.08072679663746359,\n",
       "  -1.4991303152117919,\n",
       "  1.05,\n",
       "  0.7502342145099912],\n",
       " [-0.36590237997331754,\n",
       "  5.0,\n",
       "  1.293489320461323,\n",
       "  0.40572655191865037,\n",
       "  -0.915133549675236,\n",
       "  -0.5157349163091628,\n",
       "  0.85,\n",
       "  -1.5233335144849054],\n",
       " [1.0602154675557862,\n",
       "  4.0,\n",
       "  0.632675351657904,\n",
       "  -1.2372059104831619,\n",
       "  0.7609895788251774,\n",
       "  0.6035998877034833,\n",
       "  1.2,\n",
       "  0.4914127363738536],\n",
       " [1.3481839207058586,\n",
       "  2.0,\n",
       "  0.27450293196958764,\n",
       "  -1.2901807867834902,\n",
       "  -0.25607120330773114,\n",
       "  -0.014069939018932305,\n",
       "  1.05,\n",
       "  -0.2057232293604703],\n",
       " [0.5741475853775064,\n",
       "  1.0,\n",
       "  0.8897332598468956,\n",
       "  -0.354555415145593,\n",
       "  0.19505782573705382,\n",
       "  1.9419959452731705,\n",
       "  0.9,\n",
       "  0.12326158056191104],\n",
       " [0.8633012434658724,\n",
       "  0.0,\n",
       "  -0.3270701883136266,\n",
       "  0.41443520689705093,\n",
       "  0.8410792120156994,\n",
       "  -1.4438583678211017,\n",
       "  1.1,\n",
       "  0.37604851835300535],\n",
       " [0.619012298753596,\n",
       "  2.0,\n",
       "  0.26473148833211246,\n",
       "  0.438054157655945,\n",
       "  -0.4423012159461114,\n",
       "  -1.0849360955271792,\n",
       "  1.05,\n",
       "  -0.5612671195302723],\n",
       " [0.48565874952112226,\n",
       "  3.0,\n",
       "  -1.01169833789622,\n",
       "  -0.16468061705795273,\n",
       "  0.3106998380541981,\n",
       "  -1.3113272867779924,\n",
       "  0.95,\n",
       "  -1.0640972424285726],\n",
       " [-0.1970824692366113,\n",
       "  0.0,\n",
       "  1.0587655818125683,\n",
       "  0.7118767054116764,\n",
       "  0.1562684057038216,\n",
       "  -0.5306420478522221,\n",
       "  1.1,\n",
       "  0.30625956814120997],\n",
       " [0.5554792859161312,\n",
       "  2.0,\n",
       "  -1.352546186582115,\n",
       "  0.8666924668865916,\n",
       "  -0.2804332402729594,\n",
       "  1.0237973297428316,\n",
       "  1.05,\n",
       "  -0.8263267402337233],\n",
       " [0.3807744637638607,\n",
       "  3.0,\n",
       "  -0.8111966477556833,\n",
       "  0.015928973282596473,\n",
       "  -0.3182430653529882,\n",
       "  -1.5802074177786771,\n",
       "  0.95,\n",
       "  -1.8984147714141568],\n",
       " [-0.7539598323263835,\n",
       "  4.0,\n",
       "  -0.14485782217981638,\n",
       "  0.49476483988027364,\n",
       "  0.02155724207656189,\n",
       "  -0.7838340727034986,\n",
       "  1.2,\n",
       "  -0.3720447382812026],\n",
       " [0.21315245133978455,\n",
       "  0.0,\n",
       "  0.21163031270494367,\n",
       "  -1.0935546079788987,\n",
       "  0.8380620644055301,\n",
       "  1.1669028531485486,\n",
       "  1.1,\n",
       "  0.44472314165614685],\n",
       " [1.5662236452348695,\n",
       "  2.0,\n",
       "  -1.3750714098627004,\n",
       "  1.1784812973749614,\n",
       "  -0.5622228293900889,\n",
       "  -0.06564636605066687,\n",
       "  1.05,\n",
       "  -1.1603247986907186],\n",
       " [1.2796145341355716,\n",
       "  0.0,\n",
       "  0.5775061493383095,\n",
       "  -1.3005957164311768,\n",
       "  -0.57032839145689,\n",
       "  1.0203916116720237,\n",
       "  1.1,\n",
       "  -1.5155121826761653],\n",
       " [-0.30149957104105646,\n",
       "  5.0,\n",
       "  -1.2244589222711102,\n",
       "  0.05281579296230993,\n",
       "  -0.1471964888003169,\n",
       "  -1.2026775432205103,\n",
       "  0.85,\n",
       "  1.101312976923598],\n",
       " [-0.0840042978196137,\n",
       "  4.0,\n",
       "  -0.9700689170093519,\n",
       "  1.1237380433079358,\n",
       "  0.33630406972272725,\n",
       "  -1.7732854565015885,\n",
       "  1.2,\n",
       "  -0.9845692191724654],\n",
       " [-0.9065858528955442,\n",
       "  1.0,\n",
       "  -0.1745842992869369,\n",
       "  -1.121421701346097,\n",
       "  0.284804658911829,\n",
       "  -1.1360278162223185,\n",
       "  0.9,\n",
       "  1.1119702643230092],\n",
       " [-1.5389134229307067,\n",
       "  4.0,\n",
       "  -1.149670905807503,\n",
       "  0.23726515942033335,\n",
       "  0.48931666299793836,\n",
       "  -0.3526100447226573,\n",
       "  1.2,\n",
       "  0.11498012571422699],\n",
       " [-1.0405965399573622,\n",
       "  4.0,\n",
       "  1.3028354343728015,\n",
       "  -1.1358722352077546,\n",
       "  -0.5833172120180449,\n",
       "  1.8977176181938278,\n",
       "  1.2,\n",
       "  1.065364424607942],\n",
       " [0.31324013830657865,\n",
       "  0.0,\n",
       "  0.603696134293513,\n",
       "  -1.4112845050186082,\n",
       "  -0.166934697608021,\n",
       "  1.4256806955024204,\n",
       "  1.1,\n",
       "  -0.7004258793288506],\n",
       " [-1.1435648669483982,\n",
       "  4.0,\n",
       "  -1.3798747851667184,\n",
       "  1.2560776008948258,\n",
       "  0.19470552318436518,\n",
       "  0.24568369588363345,\n",
       "  1.2,\n",
       "  1.0743442036067834],\n",
       " [0.27680333719170075,\n",
       "  4.0,\n",
       "  1.1643842785505032,\n",
       "  -1.1333559074095798,\n",
       "  -0.8081644609829921,\n",
       "  0.3477762756722055,\n",
       "  1.2,\n",
       "  1.078659911767567],\n",
       " [-0.22940412932554238,\n",
       "  4.0,\n",
       "  1.3143946750897901,\n",
       "  1.2907556398491016,\n",
       "  0.277049336805106,\n",
       "  -0.775560622232604,\n",
       "  1.2,\n",
       "  0.08704469986705718],\n",
       " [1.819772838733362,\n",
       "  1.0,\n",
       "  0.3798477242140892,\n",
       "  -0.09168926760503661,\n",
       "  0.5106475088151307,\n",
       "  -1.6617217410027942,\n",
       "  0.9,\n",
       "  -1.1355889885831854],\n",
       " [-1.1976299530187609,\n",
       "  1.0,\n",
       "  1.3769641958592809,\n",
       "  0.4873791155699391,\n",
       "  -0.3396807935876039,\n",
       "  -0.5833929839352698,\n",
       "  0.9,\n",
       "  1.0378233523842402],\n",
       " [-1.116336855339788,\n",
       "  5.0,\n",
       "  1.1966887292159911,\n",
       "  -1.2598669958529638,\n",
       "  -1.3050223284949998,\n",
       "  0.8488870721694367,\n",
       "  0.85,\n",
       "  1.077804228873966],\n",
       " [-0.16485850333078056,\n",
       "  1.0,\n",
       "  -1.6063410838718695,\n",
       "  0.017949717468430423,\n",
       "  -1.3043833365162687,\n",
       "  1.334975460919454,\n",
       "  0.9,\n",
       "  -0.1960770910264215],\n",
       " [-1.3363290505739014,\n",
       "  2.0,\n",
       "  0.07646610854916695,\n",
       "  1.9474676776223687,\n",
       "  0.746868579765458,\n",
       "  0.01502392011671847,\n",
       "  1.05,\n",
       "  0.4565902153109095],\n",
       " [-0.20630417104682636,\n",
       "  2.0,\n",
       "  -0.5463306840830457,\n",
       "  1.2470127293420519,\n",
       "  -0.37596549451643113,\n",
       "  0.14714713215319197,\n",
       "  1.05,\n",
       "  0.7343602823186988],\n",
       " [-1.1744450404932862,\n",
       "  3.0,\n",
       "  0.7777354032348478,\n",
       "  -0.2623830248895644,\n",
       "  -1.7463025511259114,\n",
       "  0.3770451293224261,\n",
       "  0.95,\n",
       "  -0.4139462561166645],\n",
       " [0.09960648105278845,\n",
       "  3.0,\n",
       "  -1.4694810016317845,\n",
       "  1.5341182016549932,\n",
       "  0.3225618288289723,\n",
       "  -0.15533282241932467,\n",
       "  0.95,\n",
       "  -1.6056476246913025],\n",
       " [0.6568432151099641,\n",
       "  1.0,\n",
       "  -0.12884169742731919,\n",
       "  -1.3155299428423803,\n",
       "  0.08810492844914741,\n",
       "  1.5196373061400752,\n",
       "  0.9,\n",
       "  0.6280746271118041],\n",
       " [-0.5057867729094395,\n",
       "  0.0,\n",
       "  -1.4292894763324735,\n",
       "  0.7145240548625897,\n",
       "  1.0377774922666811,\n",
       "  0.32789505189015644,\n",
       "  1.1,\n",
       "  -0.7739283756557144],\n",
       " [-0.5903339462453833,\n",
       "  3.0,\n",
       "  -1.3702283207865962,\n",
       "  -1.184277669871266,\n",
       "  0.02742826973617803,\n",
       "  0.3382327082235591,\n",
       "  0.95,\n",
       "  -1.4002936899734384],\n",
       " [-0.9271884676012396,\n",
       "  3.0,\n",
       "  -1.055729897501739,\n",
       "  0.3552260648386614,\n",
       "  -0.20405989460533588,\n",
       "  1.0244768664623896,\n",
       "  0.95,\n",
       "  -0.8260826630704493],\n",
       " [-0.48252374926865144,\n",
       "  4.0,\n",
       "  -0.7990822729098495,\n",
       "  -0.29685633756236207,\n",
       "  -0.2963651401626607,\n",
       "  -0.5295712257327546,\n",
       "  1.2,\n",
       "  1.0703775406207567],\n",
       " [0.8318975402381211,\n",
       "  0.0,\n",
       "  0.25769351876688,\n",
       "  -0.4096264296651957,\n",
       "  0.4425178795500957,\n",
       "  -1.5990130897270625,\n",
       "  1.1,\n",
       "  1.0772362984848232],\n",
       " [-1.123944011631285,\n",
       "  2.0,\n",
       "  1.0950116850602574,\n",
       "  -0.7329403092727581,\n",
       "  0.6263045067833479,\n",
       "  -1.4695527535794197,\n",
       "  1.05,\n",
       "  -0.44098556968355557],\n",
       " [1.2798015558324713,\n",
       "  2.0,\n",
       "  1.3908409745537542,\n",
       "  -0.08497263716798982,\n",
       "  0.3294537803609552,\n",
       "  -1.1963137884585908,\n",
       "  1.05,\n",
       "  -0.998150274251093],\n",
       " [-0.5456390654858294,\n",
       "  5.0,\n",
       "  0.05158685622680178,\n",
       "  0.4426526924092283,\n",
       "  0.4858797877199202,\n",
       "  -1.6363702081633786,\n",
       "  0.85,\n",
       "  -1.0441225068836661],\n",
       " [0.7458227641094477,\n",
       "  4.0,\n",
       "  1.4260658100018755,\n",
       "  -0.19896508985960418,\n",
       "  0.46944732003780515,\n",
       "  -0.8552419859629867,\n",
       "  1.2,\n",
       "  -1.9531105539146871],\n",
       " [-0.9220632536941908,\n",
       "  4.0,\n",
       "  0.25283432014071877,\n",
       "  -0.5938382474451551,\n",
       "  0.1284160873071043,\n",
       "  -0.04066591622167114,\n",
       "  1.2,\n",
       "  -1.094684041446201]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[num_col_names] = scaler.fit_transform(x_train[num_col_names])\n",
    "x_train = x_train.values.tolist()\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d94c446-5579-410c-b781-a366b2d65c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.2961024050889902,\n",
       "  4.0,\n",
       "  0.4471995407636188,\n",
       "  -0.9923000674831819,\n",
       "  -1.9536502240843818,\n",
       "  -0.022380347179873625,\n",
       "  1.2,\n",
       "  0.07300906351860648],\n",
       " [-0.0990024911899706,\n",
       "  3.0,\n",
       "  -1.1972356846386893,\n",
       "  -0.0198934701101238,\n",
       "  0.7070490959246708,\n",
       "  0.032182686510898374,\n",
       "  0.95,\n",
       "  0.761363685932723],\n",
       " [-0.2667556811759512,\n",
       "  4.0,\n",
       "  -0.33723999401452615,\n",
       "  -0.922004722322149,\n",
       "  0.5917060633163177,\n",
       "  -1.2604331167449043,\n",
       "  1.2,\n",
       "  -1.53925559028151],\n",
       " [-1.1862346883988808,\n",
       "  0.0,\n",
       "  1.5548457115189727,\n",
       "  1.7501109594566338,\n",
       "  0.9898549891044736,\n",
       "  0.0982404803608542,\n",
       "  1.1,\n",
       "  1.3964861553857317],\n",
       " [-1.0842077868990712,\n",
       "  1.0,\n",
       "  1.4260781105774012,\n",
       "  -1.173673613650715,\n",
       "  -0.1016774450292915,\n",
       "  -0.7818370758363253,\n",
       "  0.9,\n",
       "  0.5745537365636121],\n",
       " [-1.3450735061267136,\n",
       "  5.0,\n",
       "  -0.566847681078077,\n",
       "  0.5079166413231141,\n",
       "  0.09835518712952136,\n",
       "  0.0631104092704816,\n",
       "  0.85,\n",
       "  0.8180807799893957],\n",
       " [0.061694976110465004,\n",
       "  5.0,\n",
       "  0.07698272457761382,\n",
       "  1.265917661301853,\n",
       "  -0.35617882261871114,\n",
       "  -0.8168817743295583,\n",
       "  0.85,\n",
       "  0.2409495049163227],\n",
       " [-0.9414656171621173,\n",
       "  3.0,\n",
       "  0.9635887932777736,\n",
       "  -0.19952227558754274,\n",
       "  -1.2406509998971962,\n",
       "  0.5060226459197047,\n",
       "  0.95,\n",
       "  -1.7480874129113844],\n",
       " [-0.993441132370015,\n",
       "  1.0,\n",
       "  1.675274712317313,\n",
       "  -0.3025255304175421,\n",
       "  -0.4871964855208113,\n",
       "  -0.15091720244995813,\n",
       "  0.9,\n",
       "  -0.3814733068663819],\n",
       " [1.2679529183288318,\n",
       "  0.0,\n",
       "  -1.0451831738970914,\n",
       "  -0.6612029393335342,\n",
       "  -2.2280269928472287,\n",
       "  -1.4494673141352712,\n",
       "  1.1,\n",
       "  0.5442754917211076],\n",
       " [-0.7734774265811772,\n",
       "  1.0,\n",
       "  1.64529320793813,\n",
       "  1.4996957988507276,\n",
       "  -0.37461841332574064,\n",
       "  -0.05770312755386047,\n",
       "  0.9,\n",
       "  1.0782949175394683],\n",
       " [0.6003760345479451,\n",
       "  4.0,\n",
       "  1.267546507671332,\n",
       "  0.18193290225590653,\n",
       "  -0.5099031114885302,\n",
       "  1.019904970736082,\n",
       "  1.2,\n",
       "  -0.6293329569580188],\n",
       " [-1.3559786981107107,\n",
       "  2.0,\n",
       "  -1.529192728608487,\n",
       "  1.5273146633546593,\n",
       "  0.0922047760286381,\n",
       "  -0.8457254401698951,\n",
       "  1.05,\n",
       "  1.3935024962515856],\n",
       " [0.3239359602946431,\n",
       "  0.0,\n",
       "  -0.0026521054102487934,\n",
       "  -1.3859666322426942,\n",
       "  -1.3993144608443993,\n",
       "  -0.20273660700854415,\n",
       "  1.1,\n",
       "  0.6818358999186005],\n",
       " [-1.822352774632234,\n",
       "  2.0,\n",
       "  -0.17463142548547075,\n",
       "  -0.12550977723610757,\n",
       "  0.9639867046559029,\n",
       "  -1.0133496091623446,\n",
       "  1.05,\n",
       "  -0.2703749752752063],\n",
       " [-0.47998814612596585,\n",
       "  3.0,\n",
       "  0.6783335785126635,\n",
       "  0.3117249037635099,\n",
       "  -1.0870053636349113,\n",
       "  -0.7115794722763861,\n",
       "  0.95,\n",
       "  -0.49777015657008955],\n",
       " [0.5741420947077002,\n",
       "  4.0,\n",
       "  0.20098436196084912,\n",
       "  -0.47559494639669647,\n",
       "  -0.830736126166217,\n",
       "  0.2808137295855216,\n",
       "  1.2,\n",
       "  -0.45963131741781005],\n",
       " [-0.0461688513325189,\n",
       "  5.0,\n",
       "  0.5724339566868323,\n",
       "  -0.2199887909273013,\n",
       "  -1.3394914565408527,\n",
       "  -0.020685384730640705,\n",
       "  0.85,\n",
       "  0.963892502096112],\n",
       " [1.7270077644191983,\n",
       "  2.0,\n",
       "  0.24436101506492694,\n",
       "  -0.29149359908681854,\n",
       "  0.8301495212895734,\n",
       "  0.09748646253864228,\n",
       "  1.05,\n",
       "  1.0117533921397566],\n",
       " [-0.3774995506958658,\n",
       "  4.0,\n",
       "  0.7490035482588264,\n",
       "  -1.1084022646997473,\n",
       "  -0.34427840162918744,\n",
       "  0.2603555375214481,\n",
       "  1.2,\n",
       "  -0.6348532525933992],\n",
       " [-1.2740489627911833,\n",
       "  3.0,\n",
       "  -0.8693130665314261,\n",
       "  1.6088547201704402,\n",
       "  0.8140799200251889,\n",
       "  -1.9084802294534076,\n",
       "  0.95,\n",
       "  0.9492321736364023],\n",
       " [0.6560668139382418,\n",
       "  4.0,\n",
       "  -1.7061753278157172,\n",
       "  0.3729179676565074,\n",
       "  -0.598737930429441,\n",
       "  0.4598471099421836,\n",
       "  1.2,\n",
       "  0.912844161567208],\n",
       " [0.9666273616709692,\n",
       "  0.0,\n",
       "  -1.5556261059765426,\n",
       "  -0.027944769060243478,\n",
       "  0.5271423460162007,\n",
       "  1.2236216911895947,\n",
       "  1.1,\n",
       "  1.0300757167728825],\n",
       " [-0.5818443967860932,\n",
       "  3.0,\n",
       "  -0.5611714599935154,\n",
       "  -0.41615313587099423,\n",
       "  -0.6755180669635674,\n",
       "  0.702746278142533,\n",
       "  0.95,\n",
       "  0.6820339521941293],\n",
       " [0.6064547214609435,\n",
       "  5.0,\n",
       "  -0.5471124994850024,\n",
       "  0.2614251948443847,\n",
       "  0.034039104105499846,\n",
       "  0.22278495604583753,\n",
       "  0.85,\n",
       "  0.24851632296957896],\n",
       " [0.14648988717479536,\n",
       "  5.0,\n",
       "  0.1647260687403211,\n",
       "  -1.333671651060535,\n",
       "  0.6302611089610434,\n",
       "  -0.12999632589604335,\n",
       "  0.85,\n",
       "  0.7779003901486906],\n",
       " [0.11262706227909008,\n",
       "  4.0,\n",
       "  0.5080782159252114,\n",
       "  -0.045487857668909636,\n",
       "  0.34181543437905104,\n",
       "  -0.02917231857065239,\n",
       "  1.2,\n",
       "  -0.22691943621333832],\n",
       " [0.8343523024892211,\n",
       "  2.0,\n",
       "  -0.5996156854781828,\n",
       "  -0.7232922355208137,\n",
       "  0.569580804549984,\n",
       "  1.8771462570955568,\n",
       "  1.05,\n",
       "  0.3162428653817334],\n",
       " [-0.24809497249487591,\n",
       "  5.0,\n",
       "  1.40080224899598,\n",
       "  -1.2409530525971604,\n",
       "  -1.38608867870635,\n",
       "  0.11074902046076703,\n",
       "  0.85,\n",
       "  -1.8024055148033775],\n",
       " [-1.7744847001028778,\n",
       "  3.0,\n",
       "  1.6674398481432589,\n",
       "  -0.03145937580986626,\n",
       "  -2.645041190773342,\n",
       "  0.3195624434054241,\n",
       "  0.95,\n",
       "  -1.573088676327739],\n",
       " [1.2504359837921262,\n",
       "  2.0,\n",
       "  0.232991664989456,\n",
       "  1.8648465667625216,\n",
       "  0.7621406821851453,\n",
       "  1.6929986069638607,\n",
       "  1.05,\n",
       "  -0.49283565059972406],\n",
       " [0.2099289045200695,\n",
       "  2.0,\n",
       "  -0.21938154461513518,\n",
       "  -0.583559806805574,\n",
       "  -0.05454053368312774,\n",
       "  0.3231768214560561,\n",
       "  1.05,\n",
       "  -1.431262119302054],\n",
       " [0.6364351570871658,\n",
       "  4.0,\n",
       "  0.07291939204801604,\n",
       "  -0.33279641043817443,\n",
       "  0.17511282350558577,\n",
       "  -0.9609279464827104,\n",
       "  1.2,\n",
       "  1.0770634200576004],\n",
       " [-1.1933361191675653,\n",
       "  3.0,\n",
       "  0.015090645011684865,\n",
       "  -0.7381945723849459,\n",
       "  -3.4015175261680572,\n",
       "  0.2002738241560931,\n",
       "  0.95,\n",
       "  -0.8356274965780238],\n",
       " [-1.1134600556408303,\n",
       "  5.0,\n",
       "  0.5271948751212924,\n",
       "  -1.1557788776260394,\n",
       "  -0.1439643618408459,\n",
       "  -0.9583721620255016,\n",
       "  0.85,\n",
       "  -0.6835099460600916],\n",
       " [1.8893924520610974,\n",
       "  2.0,\n",
       "  1.0653092510917586,\n",
       "  -0.8769462153430877,\n",
       "  -0.48218282033591786,\n",
       "  1.8016733829798435,\n",
       "  1.05,\n",
       "  -0.7652594739478048],\n",
       " [0.7896264643596054,\n",
       "  2.0,\n",
       "  1.3830870773249042,\n",
       "  1.5528069885504148,\n",
       "  0.281932611529281,\n",
       "  -0.10890194436408035,\n",
       "  1.05,\n",
       "  0.833482819950608],\n",
       " [0.5935362156682945,\n",
       "  2.0,\n",
       "  -1.6095507984152473,\n",
       "  0.4392417353135054,\n",
       "  -1.2293572427707409,\n",
       "  0.20143788981011096,\n",
       "  1.05,\n",
       "  0.31295538324639677],\n",
       " [0.577705308251118,\n",
       "  5.0,\n",
       "  0.6069615060656338,\n",
       "  -1.0768980274797866,\n",
       "  -1.473654036168781,\n",
       "  -0.5182380075425272,\n",
       "  0.85,\n",
       "  0.5790439214967708],\n",
       " [1.7164159892508228,\n",
       "  4.0,\n",
       "  1.2411655063375524,\n",
       "  1.2266128843554946,\n",
       "  -0.4774231639085495,\n",
       "  0.27602368580156045,\n",
       "  1.2,\n",
       "  1.067278132158009],\n",
       " [-1.137709096693115,\n",
       "  2.0,\n",
       "  -0.9650853423385998,\n",
       "  0.39470475263443117,\n",
       "  -0.06881853277674782,\n",
       "  0.40989092282604683,\n",
       "  1.05,\n",
       "  -0.37724319058279904],\n",
       " [-0.5121950462959207,\n",
       "  0.0,\n",
       "  0.26026359613528466,\n",
       "  0.0946801917734632,\n",
       "  -0.7326577495344802,\n",
       "  0.3790941111492577,\n",
       "  1.1,\n",
       "  1.0186925367819037],\n",
       " [1.0182650617190843,\n",
       "  5.0,\n",
       "  -0.2359822478890942,\n",
       "  0.1824810278404575,\n",
       "  0.8972450563639779,\n",
       "  -1.026240509394083,\n",
       "  0.85,\n",
       "  0.369647564429093],\n",
       " [-1.0846425671181816,\n",
       "  4.0,\n",
       "  0.1697995648005529,\n",
       "  0.1054575301874588,\n",
       "  0.2846394738838803,\n",
       "  -0.008103126620485625,\n",
       "  1.2,\n",
       "  0.6123984090468505],\n",
       " [-0.5573879235190097,\n",
       "  1.0,\n",
       "  -0.6088290846591323,\n",
       "  1.7701992995585956,\n",
       "  -0.21188234660455788,\n",
       "  -1.2117400835483545,\n",
       "  0.9,\n",
       "  1.0461515316413108],\n",
       " [0.33385442463800113,\n",
       "  5.0,\n",
       "  1.2925453352017116,\n",
       "  -0.6233599022371462,\n",
       "  0.859698779094363,\n",
       "  0.8875132794104076,\n",
       "  0.85,\n",
       "  -1.1534497422588088],\n",
       " [-1.6123544929771911,\n",
       "  2.0,\n",
       "  0.7970032443181646,\n",
       "  1.7315928582086375,\n",
       "  0.09014911380850289,\n",
       "  1.715205424619692,\n",
       "  1.05,\n",
       "  -0.771587319409342],\n",
       " [0.3650380024838524,\n",
       "  0.0,\n",
       "  -1.519639233433877,\n",
       "  1.9901663620134777,\n",
       "  -0.22205461283581737,\n",
       "  -0.10898263662783665,\n",
       "  1.1,\n",
       "  0.9389063222273721],\n",
       " [-1.265602322262811,\n",
       "  2.0,\n",
       "  -1.055847448526349,\n",
       "  -0.823625342187872,\n",
       "  0.5493200342250044,\n",
       "  -0.5669114201700958,\n",
       "  1.05,\n",
       "  0.9466184501525878],\n",
       " [-0.7340506488794435,\n",
       "  5.0,\n",
       "  -1.4213766417443179,\n",
       "  1.9093882855723823,\n",
       "  0.9551985193982095,\n",
       "  -0.5205531386833382,\n",
       "  0.85,\n",
       "  -0.6666164246108937],\n",
       " [1.7930093604900597,\n",
       "  3.0,\n",
       "  0.6736461091281492,\n",
       "  -1.191950181637739,\n",
       "  -1.658872160388558,\n",
       "  0.88445410354434,\n",
       "  0.95,\n",
       "  0.21900479764371558],\n",
       " [-1.5391640556204869,\n",
       "  3.0,\n",
       "  -0.5298089657359069,\n",
       "  1.176730532078228,\n",
       "  -0.4935428158317741,\n",
       "  -1.0342694904685414,\n",
       "  0.95,\n",
       "  0.8058621452422313],\n",
       " [0.701650821299227,\n",
       "  2.0,\n",
       "  0.40853138306304776,\n",
       "  1.9935500502462116,\n",
       "  0.9164528097918583,\n",
       "  -0.2684220799191434,\n",
       "  1.05,\n",
       "  -0.06320362724595269],\n",
       " [0.12311749361382189,\n",
       "  3.0,\n",
       "  -0.2572136396597441,\n",
       "  1.288459593238029,\n",
       "  1.0139108332403308,\n",
       "  -0.7199808760923319,\n",
       "  0.95,\n",
       "  0.9201813592517322],\n",
       " [0.16336671708982992,\n",
       "  5.0,\n",
       "  0.2646423597133504,\n",
       "  0.7192177328950047,\n",
       "  1.8200614538308413,\n",
       "  0.07005925300672859,\n",
       "  0.85,\n",
       "  -1.5253658799107428],\n",
       " [0.7868569512795998,\n",
       "  4.0,\n",
       "  0.10709907778833092,\n",
       "  -0.11295414718199849,\n",
       "  0.735869226962112,\n",
       "  -0.45576576289510945,\n",
       "  1.2,\n",
       "  -1.3613112041564717],\n",
       " [-0.060573892861556435,\n",
       "  3.0,\n",
       "  -0.6285821221294181,\n",
       "  -0.5832107785803368,\n",
       "  -0.9792570631299442,\n",
       "  -0.7760383357093329,\n",
       "  0.95,\n",
       "  0.04823388738163313],\n",
       " [-0.3449119214702234,\n",
       "  4.0,\n",
       "  0.9978125998764873,\n",
       "  -1.2807397621152568,\n",
       "  0.5361046986220542,\n",
       "  -1.1648176301977626,\n",
       "  1.2,\n",
       "  1.0275796630372962],\n",
       " [-1.5927604342393076,\n",
       "  5.0,\n",
       "  -0.2728106460774001,\n",
       "  1.8439354534038803,\n",
       "  0.7221832700924127,\n",
       "  -1.0201621624294692,\n",
       "  0.85,\n",
       "  -1.885750962275695],\n",
       " [-0.34485809971934583,\n",
       "  4.0,\n",
       "  -0.8639931633728598,\n",
       "  0.9350184858898832,\n",
       "  -1.9042751628119647,\n",
       "  -0.20662333370979952,\n",
       "  1.2,\n",
       "  0.4581461307341648],\n",
       " [0.7366679636829677,\n",
       "  3.0,\n",
       "  1.0267027970557805,\n",
       "  -0.3352242380451494,\n",
       "  0.661851179206675,\n",
       "  0.09281152982877083,\n",
       "  0.95,\n",
       "  -1.2896964830197024],\n",
       " [-1.7247316917885458,\n",
       "  0.0,\n",
       "  1.418858624175011,\n",
       "  1.6845354693409524,\n",
       "  0.7154827736983677,\n",
       "  1.397463482693759,\n",
       "  1.1,\n",
       "  -0.0656283791901424],\n",
       " [0.8597487313740921,\n",
       "  4.0,\n",
       "  0.6929703534601603,\n",
       "  -0.9088448374187528,\n",
       "  -0.15634186260616484,\n",
       "  0.5162000628463803,\n",
       "  1.2,\n",
       "  0.38089985959653344],\n",
       " [0.9955130229530829,\n",
       "  2.0,\n",
       "  -0.4349997830960333,\n",
       "  -0.8915609340034627,\n",
       "  0.6817810820923541,\n",
       "  -0.5124823958652038,\n",
       "  1.05,\n",
       "  0.9974771184128693],\n",
       " [-1.473659206518193,\n",
       "  1.0,\n",
       "  -1.2041766784944195,\n",
       "  1.7024735964277584,\n",
       "  -1.092021745738207,\n",
       "  -0.04267695919010669,\n",
       "  0.9,\n",
       "  0.9419585051206941],\n",
       " [0.8660710357676125,\n",
       "  3.0,\n",
       "  1.5334242431675529,\n",
       "  -0.2919246320055127,\n",
       "  -0.31882266529889863,\n",
       "  -1.2637948876774905,\n",
       "  0.95,\n",
       "  -1.8690899662307465],\n",
       " [-1.6149096086180057,\n",
       "  2.0,\n",
       "  -0.7558946304017364,\n",
       "  -0.3189607297547924,\n",
       "  0.23103316964614953,\n",
       "  -0.7377449084382013,\n",
       "  1.05,\n",
       "  1.0426428310511888],\n",
       " [-1.2198644625717874,\n",
       "  0.0,\n",
       "  1.1050621198628938,\n",
       "  1.3396593763035318,\n",
       "  0.5967557005978694,\n",
       "  0.19507159071388813,\n",
       "  1.1,\n",
       "  1.0134513196356785],\n",
       " [0.2770262842434422,\n",
       "  2.0,\n",
       "  1.1763616540346018,\n",
       "  1.0670618905942248,\n",
       "  0.914062138822487,\n",
       "  0.097954230937152,\n",
       "  1.05,\n",
       "  -0.558228891177599],\n",
       " [-0.8902212027513856,\n",
       "  4.0,\n",
       "  -1.1219108545509282,\n",
       "  -1.0019252279893311,\n",
       "  0.8952401497004523,\n",
       "  -0.4030564123674331,\n",
       "  1.2,\n",
       "  -1.234403527215297],\n",
       " [-1.364412177478659,\n",
       "  1.0,\n",
       "  -1.2948210776804798,\n",
       "  -1.3646805705918086,\n",
       "  -0.8784207043225135,\n",
       "  0.14517323875115992,\n",
       "  0.9,\n",
       "  -0.47631870443451396],\n",
       " [1.1508670562975631,\n",
       "  2.0,\n",
       "  -1.3964354074059462,\n",
       "  -0.44964843385503583,\n",
       "  -3.058813689791473,\n",
       "  0.3922334192252117,\n",
       "  1.05,\n",
       "  0.828604750599593],\n",
       " [-0.797467033284278,\n",
       "  0.0,\n",
       "  0.2941325934987589,\n",
       "  -1.0587468319419038,\n",
       "  -1.6640400284009,\n",
       "  0.031871222428504535,\n",
       "  1.1,\n",
       "  -1.13874664412],\n",
       " [-1.3525622996468705,\n",
       "  2.0,\n",
       "  0.2242260157930965,\n",
       "  -0.8767317563093331,\n",
       "  0.6058001833040064,\n",
       "  -1.692661851345511,\n",
       "  1.05,\n",
       "  0.9534409331875202],\n",
       " [1.8581359144800451,\n",
       "  5.0,\n",
       "  -1.2691973069676603,\n",
       "  -1.0847957081960509,\n",
       "  -0.6184982768903505,\n",
       "  0.057682479761126136,\n",
       "  0.85,\n",
       "  1.0162919740541199],\n",
       " [-1.0251983617619722,\n",
       "  4.0,\n",
       "  -0.08832657048779503,\n",
       "  1.6023226817598293,\n",
       "  0.987303716299282,\n",
       "  -1.966191868112467,\n",
       "  1.2,\n",
       "  1.0266398684138212],\n",
       " [-1.2365799742383183,\n",
       "  4.0,\n",
       "  0.46260471416679516,\n",
       "  -0.7580433815916813,\n",
       "  0.46349105289855996,\n",
       "  -0.5456050740373999,\n",
       "  1.2,\n",
       "  0.4118401319721414],\n",
       " [0.5661130580262549,\n",
       "  5.0,\n",
       "  0.057647882462571784,\n",
       "  -0.16521441552618613,\n",
       "  -0.2006938370807447,\n",
       "  0.7772321301344043,\n",
       "  0.85,\n",
       "  0.6992739629488105],\n",
       " [0.045600770721660175,\n",
       "  4.0,\n",
       "  -0.06449949223222387,\n",
       "  0.10326730057908369,\n",
       "  -0.23482328750898304,\n",
       "  -1.4221505151339682,\n",
       "  1.2,\n",
       "  0.7251011018332535],\n",
       " [-0.9391834364516389,\n",
       "  5.0,\n",
       "  0.26406550107229254,\n",
       "  -0.06426673868227363,\n",
       "  0.9930967086586467,\n",
       "  -0.8390585445103969,\n",
       "  0.85,\n",
       "  1.0036511642782442],\n",
       " [-0.5834001861839281,\n",
       "  4.0,\n",
       "  0.09370375174781277,\n",
       "  0.21216476985383512,\n",
       "  -0.987082444924685,\n",
       "  -0.7632818126802928,\n",
       "  1.2,\n",
       "  1.0630982154384228],\n",
       " [-1.4938720998857955,\n",
       "  3.0,\n",
       "  0.45637586392239526,\n",
       "  -0.9957740897449231,\n",
       "  1.449670698641562,\n",
       "  1.1771430214186565,\n",
       "  0.95,\n",
       "  1.044399223618487],\n",
       " [0.9841968303192975,\n",
       "  2.0,\n",
       "  0.17213034118942103,\n",
       "  0.7540325847782641,\n",
       "  1.4488333195907175,\n",
       "  0.7861696024285729,\n",
       "  1.05,\n",
       "  0.7548784206333946],\n",
       " [-1.1560112730109695,\n",
       "  4.0,\n",
       "  -0.538938021121339,\n",
       "  1.2933632622086644,\n",
       "  0.903821568418854,\n",
       "  -0.4378941704734634,\n",
       "  1.2,\n",
       "  0.5587463392273379],\n",
       " [-1.2692026097974265,\n",
       "  5.0,\n",
       "  0.692468851872077,\n",
       "  -0.17189625589290408,\n",
       "  0.8807022849444351,\n",
       "  -1.1095661222959627,\n",
       "  0.85,\n",
       "  1.0721537775915648],\n",
       " [0.8220386719100597,\n",
       "  0.0,\n",
       "  0.45362865315692646,\n",
       "  0.4483817526202112,\n",
       "  0.18258328926547138,\n",
       "  -1.8930582643042653,\n",
       "  1.1,\n",
       "  0.8611171305145375],\n",
       " [1.1959421961122587,\n",
       "  3.0,\n",
       "  0.6374480035982688,\n",
       "  1.954505483156071,\n",
       "  0.01145383592038792,\n",
       "  -1.6347013909434327,\n",
       "  0.95,\n",
       "  0.7455526093792703],\n",
       " [0.8125464770019317,\n",
       "  2.0,\n",
       "  -0.4752206663102512,\n",
       "  0.6071373552925383,\n",
       "  0.4551841345714849,\n",
       "  0.14539015225205754,\n",
       "  1.05,\n",
       "  0.7348656641617254],\n",
       " [-0.0415820988147621,\n",
       "  0.0,\n",
       "  -1.5613464399758403,\n",
       "  -0.5642627386864504,\n",
       "  0.18784681275983553,\n",
       "  1.5833914341531319,\n",
       "  1.1,\n",
       "  0.679581240956609],\n",
       " [-0.578856157276974,\n",
       "  0.0,\n",
       "  -0.3305090762200664,\n",
       "  1.6301619765466395,\n",
       "  -0.19835026667753264,\n",
       "  -0.21517447925047647,\n",
       "  1.1,\n",
       "  0.6262669673477642],\n",
       " [0.633900906456858,\n",
       "  4.0,\n",
       "  0.8837315548252368,\n",
       "  0.5714139082144403,\n",
       "  0.560762126824178,\n",
       "  -1.0989918364370403,\n",
       "  1.2,\n",
       "  -0.031972728330950086],\n",
       " [0.9072051126849174,\n",
       "  5.0,\n",
       "  1.6267767583509127,\n",
       "  -1.0452225215026614,\n",
       "  0.1694264837100912,\n",
       "  0.26815206868597496,\n",
       "  0.85,\n",
       "  -0.7017958507250296],\n",
       " [-0.03597144999666491,\n",
       "  2.0,\n",
       "  1.320801859574249,\n",
       "  0.7453181013651077,\n",
       "  0.1959539287663889,\n",
       "  0.4905928379069084,\n",
       "  1.05,\n",
       "  -0.08936166733674747],\n",
       " [1.0291328383348883,\n",
       "  1.0,\n",
       "  0.8847353165970359,\n",
       "  1.59856198217036,\n",
       "  0.9352315825742196,\n",
       "  -1.3204667679312188,\n",
       "  0.9,\n",
       "  1.0733748157982232],\n",
       " [0.012810977798223724,\n",
       "  3.0,\n",
       "  -0.1666518844630547,\n",
       "  -1.1417271233427382,\n",
       "  0.11819568046252685,\n",
       "  -0.039060548352874126,\n",
       "  0.95,\n",
       "  2.7208227637196325],\n",
       " [-0.15770054568637398,\n",
       "  4.0,\n",
       "  -1.081479374513766,\n",
       "  1.8171465898106682,\n",
       "  -0.43823949232681847,\n",
       "  0.14870268943502898,\n",
       "  1.2,\n",
       "  -0.8942354202524225],\n",
       " [-1.6192756720970949,\n",
       "  1.0,\n",
       "  0.4980394183082765,\n",
       "  1.5790252975719494,\n",
       "  0.13732985810555695,\n",
       "  -0.48383041073849126,\n",
       "  0.9,\n",
       "  -1.5929750951476538],\n",
       " [-0.7494211455275449,\n",
       "  0.0,\n",
       "  0.6854876526125935,\n",
       "  0.056181786270704186,\n",
       "  0.9034158343089128,\n",
       "  1.1606279157644386,\n",
       "  1.1,\n",
       "  -0.3682387784294844],\n",
       " [0.8885729372391021,\n",
       "  0.0,\n",
       "  0.749521293190943,\n",
       "  -0.24999890563715346,\n",
       "  0.27337406519574936,\n",
       "  0.47058501669279734,\n",
       "  1.1,\n",
       "  -1.465470657861681],\n",
       " [0.2973323669782603,\n",
       "  2.0,\n",
       "  1.061696983331051,\n",
       "  0.5799702103238535,\n",
       "  -0.8574769015006862,\n",
       "  -0.15068318926586635,\n",
       "  1.05,\n",
       "  0.4366961439812668],\n",
       " [-1.221145621366612,\n",
       "  2.0,\n",
       "  0.0401092465592662,\n",
       "  -0.7360650133478366,\n",
       "  0.8225967370506821,\n",
       "  -0.8495926511374996,\n",
       "  1.05,\n",
       "  -1.8432644977468824],\n",
       " [-1.1862009242543248,\n",
       "  5.0,\n",
       "  0.4424552067759738,\n",
       "  -0.5583269176918007,\n",
       "  0.902576519829291,\n",
       "  0.04100977757610375,\n",
       "  0.85,\n",
       "  0.9628677286775449],\n",
       " [0.36169947320842205,\n",
       "  2.0,\n",
       "  1.287522514649417,\n",
       "  -1.1364780974549684,\n",
       "  0.05623330078692372,\n",
       "  -0.8028907101589827,\n",
       "  1.05,\n",
       "  1.0060098655877836],\n",
       " [1.4515371988067678,\n",
       "  4.0,\n",
       "  -1.2874320056850217,\n",
       "  1.479399222562103,\n",
       "  0.6671050634702362,\n",
       "  0.2951001543275584,\n",
       "  1.2,\n",
       "  -0.20672349344117702],\n",
       " [-0.1419234857728007,\n",
       "  3.0,\n",
       "  0.5256924560831534,\n",
       "  1.2992432360182462,\n",
       "  -0.3578465805097026,\n",
       "  -1.758120574353139,\n",
       "  0.95,\n",
       "  -0.13899435734222276],\n",
       " [0.27022014724954135,\n",
       "  2.0,\n",
       "  -0.4281848694498547,\n",
       "  -1.436414958903238,\n",
       "  0.415454717919407,\n",
       "  0.3647399301473303,\n",
       "  1.05,\n",
       "  0.8467263460697431],\n",
       " [1.0148402839301396,\n",
       "  5.0,\n",
       "  1.2326701795745987,\n",
       "  -0.976750870360338,\n",
       "  1.0457466770654975,\n",
       "  1.6895719331507455,\n",
       "  0.85,\n",
       "  -0.6407617663479743],\n",
       " [0.30233014405735126,\n",
       "  3.0,\n",
       "  -0.5220968899435187,\n",
       "  0.9578436407419765,\n",
       "  -2.064397895761668,\n",
       "  -0.11271503602239438,\n",
       "  0.95,\n",
       "  1.0333904385694914],\n",
       " [1.0094117227016344,\n",
       "  2.0,\n",
       "  -0.6213069524990342,\n",
       "  -0.9396373768793442,\n",
       "  0.3648997708082203,\n",
       "  0.8129431519335305,\n",
       "  1.05,\n",
       "  -0.7984926804622343],\n",
       " [-0.7532090436163207,\n",
       "  2.0,\n",
       "  -1.6943852632654788,\n",
       "  -0.9118022881594066,\n",
       "  -0.0017846623822160978,\n",
       "  -0.6743070132754044,\n",
       "  1.05,\n",
       "  -0.7941013010271584],\n",
       " [0.9312216952347744,\n",
       "  5.0,\n",
       "  1.165682261690958,\n",
       "  0.7033741410795075,\n",
       "  0.053432943745255077,\n",
       "  -0.7690579356335117,\n",
       "  0.85,\n",
       "  -0.5672083574602911],\n",
       " [1.32237813135071,\n",
       "  1.0,\n",
       "  -1.21335134388586,\n",
       "  0.02998100496119623,\n",
       "  0.9142329273584037,\n",
       "  -1.0448304917310876,\n",
       "  0.9,\n",
       "  -1.9213671268263217],\n",
       " [-0.5561037380216483,\n",
       "  5.0,\n",
       "  -0.5815557663797901,\n",
       "  -1.1146595475591106,\n",
       "  0.5839876489866631,\n",
       "  -0.9497032516287687,\n",
       "  0.85,\n",
       "  1.0489305619162987],\n",
       " [0.00906987458400427,\n",
       "  2.0,\n",
       "  -0.4289239189301665,\n",
       "  -0.7657441527182905,\n",
       "  0.5267434102375658,\n",
       "  0.6276346664523016,\n",
       "  1.05,\n",
       "  0.45597155456327176],\n",
       " [0.3762486271467413,\n",
       "  2.0,\n",
       "  0.5089071128708201,\n",
       "  0.5572436737522372,\n",
       "  0.12049945817343284,\n",
       "  -1.8246107434468903,\n",
       "  1.05,\n",
       "  -0.51836256146975],\n",
       " [-0.999715886513456,\n",
       "  5.0,\n",
       "  0.27630322352240466,\n",
       "  1.0648385740759438,\n",
       "  0.36653660803997173,\n",
       "  -1.017918065947344,\n",
       "  0.85,\n",
       "  -0.6374014306271004],\n",
       " [1.0580203309984122,\n",
       "  3.0,\n",
       "  -0.7574979147888882,\n",
       "  -0.5571101505846855,\n",
       "  -0.9358207206111148,\n",
       "  0.8129746954861025,\n",
       "  0.95,\n",
       "  0.8505340863122679],\n",
       " [0.3121611288615177,\n",
       "  3.0,\n",
       "  0.3508545485653932,\n",
       "  -1.3035523191933942,\n",
       "  -0.3313605523358259,\n",
       "  -1.0729965074502095,\n",
       "  0.95,\n",
       "  0.8150317502430182],\n",
       " [-0.1321689562791636,\n",
       "  5.0,\n",
       "  -0.31819156847526403,\n",
       "  1.0674385339246886,\n",
       "  -2.7898539378675835,\n",
       "  1.4860959626379224,\n",
       "  0.85,\n",
       "  0.01533174801144829],\n",
       " [-0.7413502980624738,\n",
       "  3.0,\n",
       "  -0.8542436674143685,\n",
       "  -1.0719408701063633,\n",
       "  0.11753316442652849,\n",
       "  1.906224442195548,\n",
       "  0.95,\n",
       "  1.0577828451077702],\n",
       " [-1.3045582137047667,\n",
       "  2.0,\n",
       "  1.3061916863051126,\n",
       "  1.1400200314866906,\n",
       "  -0.10538606020217747,\n",
       "  0.6096601315127855,\n",
       "  1.05,\n",
       "  1.0572590775910693],\n",
       " [-0.412445169097448,\n",
       "  1.0,\n",
       "  0.07179541173389117,\n",
       "  -0.05593053271773712,\n",
       "  0.34148800051649764,\n",
       "  0.00573855096568621,\n",
       "  0.9,\n",
       "  0.3636988621037285],\n",
       " [1.0572658780611601,\n",
       "  2.0,\n",
       "  0.24730715789554594,\n",
       "  1.8299778243342808,\n",
       "  0.11952683674170449,\n",
       "  -1.0900349892489227,\n",
       "  1.05,\n",
       "  -0.7347751464700131],\n",
       " [1.040269642412062,\n",
       "  0.0,\n",
       "  0.5154261424015245,\n",
       "  1.924625744805318,\n",
       "  0.6123075484456615,\n",
       "  -0.5885843902714774,\n",
       "  1.1,\n",
       "  -1.4365736944443088],\n",
       " [-1.2926844800864858,\n",
       "  2.0,\n",
       "  -1.2773952318748378,\n",
       "  -0.7522959618270413,\n",
       "  0.18001826082548922,\n",
       "  -0.01160439711104697,\n",
       "  1.05,\n",
       "  1.0566362271801606],\n",
       " [0.8416073069897448,\n",
       "  2.0,\n",
       "  0.3706236105588535,\n",
       "  0.8928687288316898,\n",
       "  -1.3652619991024602,\n",
       "  -0.381309558110312,\n",
       "  1.05,\n",
       "  0.914140804446147],\n",
       " [-1.8070725560136578,\n",
       "  0.0,\n",
       "  -1.120262816889306,\n",
       "  1.2832057004085433,\n",
       "  0.8474196112598217,\n",
       "  0.9940292387876875,\n",
       "  1.1,\n",
       "  3.743737711494053],\n",
       " [-0.5284987103861549,\n",
       "  4.0,\n",
       "  -0.8753624854740801,\n",
       "  -0.7768833927377267,\n",
       "  0.07258308792360879,\n",
       "  -0.15885487697159595,\n",
       "  1.2,\n",
       "  -0.6825031368878434],\n",
       " [-0.5145570576361366,\n",
       "  2.0,\n",
       "  1.322381624952707,\n",
       "  -0.27223727240967405,\n",
       "  0.41609032789021705,\n",
       "  -0.914473709960628,\n",
       "  1.05,\n",
       "  1.0365444501565608],\n",
       " [0.5392814683653026,\n",
       "  2.0,\n",
       "  -0.29762539936012333,\n",
       "  0.3206672067563696,\n",
       "  -0.8738676234696813,\n",
       "  0.7881058966534333,\n",
       "  1.05,\n",
       "  -1.9009551288371849],\n",
       " [0.7600023054137804,\n",
       "  3.0,\n",
       "  0.27491599380584886,\n",
       "  -0.3414316703836844,\n",
       "  -0.432708282911745,\n",
       "  -0.4230973451254963,\n",
       "  0.95,\n",
       "  0.22875532981690574],\n",
       " [1.7977123852443084,\n",
       "  1.0,\n",
       "  1.3983527992119076,\n",
       "  -0.7120949784336097,\n",
       "  -0.778555641668717,\n",
       "  1.6251971477884983,\n",
       "  0.9,\n",
       "  0.5813247575230953],\n",
       " [1.347977713220631,\n",
       "  2.0,\n",
       "  -0.8107990785374407,\n",
       "  -0.5272224562455612,\n",
       "  -1.3460752454937888,\n",
       "  0.5758324352471751,\n",
       "  1.05,\n",
       "  0.5162823328531655],\n",
       " [0.330749375027697,\n",
       "  1.0,\n",
       "  -0.5495598307876312,\n",
       "  -1.3944185368905424,\n",
       "  -0.17058303363295627,\n",
       "  1.3326375603402074,\n",
       "  0.9,\n",
       "  -1.6664855057897094],\n",
       " [1.228443955078468,\n",
       "  3.0,\n",
       "  0.7764485751768718,\n",
       "  1.2022424266037153,\n",
       "  0.8884375509402471,\n",
       "  -0.49628164722483814,\n",
       "  0.95,\n",
       "  -1.4034536115214773],\n",
       " [0.07363400562326697,\n",
       "  1.0,\n",
       "  -1.4618677244811293,\n",
       "  1.2508347788236696,\n",
       "  0.11701823055568002,\n",
       "  -1.4719437212741158,\n",
       "  0.9,\n",
       "  -1.9199604851084677],\n",
       " [-1.2648444003748862,\n",
       "  4.0,\n",
       "  0.017430175904494968,\n",
       "  -0.4613559099706201,\n",
       "  0.40583689042306714,\n",
       "  -0.37463695040332773,\n",
       "  1.2,\n",
       "  0.20070878817617288],\n",
       " [0.47720847619630324,\n",
       "  0.0,\n",
       "  1.5567409083691746,\n",
       "  -0.7544620930958051,\n",
       "  0.6385991556727565,\n",
       "  0.40700760897400867,\n",
       "  1.1,\n",
       "  1.0411280581085482],\n",
       " [0.9917882373170356,\n",
       "  3.0,\n",
       "  1.3461434640797665,\n",
       "  -0.16188977764614473,\n",
       "  -3.6242058557119994,\n",
       "  -0.07979775675943358,\n",
       "  0.95,\n",
       "  1.0270678005566687],\n",
       " [-0.25196999750681615,\n",
       "  5.0,\n",
       "  -0.7986342724722802,\n",
       "  1.8224739118917643,\n",
       "  0.944452313136512,\n",
       "  0.19822768334685373,\n",
       "  0.85,\n",
       "  1.0989881031799478],\n",
       " [1.4555659711840983,\n",
       "  5.0,\n",
       "  0.34605619536128945,\n",
       "  -1.1803640813266292,\n",
       "  0.02739415830403008,\n",
       "  0.4542406896018906,\n",
       "  0.85,\n",
       "  0.008819934528044405],\n",
       " [-1.219223225748115,\n",
       "  5.0,\n",
       "  -1.2056913607569657,\n",
       "  0.14128299120813081,\n",
       "  0.18389508217572068,\n",
       "  -1.9413813854319604,\n",
       "  0.85,\n",
       "  1.8524554824944985],\n",
       " [0.1011998832081598,\n",
       "  0.0,\n",
       "  1.2209805849316449,\n",
       "  -1.3711527080989532,\n",
       "  -0.03009622931116486,\n",
       "  0.8941838310409737,\n",
       "  1.1,\n",
       "  -0.6110945779347395],\n",
       " [-1.6871206901935802,\n",
       "  4.0,\n",
       "  -0.5645768087019577,\n",
       "  -1.3254921382926068,\n",
       "  -1.2812625006588267,\n",
       "  -1.3597674981877603,\n",
       "  1.2,\n",
       "  -1.0453922948638783],\n",
       " [0.3851601819834563,\n",
       "  1.0,\n",
       "  -1.3836349377229182,\n",
       "  1.4233910060381154,\n",
       "  0.9655198314853748,\n",
       "  -0.621801565498011,\n",
       "  0.9,\n",
       "  0.024082727135195797],\n",
       " [1.0463878564385223,\n",
       "  2.0,\n",
       "  -1.682167672841717,\n",
       "  -1.0547147262676,\n",
       "  0.28782360540236696,\n",
       "  0.08885617691200946,\n",
       "  1.05,\n",
       "  -0.48158651887154924],\n",
       " [-0.47911047495263426,\n",
       "  5.0,\n",
       "  0.3347895407199233,\n",
       "  -0.49766005892246534,\n",
       "  -2.9304044102722844,\n",
       "  0.10503566316054759,\n",
       "  0.85,\n",
       "  -1.3980809881971],\n",
       " [0.09154034455571106,\n",
       "  0.0,\n",
       "  1.0999786837204848,\n",
       "  -0.9633795449882558,\n",
       "  0.7602356188678313,\n",
       "  0.24042656385119732,\n",
       "  1.1,\n",
       "  -0.40674108612553667],\n",
       " [-1.704569413295037,\n",
       "  4.0,\n",
       "  0.614514352364046,\n",
       "  0.20849247472697538,\n",
       "  -2.8205553985390863,\n",
       "  -0.16642579180893557,\n",
       "  1.2,\n",
       "  -0.1091269631080106],\n",
       " [-1.0353201515809853,\n",
       "  4.0,\n",
       "  0.3241627821795763,\n",
       "  -0.2858440509122986,\n",
       "  0.07472732479874483,\n",
       "  0.6534642173439129,\n",
       "  1.2,\n",
       "  0.7467379546228463],\n",
       " [1.3332177385129875,\n",
       "  0.0,\n",
       "  0.7624700970913083,\n",
       "  0.308686590397363,\n",
       "  0.9345556924244763,\n",
       "  -1.060096449579104,\n",
       "  1.1,\n",
       "  1.0097354587796197],\n",
       " [-1.0437709792230883,\n",
       "  4.0,\n",
       "  -0.010102461796044975,\n",
       "  0.8932416443057074,\n",
       "  0.5859318341091762,\n",
       "  1.7148347176673242,\n",
       "  1.2,\n",
       "  -0.5864184568076963],\n",
       " [-0.8931127861238815,\n",
       "  2.0,\n",
       "  1.6703829774059336,\n",
       "  1.506657845295287,\n",
       "  -0.10964693075325148,\n",
       "  0.7897815858495691,\n",
       "  1.05,\n",
       "  -0.4095705251585936],\n",
       " [-1.1368329791661067,\n",
       "  3.0,\n",
       "  -0.5494305113099329,\n",
       "  -0.8806487478266165,\n",
       "  -1.6977237730143289,\n",
       "  0.06439151407481436,\n",
       "  0.95,\n",
       "  0.6918404293586262],\n",
       " [-0.46912827412351843,\n",
       "  5.0,\n",
       "  1.0166791701232671,\n",
       "  0.08199693353317518,\n",
       "  0.9127728437921508,\n",
       "  0.8516361294947375,\n",
       "  0.85,\n",
       "  1.040259813959146],\n",
       " [1.303034472351653,\n",
       "  3.0,\n",
       "  -0.32898912090472976,\n",
       "  1.1844770565107525,\n",
       "  -0.25689228588574436,\n",
       "  0.04140647101668407,\n",
       "  0.95,\n",
       "  -0.055647285575983245],\n",
       " [-1.2081413979548,\n",
       "  3.0,\n",
       "  1.1441747723110558,\n",
       "  0.7719188085823345,\n",
       "  0.6017993455744508,\n",
       "  0.005245543205024172,\n",
       "  0.95,\n",
       "  0.4189984080771848],\n",
       " [-0.1547122761141753,\n",
       "  4.0,\n",
       "  -0.20709881205332809,\n",
       "  -0.04326685191421787,\n",
       "  -0.0498854589127996,\n",
       "  0.35373784680942083,\n",
       "  1.2,\n",
       "  -0.8891718222575288],\n",
       " [-0.8382589001819121,\n",
       "  0.0,\n",
       "  -0.5618997477494563,\n",
       "  -0.9395758919703788,\n",
       "  0.58213960232295,\n",
       "  -1.41884952122643,\n",
       "  1.1,\n",
       "  -0.6786303045405655],\n",
       " [1.2276766447508476,\n",
       "  0.0,\n",
       "  0.1361252108508831,\n",
       "  -0.01901735012129443,\n",
       "  0.7308355816532432,\n",
       "  0.9462924180370824,\n",
       "  1.1,\n",
       "  -0.803510767993525],\n",
       " [0.9390187292702119,\n",
       "  4.0,\n",
       "  -0.47423769213559236,\n",
       "  0.25034774864321824,\n",
       "  1.0587540216137474,\n",
       "  0.3938239441370007,\n",
       "  1.2,\n",
       "  -0.11335965004612535],\n",
       " [0.3141545980866878,\n",
       "  3.0,\n",
       "  -0.5843501041957466,\n",
       "  1.5975953317407012,\n",
       "  0.8568556898843865,\n",
       "  -1.461557663132759,\n",
       "  0.95,\n",
       "  -1.8118477766885808],\n",
       " [-1.3276723394789247,\n",
       "  1.0,\n",
       "  -0.2593699922019708,\n",
       "  0.6030453278888759,\n",
       "  0.9471966531892997,\n",
       "  1.5636816868998393,\n",
       "  0.9,\n",
       "  -0.40768680067384466],\n",
       " [1.4142985896390265,\n",
       "  0.0,\n",
       "  0.7308291031539942,\n",
       "  -0.013261417700937446,\n",
       "  0.6712632549752149,\n",
       "  0.03876430745898438,\n",
       "  1.1,\n",
       "  -0.40308632475446704],\n",
       " [1.4977135426678099,\n",
       "  3.0,\n",
       "  -1.2204777030146576,\n",
       "  -0.5818257049840766,\n",
       "  0.6705918284176667,\n",
       "  0.017919685870359345,\n",
       "  0.95,\n",
       "  0.7233626350101504],\n",
       " [1.3806934013857914,\n",
       "  4.0,\n",
       "  0.027628406592019233,\n",
       "  -1.3797281598457733,\n",
       "  -1.7775032707315979,\n",
       "  0.3867881767572835,\n",
       "  1.2,\n",
       "  0.9216436649743127],\n",
       " [-0.45086048667257295,\n",
       "  1.0,\n",
       "  -1.022323133454032,\n",
       "  -0.6053196806974347,\n",
       "  -0.35670345225636246,\n",
       "  0.6265925222742765,\n",
       "  0.9,\n",
       "  -0.18051065367317698],\n",
       " [0.5242408270486072,\n",
       "  2.0,\n",
       "  -0.47861025655209855,\n",
       "  -1.4082222240525726,\n",
       "  1.283038778350767,\n",
       "  0.47994935678140926,\n",
       "  1.05,\n",
       "  -1.1233039850689086],\n",
       " [1.2876984403854859,\n",
       "  4.0,\n",
       "  -0.2293213853909739,\n",
       "  -0.01565659492567892,\n",
       "  0.26238940351241796,\n",
       "  0.16718991593133453,\n",
       "  1.2,\n",
       "  -1.9456987134772254],\n",
       " [-0.10856184419492258,\n",
       "  2.0,\n",
       "  1.3917365836356423,\n",
       "  -1.345326391589881,\n",
       "  0.6084577108217809,\n",
       "  -1.9285226422929795,\n",
       "  1.05,\n",
       "  0.5073495675965042],\n",
       " [0.2786776447259571,\n",
       "  3.0,\n",
       "  -1.4463633582952145,\n",
       "  0.1516464723940649,\n",
       "  0.9404317430357692,\n",
       "  1.033093454266344,\n",
       "  0.95,\n",
       "  0.42743165288012447],\n",
       " [0.12581862056138204,\n",
       "  4.0,\n",
       "  -1.3483200375670448,\n",
       "  0.8420945125782237,\n",
       "  0.6324363798398117,\n",
       "  0.7371749213653117,\n",
       "  1.2,\n",
       "  1.1564224942410453],\n",
       " [-1.011614220373327,\n",
       "  1.0,\n",
       "  -1.4560189833835393,\n",
       "  -1.2738242401063213,\n",
       "  0.7097578270458098,\n",
       "  -0.5941707203647164,\n",
       "  0.9,\n",
       "  1.0551887061647032],\n",
       " [-1.1079747618138869,\n",
       "  5.0,\n",
       "  -1.4448143066204715,\n",
       "  1.855159605683003,\n",
       "  1.0047046945207585,\n",
       "  1.4114802870131165,\n",
       "  0.85,\n",
       "  0.212609615353852],\n",
       " [1.5664493372091046,\n",
       "  2.0,\n",
       "  0.34516115550950416,\n",
       "  1.958031287319923,\n",
       "  0.5836589602651737,\n",
       "  0.21157238924295796,\n",
       "  1.05,\n",
       "  0.3874809593720186],\n",
       " [-0.5155842188125078,\n",
       "  0.0,\n",
       "  0.3261494149772135,\n",
       "  1.7045529395028651,\n",
       "  -0.098090774525158,\n",
       "  1.1366009911135582,\n",
       "  1.1,\n",
       "  -0.9207482451357231],\n",
       " [0.38159422833493295,\n",
       "  1.0,\n",
       "  0.649813346526881,\n",
       "  -0.5394022111711261,\n",
       "  1.7284110595037028,\n",
       "  0.2598389196404381,\n",
       "  0.9,\n",
       "  -1.2944525990135953],\n",
       " [0.8190981203731933,\n",
       "  4.0,\n",
       "  -0.27697729935422055,\n",
       "  -1.2991129418104526,\n",
       "  -0.20678093082828075,\n",
       "  1.273568036263373,\n",
       "  1.2,\n",
       "  -1.0585857098136997],\n",
       " [0.4725909241439583,\n",
       "  1.0,\n",
       "  -0.6481595270244479,\n",
       "  0.5894489481991644,\n",
       "  0.07736574607200998,\n",
       "  -0.7302264676150049,\n",
       "  0.9,\n",
       "  0.44861333633597394],\n",
       " [-0.7103546981053624,\n",
       "  3.0,\n",
       "  0.47781125170622085,\n",
       "  -0.6097344753153852,\n",
       "  -0.708354126220181,\n",
       "  0.8607021820082188,\n",
       "  0.95,\n",
       "  1.1120309369969241],\n",
       " [-0.48867038770904875,\n",
       "  2.0,\n",
       "  0.8732435047362153,\n",
       "  1.5430224473535619,\n",
       "  -2.4290466116982405,\n",
       "  0.8375977360268646,\n",
       "  1.05,\n",
       "  -0.15222699686870564],\n",
       " [0.307015749861615,\n",
       "  2.0,\n",
       "  0.31502170307483773,\n",
       "  0.302117255671595,\n",
       "  0.6576160439595502,\n",
       "  1.1300865537684652,\n",
       "  1.05,\n",
       "  -0.02761072397835879],\n",
       " [0.7207343583344504,\n",
       "  4.0,\n",
       "  -1.415910036740879,\n",
       "  -0.5880275677522857,\n",
       "  -0.04892249289877818,\n",
       "  -1.2312947176313147,\n",
       "  1.2,\n",
       "  -1.8956819610466569],\n",
       " [0.8256618874016848,\n",
       "  5.0,\n",
       "  -0.6535907322615546,\n",
       "  -0.43564703968846125,\n",
       "  0.8734098830327358,\n",
       "  -0.6980348441619271,\n",
       "  0.85,\n",
       "  0.4772139304290366],\n",
       " [0.6025703514784673,\n",
       "  5.0,\n",
       "  -0.5620599441753749,\n",
       "  0.7901443166402526,\n",
       "  -1.3475173284355872,\n",
       "  -1.5919234965092521,\n",
       "  0.85,\n",
       "  0.7154020502592524],\n",
       " [0.08187679840725226,\n",
       "  2.0,\n",
       "  0.7171525450899195,\n",
       "  -0.39141203809089675,\n",
       "  0.3376887198880448,\n",
       "  -1.0669982266948828,\n",
       "  1.05,\n",
       "  1.0555502361668043],\n",
       " [-0.6567289226447477,\n",
       "  1.0,\n",
       "  0.15526388474504527,\n",
       "  0.7252888173751617,\n",
       "  -0.5144448138654526,\n",
       "  0.9116570197411575,\n",
       "  0.9,\n",
       "  -0.42651896058502764],\n",
       " [-1.0120161908139478,\n",
       "  0.0,\n",
       "  0.8833515681716725,\n",
       "  -1.0070688944148833,\n",
       "  0.6043074508300619,\n",
       "  -1.8937596846428053,\n",
       "  1.1,\n",
       "  0.34994040089433903],\n",
       " [-1.2617846017258456,\n",
       "  2.0,\n",
       "  1.4911846343488375,\n",
       "  -1.382990278381157,\n",
       "  0.0009000049491485132,\n",
       "  0.9770546156582172,\n",
       "  1.05,\n",
       "  1.013183490685643],\n",
       " [1.0229323267251493,\n",
       "  2.0,\n",
       "  0.37501499146445055,\n",
       "  1.3088813156839048,\n",
       "  0.8896238809689573,\n",
       "  0.363221498687879,\n",
       "  1.05,\n",
       "  -0.8058205219449502],\n",
       " [0.31609688290858207,\n",
       "  1.0,\n",
       "  -0.03389036732470272,\n",
       "  1.4515418445980632,\n",
       "  -0.8998859984782835,\n",
       "  0.9944397191608256,\n",
       "  0.9,\n",
       "  0.953282594707513],\n",
       " [0.7835418249341713,\n",
       "  5.0,\n",
       "  -0.3210036395662799,\n",
       "  -1.1198759870745887,\n",
       "  0.394138416950322,\n",
       "  0.3949672979387284,\n",
       "  0.85,\n",
       "  -0.44588277069208965],\n",
       " [-1.2934255898485354,\n",
       "  0.0,\n",
       "  -1.3574968395519078,\n",
       "  0.831815768324585,\n",
       "  0.7865015087363323,\n",
       "  0.7348665938922656,\n",
       "  1.1,\n",
       "  2.4386359289647794],\n",
       " [-0.05236789792057659,\n",
       "  2.0,\n",
       "  1.4805802259311343,\n",
       "  -0.47874791362459745,\n",
       "  0.3126554369709545,\n",
       "  1.5298851559674045,\n",
       "  1.05,\n",
       "  0.9524046283351665],\n",
       " [-1.1372832510196444,\n",
       "  2.0,\n",
       "  0.07803567325080397,\n",
       "  1.1597082640858591,\n",
       "  -0.6890800585975055,\n",
       "  -0.7190981571386937,\n",
       "  1.05,\n",
       "  1.0569630173413977],\n",
       " [-0.4292307543474633,\n",
       "  0.0,\n",
       "  1.6152120434704205,\n",
       "  -0.07853618814243078,\n",
       "  0.7609259310757788,\n",
       "  0.29396976552613197,\n",
       "  1.1,\n",
       "  0.6157391886396525],\n",
       " [-1.315472820594477,\n",
       "  3.0,\n",
       "  1.141434368814529,\n",
       "  1.1245456200534234,\n",
       "  -0.17562976814528747,\n",
       "  1.268701858065347,\n",
       "  0.95,\n",
       "  -1.8339315923972375],\n",
       " [1.5548079883931365,\n",
       "  0.0,\n",
       "  0.9200714504601136,\n",
       "  0.3279542951944261,\n",
       "  0.988517975053614,\n",
       "  0.24021412622171182,\n",
       "  1.1,\n",
       "  0.33073575855601245],\n",
       " [-1.2508146565677292,\n",
       "  2.0,\n",
       "  -1.6247892600499703,\n",
       "  -0.8356935912513451,\n",
       "  0.6055836985235638,\n",
       "  0.16105625486679537,\n",
       "  1.05,\n",
       "  -0.28140794741286124],\n",
       " [1.016998237941391,\n",
       "  1.0,\n",
       "  -0.49467483661732353,\n",
       "  1.1962687184606249,\n",
       "  0.04543715946069747,\n",
       "  -0.005143184701192121,\n",
       "  0.9,\n",
       "  0.12072902379548955],\n",
       " [0.4584072242327847,\n",
       "  0.0,\n",
       "  -0.3563267228729023,\n",
       "  0.5107641649008693,\n",
       "  0.769886456405923,\n",
       "  0.05515537430405673,\n",
       "  1.1,\n",
       "  0.3715374517143843],\n",
       " [-1.6211402575722595,\n",
       "  1.0,\n",
       "  -0.2410851020614705,\n",
       "  -0.6343145659681725,\n",
       "  1.4407413976161434,\n",
       "  -0.15713753158202057,\n",
       "  0.9,\n",
       "  0.9987076271634485],\n",
       " [0.9184987053159318,\n",
       "  1.0,\n",
       "  0.94024639884269,\n",
       "  1.7828626620985761,\n",
       "  0.9445741008506396,\n",
       "  0.5852687689204447,\n",
       "  0.9,\n",
       "  1.2184981049465324],\n",
       " [1.308324080084004,\n",
       "  5.0,\n",
       "  -0.2556781088770002,\n",
       "  -1.361403432277567,\n",
       "  0.901821788908029,\n",
       "  0.9926800382863884,\n",
       "  0.85,\n",
       "  -0.31863995377278403],\n",
       " [0.42479480707546974,\n",
       "  0.0,\n",
       "  -1.602892022995693,\n",
       "  -1.393592018136252,\n",
       "  -0.9539493203118498,\n",
       "  0.4504959247547133,\n",
       "  1.1,\n",
       "  0.8319171950033851],\n",
       " [0.13092520562494334,\n",
       "  2.0,\n",
       "  -1.355817577872966,\n",
       "  -0.4783376838718505,\n",
       "  -0.5412761359260547,\n",
       "  -0.29805148812538407,\n",
       "  1.05,\n",
       "  0.37260877346760024],\n",
       " [1.2689809333236508,\n",
       "  4.0,\n",
       "  0.970865511358373,\n",
       "  1.0572507010686214,\n",
       "  -0.5136584170986555,\n",
       "  -0.28980565466797825,\n",
       "  1.2,\n",
       "  0.7255692179368043],\n",
       " [-0.14065274378792997,\n",
       "  3.0,\n",
       "  1.3636928489225157,\n",
       "  1.6176638593947588,\n",
       "  -2.103793306511198,\n",
       "  0.5540811419287167,\n",
       "  0.95,\n",
       "  0.9607320348779546],\n",
       " [-0.8655487351174618,\n",
       "  5.0,\n",
       "  0.9232171337238415,\n",
       "  0.5619874635555496,\n",
       "  0.6432915068595592,\n",
       "  -1.8348620866175276,\n",
       "  0.85,\n",
       "  -1.932699936414036],\n",
       " [-0.06442858500978328,\n",
       "  0.0,\n",
       "  -1.6578598367896051,\n",
       "  1.371752047800612,\n",
       "  1.3850958197689967,\n",
       "  -0.8060983409275992,\n",
       "  1.1,\n",
       "  -1.9522644542449514],\n",
       " [-1.2682050945780583,\n",
       "  3.0,\n",
       "  -1.2858184458081103,\n",
       "  0.040532275050781906,\n",
       "  -1.0572908803764904,\n",
       "  -1.60206761177629,\n",
       "  0.95,\n",
       "  1.36147470059662],\n",
       " [0.588048618610683,\n",
       "  2.0,\n",
       "  -0.08074276305651609,\n",
       "  0.7137557755922034,\n",
       "  0.21629248757771688,\n",
       "  0.5215135860683742,\n",
       "  1.05,\n",
       "  0.032227020361221895],\n",
       " [1.1874318093345593,\n",
       "  2.0,\n",
       "  -0.4868496612600652,\n",
       "  -1.250730565302557,\n",
       "  0.7484124008940525,\n",
       "  -0.04860242761206497,\n",
       "  1.05,\n",
       "  1.0658186242628074],\n",
       " [0.8783069602060709,\n",
       "  1.0,\n",
       "  0.2294786597808404,\n",
       "  1.7663482139236948,\n",
       "  0.603029439008893,\n",
       "  -0.5746914420159452,\n",
       "  0.9,\n",
       "  0.32178315916808653],\n",
       " [-1.3973736405131136,\n",
       "  2.0,\n",
       "  -0.6487596246259644,\n",
       "  0.22059489790523648,\n",
       "  -0.393159976876787,\n",
       "  0.09684223299550496,\n",
       "  1.05,\n",
       "  1.0402212701669746],\n",
       " [1.1697830084065057,\n",
       "  5.0,\n",
       "  -1.3682846690616008,\n",
       "  0.5783224857141142,\n",
       "  0.6798497573476536,\n",
       "  -0.503589740204587,\n",
       "  0.85,\n",
       "  1.0757554211347735],\n",
       " [-1.813481674172335,\n",
       "  1.0,\n",
       "  -0.9191706710962219,\n",
       "  1.8660397424674529,\n",
       "  -0.699156052724831,\n",
       "  1.000268359307747,\n",
       "  0.9,\n",
       "  -0.8111766276804321],\n",
       " [-1.4528658083096724,\n",
       "  2.0,\n",
       "  1.553709222732102,\n",
       "  -0.03186102469145779,\n",
       "  0.2162002088385677,\n",
       "  -0.5140586832477905,\n",
       "  1.05,\n",
       "  1.0628848300715035],\n",
       " [-0.1462542291619727,\n",
       "  5.0,\n",
       "  0.9263848294573006,\n",
       "  -1.211789806024082,\n",
       "  0.7215596455763396,\n",
       "  0.6024036690447241,\n",
       "  0.85,\n",
       "  -1.7783936400500702],\n",
       " [1.3132359738494142,\n",
       "  5.0,\n",
       "  -0.13162489337799707,\n",
       "  -0.8243821706456986,\n",
       "  0.8771089343293709,\n",
       "  1.9435263888952228,\n",
       "  0.85,\n",
       "  1.0209006593449603],\n",
       " [-0.44131502676115125,\n",
       "  4.0,\n",
       "  -0.737597619660385,\n",
       "  -0.5935907715149534,\n",
       "  0.571120460340581,\n",
       "  -1.629441377623969,\n",
       "  1.2,\n",
       "  0.26740617522302323],\n",
       " [0.25676071960931857,\n",
       "  2.0,\n",
       "  1.169906995379223,\n",
       "  0.7020338565363021,\n",
       "  -0.6106367167227821,\n",
       "  -0.5119852219507368,\n",
       "  1.05,\n",
       "  0.9215178326884214],\n",
       " [0.14402133021524716,\n",
       "  3.0,\n",
       "  0.8054195255095811,\n",
       "  0.8559207372827591,\n",
       "  0.7056228457503746,\n",
       "  -0.08136101983395572,\n",
       "  0.95,\n",
       "  1.0307550680665305],\n",
       " [-0.2091056601758253,\n",
       "  3.0,\n",
       "  -1.6576757273487803,\n",
       "  1.3926260484564603,\n",
       "  -0.550621669447098,\n",
       "  -1.0721466539938291,\n",
       "  0.95,\n",
       "  -1.1529521651822985],\n",
       " [-1.1416399301291376,\n",
       "  0.0,\n",
       "  0.2773075851239128,\n",
       "  -0.8184974738859022,\n",
       "  0.8091546260804422,\n",
       "  0.29694755321955707,\n",
       "  1.1,\n",
       "  0.7691357460016804],\n",
       " [0.10913951049337256,\n",
       "  5.0,\n",
       "  -0.8171264552246474,\n",
       "  0.543173936881938,\n",
       "  0.5690671483192389,\n",
       "  0.41810250765471846,\n",
       "  0.85,\n",
       "  -1.3490918766747761],\n",
       " [1.2588651937479263,\n",
       "  4.0,\n",
       "  0.6156731276227376,\n",
       "  -0.9345539186460599,\n",
       "  -0.6892498880469109,\n",
       "  -1.4115909940719193,\n",
       "  1.2,\n",
       "  -0.22221247559113996],\n",
       " [-0.8944736817377342,\n",
       "  5.0,\n",
       "  -1.0224141951790386,\n",
       "  -0.9615706335949676,\n",
       "  0.7949678405282065,\n",
       "  -1.4494954925022534,\n",
       "  0.85,\n",
       "  1.0079233256259736],\n",
       " [-0.878167650679353,\n",
       "  3.0,\n",
       "  -0.8083491535874422,\n",
       "  1.3866637345233803,\n",
       "  -0.03898221277908828,\n",
       "  -0.40998576487515725,\n",
       "  0.95,\n",
       "  -0.8368776541235918],\n",
       " [1.3583495008593998,\n",
       "  1.0,\n",
       "  -1.481730589737809,\n",
       "  -1.2209954575046944,\n",
       "  0.7381845063758364,\n",
       "  0.1672010555951756,\n",
       "  0.9,\n",
       "  1.0569870200570917],\n",
       " [-0.5528715181389453,\n",
       "  1.0,\n",
       "  1.2552919192534626,\n",
       "  0.02137662263865484,\n",
       "  0.0824217232974958,\n",
       "  -0.7369882009063913,\n",
       "  0.9,\n",
       "  -1.7075625109062893],\n",
       " [0.7181670542601739,\n",
       "  1.0,\n",
       "  0.19675153405111193,\n",
       "  -1.4006000562339154,\n",
       "  0.8538837621896652,\n",
       "  1.9050215400470865,\n",
       "  0.9,\n",
       "  -0.3593211688689671],\n",
       " [0.4910842431641814,\n",
       "  0.0,\n",
       "  -0.7405087628386101,\n",
       "  -1.3982857604620644,\n",
       "  0.8624508173859262,\n",
       "  -0.6472268720175058,\n",
       "  1.1,\n",
       "  -0.9663521466033553],\n",
       " [-1.21977019359999,\n",
       "  2.0,\n",
       "  -0.2921057509743341,\n",
       "  1.4444823437214689,\n",
       "  0.17289293920343912,\n",
       "  -1.7703436678434068,\n",
       "  1.05,\n",
       "  -0.16199188504273654],\n",
       " [0.4480659988130735,\n",
       "  4.0,\n",
       "  0.5712840263401486,\n",
       "  -1.3981158049385234,\n",
       "  0.7500013789123217,\n",
       "  -0.12848403011577608,\n",
       "  1.2,\n",
       "  -0.7101435166263547],\n",
       " [-1.0221900974305436,\n",
       "  3.0,\n",
       "  0.7313264549169708,\n",
       "  -1.1649057531724802,\n",
       "  -0.3021600728004266,\n",
       "  -0.6688447345350305,\n",
       "  0.95,\n",
       "  1.0097696133281293],\n",
       " [0.2353684522080816,\n",
       "  4.0,\n",
       "  -0.34803364862449454,\n",
       "  -0.6841060706099952,\n",
       "  0.7285173964335715,\n",
       "  -0.9020898987556839,\n",
       "  1.2,\n",
       "  0.33725898788220654],\n",
       " [1.255421741835403,\n",
       "  3.0,\n",
       "  -1.3002921538209213,\n",
       "  1.4562007414217704,\n",
       "  1.1213015846441148,\n",
       "  0.030312165618706456,\n",
       "  0.95,\n",
       "  0.14745312892045154],\n",
       " [1.0615794504898861,\n",
       "  1.0,\n",
       "  0.3867880505187881,\n",
       "  -1.305972239892591,\n",
       "  -0.006398962023963815,\n",
       "  0.20411384334567204,\n",
       "  0.9,\n",
       "  -0.2725049753763958],\n",
       " [-0.9462272855916021,\n",
       "  3.0,\n",
       "  0.18058506203803312,\n",
       "  1.556403745117659,\n",
       "  0.24752933525637072,\n",
       "  0.9531751009659393,\n",
       "  0.95,\n",
       "  0.9904905674362247],\n",
       " [1.7090390200965666,\n",
       "  1.0,\n",
       "  -0.9639225154924008,\n",
       "  -0.6537706316730163,\n",
       "  0.23944653761953952,\n",
       "  -0.6197612472462877,\n",
       "  0.9,\n",
       "  1.0235419807499064],\n",
       " [-0.8964917478696895,\n",
       "  3.0,\n",
       "  -1.3061879989203173,\n",
       "  -1.1554766070949753,\n",
       "  -2.591254902730568,\n",
       "  -0.46856336653398456,\n",
       "  0.95,\n",
       "  0.13010990209064385],\n",
       " [0.40248575377139145,\n",
       "  2.0,\n",
       "  -1.0210499884859154,\n",
       "  0.07856700749192816,\n",
       "  0.5849497787360499,\n",
       "  0.1371901324815664,\n",
       "  1.05,\n",
       "  0.7707567033799573],\n",
       " [1.258520764482023,\n",
       "  4.0,\n",
       "  -1.6400208944824732,\n",
       "  0.9245446731952279,\n",
       "  -0.48352818917539514,\n",
       "  -0.6010981037502531,\n",
       "  1.2,\n",
       "  0.9099373377392258],\n",
       " [-0.510426254947131,\n",
       "  1.0,\n",
       "  1.6409671857305776,\n",
       "  -1.4123828895125352,\n",
       "  -1.216233154254439,\n",
       "  -1.689849424741924,\n",
       "  0.9,\n",
       "  1.0784620709209636],\n",
       " [1.2539349076473814,\n",
       "  1.0,\n",
       "  1.0589611606269163,\n",
       "  -1.079880003737719,\n",
       "  1.1487859718392663,\n",
       "  -0.07228257112196634,\n",
       "  0.9,\n",
       "  -1.3983428591857252],\n",
       " [0.8301322582746123,\n",
       "  3.0,\n",
       "  -1.001679362824479,\n",
       "  -0.3016994480417771,\n",
       "  -0.969594312782019,\n",
       "  -1.849903351868178,\n",
       "  0.95,\n",
       "  -1.7633676144010857],\n",
       " [-1.1113962372772348,\n",
       "  0.0,\n",
       "  1.1651424970578164,\n",
       "  -0.2774645559327598,\n",
       "  0.7560248428546189,\n",
       "  -0.20008089839402038,\n",
       "  1.1,\n",
       "  -1.073679866628936],\n",
       " [-1.365187072720451,\n",
       "  2.0,\n",
       "  1.393472907642646,\n",
       "  1.9911047436217275,\n",
       "  0.7718879189133938,\n",
       "  -0.5433712882521736,\n",
       "  1.05,\n",
       "  -1.8233774817930681],\n",
       " [0.5222790978883891,\n",
       "  0.0,\n",
       "  0.1552571169640098,\n",
       "  0.7396016383791226,\n",
       "  -0.13705580597748068,\n",
       "  1.5828469027045717,\n",
       "  1.1,\n",
       "  0.998716078330231],\n",
       " [-0.37767130301236873,\n",
       "  1.0,\n",
       "  -0.920702451213263,\n",
       "  -0.6781318930441154,\n",
       "  -0.28485988668942813,\n",
       "  1.404541813986407,\n",
       "  0.9,\n",
       "  0.5903687738787712],\n",
       " [-0.9654358573257552,\n",
       "  3.0,\n",
       "  -1.0920360221171859,\n",
       "  1.8514656001989744,\n",
       "  -0.7323861220656116,\n",
       "  1.7083017387574084,\n",
       "  0.95,\n",
       "  -0.26798281618551467],\n",
       " [-1.4785352637015499,\n",
       "  5.0,\n",
       "  -0.34336351901780693,\n",
       "  -0.6916792251088829,\n",
       "  0.9473173960574222,\n",
       "  -0.35141312563563204,\n",
       "  0.85,\n",
       "  1.0672603323960936],\n",
       " [1.5584959322360632,\n",
       "  5.0,\n",
       "  -1.2847544020346895,\n",
       "  -0.6739381889596434,\n",
       "  0.4250677338310231,\n",
       "  -1.9378690844735411,\n",
       "  0.85,\n",
       "  1.0249473825735966],\n",
       " [0.9196116244748188,\n",
       "  0.0,\n",
       "  1.0526483758764247,\n",
       "  1.54934266962921,\n",
       "  -0.8186310838055231,\n",
       "  0.9505080999823564,\n",
       "  1.1,\n",
       "  0.9471431963897796],\n",
       " [-0.7927544382566173,\n",
       "  1.0,\n",
       "  1.493561322681536,\n",
       "  -0.6699494911462561,\n",
       "  -1.4350194761401693,\n",
       "  0.0002189037402163272,\n",
       "  0.9,\n",
       "  0.47614203689920487],\n",
       " [1.1743340929674237,\n",
       "  0.0,\n",
       "  0.41471253720107804,\n",
       "  -1.2542523734437185,\n",
       "  -2.6736295298148325,\n",
       "  -0.1800006469676879,\n",
       "  1.1,\n",
       "  0.5673237545644955],\n",
       " [0.6261347775384833,\n",
       "  4.0,\n",
       "  -1.0622314349647637,\n",
       "  -0.38745408543935445,\n",
       "  0.8150614398315728,\n",
       "  0.4708274443933254,\n",
       "  1.2,\n",
       "  2.2131030280746096],\n",
       " [0.5197405956953121,\n",
       "  3.0,\n",
       "  -1.4971863324903698,\n",
       "  0.8245570296818282,\n",
       "  -2.503420863963962,\n",
       "  -1.4349899285892769,\n",
       "  0.95,\n",
       "  -0.31662739648439636],\n",
       " [1.3810377302596661,\n",
       "  4.0,\n",
       "  -1.1650628488622188,\n",
       "  -1.1117020693020523,\n",
       "  1.171261253504554,\n",
       "  -0.8043981815106376,\n",
       "  1.2,\n",
       "  -0.08446024385664813],\n",
       " [1.5780025331489778,\n",
       "  2.0,\n",
       "  -0.8562810545766548,\n",
       "  -0.8382549039756996,\n",
       "  0.9668668999306697,\n",
       "  -1.1246782181371269,\n",
       "  1.05,\n",
       "  -0.5877493885675329],\n",
       " [-0.5887737815479755,\n",
       "  5.0,\n",
       "  1.5657224762707838,\n",
       "  0.36252050885935366,\n",
       "  -0.8803103245156475,\n",
       "  0.2464767966290859,\n",
       "  0.85,\n",
       "  -0.6448488841378457],\n",
       " [1.0336114280411643,\n",
       "  4.0,\n",
       "  -1.645271942980226,\n",
       "  0.10386363048692833,\n",
       "  1.1294496404329457,\n",
       "  -0.2345188035340987,\n",
       "  1.2,\n",
       "  1.05680096119626],\n",
       " [-0.8911639789143048,\n",
       "  1.0,\n",
       "  -0.749871626885906,\n",
       "  -1.2087592486639451,\n",
       "  -0.18000970809362574,\n",
       "  -0.7834810007915551,\n",
       "  0.9,\n",
       "  -0.7587562592765258],\n",
       " [0.35053729960912383,\n",
       "  0.0,\n",
       "  -0.2629679742406559,\n",
       "  -0.6242910589019456,\n",
       "  -0.0034271622604142003,\n",
       "  0.4140116455817456,\n",
       "  1.1,\n",
       "  0.9810237932129596],\n",
       " [-1.3546383038624885,\n",
       "  5.0,\n",
       "  -0.667520795193585,\n",
       "  0.9021897563165097,\n",
       "  1.2522908198782254,\n",
       "  -0.34467449685861373,\n",
       "  0.85,\n",
       "  0.15193855686474642],\n",
       " [0.616985517052237,\n",
       "  0.0,\n",
       "  -0.5649366264902829,\n",
       "  0.5139563828637125,\n",
       "  -0.24045209593537775,\n",
       "  -0.2581196567519659,\n",
       "  1.1,\n",
       "  -1.6066121161298774],\n",
       " [1.034921061134924,\n",
       "  2.0,\n",
       "  -1.2215838733781172,\n",
       "  1.5708764079040773,\n",
       "  -1.3592725962980956,\n",
       "  -0.9163611236659968,\n",
       "  1.05,\n",
       "  -0.0957741152827693],\n",
       " [1.4376764785587355,\n",
       "  5.0,\n",
       "  -0.629474785167939,\n",
       "  -0.5542599792756204,\n",
       "  0.23177064753709678,\n",
       "  -0.08396593439045,\n",
       "  0.85,\n",
       "  -1.031522508763455],\n",
       " [1.3170222145261028,\n",
       "  2.0,\n",
       "  -1.621717337719554,\n",
       "  -0.09147035247287535,\n",
       "  0.3985965578912009,\n",
       "  -0.8792926024502412,\n",
       "  1.05,\n",
       "  -1.640023342943119],\n",
       " [-0.8485696340112988,\n",
       "  3.0,\n",
       "  1.494904556884954,\n",
       "  1.7540513199658483,\n",
       "  0.5453365137891821,\n",
       "  -1.1353564750197531,\n",
       "  0.95,\n",
       "  1.037952013891009],\n",
       " [1.085950714994251,\n",
       "  1.0,\n",
       "  -0.02193089056344288,\n",
       "  0.4246686134520454,\n",
       "  0.13508918485335375,\n",
       "  1.1471817733787675,\n",
       "  0.9,\n",
       "  1.0400071147647216],\n",
       " [-0.7692970984624946,\n",
       "  2.0,\n",
       "  0.501415545674679,\n",
       "  -1.3524026598684378,\n",
       "  0.6371943984791766,\n",
       "  0.4120987868209565,\n",
       "  1.05,\n",
       "  1.0109858993491014],\n",
       " [1.2640193720875448,\n",
       "  1.0,\n",
       "  1.4933267694036445,\n",
       "  1.081530246887112,\n",
       "  -0.3471029356770115,\n",
       "  -0.5598162980086131,\n",
       "  0.9,\n",
       "  -0.7157819593652485],\n",
       " [-0.9220873480055396,\n",
       "  2.0,\n",
       "  0.5693170844940341,\n",
       "  0.018183750052083437,\n",
       "  0.4036944216730955,\n",
       "  0.9339834381196308,\n",
       "  1.05,\n",
       "  -0.6638600319487259],\n",
       " [-1.3563283463980833,\n",
       "  5.0,\n",
       "  0.84186430575778,\n",
       "  -0.2994751166553539,\n",
       "  0.0371583438499042,\n",
       "  -0.20422990018610837,\n",
       "  0.85,\n",
       "  -1.7889648411942187],\n",
       " [1.4458551507542965,\n",
       "  5.0,\n",
       "  -1.2886576172475421,\n",
       "  -0.8714588615458118,\n",
       "  0.8196164700250935,\n",
       "  1.477102758552495,\n",
       "  0.85,\n",
       "  -1.4256503207079287],\n",
       " [-0.6611105038819036,\n",
       "  4.0,\n",
       "  0.27053783761523675,\n",
       "  -1.2098106350678035,\n",
       "  0.8455482197581805,\n",
       "  -0.7325744992312101,\n",
       "  1.2,\n",
       "  0.6651477737156032],\n",
       " [0.23322161306682543,\n",
       "  4.0,\n",
       "  0.36087428537042354,\n",
       "  1.3756119135414753,\n",
       "  -0.43900152359882283,\n",
       "  1.8517193461727415,\n",
       "  1.2,\n",
       "  0.22061827641943382],\n",
       " [0.7145644915241445,\n",
       "  0.0,\n",
       "  -0.26260653777144066,\n",
       "  0.5932715689247361,\n",
       "  0.31704060402157036,\n",
       "  1.4300940545435576,\n",
       "  1.1,\n",
       "  -1.5983782871253625],\n",
       " [-1.4527773052918163,\n",
       "  2.0,\n",
       "  -1.698691615525416,\n",
       "  -0.958931879097316,\n",
       "  1.858617687432028,\n",
       "  -0.9816534936824208,\n",
       "  1.05,\n",
       "  -0.2318971522054137],\n",
       " [-0.23931125992955532,\n",
       "  3.0,\n",
       "  -0.5629162348030211,\n",
       "  -1.2815928313690006,\n",
       "  0.4565517172018015,\n",
       "  -0.39052941147445525,\n",
       "  0.95,\n",
       "  0.7422835685187766],\n",
       " [-0.08947171862636771,\n",
       "  2.0,\n",
       "  1.1573635326722072,\n",
       "  -0.5560060634529458,\n",
       "  0.7717106502898605,\n",
       "  -1.7266094255521185,\n",
       "  1.05,\n",
       "  0.3703784171878081],\n",
       " [-1.1091755663171927,\n",
       "  1.0,\n",
       "  -1.5477708450485932,\n",
       "  0.7825953791056208,\n",
       "  0.9369616392469037,\n",
       "  -1.3350918661588165,\n",
       "  0.9,\n",
       "  -1.5878474513434178],\n",
       " [-0.10621466773845063,\n",
       "  2.0,\n",
       "  0.806093018077287,\n",
       "  0.5742367392127663,\n",
       "  -2.117819618742496,\n",
       "  1.624727308423209,\n",
       "  1.05,\n",
       "  1.2378219781411284],\n",
       " [0.11326896933423983,\n",
       "  0.0,\n",
       "  0.10725789647952332,\n",
       "  -1.100079825287361,\n",
       "  0.6807422050685057,\n",
       "  -1.0026096262662463,\n",
       "  1.1,\n",
       "  1.0114988990407983],\n",
       " [0.01832244963775017,\n",
       "  3.0,\n",
       "  0.1662538994469714,\n",
       "  -0.26354029532794887,\n",
       "  0.3770156449503109,\n",
       "  -1.661869442709633,\n",
       "  0.95,\n",
       "  -0.6330244704581766],\n",
       " [-0.46300442385367424,\n",
       "  0.0,\n",
       "  0.19070861397239364,\n",
       "  -0.4421783326696927,\n",
       "  -0.15338090534580825,\n",
       "  -1.4998975842247886,\n",
       "  1.1,\n",
       "  -0.4602862559450745],\n",
       " [1.1124901368263715,\n",
       "  3.0,\n",
       "  0.4373573530469566,\n",
       "  1.3175257246727163,\n",
       "  1.2913912821764508,\n",
       "  -0.062077899964391635,\n",
       "  0.95,\n",
       "  -0.9447155232436008],\n",
       " [-0.2772325409785126,\n",
       "  5.0,\n",
       "  0.16051940418699584,\n",
       "  0.6730926213624326,\n",
       "  -1.2084241930278576,\n",
       "  1.899071454143521,\n",
       "  0.85,\n",
       "  0.8957047960197072],\n",
       " [-1.5255510403174872,\n",
       "  4.0,\n",
       "  -1.4641783671295436,\n",
       "  -1.2727943381712574,\n",
       "  -1.0943990849599308,\n",
       "  0.34377012323854533,\n",
       "  1.2,\n",
       "  -0.0558270221754258],\n",
       " [1.0187355442947645,\n",
       "  0.0,\n",
       "  -0.5865253358768105,\n",
       "  1.5320027811343528,\n",
       "  0.8221154220902591,\n",
       "  0.3446183668698525,\n",
       "  1.1,\n",
       "  0.9298350706084308],\n",
       " [-0.8276075050251231,\n",
       "  1.0,\n",
       "  0.5165126509577637,\n",
       "  -0.8788724101122349,\n",
       "  0.6529747640674756,\n",
       "  -1.7385429639217505,\n",
       "  0.9,\n",
       "  0.7803101424679849],\n",
       " [0.7548950123278393,\n",
       "  3.0,\n",
       "  1.4145473671068072,\n",
       "  -0.9961798291946358,\n",
       "  -0.06307265203868993,\n",
       "  -0.11254450938903736,\n",
       "  0.95,\n",
       "  0.7289069526557777],\n",
       " [-0.9233099352108624,\n",
       "  1.0,\n",
       "  1.398937849226542,\n",
       "  -1.1597571654275376,\n",
       "  -0.32750855505533166,\n",
       "  1.340374713848475,\n",
       "  0.9,\n",
       "  1.0007543765665057],\n",
       " [-0.9867924453837771,\n",
       "  3.0,\n",
       "  0.5268766776953654,\n",
       "  1.6094943904542118,\n",
       "  0.2537142183103918,\n",
       "  0.1804651808081043,\n",
       "  0.95,\n",
       "  0.49939477994352205],\n",
       " [-1.6951636690873004,\n",
       "  5.0,\n",
       "  0.9288084983867283,\n",
       "  1.9858124034653537,\n",
       "  0.6240971422409152,\n",
       "  0.4854980857909923,\n",
       "  0.85,\n",
       "  0.7069243194177033],\n",
       " [-1.6858854378170003,\n",
       "  3.0,\n",
       "  -1.2512892648441076,\n",
       "  -0.7714872651764716,\n",
       "  0.14718803130541347,\n",
       "  -1.0284690043349334,\n",
       "  0.95,\n",
       "  0.7212595969142873],\n",
       " [1.7037978842575132,\n",
       "  3.0,\n",
       "  1.203629258517809,\n",
       "  -0.5516548710204878,\n",
       "  -0.7759499398280222,\n",
       "  1.0795361337735938,\n",
       "  0.95,\n",
       "  -0.1679964917894816],\n",
       " [0.4966449274123086,\n",
       "  5.0,\n",
       "  1.2499406078785131,\n",
       "  -0.17938812415715297,\n",
       "  0.4114118628572147,\n",
       "  -1.4728479134256172,\n",
       "  0.85,\n",
       "  -1.8469058423494824]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[num_col_names] = scaler.transform(x_test[num_col_names])\n",
    "x_test = x_test.values.tolist()\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471101f5-8c1e-4cca-9c2f-03422c3be5a3",
   "metadata": {},
   "source": [
    "### Variáveis de entrada mais importantes para as tomadas de decisão do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e69cad-b5c7-45d3-9374-252e50b9b44c",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f9cb1f5-9e9b-42c1-8b33-ddeeebb86066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.666666666666664\n",
      "            importance\n",
      "feature_3 0.1929074669\n",
      "feature_8 0.1892358160\n",
      "feature_4 0.1695854165\n",
      "feature_1 0.1451937197\n",
      "feature_5 0.1140707840\n",
      "feature_6 0.1091405226\n",
      "feature_7 0.0487240333\n",
      "feature_2 0.0311422410\n"
     ]
    }
   ],
   "source": [
    "if model_type == 'classifier':\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # Realizando Random Forest para identificar a relevância das variáveis.\n",
    "    # Feature Extraction by Random Forest\n",
    "    model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                           criterion='gini', max_depth=None, max_features=3, # nao sei o que eh este max_features\n",
    "                           max_leaf_nodes=None, max_samples=None,\n",
    "                           min_impurity_decrease=0.0,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=10,\n",
    "                           n_jobs=None, oob_score=False, random_state=None,\n",
    "                           verbose=0, warm_start=False)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    feature_importances_val = model.feature_importances_\n",
    "    pd.options.display.float_format = '{:.10f}'.format\n",
    "    \n",
    "    x_pd = pd.DataFrame(x_train, columns=col_names_order[:-1])\n",
    "    feature_importances = pd.DataFrame(feature_importances_val,\n",
    "                                       index = x_pd.columns,\n",
    "                                       columns=['importance']).sort_values('importance', ascending = False)\n",
    "    print(f'Accuracy: {model.score(x_test, y_test) * 100}')\n",
    "    print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e73007-2f3d-4a6e-925e-08f49f3ac156",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34b57b03-3f6d-475d-8003-e1baa11ac100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.666666666666664\n",
      "Confusion matrix: [[29 20  8  2  4]\n",
      " [ 6 13 13  2  1]\n",
      " [ 7 14 14  5  4]\n",
      " [10 13 29 41 37]\n",
      " [ 0  2  2  5 19]]\n",
      "0-feature_1, Score: 0.26982684180453964\n",
      "1-feature_2, Score: 0.0\n",
      "2-feature_3, Score: 0.266048913142995\n",
      "3-feature_4, Score: 0.13449943991131993\n",
      "4-feature_5, Score: 0.0\n",
      "5-feature_6, Score: 0.0\n",
      "6-feature_7, Score: 0.0\n",
      "7-feature_8, Score: 0.32962480514114534\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    model = DecisionTreeClassifier(max_depth=3)\n",
    "else:\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    model = DecisionTreeRegressor(max_depth=3)    \n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "if model_type == 'classifier':\n",
    "    print(f'Accuracy: {model.score(x_test, y_test) * 100}')\n",
    "    print(f'Confusion matrix: {confusion_matrix(model.predict(x_test), y_test)}')\n",
    "else:\n",
    "    print(f'MSE: {mean_squared_error(model.predict(x_test), y_test)}')\n",
    "\n",
    "importance = model.feature_importances_\n",
    "for idx, score in enumerate(importance):\n",
    "    print(f'{idx}-{df.keys()[idx]}, Score: {score}')\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7a775-07df-43ad-b57c-a90dae2dc6ef",
   "metadata": {},
   "source": [
    "## Treinar diversos estimators disponíveis no Sklearn\n",
    "https://scikit-learn.org/stable/supervised_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "174d9ef1-cf9f-495a-bc0f-14ad12fc7900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending AdaBoostClassifier\n",
      "Appending BaggingClassifier\n",
      "Appending BernoulliNB\n",
      "Appending CalibratedClassifierCV\n",
      "Appending CategoricalNB\n",
      "Appending ClassifierChain\n",
      "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending ComplementNB\n",
      "Appending DecisionTreeClassifier\n",
      "Appending DummyClassifier\n",
      "Appending ExtraTreeClassifier\n",
      "Appending ExtraTreesClassifier\n",
      "Appending GaussianNB\n",
      "Appending GaussianProcessClassifier\n",
      "Appending GradientBoostingClassifier\n",
      "Appending HistGradientBoostingClassifier\n",
      "Appending KNeighborsClassifier\n",
      "Appending LabelPropagation\n",
      "Appending LabelSpreading\n",
      "Appending LinearDiscriminantAnalysis\n",
      "Appending LinearSVC\n",
      "Appending LogisticRegression\n",
      "Appending LogisticRegressionCV\n",
      "Appending MLPClassifier\n",
      "Appending MultiOutputClassifier\n",
      "MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultinomialNB\n",
      "Appending NearestCentroid\n",
      "Appending NuSVC\n",
      "Appending OneVsOneClassifier\n",
      "OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending OneVsRestClassifier\n",
      "OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending OutputCodeClassifier\n",
      "OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending PassiveAggressiveClassifier\n",
      "Appending Perceptron\n",
      "Appending QuadraticDiscriminantAnalysis\n",
      "Appending RadiusNeighborsClassifier\n",
      "Appending RandomForestClassifier\n",
      "Appending RidgeClassifier\n",
      "Appending RidgeClassifierCV\n",
      "Appending SGDClassifier\n",
      "Appending SVC\n",
      "Appending StackingClassifier\n",
      "StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending VotingClassifier\n",
      "VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# classifier, regressor, cluster, transformer\n",
    "estimators = all_estimators(type_filter=model_type)\n",
    "\n",
    "all_estimators = {}\n",
    "for name, estimator in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        est = estimator()\n",
    "        all_estimators[name] = est\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a626346-eda4-4754-be86-e8dbaddb3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_sklearn_estimators(estimators, x_train, y_train, x_test, y_test, model_type='classifier'):\n",
    "    if model_type == 'classifier':\n",
    "        best_acc = ['', 0.0]  # [estimator_name, accuracy]\n",
    "    else:\n",
    "        best_acc = ['', 99999.0]  # [estimator_name, error]\n",
    "    \n",
    "    for estimator_name, estimator in estimators.items():\n",
    "        try:\n",
    "            print(f'##### {estimator_name} #####')\n",
    "\n",
    "            estimator.fit(x_train, y_train)\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                print('Train ACC: %.3f%%' % (estimator.score(x_train, y_train) * 100.00))\n",
    "            else:\n",
    "                train_mse = mean_squared_error(estimator.predict(x_train), y_train)\n",
    "                print('Train MSE: %.3f' % (train_mse))\n",
    "                print(f'Train inference error (RMSE): ±{math.sqrt(train_mse)}')\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                test_acc = estimator.score(x_test, y_test) * 100.00\n",
    "                print('Test ACC: %.3f%%' % (test_acc))\n",
    "            else:\n",
    "                test_mse = mean_squared_error(estimator.predict(x_test), y_test)\n",
    "                print('Test MSE: %.3f' % (test_mse))\n",
    "                print(f'Test inference error (RMSE): ±{math.sqrt(test_mse)}')\n",
    "            print()\n",
    "    \n",
    "            if model_type == 'classifier' and test_acc > best_acc[1]:\n",
    "                best_acc = [estimator_name, test_acc]\n",
    "            elif model_type == 'regressor' and test_mse < best_acc[1]:\n",
    "                best_acc = [estimator_name, test_mse, math.sqrt(test_mse)]\n",
    "            \n",
    "            # Confusion Matrix\n",
    "            if model_type == 'classifier':\n",
    "                preds = estimator.predict(x_test)\n",
    "                matrix = confusion_matrix(y_test, preds)\n",
    "                print('Confusion Matrix Test:')\n",
    "                print(matrix)\n",
    "        except Exception as e:\n",
    "            print(f'Error ({estimator_name}): {e}')\n",
    "\n",
    "    print('########## Best Estimator ##########')\n",
    "    print(best_acc)\n",
    "    \n",
    "    return estimators, best_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c94079be-a30a-4a7b-97f4-7785c869ac03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### AdaBoostClassifier #####\n",
      "Train ACC: 58.512%\n",
      "Test ACC: 50.667%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[21 17 10  4  0]\n",
      " [ 1 33 23  5  0]\n",
      " [ 5 16 36  9  0]\n",
      " [ 1  4 12 32  6]\n",
      " [ 1  0  8 26 30]]\n",
      "##### BaggingClassifier #####\n",
      "Train ACC: 98.999%\n",
      "Test ACC: 57.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[39  7  4  2  0]\n",
      " [22 28  7  3  2]\n",
      " [ 5 21 32  7  1]\n",
      " [ 2  3  8 33  9]\n",
      " [ 1  1  6 17 40]]\n",
      "##### BernoulliNB #####\n",
      "Train ACC: 45.923%\n",
      "Test ACC: 39.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[27 13  7  5  0]\n",
      " [23 21  9  5  4]\n",
      " [11 21  7 20  7]\n",
      " [ 5  7  2 25 16]\n",
      " [10  2  3 12 38]]\n",
      "##### CalibratedClassifierCV #####\n",
      "Train ACC: 59.371%\n",
      "Test ACC: 51.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[36  8  5  2  1]\n",
      " [26 25  7  2  2]\n",
      " [ 4 28  8 22  4]\n",
      " [ 3  1  3 32 16]\n",
      " [ 1  3  0  9 52]]\n",
      "##### CategoricalNB #####\n",
      "Error (CategoricalNB): Negative values in data passed to CategoricalNB (input X)\n",
      "##### ComplementNB #####\n",
      "Error (ComplementNB): Negative values in data passed to ComplementNB (input X)\n",
      "##### DecisionTreeClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 47.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[32 11  8  0  1]\n",
      " [14 20 19  8  1]\n",
      " [ 5 17 26 13  5]\n",
      " [ 1  2 14 26 12]\n",
      " [ 0  5  7 15 38]]\n",
      "##### DummyClassifier #####\n",
      "Train ACC: 21.173%\n",
      "Test ACC: 17.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[52  0  0  0  0]\n",
      " [62  0  0  0  0]\n",
      " [66  0  0  0  0]\n",
      " [55  0  0  0  0]\n",
      " [65  0  0  0  0]]\n",
      "##### ExtraTreeClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 36.667%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[20 15  7  5  5]\n",
      " [ 9 18 18 12  5]\n",
      " [11  9 17 20  9]\n",
      " [ 5 12  9 23  6]\n",
      " [ 4  9  7 13 32]]\n",
      "##### ExtraTreesClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 60.667%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[44  6  2  0  0]\n",
      " [11 31 15  2  3]\n",
      " [ 2 19 28 15  2]\n",
      " [ 0  2 13 33  7]\n",
      " [ 0  1  1 17 46]]\n",
      "##### GaussianNB #####\n",
      "Train ACC: 58.226%\n",
      "Test ACC: 52.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[28 13  9  1  1]\n",
      " [11 33 13  4  1]\n",
      " [ 1 28 19 14  4]\n",
      " [ 1  2 10 30 12]\n",
      " [ 0  1  5 13 46]]\n",
      "##### GaussianProcessClassifier #####\n",
      "Train ACC: 95.136%\n",
      "Test ACC: 60.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[44  5  3  0  0]\n",
      " [ 8 34 17  1  2]\n",
      " [ 2 22 26 16  0]\n",
      " [ 1  4  8 35  7]\n",
      " [ 0  3  2 19 41]]\n",
      "##### GradientBoostingClassifier #####\n",
      "Train ACC: 99.714%\n",
      "Test ACC: 59.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[39  8  3  2  0]\n",
      " [ 6 35 15  5  1]\n",
      " [ 1 20 29 14  2]\n",
      " [ 0  4  9 32 10]\n",
      " [ 1  1  1 20 42]]\n",
      "##### HistGradientBoostingClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 60.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[39  9  3  1  0]\n",
      " [10 31 15  5  1]\n",
      " [ 2 20 29 13  2]\n",
      " [ 0  0  9 36 10]\n",
      " [ 0  1  2 17 45]]\n",
      "##### KNeighborsClassifier #####\n",
      "Train ACC: 66.524%\n",
      "Test ACC: 53.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[41  7  2  0  2]\n",
      " [14 31 13  4  0]\n",
      " [ 1 25 22 16  2]\n",
      " [ 1  6 14 29  5]\n",
      " [ 0  3  4 21 37]]\n",
      "##### LabelPropagation #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 47.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[33 10  9  0  0]\n",
      " [ 9 23 21  8  1]\n",
      " [ 4 15 27 14  6]\n",
      " [ 1  7 16 22  9]\n",
      " [ 0  4  3 21 37]]\n",
      "##### LabelSpreading #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 47.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[33 10  9  0  0]\n",
      " [ 9 23 21  8  1]\n",
      " [ 4 15 27 14  6]\n",
      " [ 1  7 16 22  9]\n",
      " [ 0  4  3 21 37]]\n",
      "##### LinearDiscriminantAnalysis #####\n",
      "Train ACC: 64.521%\n",
      "Test ACC: 57.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[33  8  9  2  0]\n",
      " [14 30 13  3  2]\n",
      " [ 3 18 27 18  0]\n",
      " [ 2  2  6 36  9]\n",
      " [ 1  1  4 14 45]]\n",
      "##### LinearSVC #####\n",
      "Train ACC: 56.509%\n",
      "Test ACC: 52.667%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[39  7  4  1  1]\n",
      " [27 26  4  2  3]\n",
      " [ 6 29  6 21  4]\n",
      " [ 3  1  2 31 18]\n",
      " [ 1  2  0  6 56]]\n",
      "##### LogisticRegression #####\n",
      "Train ACC: 64.950%\n",
      "Test ACC: 55.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[34  8  8  1  1]\n",
      " [16 28 14  2  2]\n",
      " [ 1 19 26 19  1]\n",
      " [ 2  2  4 33 14]\n",
      " [ 0  3  2 16 44]]\n",
      "##### LogisticRegressionCV #####\n",
      "Train ACC: 65.522%\n",
      "Test ACC: 57.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[35  7  9  1  0]\n",
      " [14 29 15  2  2]\n",
      " [ 1 18 31 15  1]\n",
      " [ 2  2  4 34 13]\n",
      " [ 0  2  4 16 43]]\n",
      "##### MLPClassifier #####\n",
      "Train ACC: 78.970%\n",
      "Test ACC: 66.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[41  7  4  0  0]\n",
      " [ 9 39 12  2  0]\n",
      " [ 1 16 37 12  0]\n",
      " [ 0  4  7 35  9]\n",
      " [ 0  2  1 16 46]]\n",
      "##### MultinomialNB #####\n",
      "Error (MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### NearestCentroid #####\n",
      "Train ACC: 52.074%\n",
      "Test ACC: 45.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[24 13 12  1  2]\n",
      " [11 27 21  1  2]\n",
      " [ 0 29 21 12  4]\n",
      " [ 0  5 15 22 13]\n",
      " [ 0  3 10 10 42]]\n",
      "##### NuSVC #####\n",
      "Train ACC: 83.548%\n",
      "Test ACC: 69.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[39  6  7  0  0]\n",
      " [ 5 43 12  2  0]\n",
      " [ 0 15 43  8  0]\n",
      " [ 0  4  7 37  7]\n",
      " [ 1  1  2 16 45]]\n",
      "##### PassiveAggressiveClassifier #####\n",
      "Train ACC: 38.054%\n",
      "Test ACC: 34.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[36 10  3  3  0]\n",
      " [19 24  7 11  1]\n",
      " [ 9 24 10 23  0]\n",
      " [ 2 15 12 24  2]\n",
      " [ 1  9 12 35  8]]\n",
      "##### Perceptron #####\n",
      "Train ACC: 41.631%\n",
      "Test ACC: 37.667%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[ 4 43  4  0  1]\n",
      " [ 1 51  3  1  6]\n",
      " [ 0 46  5  0 15]\n",
      " [ 0 18  5  0 32]\n",
      " [ 0  9  2  1 53]]\n",
      "##### QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 71.102%\n",
      "Test ACC: 62.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[36  8  8  0  0]\n",
      " [ 9 41  8  4  0]\n",
      " [ 1 19 29 17  0]\n",
      " [ 1  2  6 37  9]\n",
      " [ 0  3  2 17 43]]\n",
      "##### RadiusNeighborsClassifier #####\n",
      "Train ACC: 94.421%\n",
      "Error (RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   6,   7,   9,  11,  12,  13,  14,  15,  16,  17,\n",
      "        19,  20,  22,  24,  25,  26,  27,  28,  29,  33,  34,  35,  36,\n",
      "        37,  38,  40,  41,  42,  47,  48,  49,  50,  53,  54,  56,  57,\n",
      "        58,  59,  60,  61,  64,  65,  66,  69,  70,  71,  72,  73,  74,\n",
      "        78,  79,  80,  81,  82,  84,  86,  87,  89,  90,  93,  94,  95,\n",
      "        96,  97,  99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
      "       112, 113, 115, 116, 118, 119, 123, 124, 126, 128, 129, 131, 132,\n",
      "       133, 134, 135, 138, 140, 141, 143, 144, 145, 146, 147, 148, 150,\n",
      "       151, 152, 153, 154, 155, 156, 158, 159, 161, 162, 164, 166, 167,\n",
      "       168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 182,\n",
      "       183, 184, 185, 186, 189, 190, 192, 193, 194, 195, 196, 197, 198,\n",
      "       199, 201, 202, 203, 204, 207, 208, 209, 210, 213, 215, 216, 217,\n",
      "       219, 222, 223, 225, 226, 227, 229, 230, 231, 232, 233, 238, 239,\n",
      "       240, 241, 243, 244, 245, 247, 248, 249, 251, 253, 254, 255, 256,\n",
      "       257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "       270, 272, 273, 274, 275, 276, 278, 279, 280, 283, 284, 286, 287,\n",
      "       288, 289, 290, 291, 295, 296, 297, 298, 299]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### RandomForestClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 60.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[45  5  1  1  0]\n",
      " [12 32 13  3  2]\n",
      " [ 4 23 26 13  0]\n",
      " [ 1  0 11 35  8]\n",
      " [ 0  1  4 18 42]]\n",
      "##### RidgeClassifier #####\n",
      "Train ACC: 49.642%\n",
      "Test ACC: 49.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[44  4  1  0  3]\n",
      " [37 20  0  2  3]\n",
      " [11 22  3 16 14]\n",
      " [ 3  0  2 25 25]\n",
      " [ 1  1  0  7 56]]\n",
      "##### RidgeClassifierCV #####\n",
      "Train ACC: 49.356%\n",
      "Test ACC: 49.667%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[44  4  1  0  3]\n",
      " [37 20  0  2  3]\n",
      " [11 22  4 16 13]\n",
      " [ 4  0  1 25 25]\n",
      " [ 1  1  0  7 56]]\n",
      "##### SGDClassifier #####\n",
      "Train ACC: 47.353%\n",
      "Test ACC: 42.000%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[44  3  5  0  0]\n",
      " [39 11  8  1  3]\n",
      " [16 14 15 10 11]\n",
      " [ 9  0 13  5 28]\n",
      " [ 4  2  6  2 51]]\n",
      "##### SVC #####\n",
      "Train ACC: 73.677%\n",
      "Test ACC: 62.333%\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[40  8  4  0  0]\n",
      " [ 6 39 15  2  0]\n",
      " [ 2 17 30 17  0]\n",
      " [ 0  4  6 38  7]\n",
      " [ 1  2  2 20 40]]\n",
      "########## Best Estimator ##########\n",
      "['NuSVC', 69.0]\n",
      "Total time: 5.520238876342773\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimators_trained, best_estimator_name = run_sklearn_estimators(\n",
    "    all_estimators,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    model_type\n",
    ")\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fda6aea5-fd41-49f6-b7da-a5ef7d849c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NuSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NuSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.NuSVC.html\">?<span>Documentation for NuSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NuSVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NuSVC()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_trained[best_estimator_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9bb95-4f93-497e-a7bd-fe9ce5e291d8",
   "metadata": {},
   "source": [
    "### Save Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0f2b4f21-99f9-42af-89c1-dd2a21e11b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(estimators_trained[best_estimator_name], open('results/estimator_sklearn.sav', 'wb'))\n",
    "\n",
    "# Scaler\n",
    "pickle.dump(scaler, open('results/scaler.pkl','wb'))\n",
    "\n",
    "# Save columns names and informations\n",
    "data_to_save = {\n",
    "    'col_names_order': col_names_order,\n",
    "    'num_col_names': num_col_names,\n",
    "    'cat_col_names': cat_col_names,\n",
    "    'date_col_names': date_col_names,\n",
    "    'target_cols': target_cols,\n",
    "    'category_mappings': category_mappings,\n",
    "    'window_size': window_size\n",
    "}\n",
    "with open('results/columns_metadata_sklearn.json', 'w') as json_file:\n",
    "    json.dump(data_to_save, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70756f5f-6703-4179-91f9-9a2ee059e073",
   "metadata": {},
   "source": [
    "## Stacking estimators\n",
    "Classificador: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier\n",
    "\n",
    "Regressor: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37139066-befd-458e-919e-9e21bffceed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending AdaBoostClassifier\n",
      "Appending BaggingClassifier\n",
      "Appending BernoulliNB\n",
      "Appending CalibratedClassifierCV\n",
      "Appending CategoricalNB\n",
      "Appending ClassifierChain\n",
      "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending ComplementNB\n",
      "Appending DecisionTreeClassifier\n",
      "Appending DummyClassifier\n",
      "Appending ExtraTreeClassifier\n",
      "Appending ExtraTreesClassifier\n",
      "Appending GaussianNB\n",
      "Appending GaussianProcessClassifier\n",
      "Appending GradientBoostingClassifier\n",
      "Appending HistGradientBoostingClassifier\n",
      "Appending KNeighborsClassifier\n",
      "Appending LabelPropagation\n",
      "Appending LabelSpreading\n",
      "Appending LinearDiscriminantAnalysis\n",
      "Appending LinearSVC\n",
      "Appending LogisticRegression\n",
      "Appending LogisticRegressionCV\n",
      "Appending MLPClassifier\n",
      "Appending MultiOutputClassifier\n",
      "MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultinomialNB\n",
      "Appending NearestCentroid\n",
      "Appending NuSVC\n",
      "Appending OneVsOneClassifier\n",
      "OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending OneVsRestClassifier\n",
      "OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending OutputCodeClassifier\n",
      "OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending PassiveAggressiveClassifier\n",
      "Appending Perceptron\n",
      "Appending QuadraticDiscriminantAnalysis\n",
      "Appending RadiusNeighborsClassifier\n",
      "Appending RandomForestClassifier\n",
      "Appending RidgeClassifier\n",
      "Appending RidgeClassifierCV\n",
      "Appending SGDClassifier\n",
      "Appending SVC\n",
      "Appending StackingClassifier\n",
      "StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending VotingClassifier\n",
      "VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# classifier, regressor, cluster, transformer\n",
    "estimators = all_estimators(type_filter=model_type)\n",
    "\n",
    "all_estimators = {}\n",
    "for name, estimator in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        est = estimator()\n",
    "        all_estimators[name] = est\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "837e27c3-4b1c-4ba2-94a1-d1040bad2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_sklearn_estimators_with_stacking(estimators, x_train, y_train, x_test, y_test, model_type):\n",
    "    if model_type == 'classifier':\n",
    "        best_acc = ['', 0.0]  # [estimator_name, accuracy]\n",
    "    else:\n",
    "        best_acc = ['', 99999.0]  # [estimator_name, error]\n",
    "    estimators_stacked_trained = {}\n",
    "    \n",
    "    idx = 0\n",
    "    for estimator_name, estimator in estimators.items():\n",
    "        count = 0\n",
    "        for estimator_name2, estimator2 in estimators.items():\n",
    "            if count <= idx:\n",
    "                count += 1\n",
    "                continue\n",
    "            try:\n",
    "                print(f'##### {estimator_name} - {estimator_name2} #####')\n",
    "\n",
    "                if model_type == 'classifier':\n",
    "                    stack = StackingClassifier([(estimator_name, copy.deepcopy(estimator)), (estimator_name2, copy.deepcopy(estimator2))],\n",
    "                                              final_estimator=LogisticRegression())\n",
    "                else:\n",
    "                    stack = StackingRegressor([(estimator_name, copy.deepcopy(estimator)), (estimator_name2, copy.deepcopy(estimator2))],\n",
    "                                              final_estimator=RidgeCV())\n",
    "\n",
    "                stack.fit(x_train, y_train)\n",
    "                \n",
    "                if model_type == 'classifier':\n",
    "                    print('Train ACC: %.3f%%' % (stack.score(x_train, y_train) * 100.00))\n",
    "                else:\n",
    "                    train_mse = mean_squared_error(stack.predict(x_train), y_train)\n",
    "                    print('Train MSE: %.3f' % (train_mse))\n",
    "                    print(f'Train inference error (RMSE): ±{math.sqrt(train_mse)}')\n",
    "                \n",
    "                if model_type == 'classifier':\n",
    "                    test_acc = stack.score(x_test, y_test) * 100.00\n",
    "                    print('Test ACC: %.3f%%' % (test_acc))\n",
    "                else:\n",
    "                    test_mse = mean_squared_error(stack.predict(x_test), y_test)\n",
    "                    print('Test MSE: %.3f' % (test_mse))\n",
    "                    print(f'Test inference error (RMSE): ±{math.sqrt(test_mse)}')\n",
    "        \n",
    "                if model_type == 'classifier' and test_acc > best_acc[1]:\n",
    "                    best_acc = [f'{estimator_name}-{estimator_name2}', test_acc]\n",
    "                elif model_type == 'regressor' and test_mse < best_acc[1]:\n",
    "                    best_acc = [f'{estimator_name}-{estimator_name2}', test_mse, math.sqrt(test_mse)]\n",
    "                \n",
    "                # Confusion Matrix\n",
    "                if model_type == 'classifier':\n",
    "                    preds = stack.predict(x_test)\n",
    "                    matrix = confusion_matrix(y_test, preds)\n",
    "                    print('Confusion Matrix Test:')\n",
    "                    print(matrix)\n",
    "\n",
    "                estimators_stacked_trained[f'{estimator_name}-{estimator_name2}'] = copy.deepcopy(stack)\n",
    "            except Exception as e:\n",
    "                print(f'Error ({estimator_name}-{estimator_name2}): {e}')\n",
    "                continue\n",
    "        \n",
    "        idx += 1\n",
    "\n",
    "    print('########## Best Estimator ##########')\n",
    "    print(best_acc)\n",
    "    \n",
    "    return estimators_stacked_trained, best_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f4d5044-760a-421c-9eee-908ad2d38951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### AdaBoostClassifier - BaggingClassifier #####\n",
      "Train ACC: 96.423%\n",
      "Test ACC: 59.000%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  5  1  0]\n",
      " [14 35 10  1  2]\n",
      " [ 3 12 36 13  2]\n",
      " [ 0  4 10 32  9]\n",
      " [ 1  2  6 19 37]]\n",
      "##### AdaBoostClassifier - BernoulliNB #####\n",
      "Train ACC: 47.210%\n",
      "Test ACC: 41.000%\n",
      "Confusion Matrix Test:\n",
      "[[30  7  9  6  0]\n",
      " [22 15 15  7  3]\n",
      " [ 5 20 15 21  5]\n",
      " [ 2  4  7 27 15]\n",
      " [ 7  3  3 16 36]]\n",
      "##### AdaBoostClassifier - CalibratedClassifierCV #####\n",
      "Train ACC: 63.948%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  7  1  1]\n",
      " [19 25 14  2  2]\n",
      " [ 2 15 37 11  1]\n",
      " [ 2  1 13 25 14]\n",
      " [ 0  1  3 13 48]]\n",
      "##### AdaBoostClassifier - CategoricalNB #####\n",
      "Error (AdaBoostClassifier-CategoricalNB): Negative values in data passed to CategoricalNB (input X)\n",
      "##### AdaBoostClassifier - ComplementNB #####\n",
      "Error (AdaBoostClassifier-ComplementNB): Negative values in data passed to ComplementNB (input X)\n",
      "##### AdaBoostClassifier - DecisionTreeClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 50.000%\n",
      "Confusion Matrix Test:\n",
      "[[32 11  9  0  0]\n",
      " [15 19 20  8  0]\n",
      " [ 7 13 32 14  0]\n",
      " [ 3  2  9 30 11]\n",
      " [ 0  5  6 17 37]]\n",
      "##### AdaBoostClassifier - DummyClassifier #####\n",
      "Train ACC: 51.359%\n",
      "Test ACC: 46.333%\n",
      "Confusion Matrix Test:\n",
      "[[48  0  0  3  1]\n",
      " [50  0  0 10  2]\n",
      " [32  0  0 32  2]\n",
      " [ 6  0  0 42  7]\n",
      " [ 1  0  0 15 49]]\n",
      "##### AdaBoostClassifier - ExtraTreeClassifier #####\n",
      "Train ACC: 80.544%\n",
      "Test ACC: 40.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  0  8  2  3]\n",
      " [32  0 19 11  0]\n",
      " [24  0 22 14  6]\n",
      " [ 9  0 12 23 11]\n",
      " [ 6  1  9 13 36]]\n",
      "##### AdaBoostClassifier - ExtraTreesClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 65.333%\n",
      "Confusion Matrix Test:\n",
      "[[38 13  0  0  1]\n",
      " [ 7 38 13  2  2]\n",
      " [ 2 17 32 14  1]\n",
      " [ 0  2  5 39  9]\n",
      " [ 0  1  1 14 49]]\n",
      "##### AdaBoostClassifier - GaussianNB #####\n",
      "Train ACC: 63.805%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  7  2  0]\n",
      " [15 31 11  4  1]\n",
      " [ 2 21 24 16  3]\n",
      " [ 1  3  4 35 12]\n",
      " [ 1  1  3 15 45]]\n",
      "##### AdaBoostClassifier - GaussianProcessClassifier #####\n",
      "Train ACC: 83.977%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[49  3  0  0  0]\n",
      " [18 38  2  3  1]\n",
      " [ 7 14 21 23  1]\n",
      " [ 1  1  3 41  9]\n",
      " [ 1  0  0 16 48]]\n",
      "##### AdaBoostClassifier - GradientBoostingClassifier #####\n",
      "Train ACC: 96.137%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  3  0  1]\n",
      " [ 5 42 11  2  2]\n",
      " [ 1 22 25 16  2]\n",
      " [ 0  3  6 38  8]\n",
      " [ 1  0  1 21 42]]\n",
      "##### AdaBoostClassifier - HistGradientBoostingClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[39 11  2  0  0]\n",
      " [11 33 14  2  2]\n",
      " [ 3 20 27 14  2]\n",
      " [ 0  3  6 37  9]\n",
      " [ 0  1  2 18 44]]\n",
      "##### AdaBoostClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 66.810%\n",
      "Test ACC: 58.000%\n",
      "Confusion Matrix Test:\n",
      "[[40 10  1  0  1]\n",
      " [14 38  6  4  0]\n",
      " [ 1 22 20 16  7]\n",
      " [ 1  4  8 25 17]\n",
      " [ 1  0  3 10 51]]\n",
      "##### AdaBoostClassifier - LabelPropagation #####\n",
      "Train ACC: 94.993%\n",
      "Test ACC: 48.333%\n",
      "Confusion Matrix Test:\n",
      "[[35 11  6  0  0]\n",
      " [ 9 26 18  8  1]\n",
      " [ 4 19 14 23  6]\n",
      " [ 1  5  7 33  9]\n",
      " [ 0  4  0 24 37]]\n",
      "##### AdaBoostClassifier - LabelSpreading #####\n",
      "Train ACC: 87.697%\n",
      "Test ACC: 48.667%\n",
      "Confusion Matrix Test:\n",
      "[[36 12  4  0  0]\n",
      " [ 9 28 15  9  1]\n",
      " [ 5 18 13 24  6]\n",
      " [ 1  6  7 32  9]\n",
      " [ 0  4  0 24 37]]\n",
      "##### AdaBoostClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 63.805%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  7  7  2  0]\n",
      " [13 29 16  2  2]\n",
      " [ 2 15 35 14  0]\n",
      " [ 2  1  6 38  8]\n",
      " [ 1  1  5 13 45]]\n",
      "##### AdaBoostClassifier - LinearSVC #####\n",
      "Train ACC: 64.378%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  2  0]\n",
      " [13 29 16  2  2]\n",
      " [ 2 15 32 16  1]\n",
      " [ 2  1 10 32 10]\n",
      " [ 0  2  5 15 43]]\n",
      "##### AdaBoostClassifier - LogisticRegression #####\n",
      "Train ACC: 66.094%\n",
      "Test ACC: 60.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  9  1  0]\n",
      " [11 34 13  2  2]\n",
      " [ 2 15 35 14  0]\n",
      " [ 1  3  5 37  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### AdaBoostClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 66.381%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[34  8  9  1  0]\n",
      " [13 31 14  2  2]\n",
      " [ 1 16 35 14  0]\n",
      " [ 1  3  5 37  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### AdaBoostClassifier - MLPClassifier #####\n",
      "Train ACC: 77.253%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  7  4  1  0]\n",
      " [10 40  9  3  0]\n",
      " [ 2 16 39  9  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 1  0  2 17 45]]\n",
      "##### AdaBoostClassifier - MultinomialNB #####\n",
      "Error (AdaBoostClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### AdaBoostClassifier - NearestCentroid #####\n",
      "Train ACC: 55.222%\n",
      "Test ACC: 47.667%\n",
      "Confusion Matrix Test:\n",
      "[[34  3 12  1  2]\n",
      " [15 23 21  1  2]\n",
      " [ 5 24 21 12  4]\n",
      " [ 1  4 15 22 13]\n",
      " [ 0  3 10  9 43]]\n",
      "##### AdaBoostClassifier - NuSVC #####\n",
      "Train ACC: 75.966%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  1  0]\n",
      " [17 32 11  2  0]\n",
      " [ 2 12 40 12  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 16 46]]\n",
      "##### AdaBoostClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 49.070%\n",
      "Test ACC: 44.333%\n",
      "Confusion Matrix Test:\n",
      "[[38  7  7  0  0]\n",
      " [22 20 15  5  0]\n",
      " [10 13 32 11  0]\n",
      " [ 2  4 20 27  2]\n",
      " [ 1  3 11 34 16]]\n",
      "##### AdaBoostClassifier - Perceptron #####\n",
      "Train ACC: 40.916%\n",
      "Test ACC: 39.333%\n",
      "Confusion Matrix Test:\n",
      "[[27  9  6  7  3]\n",
      " [ 8  9 20 13 12]\n",
      " [ 5  3 10 19 29]\n",
      " [ 2  1  2 16 34]\n",
      " [ 1  1  1  6 56]]\n",
      "##### AdaBoostClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 70.529%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  6  0  0]\n",
      " [10 40  9  3  0]\n",
      " [ 2 17 31 16  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 0  1  3 18 43]]\n",
      "##### AdaBoostClassifier - RadiusNeighborsClassifier #####\n",
      "Error (AdaBoostClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### AdaBoostClassifier - RandomForestClassifier #####\n",
      "Train ACC: 98.426%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[43  4  3  1  1]\n",
      " [14 39  6  1  2]\n",
      " [ 4 16 33 12  1]\n",
      " [ 0  4  4 39  8]\n",
      " [ 0  1  1 17 46]]\n",
      "##### AdaBoostClassifier - RidgeClassifier #####\n",
      "Train ACC: 64.235%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  1  1]\n",
      " [14 30 14  2  2]\n",
      " [ 2 16 32 15  1]\n",
      " [ 2  1  7 35 10]\n",
      " [ 1  1  5 13 45]]\n",
      "##### AdaBoostClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 64.235%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  5  8  1  1]\n",
      " [14 30 14  2  2]\n",
      " [ 3 16 30 16  1]\n",
      " [ 3  0  7 34 11]\n",
      " [ 0  2  5 11 47]]\n",
      "##### AdaBoostClassifier - SGDClassifier #####\n",
      "Train ACC: 43.348%\n",
      "Test ACC: 36.000%\n",
      "Confusion Matrix Test:\n",
      "[[40 10  2  0  0]\n",
      " [34 22  3  3  0]\n",
      " [12 43 11  0  0]\n",
      " [ 2 22 17 11  3]\n",
      " [ 1  7 10 23 24]]\n",
      "##### AdaBoostClassifier - SVC #####\n",
      "Train ACC: 72.389%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  1  0]\n",
      " [ 5 44 10  2  1]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  3 21 40]]\n",
      "##### BaggingClassifier - BernoulliNB #####\n",
      "Train ACC: 93.991%\n",
      "Test ACC: 63.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  3  7  2  0]\n",
      " [13 38  5  5  1]\n",
      " [ 1 18 36  9  2]\n",
      " [ 2  2  7 35  9]\n",
      " [ 1  2  3 18 41]]\n",
      "##### BaggingClassifier - CalibratedClassifierCV #####\n",
      "Train ACC: 90.558%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[38 10  2  1  1]\n",
      " [12 34 12  2  2]\n",
      " [ 1 15 39  9  2]\n",
      " [ 2  2  7 37  7]\n",
      " [ 0  1  2 21 41]]\n",
      "##### BaggingClassifier - CategoricalNB #####\n",
      "Error (BaggingClassifier-CategoricalNB): Negative values in data passed to CategoricalNB (input X)\n",
      "##### BaggingClassifier - ComplementNB #####\n",
      "Error (BaggingClassifier-ComplementNB): Negative values in data passed to ComplementNB (input X)\n",
      "##### BaggingClassifier - DecisionTreeClassifier #####\n",
      "Train ACC: 98.140%\n",
      "Test ACC: 58.333%\n",
      "Confusion Matrix Test:\n",
      "[[45  5  2  0  0]\n",
      " [16 33  9  3  1]\n",
      " [ 3 21 25 16  1]\n",
      " [ 1  2  8 31 13]\n",
      " [ 0  2  7 15 41]]\n",
      "##### BaggingClassifier - DummyClassifier #####\n",
      "Train ACC: 96.137%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  3  0  0]\n",
      " [14 32 10  4  2]\n",
      " [ 4 18 31 11  2]\n",
      " [ 1  4  6 35  9]\n",
      " [ 2  0  3 19 41]]\n",
      "##### BaggingClassifier - ExtraTreeClassifier #####\n",
      "Train ACC: 94.850%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[38  8  5  1  0]\n",
      " [18 31  9  2  2]\n",
      " [ 5 19 22 17  3]\n",
      " [ 0  3  7 34 11]\n",
      " [ 0  2  3 15 45]]\n",
      "##### BaggingClassifier - ExtraTreesClassifier #####\n",
      "Train ACC: 98.426%\n",
      "Test ACC: 65.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  9  1  1  0]\n",
      " [11 40  8  1  2]\n",
      " [ 3 17 34 11  1]\n",
      " [ 0  1  7 34 13]\n",
      " [ 0  1  3 14 47]]\n",
      "##### BaggingClassifier - GaussianNB #####\n",
      "Train ACC: 91.989%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [14 33 12  1  2]\n",
      " [ 3 15 37 10  1]\n",
      " [ 2  1  6 36 10]\n",
      " [ 1  0  4 15 45]]\n",
      "##### BaggingClassifier - GaussianProcessClassifier #####\n",
      "Train ACC: 92.704%\n",
      "Test ACC: 61.333%\n",
      "Confusion Matrix Test:\n",
      "[[38 12  0  2  0]\n",
      " [14 39  3  4  2]\n",
      " [ 6 16 31 12  1]\n",
      " [ 2  1  8 34 10]\n",
      " [ 0  0  5 18 42]]\n",
      "##### BaggingClassifier - GradientBoostingClassifier #####\n",
      "Train ACC: 97.997%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[42  8  1  0  1]\n",
      " [ 8 44  6  2  2]\n",
      " [ 1 21 30 12  2]\n",
      " [ 0  3  5 37 10]\n",
      " [ 1  0  1 16 47]]\n",
      "##### BaggingClassifier - HistGradientBoostingClassifier #####\n",
      "Train ACC: 99.857%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  9  1  1  0]\n",
      " [10 37 12  1  2]\n",
      " [ 2 17 34 11  2]\n",
      " [ 0  2  7 36 10]\n",
      " [ 0  1  1 19 44]]\n",
      "##### BaggingClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 93.991%\n",
      "Test ACC: 65.333%\n",
      "Confusion Matrix Test:\n",
      "[[40 12  0  0  0]\n",
      " [11 41  7  1  2]\n",
      " [ 2 20 31 12  1]\n",
      " [ 0  4  8 37  6]\n",
      " [ 0  1  3 14 47]]\n",
      "##### BaggingClassifier - LabelPropagation #####\n",
      "Train ACC: 97.997%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[39 13  0  0  0]\n",
      " [11 37 11  1  2]\n",
      " [ 4 15 35 12  0]\n",
      " [ 1  1 12 33  8]\n",
      " [ 1  1  3 15 45]]\n",
      "##### BaggingClassifier - LabelSpreading #####\n",
      "Train ACC: 97.425%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [10 32 16  2  2]\n",
      " [ 5 16 29 15  1]\n",
      " [ 1  2  8 35  9]\n",
      " [ 0  3  0 19 43]]\n",
      "##### BaggingClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 84.549%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  7  8  0  1]\n",
      " [ 6 41 11  2  2]\n",
      " [ 2 15 37 12  0]\n",
      " [ 0  3  8 39  5]\n",
      " [ 0  2  3 16 44]]\n",
      "##### BaggingClassifier - LinearSVC #####\n",
      "Train ACC: 83.977%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  8  4  2  1]\n",
      " [ 9 38 12  1  2]\n",
      " [ 3 14 36 12  1]\n",
      " [ 0  3  6 38  8]\n",
      " [ 0  1  1 19 44]]\n",
      "##### BaggingClassifier - LogisticRegression #####\n",
      "Train ACC: 80.544%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[38  5  8  1  0]\n",
      " [ 8 36 15  1  2]\n",
      " [ 1 15 36 14  0]\n",
      " [ 0  4  6 34 11]\n",
      " [ 0  2  3 15 45]]\n",
      "##### BaggingClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 79.685%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[37  5  9  1  0]\n",
      " [ 8 39 11  2  2]\n",
      " [ 1 18 35 12  0]\n",
      " [ 0  3  6 37  9]\n",
      " [ 0  1  2 18 44]]\n",
      "##### BaggingClassifier - MLPClassifier #####\n",
      "Train ACC: 86.838%\n",
      "Test ACC: 70.000%\n",
      "Confusion Matrix Test:\n",
      "[[38 10  4  0  0]\n",
      " [ 6 47  7  2  0]\n",
      " [ 1 17 39  9  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 15 47]]\n",
      "##### BaggingClassifier - MultinomialNB #####\n",
      "Error (BaggingClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### BaggingClassifier - NearestCentroid #####\n",
      "Train ACC: 88.698%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[38  6  7  0  1]\n",
      " [15 33 12  0  2]\n",
      " [ 1 22 28 13  2]\n",
      " [ 1  2  5 38  9]\n",
      " [ 0  2  3 19 41]]\n",
      "##### BaggingClassifier - NuSVC #####\n",
      "Train ACC: 86.695%\n",
      "Test ACC: 70.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  9  2  1  0]\n",
      " [ 8 42 10  0  2]\n",
      " [ 1 13 42 10  0]\n",
      " [ 0  3  5 40  7]\n",
      " [ 1  0  2 15 47]]\n",
      "##### BaggingClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 84.692%\n",
      "Test ACC: 53.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  4  6  1  1]\n",
      " [13 17 25  5  2]\n",
      " [ 3  6 28 26  3]\n",
      " [ 1  2  3 29 20]\n",
      " [ 0  1  3 15 46]]\n",
      "##### BaggingClassifier - Perceptron #####\n",
      "Train ACC: 83.691%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  7  6  2  0]\n",
      " [10 19 26  4  3]\n",
      " [ 2  6 31 21  6]\n",
      " [ 0  1  4 37 13]\n",
      " [ 1  0  1 17 46]]\n",
      "##### BaggingClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 87.840%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[36 11  5  0  0]\n",
      " [ 9 42  9  1  1]\n",
      " [ 2 16 36 12  0]\n",
      " [ 0  3  3 40  9]\n",
      " [ 0  2  1 17 45]]\n",
      "##### BaggingClassifier - RadiusNeighborsClassifier #####\n",
      "Error (BaggingClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### BaggingClassifier - RandomForestClassifier #####\n",
      "Train ACC: 99.428%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  6  3  0  1]\n",
      " [15 34  9  2  2]\n",
      " [ 3 17 31 15  0]\n",
      " [ 0  3  8 39  5]\n",
      " [ 1  0  2 19 43]]\n",
      "##### BaggingClassifier - RidgeClassifier #####\n",
      "Train ACC: 88.412%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  7  6  0  0]\n",
      " [15 33 11  1  2]\n",
      " [ 3 16 35 12  0]\n",
      " [ 1  2  9 36  7]\n",
      " [ 0  1  2 18 44]]\n",
      "##### BaggingClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 88.841%\n",
      "Test ACC: 63.333%\n",
      "Confusion Matrix Test:\n",
      "[[35 10  7  0  0]\n",
      " [11 40  8  1  2]\n",
      " [ 1 20 35  8  2]\n",
      " [ 1  3  8 36  7]\n",
      " [ 0  2  2 17 44]]\n",
      "##### BaggingClassifier - SGDClassifier #####\n",
      "Train ACC: 73.677%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[38  8  5  1  0]\n",
      " [18 30 10  3  1]\n",
      " [ 5 23 34  4  0]\n",
      " [ 3  1 13 31  7]\n",
      " [ 1  2  2 23 37]]\n",
      "##### BaggingClassifier - SVC #####\n",
      "Train ACC: 83.548%\n",
      "Test ACC: 67.667%\n",
      "Confusion Matrix Test:\n",
      "[[43  5  3  1  0]\n",
      " [ 6 44  9  2  1]\n",
      " [ 3 14 37 12  0]\n",
      " [ 0  3  7 34 11]\n",
      " [ 0  1  3 16 45]]\n",
      "##### BernoulliNB - CalibratedClassifierCV #####\n",
      "Train ACC: 62.947%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  5  8  1  1]\n",
      " [18 25 15  2  2]\n",
      " [ 3 15 35 12  1]\n",
      " [ 3  0  7 33 12]\n",
      " [ 0  1  4 12 48]]\n",
      "##### BernoulliNB - CategoricalNB #####\n",
      "Error (BernoulliNB-CategoricalNB): Negative values in data passed to CategoricalNB (input X)\n",
      "##### BernoulliNB - ComplementNB #####\n",
      "Error (BernoulliNB-ComplementNB): Negative values in data passed to ComplementNB (input X)\n",
      "##### BernoulliNB - DecisionTreeClassifier #####\n",
      "Train ACC: 87.268%\n",
      "Test ACC: 53.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  9  0  0]\n",
      " [20 28  9  4  1]\n",
      " [ 5 19 26 13  3]\n",
      " [ 3  3  7 29 13]\n",
      " [ 2  3  5 14 41]]\n",
      "##### BernoulliNB - DummyClassifier #####\n",
      "Train ACC: 45.780%\n",
      "Test ACC: 40.667%\n",
      "Confusion Matrix Test:\n",
      "[[30  6 10  6  0]\n",
      " [22 14 14  9  3]\n",
      " [ 5 18 15 23  5]\n",
      " [ 2  5  7 26 15]\n",
      " [ 9  1  6 12 37]]\n",
      "##### BernoulliNB - ExtraTreeClassifier #####\n",
      "Train ACC: 73.104%\n",
      "Test ACC: 42.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  5  3  1]\n",
      " [25 14 12  6  5]\n",
      " [ 5 10 18 27  6]\n",
      " [ 3  3 14 21 14]\n",
      " [ 7  1  8 11 38]]\n",
      "##### BernoulliNB - ExtraTreesClassifier #####\n",
      "Train ACC: 96.710%\n",
      "Test ACC: 63.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  3  0  1]\n",
      " [ 9 35 15  1  2]\n",
      " [ 2 17 29 16  2]\n",
      " [ 0  2  3 39 11]\n",
      " [ 0  1  1 16 47]]\n",
      "##### BernoulliNB - GaussianNB #####\n",
      "Train ACC: 62.947%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  6 10  1  0]\n",
      " [15 29 15  2  1]\n",
      " [ 2 16 27 19  2]\n",
      " [ 1  3  3 37 11]\n",
      " [ 1  1  4 14 45]]\n",
      "##### BernoulliNB - GaussianProcessClassifier #####\n",
      "Train ACC: 70.243%\n",
      "Test ACC: 56.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  7  3  6  0]\n",
      " [20 29  8  2  3]\n",
      " [ 5 12 28 18  3]\n",
      " [ 4  1  5 35 10]\n",
      " [ 7  0  4 14 40]]\n",
      "##### BernoulliNB - GradientBoostingClassifier #####\n",
      "Train ACC: 93.562%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  6  5  0  0]\n",
      " [ 8 41  9  2  2]\n",
      " [ 1 18 29 16  2]\n",
      " [ 0  2  6 39  8]\n",
      " [ 1  0  1 20 43]]\n",
      "##### BernoulliNB - HistGradientBoostingClassifier #####\n",
      "Train ACC: 96.853%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  3  1  0]\n",
      " [11 39  7  3  2]\n",
      " [ 4 17 29 14  2]\n",
      " [ 0  2  5 39  9]\n",
      " [ 0  1  2 18 44]]\n",
      "##### BernoulliNB - KNeighborsClassifier #####\n",
      "Train ACC: 65.665%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[43  5  3  0  1]\n",
      " [14 35 10  3  0]\n",
      " [ 1 21 17 21  6]\n",
      " [ 1  2  9 30 13]\n",
      " [ 1  0  5 13 46]]\n",
      "##### BernoulliNB - LabelPropagation #####\n",
      "Train ACC: 81.974%\n",
      "Test ACC: 52.667%\n",
      "Confusion Matrix Test:\n",
      "[[38 10  3  1  0]\n",
      " [13 31  7 10  1]\n",
      " [ 4 21 13 22  6]\n",
      " [ 3  3  8 30 11]\n",
      " [ 2  3  2 12 46]]\n",
      "##### BernoulliNB - LabelSpreading #####\n",
      "Train ACC: 81.259%\n",
      "Test ACC: 52.333%\n",
      "Confusion Matrix Test:\n",
      "[[38 11  2  1  0]\n",
      " [13 30 10  8  1]\n",
      " [ 5 18 15 22  6]\n",
      " [ 2  4  9 28 12]\n",
      " [ 2  3  2 12 46]]\n",
      "##### BernoulliNB - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 63.805%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [12 28 18  2  2]\n",
      " [ 2 16 31 17  0]\n",
      " [ 2  1  5 39  8]\n",
      " [ 0  2  5 12 46]]\n",
      "##### BernoulliNB - LinearSVC #####\n",
      "Train ACC: 64.092%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  5  9  1  1]\n",
      " [12 30 16  2  2]\n",
      " [ 2 16 30 17  1]\n",
      " [ 1  2  9 33 10]\n",
      " [ 0  2  5 14 44]]\n",
      "##### BernoulliNB - LogisticRegression #####\n",
      "Train ACC: 66.094%\n",
      "Test ACC: 59.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  9  1  0]\n",
      " [14 30 14  2  2]\n",
      " [ 1 17 33 15  0]\n",
      " [ 1  3  4 38  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### BernoulliNB - LogisticRegressionCV #####\n",
      "Train ACC: 66.524%\n",
      "Test ACC: 58.667%\n",
      "Confusion Matrix Test:\n",
      "[[34  8  9  1  0]\n",
      " [14 30 14  2  2]\n",
      " [ 1 17 33 15  0]\n",
      " [ 1  3  4 38  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### BernoulliNB - MLPClassifier #####\n",
      "Train ACC: 78.541%\n",
      "Test ACC: 68.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  6  0  0]\n",
      " [ 9 40 10  3  0]\n",
      " [ 1 13 40 12  0]\n",
      " [ 0  3  7 39  6]\n",
      " [ 1  0  3 16 45]]\n",
      "##### BernoulliNB - MultinomialNB #####\n",
      "Error (BernoulliNB-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### BernoulliNB - NearestCentroid #####\n",
      "Train ACC: 53.648%\n",
      "Test ACC: 48.000%\n",
      "Confusion Matrix Test:\n",
      "[[32  6  7  5  2]\n",
      " [20 18 20  1  3]\n",
      " [ 2 24 21 15  4]\n",
      " [ 1  3 11 27 13]\n",
      " [ 0  3  6 10 46]]\n",
      "##### BernoulliNB - NuSVC #####\n",
      "Train ACC: 77.110%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  9  2  1  0]\n",
      " [16 34 10  1  1]\n",
      " [ 2 12 39 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 16 46]]\n",
      "##### BernoulliNB - PassiveAggressiveClassifier #####\n",
      "Train ACC: 55.079%\n",
      "Test ACC: 48.667%\n",
      "Confusion Matrix Test:\n",
      "[[34  2  9  7  0]\n",
      " [15 25  8 14  0]\n",
      " [ 5 18 13 30  0]\n",
      " [ 3  0  6 38  8]\n",
      " [ 1  0  4 24 36]]\n",
      "##### BernoulliNB - Perceptron #####\n",
      "Train ACC: 43.205%\n",
      "Test ACC: 41.667%\n",
      "Confusion Matrix Test:\n",
      "[[29  6  7  7  3]\n",
      " [ 9 11 19 13 10]\n",
      " [ 4  3 11 24 24]\n",
      " [ 2  0  4 20 29]\n",
      " [ 1  0  2  8 54]]\n",
      "##### BernoulliNB - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 71.102%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  6  0  0]\n",
      " [10 39 10  3  0]\n",
      " [ 2 17 31 16  0]\n",
      " [ 0  3  4 39  9]\n",
      " [ 0  2  2 16 45]]\n",
      "##### BernoulliNB - RadiusNeighborsClassifier #####\n",
      "Error (BernoulliNB-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### BernoulliNB - RandomForestClassifier #####\n",
      "Train ACC: 98.283%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[44  5  3  0  0]\n",
      " [15 37  6  2  2]\n",
      " [ 2 19 31 14  0]\n",
      " [ 0  2  7 38  8]\n",
      " [ 0  1  3 16 45]]\n",
      "##### BernoulliNB - RidgeClassifier #####\n",
      "Train ACC: 64.235%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  5  9  1  1]\n",
      " [14 28 16  2  2]\n",
      " [ 3 15 30 17  1]\n",
      " [ 3  0  5 38  9]\n",
      " [ 0  2  5 11 47]]\n",
      "##### BernoulliNB - RidgeClassifierCV #####\n",
      "Train ACC: 63.090%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  5  9  1  1]\n",
      " [14 29 15  2  2]\n",
      " [ 2 16 31 16  1]\n",
      " [ 2  1  5 37 10]\n",
      " [ 0  2  5 10 48]]\n",
      "##### BernoulliNB - SGDClassifier #####\n",
      "Train ACC: 56.366%\n",
      "Test ACC: 53.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  3  7  1  0]\n",
      " [33  7 17  4  1]\n",
      " [ 9  7 32 17  1]\n",
      " [ 2  1  8 31 13]\n",
      " [ 2  0  6  9 48]]\n",
      "##### BernoulliNB - SVC #####\n",
      "Train ACC: 71.960%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  1  0]\n",
      " [10 39 10  1  2]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 1  0  3 20 41]]\n",
      "##### CalibratedClassifierCV - CategoricalNB #####\n",
      "Error (CalibratedClassifierCV-CategoricalNB): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CalibratedClassifierCV - ComplementNB #####\n",
      "Error (CalibratedClassifierCV-ComplementNB): Negative values in data passed to ComplementNB (input X)\n",
      "##### CalibratedClassifierCV - DecisionTreeClassifier #####\n",
      "Train ACC: 85.408%\n",
      "Test ACC: 55.333%\n",
      "Confusion Matrix Test:\n",
      "[[34 13  4  0  1]\n",
      " [18 26 13  3  2]\n",
      " [ 5 11 34 16  0]\n",
      " [ 1  4  8 29 13]\n",
      " [ 0  2  5 15 43]]\n",
      "##### CalibratedClassifierCV - DummyClassifier #####\n",
      "Train ACC: 63.233%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  7  1  1]\n",
      " [19 25 14  2  2]\n",
      " [ 2 15 38 10  1]\n",
      " [ 2  1 13 25 14]\n",
      " [ 0  1  3 13 48]]\n",
      "##### CalibratedClassifierCV - ExtraTreeClassifier #####\n",
      "Train ACC: 77.253%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  7  6  1  1]\n",
      " [19 25 14  2  2]\n",
      " [ 2 18 31 14  1]\n",
      " [ 1  2  8 31 13]\n",
      " [ 1  0  4 14 46]]\n",
      "##### CalibratedClassifierCV - ExtraTreesClassifier #####\n",
      "Train ACC: 86.838%\n",
      "Test ACC: 65.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  2  1  1]\n",
      " [ 8 40 11  1  2]\n",
      " [ 2 15 38 11  0]\n",
      " [ 0  3  8 34 10]\n",
      " [ 0  1  2 18 44]]\n",
      "##### CalibratedClassifierCV - GaussianNB #####\n",
      "Train ACC: 64.664%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  7  1  1]\n",
      " [16 29 13  2  2]\n",
      " [ 2 16 35 11  2]\n",
      " [ 2  1 10 29 13]\n",
      " [ 0  2  3 15 45]]\n",
      "##### CalibratedClassifierCV - GaussianProcessClassifier #####\n",
      "Train ACC: 70.243%\n",
      "Test ACC: 60.667%\n",
      "Confusion Matrix Test:\n",
      "[[38  6  6  1  1]\n",
      " [16 31 11  2  2]\n",
      " [ 2 14 37 12  1]\n",
      " [ 2  1  8 30 14]\n",
      " [ 0  1  4 14 46]]\n",
      "##### CalibratedClassifierCV - GradientBoostingClassifier #####\n",
      "Train ACC: 90.415%\n",
      "Test ACC: 67.667%\n",
      "Confusion Matrix Test:\n",
      "[[42  6  3  0  1]\n",
      " [ 6 43  9  2  2]\n",
      " [ 2 15 35 14  0]\n",
      " [ 0  3  6 37  9]\n",
      " [ 1  0  1 17 46]]\n",
      "##### CalibratedClassifierCV - HistGradientBoostingClassifier #####\n",
      "Train ACC: 95.422%\n",
      "Test ACC: 68.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  4  5  1  0]\n",
      " [ 7 46  7  0  2]\n",
      " [ 2 17 31 14  2]\n",
      " [ 0  3  6 38  8]\n",
      " [ 0  1  1 15 48]]\n",
      "##### CalibratedClassifierCV - KNeighborsClassifier #####\n",
      "Train ACC: 70.243%\n",
      "Test ACC: 61.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  9  1  0  2]\n",
      " [13 39  5  3  2]\n",
      " [ 2 16 29 18  1]\n",
      " [ 0  4  8 30 13]\n",
      " [ 1  0  2 16 46]]\n",
      "##### CalibratedClassifierCV - LabelPropagation #####\n",
      "Train ACC: 76.538%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[37 13  2  0  0]\n",
      " [11 39  8  2  2]\n",
      " [ 4 20 29 11  2]\n",
      " [ 1  2 11 33  8]\n",
      " [ 1  2  3 14 45]]\n",
      "##### CalibratedClassifierCV - LabelSpreading #####\n",
      "Train ACC: 76.538%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[36 14  2  0  0]\n",
      " [10 40  8  2  2]\n",
      " [ 4 20 29 11  2]\n",
      " [ 1  2 12 30 10]\n",
      " [ 1  2  3 14 45]]\n",
      "##### CalibratedClassifierCV - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 64.092%\n",
      "Test ACC: 60.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  7  7  2  0]\n",
      " [13 30 15  2  2]\n",
      " [ 2 14 35 15  0]\n",
      " [ 1  2  7 36  9]\n",
      " [ 0  2  4 14 45]]\n",
      "##### CalibratedClassifierCV - LinearSVC #####\n",
      "Train ACC: 64.664%\n",
      "Test ACC: 58.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  7  1  1]\n",
      " [13 29 16  2  2]\n",
      " [ 2 14 34 15  1]\n",
      " [ 2  1 10 32 10]\n",
      " [ 0  2  5 14 44]]\n",
      "##### CalibratedClassifierCV - LogisticRegression #####\n",
      "Train ACC: 66.381%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [13 33 12  2  2]\n",
      " [ 2 15 36 13  0]\n",
      " [ 1  3  5 37  9]\n",
      " [ 0  2  4 17 42]]\n",
      "##### CalibratedClassifierCV - LogisticRegressionCV #####\n",
      "Train ACC: 66.237%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  9  1  0]\n",
      " [14 30 14  2  2]\n",
      " [ 2 15 35 14  0]\n",
      " [ 1  3  4 38  9]\n",
      " [ 0  2  4 17 42]]\n",
      "##### CalibratedClassifierCV - MLPClassifier #####\n",
      "Train ACC: 78.398%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [12 37 10  3  0]\n",
      " [ 2 14 40 10  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 1  1  1 15 47]]\n",
      "##### CalibratedClassifierCV - MultinomialNB #####\n",
      "Error (CalibratedClassifierCV-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### CalibratedClassifierCV - NearestCentroid #####\n",
      "Train ACC: 61.660%\n",
      "Test ACC: 53.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  7  1  1]\n",
      " [20 22 16  2  2]\n",
      " [ 2 25 24 14  1]\n",
      " [ 2  2  8 31 12]\n",
      " [ 0  3  3 12 47]]\n",
      "##### CalibratedClassifierCV - NuSVC #####\n",
      "Train ACC: 76.538%\n",
      "Test ACC: 65.333%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  2  1  0]\n",
      " [14 36 10  1  1]\n",
      " [ 2 16 36 12  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 16 46]]\n",
      "##### CalibratedClassifierCV - PassiveAggressiveClassifier #####\n",
      "Train ACC: 60.658%\n",
      "Test ACC: 55.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  7  1  1]\n",
      " [17 29 12  2  2]\n",
      " [ 4 18 33 10  1]\n",
      " [ 2  2 14 23 14]\n",
      " [ 1  1  3 13 47]]\n",
      "##### CalibratedClassifierCV - Perceptron #####\n",
      "Train ACC: 52.217%\n",
      "Test ACC: 47.333%\n",
      "Confusion Matrix Test:\n",
      "[[32  8  8  3  1]\n",
      " [10 17 22  9  4]\n",
      " [ 4  6 18 30  8]\n",
      " [ 2  1  6 22 24]\n",
      " [ 1  0  3  8 53]]\n",
      "##### CalibratedClassifierCV - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 69.528%\n",
      "Test ACC: 62.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  8  6  1  0]\n",
      " [11 37 11  3  0]\n",
      " [ 2 17 33 14  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 0  1  4 17 43]]\n",
      "##### CalibratedClassifierCV - RadiusNeighborsClassifier #####\n",
      "Error (CalibratedClassifierCV-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### CalibratedClassifierCV - RandomForestClassifier #####\n",
      "Train ACC: 93.848%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[39  7  5  0  1]\n",
      " [11 38 10  1  2]\n",
      " [ 2 16 36 12  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 0  1  2 16 46]]\n",
      "##### CalibratedClassifierCV - RidgeClassifier #####\n",
      "Train ACC: 64.664%\n",
      "Test ACC: 59.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  1  1]\n",
      " [13 30 15  2  2]\n",
      " [ 2 14 35 14  1]\n",
      " [ 2  1 10 31 11]\n",
      " [ 0  2  4 14 45]]\n",
      "##### CalibratedClassifierCV - RidgeClassifierCV #####\n",
      "Train ACC: 64.521%\n",
      "Test ACC: 60.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  5  8  1  1]\n",
      " [13 31 14  2  2]\n",
      " [ 2 14 35 14  1]\n",
      " [ 2  1  8 33 11]\n",
      " [ 0  2  4 13 46]]\n",
      "##### CalibratedClassifierCV - SGDClassifier #####\n",
      "Train ACC: 60.372%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[33  8  8  3  0]\n",
      " [ 8 33 16  3  2]\n",
      " [ 2 12 37 15  0]\n",
      " [ 1  2 11 33  8]\n",
      " [ 1  1  3 23 37]]\n",
      "##### CalibratedClassifierCV - SVC #####\n",
      "Train ACC: 69.957%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [12 37 10  1  2]\n",
      " [ 2 14 35 15  0]\n",
      " [ 0  3  7 36  9]\n",
      " [ 1  0  3 19 42]]\n",
      "##### CategoricalNB - ComplementNB #####\n",
      "Error (CategoricalNB-ComplementNB): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - DecisionTreeClassifier #####\n",
      "Error (CategoricalNB-DecisionTreeClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - DummyClassifier #####\n",
      "Error (CategoricalNB-DummyClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - ExtraTreeClassifier #####\n",
      "Error (CategoricalNB-ExtraTreeClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - ExtraTreesClassifier #####\n",
      "Error (CategoricalNB-ExtraTreesClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - GaussianNB #####\n",
      "Error (CategoricalNB-GaussianNB): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - GaussianProcessClassifier #####\n",
      "Error (CategoricalNB-GaussianProcessClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - GradientBoostingClassifier #####\n",
      "Error (CategoricalNB-GradientBoostingClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - HistGradientBoostingClassifier #####\n",
      "Error (CategoricalNB-HistGradientBoostingClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - KNeighborsClassifier #####\n",
      "Error (CategoricalNB-KNeighborsClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - LabelPropagation #####\n",
      "Error (CategoricalNB-LabelPropagation): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - LabelSpreading #####\n",
      "Error (CategoricalNB-LabelSpreading): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - LinearDiscriminantAnalysis #####\n",
      "Error (CategoricalNB-LinearDiscriminantAnalysis): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - LinearSVC #####\n",
      "Error (CategoricalNB-LinearSVC): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - LogisticRegression #####\n",
      "Error (CategoricalNB-LogisticRegression): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - LogisticRegressionCV #####\n",
      "Error (CategoricalNB-LogisticRegressionCV): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - MLPClassifier #####\n",
      "Error (CategoricalNB-MLPClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - MultinomialNB #####\n",
      "Error (CategoricalNB-MultinomialNB): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - NearestCentroid #####\n",
      "Error (CategoricalNB-NearestCentroid): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - NuSVC #####\n",
      "Error (CategoricalNB-NuSVC): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - PassiveAggressiveClassifier #####\n",
      "Error (CategoricalNB-PassiveAggressiveClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - Perceptron #####\n",
      "Error (CategoricalNB-Perceptron): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - QuadraticDiscriminantAnalysis #####\n",
      "Error (CategoricalNB-QuadraticDiscriminantAnalysis): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - RadiusNeighborsClassifier #####\n",
      "Error (CategoricalNB-RadiusNeighborsClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - RandomForestClassifier #####\n",
      "Error (CategoricalNB-RandomForestClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - RidgeClassifier #####\n",
      "Error (CategoricalNB-RidgeClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - RidgeClassifierCV #####\n",
      "Error (CategoricalNB-RidgeClassifierCV): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - SGDClassifier #####\n",
      "Error (CategoricalNB-SGDClassifier): Negative values in data passed to CategoricalNB (input X)\n",
      "##### CategoricalNB - SVC #####\n",
      "Error (CategoricalNB-SVC): Negative values in data passed to CategoricalNB (input X)\n",
      "##### ComplementNB - DecisionTreeClassifier #####\n",
      "Error (ComplementNB-DecisionTreeClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - DummyClassifier #####\n",
      "Error (ComplementNB-DummyClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - ExtraTreeClassifier #####\n",
      "Error (ComplementNB-ExtraTreeClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - ExtraTreesClassifier #####\n",
      "Error (ComplementNB-ExtraTreesClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - GaussianNB #####\n",
      "Error (ComplementNB-GaussianNB): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - GaussianProcessClassifier #####\n",
      "Error (ComplementNB-GaussianProcessClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - GradientBoostingClassifier #####\n",
      "Error (ComplementNB-GradientBoostingClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - HistGradientBoostingClassifier #####\n",
      "Error (ComplementNB-HistGradientBoostingClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - KNeighborsClassifier #####\n",
      "Error (ComplementNB-KNeighborsClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - LabelPropagation #####\n",
      "Error (ComplementNB-LabelPropagation): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - LabelSpreading #####\n",
      "Error (ComplementNB-LabelSpreading): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - LinearDiscriminantAnalysis #####\n",
      "Error (ComplementNB-LinearDiscriminantAnalysis): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - LinearSVC #####\n",
      "Error (ComplementNB-LinearSVC): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - LogisticRegression #####\n",
      "Error (ComplementNB-LogisticRegression): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - LogisticRegressionCV #####\n",
      "Error (ComplementNB-LogisticRegressionCV): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - MLPClassifier #####\n",
      "Error (ComplementNB-MLPClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - MultinomialNB #####\n",
      "Error (ComplementNB-MultinomialNB): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - NearestCentroid #####\n",
      "Error (ComplementNB-NearestCentroid): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - NuSVC #####\n",
      "Error (ComplementNB-NuSVC): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - PassiveAggressiveClassifier #####\n",
      "Error (ComplementNB-PassiveAggressiveClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - Perceptron #####\n",
      "Error (ComplementNB-Perceptron): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - QuadraticDiscriminantAnalysis #####\n",
      "Error (ComplementNB-QuadraticDiscriminantAnalysis): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - RadiusNeighborsClassifier #####\n",
      "Error (ComplementNB-RadiusNeighborsClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - RandomForestClassifier #####\n",
      "Error (ComplementNB-RandomForestClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - RidgeClassifier #####\n",
      "Error (ComplementNB-RidgeClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - RidgeClassifierCV #####\n",
      "Error (ComplementNB-RidgeClassifierCV): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - SGDClassifier #####\n",
      "Error (ComplementNB-SGDClassifier): Negative values in data passed to ComplementNB (input X)\n",
      "##### ComplementNB - SVC #####\n",
      "Error (ComplementNB-SVC): Negative values in data passed to ComplementNB (input X)\n",
      "##### DecisionTreeClassifier - DummyClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 48.667%\n",
      "Confusion Matrix Test:\n",
      "[[29 13  8  1  1]\n",
      " [16 19 19  8  0]\n",
      " [ 6 12 32 14  2]\n",
      " [ 3  1 12 27 12]\n",
      " [ 0  2  7 17 39]]\n",
      "##### DecisionTreeClassifier - ExtraTreeClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 50.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  9  7  1  0]\n",
      " [17 19 18  6  2]\n",
      " [ 5 17 30 13  1]\n",
      " [ 2  2 11 29 11]\n",
      " [ 1  5  8 14 37]]\n",
      "##### DecisionTreeClassifier - ExtraTreesClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 64.667%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  3  0  0]\n",
      " [ 8 37 14  1  2]\n",
      " [ 3 12 37 12  2]\n",
      " [ 0  2 10 35  8]\n",
      " [ 0  0  6 13 46]]\n",
      "##### DecisionTreeClassifier - GaussianNB #####\n",
      "Train ACC: 84.979%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[38 10  4  0  0]\n",
      " [12 36 10  3  1]\n",
      " [ 2 18 32 13  1]\n",
      " [ 1  2 11 29 12]\n",
      " [ 0  2  7 11 45]]\n",
      "##### DecisionTreeClassifier - GaussianProcessClassifier #####\n",
      "Train ACC: 98.856%\n",
      "Test ACC: 53.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  5  6  0  1]\n",
      " [11 25 17  8  1]\n",
      " [ 4 17 28 11  6]\n",
      " [ 1  2 12 29 11]\n",
      " [ 0  2 10 15 38]]\n",
      "##### DecisionTreeClassifier - GradientBoostingClassifier #####\n",
      "Train ACC: 99.428%\n",
      "Test ACC: 65.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  7  3  0  0]\n",
      " [ 7 40 10  3  2]\n",
      " [ 3 18 33 11  1]\n",
      " [ 0  4  6 37  8]\n",
      " [ 1  0  2 18 44]]\n",
      "##### DecisionTreeClassifier - HistGradientBoostingClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 61.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  9  3  0  0]\n",
      " [ 9 35 13  4  1]\n",
      " [ 3 17 29 16  1]\n",
      " [ 0  2  6 37 10]\n",
      " [ 0  0  4 18 43]]\n",
      "##### DecisionTreeClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 86.981%\n",
      "Test ACC: 58.000%\n",
      "Confusion Matrix Test:\n",
      "[[38 11  2  1  0]\n",
      " [11 37 10  3  1]\n",
      " [ 1 23 25 15  2]\n",
      " [ 0  4 12 30  9]\n",
      " [ 0  1  7 13 44]]\n",
      "##### DecisionTreeClassifier - LabelPropagation #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 53.333%\n",
      "Confusion Matrix Test:\n",
      "[[38 13  1  0  0]\n",
      " [11 32 13  4  2]\n",
      " [ 7 19 21 15  4]\n",
      " [ 1  5 10 27 12]\n",
      " [ 2  3  6 12 42]]\n",
      "##### DecisionTreeClassifier - LabelSpreading #####\n",
      "Train ACC: 98.856%\n",
      "Test ACC: 53.667%\n",
      "Confusion Matrix Test:\n",
      "[[35 15  1  1  0]\n",
      " [10 33 16  3  0]\n",
      " [ 6 19 24 17  0]\n",
      " [ 1  6 10 29  9]\n",
      " [ 0  5 10 10 40]]\n",
      "##### DecisionTreeClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 77.110%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[34 10  7  1  0]\n",
      " [ 9 38 12  2  1]\n",
      " [ 2 16 37 11  0]\n",
      " [ 1  2  8 35  9]\n",
      " [ 0  1  4 17 43]]\n",
      "##### DecisionTreeClassifier - LinearSVC #####\n",
      "Train ACC: 79.542%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[34 12  6  0  0]\n",
      " [13 33 13  1  2]\n",
      " [ 2 15 33 16  0]\n",
      " [ 1  3  6 35 10]\n",
      " [ 0  1  5 14 45]]\n",
      "##### DecisionTreeClassifier - LogisticRegression #####\n",
      "Train ACC: 76.538%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[34 11  6  1  0]\n",
      " [12 35 11  2  2]\n",
      " [ 1 14 38 13  0]\n",
      " [ 1  2  9 33 10]\n",
      " [ 0  1  5 16 43]]\n",
      "##### DecisionTreeClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 74.678%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[33 14  4  1  0]\n",
      " [11 37 10  2  2]\n",
      " [ 1 18 34 13  0]\n",
      " [ 1  4  6 35  9]\n",
      " [ 0  1  5 17 42]]\n",
      "##### DecisionTreeClassifier - MLPClassifier #####\n",
      "Train ACC: 84.263%\n",
      "Test ACC: 70.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  3  1  0]\n",
      " [ 8 46  5  3  0]\n",
      " [ 2 14 43  7  0]\n",
      " [ 0  3  8 37  7]\n",
      " [ 1  0  3 15 46]]\n",
      "##### DecisionTreeClassifier - MultinomialNB #####\n",
      "Error (DecisionTreeClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### DecisionTreeClassifier - NearestCentroid #####\n",
      "Train ACC: 78.398%\n",
      "Test ACC: 52.000%\n",
      "Confusion Matrix Test:\n",
      "[[37  7  5  1  2]\n",
      " [15 28 16  1  2]\n",
      " [ 3 26 22 13  2]\n",
      " [ 2  3 11 28 11]\n",
      " [ 0  1 10 13 41]]\n",
      "##### DecisionTreeClassifier - NuSVC #####\n",
      "Train ACC: 84.406%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[38 11  3  0  0]\n",
      " [13 35 12  0  2]\n",
      " [ 2 13 40 11  0]\n",
      " [ 0  3  8 36  8]\n",
      " [ 1  0  1 15 48]]\n",
      "##### DecisionTreeClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 71.817%\n",
      "Test ACC: 54.000%\n",
      "Confusion Matrix Test:\n",
      "[[33 13  5  1  0]\n",
      " [16 27 11  5  3]\n",
      " [ 2 16 34 11  3]\n",
      " [ 1  3 13 24 14]\n",
      " [ 0  1  7 13 44]]\n",
      "##### DecisionTreeClassifier - Perceptron #####\n",
      "Train ACC: 66.667%\n",
      "Test ACC: 43.333%\n",
      "Confusion Matrix Test:\n",
      "[[32  6 12  0  2]\n",
      " [13  8 31  3  7]\n",
      " [ 4  6 17 13 26]\n",
      " [ 1  2  2 20 30]\n",
      " [ 0  1  2  9 53]]\n",
      "##### DecisionTreeClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 80.830%\n",
      "Test ACC: 63.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  8  5  0  0]\n",
      " [11 39  9  2  1]\n",
      " [ 2 17 33 14  0]\n",
      " [ 0  3  6 37  9]\n",
      " [ 0  1  4 18 42]]\n",
      "##### DecisionTreeClassifier - RadiusNeighborsClassifier #####\n",
      "Error (DecisionTreeClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### DecisionTreeClassifier - RandomForestClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 61.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  8  1  1  0]\n",
      " [12 35 10  3  2]\n",
      " [ 5 15 31 14  1]\n",
      " [ 0  3 10 32 10]\n",
      " [ 0  1  7 13 44]]\n",
      "##### DecisionTreeClassifier - RidgeClassifier #####\n",
      "Train ACC: 78.541%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  9  7  0  0]\n",
      " [13 34 12  1  2]\n",
      " [ 3 16 30 17  0]\n",
      " [ 1  2 10 30 12]\n",
      " [ 0  1  5 16 43]]\n",
      "##### DecisionTreeClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 80.973%\n",
      "Test ACC: 58.667%\n",
      "Confusion Matrix Test:\n",
      "[[34 11  7  0  0]\n",
      " [13 33 12  2  2]\n",
      " [ 2 17 33 14  0]\n",
      " [ 1  3  6 32 13]\n",
      " [ 0  1  6 14 44]]\n",
      "##### DecisionTreeClassifier - SGDClassifier #####\n",
      "Train ACC: 72.532%\n",
      "Test ACC: 52.000%\n",
      "Confusion Matrix Test:\n",
      "[[34  4 10  3  1]\n",
      " [12 10 32  7  1]\n",
      " [ 1  7 34 22  2]\n",
      " [ 1  1  8 32 13]\n",
      " [ 0  0  2 17 46]]\n",
      "##### DecisionTreeClassifier - SVC #####\n",
      "Train ACC: 83.119%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [ 9 40 10  1  2]\n",
      " [ 2 14 36 14  0]\n",
      " [ 0  3  5 37 10]\n",
      " [ 1  0  3 14 47]]\n",
      "##### DummyClassifier - ExtraTreeClassifier #####\n",
      "Train ACC: 60.086%\n",
      "Test ACC: 37.333%\n",
      "Confusion Matrix Test:\n",
      "[[30  7  0  5 10]\n",
      " [13 18  0 15 16]\n",
      " [ 3 18  0 17 28]\n",
      " [ 4  8  0 13 30]\n",
      " [ 4  2  0  8 51]]\n",
      "##### DummyClassifier - ExtraTreesClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 70.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  8  1  0  1]\n",
      " [ 5 44 11  0  2]\n",
      " [ 2 15 34 13  2]\n",
      " [ 0  1  6 44  4]\n",
      " [ 0  1  0 17 47]]\n",
      "##### DummyClassifier - GaussianNB #####\n",
      "Train ACC: 63.376%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  7  2  0]\n",
      " [16 30 11  4  1]\n",
      " [ 2 20 26 15  3]\n",
      " [ 1  3  4 35 12]\n",
      " [ 1  1  3 16 44]]\n",
      "##### DummyClassifier - GaussianProcessClassifier #####\n",
      "Train ACC: 82.690%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[52  0  0  0  0]\n",
      " [23 35  1  3  0]\n",
      " [ 5 16 19 25  1]\n",
      " [ 1  2  3 41  8]\n",
      " [ 2  0  1 20 42]]\n",
      "##### DummyClassifier - GradientBoostingClassifier #####\n",
      "Train ACC: 96.423%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[42  7  2  0  1]\n",
      " [ 5 42 11  2  2]\n",
      " [ 1 21 26 16  2]\n",
      " [ 0  3  5 39  8]\n",
      " [ 1  0  1 21 42]]\n",
      "##### DummyClassifier - HistGradientBoostingClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[39 11  2  0  0]\n",
      " [11 33 14  2  2]\n",
      " [ 3 20 27 14  2]\n",
      " [ 0  2  7 37  9]\n",
      " [ 0  1  2 18 44]]\n",
      "##### DummyClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 67.096%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[40 10  0  0  2]\n",
      " [14 38  6  4  0]\n",
      " [ 1 22 20 16  7]\n",
      " [ 1  5  8 24 17]\n",
      " [ 1  0  4  9 51]]\n",
      "##### DummyClassifier - LabelPropagation #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 46.333%\n",
      "Confusion Matrix Test:\n",
      "[[34 12  6  0  0]\n",
      " [ 9 24 20  8  1]\n",
      " [ 4 19 20 17  6]\n",
      " [ 1  5 16 24  9]\n",
      " [ 0  4  2 22 37]]\n",
      "##### DummyClassifier - LabelSpreading #####\n",
      "Train ACC: 91.130%\n",
      "Test ACC: 47.333%\n",
      "Confusion Matrix Test:\n",
      "[[35 13  4  0  0]\n",
      " [10 27 15  9  1]\n",
      " [ 5 18 17 20  6]\n",
      " [ 2  6 12 26  9]\n",
      " [ 1  4  1 22 37]]\n",
      "##### DummyClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 63.805%\n",
      "Test ACC: 61.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  7  7  2  0]\n",
      " [13 29 16  2  2]\n",
      " [ 2 15 35 14  0]\n",
      " [ 2  1  6 38  8]\n",
      " [ 0  2  5 12 46]]\n",
      "##### DummyClassifier - LinearSVC #####\n",
      "Train ACC: 64.378%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  2  0]\n",
      " [13 29 16  2  2]\n",
      " [ 2 15 32 16  1]\n",
      " [ 2  1 10 32 10]\n",
      " [ 0  2  5 14 44]]\n",
      "##### DummyClassifier - LogisticRegression #####\n",
      "Train ACC: 66.094%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  9  1  0]\n",
      " [12 33 13  2  2]\n",
      " [ 2 15 35 14  0]\n",
      " [ 1  3  5 37  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### DummyClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 66.094%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[34  8  9  1  0]\n",
      " [13 31 14  2  2]\n",
      " [ 1 16 35 14  0]\n",
      " [ 1  3  4 38  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### DummyClassifier - MLPClassifier #####\n",
      "Train ACC: 78.112%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  6  5  1  0]\n",
      " [ 9 38 12  3  0]\n",
      " [ 1 17 36 12  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 0  1  3 14 47]]\n",
      "##### DummyClassifier - MultinomialNB #####\n",
      "Error (DummyClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### DummyClassifier - NearestCentroid #####\n",
      "Train ACC: 52.074%\n",
      "Test ACC: 45.333%\n",
      "Confusion Matrix Test:\n",
      "[[24 13 12  1  2]\n",
      " [11 27 21  1  2]\n",
      " [ 0 29 21 12  4]\n",
      " [ 0  5 15 22 13]\n",
      " [ 0  3 10 10 42]]\n",
      "##### DummyClassifier - NuSVC #####\n",
      "Train ACC: 76.252%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [18 32 10  2  0]\n",
      " [ 2 12 40 12  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 16 46]]\n",
      "##### DummyClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 54.649%\n",
      "Test ACC: 53.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  7  4  2  0]\n",
      " [24 20 13  5  0]\n",
      " [ 7 15 37  7  0]\n",
      " [ 2  2 18 17 16]\n",
      " [ 1  1  8  9 46]]\n",
      "##### DummyClassifier - Perceptron #####\n",
      "Train ACC: 40.343%\n",
      "Test ACC: 38.667%\n",
      "Confusion Matrix Test:\n",
      "[[25  9  7  8  3]\n",
      " [ 8  9 22 11 12]\n",
      " [ 5  3 12 16 30]\n",
      " [ 2  1  2 14 36]\n",
      " [ 1  1  1  6 56]]\n",
      "##### DummyClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 70.529%\n",
      "Test ACC: 62.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  6  0  0]\n",
      " [11 39  9  3  0]\n",
      " [ 2 17 32 15  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 0  1  3 19 42]]\n",
      "##### DummyClassifier - RadiusNeighborsClassifier #####\n",
      "Error (DummyClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### DummyClassifier - RandomForestClassifier #####\n",
      "Train ACC: 98.140%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[45  5  2  0  0]\n",
      " [13 40  7  0  2]\n",
      " [ 3 18 29 15  1]\n",
      " [ 0  3  4 42  6]\n",
      " [ 0  1  2 17 45]]\n",
      "##### DummyClassifier - RidgeClassifier #####\n",
      "Train ACC: 63.948%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  1  1]\n",
      " [14 30 14  2  2]\n",
      " [ 2 16 32 15  1]\n",
      " [ 2  1  8 35  9]\n",
      " [ 1  1  5 13 45]]\n",
      "##### DummyClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 63.662%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  5  8  1  1]\n",
      " [14 30 14  2  2]\n",
      " [ 3 16 30 16  1]\n",
      " [ 3  0  7 34 11]\n",
      " [ 0  2  5 11 47]]\n",
      "##### DummyClassifier - SGDClassifier #####\n",
      "Train ACC: 47.639%\n",
      "Test ACC: 45.667%\n",
      "Confusion Matrix Test:\n",
      "[[30  1 16  2  3]\n",
      " [ 8  5 40  6  3]\n",
      " [ 4  3 27 23  9]\n",
      " [ 1  0  6 17 31]\n",
      " [ 1  0  4  2 58]]\n",
      "##### DummyClassifier - SVC #####\n",
      "Train ACC: 72.961%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  1  0]\n",
      " [ 5 44 10  2  1]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  3 21 40]]\n",
      "##### ExtraTreeClassifier - ExtraTreesClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[39  9  3  1  0]\n",
      " [ 7 40 11  2  2]\n",
      " [ 3 19 30 13  1]\n",
      " [ 0  3  5 40  7]\n",
      " [ 1  0  1 21 42]]\n",
      "##### ExtraTreeClassifier - GaussianNB #####\n",
      "Train ACC: 69.099%\n",
      "Test ACC: 54.667%\n",
      "Confusion Matrix Test:\n",
      "[[36 11  3  2  0]\n",
      " [17 28 12  3  2]\n",
      " [ 2 22 23 17  2]\n",
      " [ 2  2  5 32 14]\n",
      " [ 0  2  5 13 45]]\n",
      "##### ExtraTreeClassifier - GaussianProcessClassifier #####\n",
      "Train ACC: 88.269%\n",
      "Test ACC: 55.667%\n",
      "Confusion Matrix Test:\n",
      "[[43  6  3  0  0]\n",
      " [13 32  7  2  8]\n",
      " [ 4 19 22 16  5]\n",
      " [ 6  4  3 30 12]\n",
      " [ 1  2  4 18 40]]\n",
      "##### ExtraTreeClassifier - GradientBoostingClassifier #####\n",
      "Train ACC: 98.999%\n",
      "Test ACC: 62.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [ 7 38 11  4  2]\n",
      " [ 2 20 30 12  2]\n",
      " [ 0  3  9 35  8]\n",
      " [ 1  0  0 22 42]]\n",
      "##### ExtraTreeClassifier - HistGradientBoostingClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 59.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  9  3  1  0]\n",
      " [ 8 36 15  1  2]\n",
      " [ 2 25 22 15  2]\n",
      " [ 0  1  7 36 11]\n",
      " [ 0  1  2 18 44]]\n",
      "##### ExtraTreeClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 75.107%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[38 12  1  0  1]\n",
      " [ 9 44  6  3  0]\n",
      " [ 1 21 18 20  6]\n",
      " [ 1  2 13 21 18]\n",
      " [ 1  0  4 11 49]]\n",
      "##### ExtraTreeClassifier - LabelPropagation #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 47.667%\n",
      "Confusion Matrix Test:\n",
      "[[36 14  2  0  0]\n",
      " [11 33  6 11  1]\n",
      " [ 5 23  9 23  6]\n",
      " [ 2  7 10 27  9]\n",
      " [ 0  4  2 21 38]]\n",
      "##### ExtraTreeClassifier - LabelSpreading #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 48.000%\n",
      "Confusion Matrix Test:\n",
      "[[34 14  3  1  0]\n",
      " [14 29  8 10  1]\n",
      " [ 6 25  7 21  7]\n",
      " [ 3  8  2 31 11]\n",
      " [ 0  4  1 17 43]]\n",
      "##### ExtraTreeClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 64.521%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [12 31 15  2  2]\n",
      " [ 3 14 33 16  0]\n",
      " [ 2  1  9 36  7]\n",
      " [ 1  1  4 13 46]]\n",
      "##### ExtraTreeClassifier - LinearSVC #####\n",
      "Train ACC: 72.389%\n",
      "Test ACC: 55.333%\n",
      "Confusion Matrix Test:\n",
      "[[31  8 11  2  0]\n",
      " [19 27 11  3  2]\n",
      " [ 3 14 32 17  0]\n",
      " [ 0  4  8 34  9]\n",
      " [ 0  2  3 18 42]]\n",
      "##### ExtraTreeClassifier - LogisticRegression #####\n",
      "Train ACC: 62.518%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  8  6  2  0]\n",
      " [14 31 13  2  2]\n",
      " [ 1 22 28 15  0]\n",
      " [ 1  2  7 35 10]\n",
      " [ 1  1  3 19 41]]\n",
      "##### ExtraTreeClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 71.388%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  2  0]\n",
      " [10 33 15  2  2]\n",
      " [ 1 18 32 14  1]\n",
      " [ 1  2  6 35 11]\n",
      " [ 0  1  5 17 42]]\n",
      "##### ExtraTreeClassifier - MLPClassifier #####\n",
      "Train ACC: 80.114%\n",
      "Test ACC: 68.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  6  7  0  0]\n",
      " [ 9 42  8  3  0]\n",
      " [ 2 12 37 15  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 1  1  1 13 49]]\n",
      "##### ExtraTreeClassifier - MultinomialNB #####\n",
      "Error (ExtraTreeClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### ExtraTreeClassifier - NearestCentroid #####\n",
      "Train ACC: 60.515%\n",
      "Test ACC: 38.667%\n",
      "Confusion Matrix Test:\n",
      "[[27 10 12  3  0]\n",
      " [25 13 17  5  2]\n",
      " [18 11 16 16  5]\n",
      " [ 1  4 12 15 23]\n",
      " [ 0  3  6 11 45]]\n",
      "##### ExtraTreeClassifier - NuSVC #####\n",
      "Train ACC: 71.960%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  3  1  0]\n",
      " [16 29 15  1  1]\n",
      " [ 1 12 39 14  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 16 46]]\n",
      "##### ExtraTreeClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 54.793%\n",
      "Test ACC: 46.000%\n",
      "Confusion Matrix Test:\n",
      "[[28 20  2  1  1]\n",
      " [ 5 52  1  3  1]\n",
      " [ 5 46  8  4  3]\n",
      " [ 0 27  9  8 11]\n",
      " [ 2  6  3 12 42]]\n",
      "##### ExtraTreeClassifier - Perceptron #####\n",
      "Train ACC: 56.223%\n",
      "Test ACC: 44.333%\n",
      "Confusion Matrix Test:\n",
      "[[30  9  6  4  3]\n",
      " [ 9 14 22 10  7]\n",
      " [ 4  4 15 26 17]\n",
      " [ 2  2  2 21 28]\n",
      " [ 1  1  2  8 53]]\n",
      "##### ExtraTreeClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 75.393%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[38  7  7  0  0]\n",
      " [10 40  9  3  0]\n",
      " [ 2 17 31 16  0]\n",
      " [ 1  2  4 40  8]\n",
      " [ 1  0  3 18 43]]\n",
      "##### ExtraTreeClassifier - RadiusNeighborsClassifier #####\n",
      "Error (ExtraTreeClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### ExtraTreeClassifier - RandomForestClassifier #####\n",
      "Train ACC: 98.426%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[43  8  1  0  0]\n",
      " [11 38 10  1  2]\n",
      " [ 2 20 32 11  1]\n",
      " [ 0  2  7 37  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### ExtraTreeClassifier - RidgeClassifier #####\n",
      "Train ACC: 62.947%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  7  1  1]\n",
      " [14 29 14  3  2]\n",
      " [ 2 19 30 15  0]\n",
      " [ 3  0  8 33 11]\n",
      " [ 0  3  2 15 45]]\n",
      "##### ExtraTreeClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 64.664%\n",
      "Test ACC: 58.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  1  1]\n",
      " [13 27 19  1  2]\n",
      " [ 2 17 29 18  0]\n",
      " [ 1  2  8 35  9]\n",
      " [ 0  2  3 12 48]]\n",
      "##### ExtraTreeClassifier - SGDClassifier #####\n",
      "Train ACC: 53.362%\n",
      "Test ACC: 40.667%\n",
      "Confusion Matrix Test:\n",
      "[[13 22 12  0  5]\n",
      " [ 0 20 31  4  7]\n",
      " [ 1  7 22 15 21]\n",
      " [ 1  1  9 10 34]\n",
      " [ 0  1  2  5 57]]\n",
      "##### ExtraTreeClassifier - SVC #####\n",
      "Train ACC: 80.401%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[43  6  2  1  0]\n",
      " [ 8 41 10  1  2]\n",
      " [ 2 14 35 15  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 1  0  3 18 43]]\n",
      "##### ExtraTreesClassifier - GaussianNB #####\n",
      "Train ACC: 97.854%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  1  1  1]\n",
      " [10 41  7  2  2]\n",
      " [ 2 15 37 12  0]\n",
      " [ 0  3  5 40  7]\n",
      " [ 0  1  2 17 45]]\n",
      "##### ExtraTreesClassifier - GaussianProcessClassifier #####\n",
      "Train ACC: 99.857%\n",
      "Test ACC: 68.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  7  2  0  1]\n",
      " [ 7 41 11  1  2]\n",
      " [ 2 16 34 13  1]\n",
      " [ 0  2  6 40  7]\n",
      " [ 0  1  0 17 47]]\n",
      "##### ExtraTreesClassifier - GradientBoostingClassifier #####\n",
      "Train ACC: 98.426%\n",
      "Test ACC: 70.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  8  1  0  1]\n",
      " [ 6 43  9  2  2]\n",
      " [ 2 14 37 12  1]\n",
      " [ 0  2  6 40  7]\n",
      " [ 1  0  0 15 49]]\n",
      "##### ExtraTreesClassifier - HistGradientBoostingClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[40 10  1  1  0]\n",
      " [ 9 37 13  1  2]\n",
      " [ 2 17 31 15  1]\n",
      " [ 0  2  5 40  8]\n",
      " [ 0  1  2 15 47]]\n",
      "##### ExtraTreesClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 94.421%\n",
      "Test ACC: 68.333%\n",
      "Confusion Matrix Test:\n",
      "[[43  9  0  0  0]\n",
      " [11 43  5  2  1]\n",
      " [ 2 14 33 16  1]\n",
      " [ 0  2  7 38  8]\n",
      " [ 1  0  1 15 48]]\n",
      "##### ExtraTreesClassifier - LabelPropagation #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 62.000%\n",
      "Confusion Matrix Test:\n",
      "[[40 12  0  0  0]\n",
      " [10 38 11  2  1]\n",
      " [ 4 21 22 18  1]\n",
      " [ 0  5  3 41  6]\n",
      " [ 0  2  0 18 45]]\n",
      "##### ExtraTreesClassifier - LabelSpreading #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 64.667%\n",
      "Confusion Matrix Test:\n",
      "[[40 12  0  0  0]\n",
      " [ 6 45  8  1  2]\n",
      " [ 5 18 22 19  2]\n",
      " [ 0  3  6 40  6]\n",
      " [ 0  2  0 16 47]]\n",
      "##### ExtraTreesClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 80.544%\n",
      "Test ACC: 64.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  6  4  1  1]\n",
      " [ 6 36 16  2  2]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  8 36  8]\n",
      " [ 0  1  2 17 45]]\n",
      "##### ExtraTreesClassifier - LinearSVC #####\n",
      "Train ACC: 67.811%\n",
      "Test ACC: 63.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  8  6  0  1]\n",
      " [ 8 35 16  1  2]\n",
      " [ 2 15 37 11  1]\n",
      " [ 0  2  9 37  7]\n",
      " [ 0  1  5 15 44]]\n",
      "##### ExtraTreesClassifier - LogisticRegression #####\n",
      "Train ACC: 81.116%\n",
      "Test ACC: 64.667%\n",
      "Confusion Matrix Test:\n",
      "[[38  7  6  1  0]\n",
      " [ 7 39 12  2  2]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  6 36 10]\n",
      " [ 0  1  3 17 44]]\n",
      "##### ExtraTreesClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 73.391%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[38  7  6  1  0]\n",
      " [ 7 38 13  2  2]\n",
      " [ 2 15 35 14  0]\n",
      " [ 0  3  6 36 10]\n",
      " [ 0  1  4 18 42]]\n",
      "##### ExtraTreesClassifier - MLPClassifier #####\n",
      "Train ACC: 77.969%\n",
      "Test ACC: 69.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  6  5  0  0]\n",
      " [ 8 41 11  2  0]\n",
      " [ 2 12 40 12  0]\n",
      " [ 0  3  6 40  6]\n",
      " [ 1  0  2 15 47]]\n",
      "##### ExtraTreesClassifier - MultinomialNB #####\n",
      "Error (ExtraTreesClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### ExtraTreesClassifier - NearestCentroid #####\n",
      "Train ACC: 97.568%\n",
      "Test ACC: 62.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  2  1  1]\n",
      " [ 7 33 19  1  2]\n",
      " [ 2 21 28 14  1]\n",
      " [ 0  3  9 36  7]\n",
      " [ 0  1  3 12 49]]\n",
      "##### ExtraTreesClassifier - NuSVC #####\n",
      "Train ACC: 85.122%\n",
      "Test ACC: 68.667%\n",
      "Confusion Matrix Test:\n",
      "[[39  8  5  0  0]\n",
      " [10 40 10  1  1]\n",
      " [ 2 12 40 12  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  1 15 48]]\n",
      "##### ExtraTreesClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 90.415%\n",
      "Test ACC: 55.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  7  4  0  1]\n",
      " [16 32 10  2  2]\n",
      " [ 3 28 25  9  1]\n",
      " [ 1  7 11 27  9]\n",
      " [ 1  0  7 14 43]]\n",
      "##### ExtraTreesClassifier - Perceptron #####\n",
      "Train ACC: 86.409%\n",
      "Test ACC: 53.333%\n",
      "Confusion Matrix Test:\n",
      "[[43  4  2  3  0]\n",
      " [11 16 23 10  2]\n",
      " [ 3  6 16 39  2]\n",
      " [ 0  2  2 36 15]\n",
      " [ 0  1  2 13 49]]\n",
      "##### ExtraTreesClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 77.110%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[38  9  5  0  0]\n",
      " [ 7 42 11  1  1]\n",
      " [ 2 15 34 15  0]\n",
      " [ 0  3  4 38 10]\n",
      " [ 0  1  2 17 45]]\n",
      "##### ExtraTreesClassifier - RadiusNeighborsClassifier #####\n",
      "Error (ExtraTreesClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### ExtraTreesClassifier - RandomForestClassifier #####\n",
      "Train ACC: 99.285%\n",
      "Test ACC: 67.667%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  2  0  1]\n",
      " [ 8 45  6  1  2]\n",
      " [ 2 17 32 14  1]\n",
      " [ 0  2  5 41  7]\n",
      " [ 0  1  2 16 46]]\n",
      "##### ExtraTreesClassifier - RidgeClassifier #####\n",
      "Train ACC: 89.270%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  6  4  1  1]\n",
      " [ 8 38 13  1  2]\n",
      " [ 2 15 34 15  0]\n",
      " [ 1  2  8 37  7]\n",
      " [ 0  1  2 16 46]]\n",
      "##### ExtraTreesClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 82.690%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[38  7  5  1  1]\n",
      " [ 8 38 13  1  2]\n",
      " [ 2 16 34 14  0]\n",
      " [ 0  2  7 40  6]\n",
      " [ 0  1  2 19 43]]\n",
      "##### ExtraTreesClassifier - SGDClassifier #####\n",
      "Train ACC: 81.116%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  1  7  1]\n",
      " [ 9 32  4 15  2]\n",
      " [ 2  8 11 43  2]\n",
      " [ 1  2  0 42 10]\n",
      " [ 0  1  1 12 51]]\n",
      "##### ExtraTreesClassifier - SVC #####\n",
      "Train ACC: 84.120%\n",
      "Test ACC: 69.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  0  1]\n",
      " [ 6 44  9  1  2]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 1  0  2 13 49]]\n",
      "##### GaussianNB - GaussianProcessClassifier #####\n",
      "Train ACC: 71.245%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  4  2  0]\n",
      " [10 37 11  3  1]\n",
      " [ 2 15 31 16  2]\n",
      " [ 1  3  4 36 11]\n",
      " [ 1  0  4 14 46]]\n",
      "##### GaussianNB - GradientBoostingClassifier #####\n",
      "Train ACC: 88.984%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  1  0]\n",
      " [ 7 40 11  3  1]\n",
      " [ 2 18 33 13  0]\n",
      " [ 0  2  6 39  8]\n",
      " [ 1  0  1 19 44]]\n",
      "##### GaussianNB - HistGradientBoostingClassifier #####\n",
      "Train ACC: 94.993%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  4  0  0]\n",
      " [ 7 41 11  2  1]\n",
      " [ 2 21 28 13  2]\n",
      " [ 0  2  6 38  9]\n",
      " [ 0  1  2 16 46]]\n",
      "##### GaussianNB - KNeighborsClassifier #####\n",
      "Train ACC: 68.240%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  9  2  1  1]\n",
      " [11 41  7  2  1]\n",
      " [ 2 16 25 20  3]\n",
      " [ 0  3  8 30 14]\n",
      " [ 1  0  3 18 43]]\n",
      "##### GaussianNB - LabelPropagation #####\n",
      "Train ACC: 76.967%\n",
      "Test ACC: 56.333%\n",
      "Confusion Matrix Test:\n",
      "[[37 12  3  0  0]\n",
      " [11 37  9  4  1]\n",
      " [ 4 23 20 17  2]\n",
      " [ 0  2 10 33 10]\n",
      " [ 1  1  4 17 42]]\n",
      "##### GaussianNB - LabelSpreading #####\n",
      "Train ACC: 76.681%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[37 13  1  1  0]\n",
      " [11 37 10  3  1]\n",
      " [ 4 21 20 19  2]\n",
      " [ 0  3  9 34  9]\n",
      " [ 1  1  5 15 43]]\n",
      "##### GaussianNB - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 65.236%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[34  9  7  2  0]\n",
      " [12 31 15  2  2]\n",
      " [ 2 14 36 14  0]\n",
      " [ 1  2  6 38  8]\n",
      " [ 0  2  4 15 44]]\n",
      "##### GaussianNB - LinearSVC #####\n",
      "Train ACC: 64.807%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [14 28 16  2  2]\n",
      " [ 2 14 33 16  1]\n",
      " [ 1  2 10 33  9]\n",
      " [ 1  1  5 15 43]]\n",
      "##### GaussianNB - LogisticRegression #####\n",
      "Train ACC: 66.524%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[34  9  7  2  0]\n",
      " [12 32 14  2  2]\n",
      " [ 2 16 34 14  0]\n",
      " [ 1  3  4 38  9]\n",
      " [ 0  2  4 19 40]]\n",
      "##### GaussianNB - LogisticRegressionCV #####\n",
      "Train ACC: 66.524%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[34  9  8  1  0]\n",
      " [12 32 14  2  2]\n",
      " [ 2 16 34 14  0]\n",
      " [ 1  2  5 38  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### GaussianNB - MLPClassifier #####\n",
      "Train ACC: 78.684%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  6  6  0  0]\n",
      " [10 39 10  3  0]\n",
      " [ 2 15 38 11  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 0  2  2 16 45]]\n",
      "##### GaussianNB - MultinomialNB #####\n",
      "Error (GaussianNB-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### GaussianNB - NearestCentroid #####\n",
      "Train ACC: 61.230%\n",
      "Test ACC: 52.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  7  1  1]\n",
      " [11 30 16  3  2]\n",
      " [ 3 27 19 14  3]\n",
      " [ 1  3  8 30 13]\n",
      " [ 1  3  3 14 44]]\n",
      "##### GaussianNB - NuSVC #####\n",
      "Train ACC: 76.824%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  2  1  0]\n",
      " [12 37 11  2  0]\n",
      " [ 2 13 39 12  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 1  0  2 15 47]]\n",
      "##### GaussianNB - PassiveAggressiveClassifier #####\n",
      "Train ACC: 48.784%\n",
      "Test ACC: 44.333%\n",
      "Confusion Matrix Test:\n",
      "[[25 13  8  5  1]\n",
      " [ 6 18 21 14  3]\n",
      " [ 5  3 15 26 17]\n",
      " [ 1  2  2 22 28]\n",
      " [ 1  0  2  9 53]]\n",
      "##### GaussianNB - Perceptron #####\n",
      "Train ACC: 51.788%\n",
      "Test ACC: 43.667%\n",
      "Confusion Matrix Test:\n",
      "[[31  7  7  6  1]\n",
      " [ 6 14 20 19  3]\n",
      " [ 4  5 10 39  8]\n",
      " [ 2  1  3 27 22]\n",
      " [ 1  0  2 13 49]]\n",
      "##### GaussianNB - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 70.243%\n",
      "Test ACC: 62.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  9  7  0  0]\n",
      " [ 9 38 12  3  0]\n",
      " [ 2 18 29 17  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 0  1  3 16 45]]\n",
      "##### GaussianNB - RadiusNeighborsClassifier #####\n",
      "Error (GaussianNB-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### GaussianNB - RandomForestClassifier #####\n",
      "Train ACC: 90.701%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  6  5  1  0]\n",
      " [ 8 45  6  1  2]\n",
      " [ 3 16 32 13  2]\n",
      " [ 0  2  7 38  8]\n",
      " [ 0  1  5 13 46]]\n",
      "##### GaussianNB - RidgeClassifier #####\n",
      "Train ACC: 65.236%\n",
      "Test ACC: 59.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  6  9  2  0]\n",
      " [14 30 14  2  2]\n",
      " [ 2 15 34 14  1]\n",
      " [ 1  2  9 33 10]\n",
      " [ 1  1  5 13 45]]\n",
      "##### GaussianNB - RidgeClassifierCV #####\n",
      "Train ACC: 64.664%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  6  9  2  0]\n",
      " [14 30 14  2  2]\n",
      " [ 2 15 32 16  1]\n",
      " [ 1  3  6 35 10]\n",
      " [ 1  1  5 12 46]]\n",
      "##### GaussianNB - SGDClassifier #####\n",
      "Train ACC: 60.658%\n",
      "Test ACC: 54.333%\n",
      "Confusion Matrix Test:\n",
      "[[29  9 10  4  0]\n",
      " [ 4 32 17  7  2]\n",
      " [ 1 11 26 27  1]\n",
      " [ 0  2  8 32 13]\n",
      " [ 0  2  1 18 44]]\n",
      "##### GaussianNB - SVC #####\n",
      "Train ACC: 70.815%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [ 7 42 10  2  1]\n",
      " [ 2 14 36 14  0]\n",
      " [ 0  3  7 36  9]\n",
      " [ 1  0  3 17 44]]\n",
      "##### GaussianProcessClassifier - GradientBoostingClassifier #####\n",
      "Train ACC: 95.994%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  0  1]\n",
      " [ 6 41 11  3  1]\n",
      " [ 1 18 32 13  2]\n",
      " [ 0  2  5 41  7]\n",
      " [ 1  0  1 19 44]]\n",
      "##### GaussianProcessClassifier - HistGradientBoostingClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  9  2  0  0]\n",
      " [10 36 12  2  2]\n",
      " [ 3 17 30 14  2]\n",
      " [ 0  2  6 39  8]\n",
      " [ 0  1  2 17 45]]\n",
      "##### GaussianProcessClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 71.102%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[41 10  0  0  1]\n",
      " [12 40  7  3  0]\n",
      " [ 1 16 26 16  7]\n",
      " [ 1  3  9 31 11]\n",
      " [ 1  0  4  9 51]]\n",
      "##### GaussianProcessClassifier - LabelPropagation #####\n",
      "Train ACC: 92.418%\n",
      "Test ACC: 55.667%\n",
      "Confusion Matrix Test:\n",
      "[[37 15  0  0  0]\n",
      " [ 9 40  7  5  1]\n",
      " [ 4 21 14 21  6]\n",
      " [ 1  4  5 37  8]\n",
      " [ 1  3  1 21 39]]\n",
      "##### GaussianProcessClassifier - LabelSpreading #####\n",
      "Train ACC: 89.986%\n",
      "Test ACC: 56.000%\n",
      "Confusion Matrix Test:\n",
      "[[39 13  0  0  0]\n",
      " [ 9 39  8  5  1]\n",
      " [ 4 21 14 21  6]\n",
      " [ 1  4  5 37  8]\n",
      " [ 2  2  2 20 39]]\n",
      "##### GaussianProcessClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 66.381%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  7  7  2  0]\n",
      " [12 32 14  2  2]\n",
      " [ 2 15 36 13  0]\n",
      " [ 1  2  6 39  7]\n",
      " [ 1  1  5 12 46]]\n",
      "##### GaussianProcessClassifier - LinearSVC #####\n",
      "Train ACC: 67.811%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  7  7  2  0]\n",
      " [12 31 15  2  2]\n",
      " [ 2 15 32 16  1]\n",
      " [ 2  1  8 36  8]\n",
      " [ 1  1  5 14 44]]\n",
      "##### GaussianProcessClassifier - LogisticRegression #####\n",
      "Train ACC: 67.525%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  8  1  0]\n",
      " [11 35 12  2  2]\n",
      " [ 1 15 37 13  0]\n",
      " [ 1  3  5 37  9]\n",
      " [ 0  2  4 16 43]]\n",
      "##### GaussianProcessClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 67.382%\n",
      "Test ACC: 61.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  8  1  0]\n",
      " [11 34 13  2  2]\n",
      " [ 1 16 36 13  0]\n",
      " [ 1  3  4 38  9]\n",
      " [ 0  2  4 17 42]]\n",
      "##### GaussianProcessClassifier - MLPClassifier #####\n",
      "Train ACC: 78.112%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  4  6  1  0]\n",
      " [10 37 12  3  0]\n",
      " [ 2 13 38 13  0]\n",
      " [ 0  4  6 36  9]\n",
      " [ 1  0  2 15 47]]\n",
      "##### GaussianProcessClassifier - MultinomialNB #####\n",
      "Error (GaussianProcessClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### GaussianProcessClassifier - NearestCentroid #####\n",
      "Train ACC: 65.236%\n",
      "Test ACC: 51.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  1 11  1  2]\n",
      " [13 25 21  1  2]\n",
      " [ 3 26 21 12  4]\n",
      " [ 1  4 10 27 13]\n",
      " [ 2  1  5 12 45]]\n",
      "##### GaussianProcessClassifier - NuSVC #####\n",
      "Train ACC: 78.112%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [18 32 10  2  0]\n",
      " [ 2 12 39 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 16 46]]\n",
      "##### GaussianProcessClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 61.373%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[42  1  8  0  1]\n",
      " [26 17 17  0  2]\n",
      " [ 6  6 41  7  6]\n",
      " [ 3  0  9 17 26]\n",
      " [ 0  1  4  7 53]]\n",
      "##### GaussianProcessClassifier - Perceptron #####\n",
      "Train ACC: 46.495%\n",
      "Test ACC: 40.000%\n",
      "Confusion Matrix Test:\n",
      "[[24 10  8  7  3]\n",
      " [ 7 14 18 14  9]\n",
      " [ 6  3  9 25 23]\n",
      " [ 2  1  2 18 32]\n",
      " [ 1  1  1  7 55]]\n",
      "##### GaussianProcessClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 72.675%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  6  0  0]\n",
      " [ 9 41  9  3  0]\n",
      " [ 2 17 33 14  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 0  1  3 18 43]]\n",
      "##### GaussianProcessClassifier - RadiusNeighborsClassifier #####\n",
      "Error (GaussianProcessClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### GaussianProcessClassifier - RandomForestClassifier #####\n",
      "Train ACC: 99.571%\n",
      "Test ACC: 69.000%\n",
      "Confusion Matrix Test:\n",
      "[[43  6  2  0  1]\n",
      " [16 38  5  2  1]\n",
      " [ 2 15 38 10  1]\n",
      " [ 1  2  3 42  7]\n",
      " [ 0  1  3 15 46]]\n",
      "##### GaussianProcessClassifier - RidgeClassifier #####\n",
      "Train ACC: 68.383%\n",
      "Test ACC: 61.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  7  6  1  1]\n",
      " [13 31 14  2  2]\n",
      " [ 2 16 33 14  1]\n",
      " [ 2  1  7 38  7]\n",
      " [ 1  1  5 12 46]]\n",
      "##### GaussianProcessClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 67.525%\n",
      "Test ACC: 61.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  7  6  1  1]\n",
      " [12 33 14  1  2]\n",
      " [ 3 15 33 14  1]\n",
      " [ 2  1  8 36  8]\n",
      " [ 1  1  5 12 46]]\n",
      "##### GaussianProcessClassifier - SGDClassifier #####\n",
      "Train ACC: 59.371%\n",
      "Test ACC: 46.667%\n",
      "Confusion Matrix Test:\n",
      "[[35 11  4  2  0]\n",
      " [14 36  6  6  0]\n",
      " [ 8 26 15 17  0]\n",
      " [ 1  6 13 33  2]\n",
      " [ 2  3  2 37 21]]\n",
      "##### GaussianProcessClassifier - SVC #####\n",
      "Train ACC: 75.393%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  1  0]\n",
      " [ 6 43 10  2  1]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  3 20 41]]\n",
      "##### GradientBoostingClassifier - HistGradientBoostingClassifier #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  8  2  0  0]\n",
      " [ 7 39 13  1  2]\n",
      " [ 1 21 29 13  2]\n",
      " [ 0  3  3 41  8]\n",
      " [ 1  0  1 19 44]]\n",
      "##### GradientBoostingClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 89.843%\n",
      "Test ACC: 68.667%\n",
      "Confusion Matrix Test:\n",
      "[[42  8  2  0  0]\n",
      " [ 6 48  3  4  1]\n",
      " [ 1 19 30 15  1]\n",
      " [ 0  2  5 39  9]\n",
      " [ 1  0  1 16 47]]\n",
      "##### GradientBoostingClassifier - LabelPropagation #####\n",
      "Train ACC: 95.279%\n",
      "Test ACC: 62.667%\n",
      "Confusion Matrix Test:\n",
      "[[40 12  0  0  0]\n",
      " [ 8 40 10  3  1]\n",
      " [ 1 25 23 16  1]\n",
      " [ 0  2  5 41  7]\n",
      " [ 1  0  0 20 44]]\n",
      "##### GradientBoostingClassifier - LabelSpreading #####\n",
      "Train ACC: 96.280%\n",
      "Test ACC: 63.333%\n",
      "Confusion Matrix Test:\n",
      "[[40 12  0  0  0]\n",
      " [ 8 41  9  3  1]\n",
      " [ 1 24 25 15  1]\n",
      " [ 0  2  6 40  7]\n",
      " [ 1  0  0 20 44]]\n",
      "##### GradientBoostingClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 83.548%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  4  5  1  0]\n",
      " [ 6 40 12  2  2]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  6 37  9]\n",
      " [ 1  0  3 16 45]]\n",
      "##### GradientBoostingClassifier - LinearSVC #####\n",
      "Train ACC: 83.548%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  4  5  0  1]\n",
      " [ 7 39 13  1  2]\n",
      " [ 2 14 35 15  0]\n",
      " [ 0  3  6 36 10]\n",
      " [ 1  0  3 15 46]]\n",
      "##### GradientBoostingClassifier - LogisticRegression #####\n",
      "Train ACC: 82.260%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [ 6 39 13  2  2]\n",
      " [ 1 17 35 13  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 1  0  3 15 46]]\n",
      "##### GradientBoostingClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 82.260%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  4  5  1  0]\n",
      " [ 6 39 13  2  2]\n",
      " [ 1 16 36 13  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 1  0  3 15 46]]\n",
      "##### GradientBoostingClassifier - MLPClassifier #####\n",
      "Train ACC: 85.265%\n",
      "Test ACC: 72.000%\n",
      "Confusion Matrix Test:\n",
      "[[43  4  5  0  0]\n",
      " [ 6 41 12  3  0]\n",
      " [ 1 14 41 10  0]\n",
      " [ 0  3  4 42  6]\n",
      " [ 1  0  3 12 49]]\n",
      "##### GradientBoostingClassifier - MultinomialNB #####\n",
      "Error (GradientBoostingClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### GradientBoostingClassifier - NearestCentroid #####\n",
      "Train ACC: 90.987%\n",
      "Test ACC: 65.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  7  3  1  1]\n",
      " [ 5 42 11  2  2]\n",
      " [ 1 21 30 12  2]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  1 18 45]]\n",
      "##### GradientBoostingClassifier - NuSVC #####\n",
      "Train ACC: 85.551%\n",
      "Test ACC: 71.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  4  5  1  0]\n",
      " [ 8 42 10  0  2]\n",
      " [ 1 14 42  9  0]\n",
      " [ 0  3  4 39  9]\n",
      " [ 1  0  2 14 48]]\n",
      "##### GradientBoostingClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 90.987%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  1  0]\n",
      " [ 6 39 14  1  2]\n",
      " [ 2 19 32 11  2]\n",
      " [ 0  2 11 33  9]\n",
      " [ 1  0  2 16 46]]\n",
      "##### GradientBoostingClassifier - Perceptron #####\n",
      "Train ACC: 75.393%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  6  5  1  1]\n",
      " [ 9 19 28  4  2]\n",
      " [ 3  5 30 22  6]\n",
      " [ 1  1  2 36 15]\n",
      " [ 1  0  0 16 48]]\n",
      "##### GradientBoostingClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 84.549%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  8  5  0  0]\n",
      " [ 5 45  9  2  1]\n",
      " [ 2 18 34 12  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 1  0  3 16 45]]\n",
      "##### GradientBoostingClassifier - RadiusNeighborsClassifier #####\n",
      "Error (GradientBoostingClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### GradientBoostingClassifier - RandomForestClassifier #####\n",
      "Train ACC: 99.428%\n",
      "Test ACC: 69.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  7  2  0  1]\n",
      " [ 7 45  6  2  2]\n",
      " [ 1 16 35 12  2]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  1 16 47]]\n",
      "##### GradientBoostingClassifier - RidgeClassifier #####\n",
      "Train ACC: 85.122%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[42  4  5  0  1]\n",
      " [ 6 43  9  2  2]\n",
      " [ 2 16 32 16  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 1  0  3 16 45]]\n",
      "##### GradientBoostingClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 85.122%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[42  4  5  0  1]\n",
      " [ 6 43  9  2  2]\n",
      " [ 2 16 33 15  0]\n",
      " [ 0  3  5 37 10]\n",
      " [ 1  0  3 16 45]]\n",
      "##### GradientBoostingClassifier - SGDClassifier #####\n",
      "Train ACC: 83.262%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[43  6  3  0  0]\n",
      " [ 9 34 16  2  1]\n",
      " [ 2 10 50  3  1]\n",
      " [ 0  3 15 33  4]\n",
      " [ 1  0  7 25 32]]\n",
      "##### GradientBoostingClassifier - SVC #####\n",
      "Train ACC: 82.976%\n",
      "Test ACC: 68.667%\n",
      "Confusion Matrix Test:\n",
      "[[45  4  2  1  0]\n",
      " [ 7 42 10  1  2]\n",
      " [ 2 14 36 14  0]\n",
      " [ 0  3  5 37 10]\n",
      " [ 1  0  3 15 46]]\n",
      "##### HistGradientBoostingClassifier - KNeighborsClassifier #####\n",
      "Train ACC: 94.564%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  9  1  0  0]\n",
      " [10 39 10  2  1]\n",
      " [ 1 24 26 12  3]\n",
      " [ 0  2  6 39  8]\n",
      " [ 0  1  2 13 49]]\n",
      "##### HistGradientBoostingClassifier - LabelPropagation #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[38 13  1  0  0]\n",
      " [ 9 36 15  1  1]\n",
      " [ 3 20 27 15  1]\n",
      " [ 0  3  4 41  7]\n",
      " [ 0  1  2 15 47]]\n",
      "##### HistGradientBoostingClassifier - LabelSpreading #####\n",
      "Train ACC: 100.000%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[38 13  1  0  0]\n",
      " [ 9 38 13  1  1]\n",
      " [ 3 19 29 14  1]\n",
      " [ 0  2  4 40  9]\n",
      " [ 0  1  2 15 47]]\n",
      "##### HistGradientBoostingClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 85.694%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  6  5  1  0]\n",
      " [ 7 40 13  0  2]\n",
      " [ 2 15 36 13  0]\n",
      " [ 0  3  7 38  7]\n",
      " [ 0  1  1 17 46]]\n",
      "##### HistGradientBoostingClassifier - LinearSVC #####\n",
      "Train ACC: 85.837%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  7  6  0  0]\n",
      " [ 7 40 13  0  2]\n",
      " [ 2 15 35 14  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 0  1  1 16 47]]\n",
      "##### HistGradientBoostingClassifier - LogisticRegression #####\n",
      "Train ACC: 84.549%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [ 7 41 12  0  2]\n",
      " [ 2 13 36 15  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 0  1  1 18 45]]\n",
      "##### HistGradientBoostingClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 83.691%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [ 7 41 12  0  2]\n",
      " [ 2 13 36 15  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 0  1  1 18 45]]\n",
      "##### HistGradientBoostingClassifier - MLPClassifier #####\n",
      "Train ACC: 85.551%\n",
      "Test ACC: 69.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  3  0  0]\n",
      " [ 8 45  6  3  0]\n",
      " [ 2 16 36 12  0]\n",
      " [ 0  3  7 39  6]\n",
      " [ 1  0  2 16 46]]\n",
      "##### HistGradientBoostingClassifier - MultinomialNB #####\n",
      "Error (HistGradientBoostingClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### HistGradientBoostingClassifier - NearestCentroid #####\n",
      "Train ACC: 92.561%\n",
      "Test ACC: 61.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  8  3  2  0]\n",
      " [10 36 12  2  2]\n",
      " [ 3 22 26 13  2]\n",
      " [ 0  2  5 38 10]\n",
      " [ 0  0  3 17 45]]\n",
      "##### HistGradientBoostingClassifier - NuSVC #####\n",
      "Train ACC: 87.268%\n",
      "Test ACC: 70.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  9  2  1  0]\n",
      " [10 40 10  1  1]\n",
      " [ 2 12 42 10  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 0  1  1 12 51]]\n",
      "##### HistGradientBoostingClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 78.255%\n",
      "Test ACC: 60.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  4  0  0]\n",
      " [11 39 10  2  0]\n",
      " [ 2 30 30  4  0]\n",
      " [ 0  4 14 29  8]\n",
      " [ 0  2  5 14 44]]\n",
      "##### HistGradientBoostingClassifier - Perceptron #####\n",
      "Train ACC: 77.110%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  4  4  1  1]\n",
      " [14 16 26  2  4]\n",
      " [ 3  5 29 25  4]\n",
      " [ 0  3  1 36 15]\n",
      " [ 0  1  0 15 49]]\n",
      "##### HistGradientBoostingClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 83.977%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  8  5  0  0]\n",
      " [ 8 42 10  0  2]\n",
      " [ 2 16 30 17  1]\n",
      " [ 0  3  3 41  8]\n",
      " [ 0  1  1 17 46]]\n",
      "##### HistGradientBoostingClassifier - RadiusNeighborsClassifier #####\n",
      "Error (HistGradientBoostingClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### HistGradientBoostingClassifier - RandomForestClassifier #####\n",
      "Train ACC: 98.999%\n",
      "Test ACC: 68.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  9  2  0  0]\n",
      " [ 9 43  7  1  2]\n",
      " [ 3 18 33 11  1]\n",
      " [ 0  3  2 41  9]\n",
      " [ 0  1  2 15 47]]\n",
      "##### HistGradientBoostingClassifier - RidgeClassifier #####\n",
      "Train ACC: 88.412%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  7  6  0  0]\n",
      " [ 7 42 11  0  2]\n",
      " [ 2 18 31 14  1]\n",
      " [ 0  2  6 39  8]\n",
      " [ 0  1  1 16 47]]\n",
      "##### HistGradientBoostingClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 88.269%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  6  6  0  0]\n",
      " [ 7 42 11  0  2]\n",
      " [ 2 18 32 13  1]\n",
      " [ 0  2  5 40  8]\n",
      " [ 0  1  1 16 47]]\n",
      "##### HistGradientBoostingClassifier - SGDClassifier #####\n",
      "Train ACC: 84.406%\n",
      "Test ACC: 61.667%\n",
      "Confusion Matrix Test:\n",
      "[[34 11  4  0  3]\n",
      " [ 4 36 18  2  2]\n",
      " [ 1 13 29 19  4]\n",
      " [ 0  2  4 34 15]\n",
      " [ 0  1  1 11 52]]\n",
      "##### HistGradientBoostingClassifier - SVC #####\n",
      "Train ACC: 82.690%\n",
      "Test ACC: 69.000%\n",
      "Confusion Matrix Test:\n",
      "[[43  6  2  1  0]\n",
      " [ 6 44  9  1  2]\n",
      " [ 2 14 34 16  0]\n",
      " [ 0  3  5 37 10]\n",
      " [ 1  0  1 14 49]]\n",
      "##### KNeighborsClassifier - LabelPropagation #####\n",
      "Train ACC: 70.386%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[38 14  0  0  0]\n",
      " [12 35 12  3  0]\n",
      " [ 3 20 21 17  5]\n",
      " [ 0  6  8 28 13]\n",
      " [ 1  1  5  8 50]]\n",
      "##### KNeighborsClassifier - LabelSpreading #####\n",
      "Train ACC: 71.674%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[38 14  0  0  0]\n",
      " [12 35 12  3  0]\n",
      " [ 1 21 19 20  5]\n",
      " [ 1  5  7 29 13]\n",
      " [ 1  1  5  8 50]]\n",
      "##### KNeighborsClassifier - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 68.526%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[37  8  5  2  0]\n",
      " [ 7 40 12  1  2]\n",
      " [ 2 16 33 15  0]\n",
      " [ 0  4  6 35 10]\n",
      " [ 1  0  4 16 44]]\n",
      "##### KNeighborsClassifier - LinearSVC #####\n",
      "Train ACC: 69.957%\n",
      "Test ACC: 61.333%\n",
      "Confusion Matrix Test:\n",
      "[[38  8  4  2  0]\n",
      " [11 37 10  2  2]\n",
      " [ 2 16 31 17  0]\n",
      " [ 0  4  6 33 12]\n",
      " [ 1  0  5 14 45]]\n",
      "##### KNeighborsClassifier - LogisticRegression #####\n",
      "Train ACC: 68.670%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  5  1  0]\n",
      " [ 8 41  9  2  2]\n",
      " [ 2 15 34 15  0]\n",
      " [ 0  4  6 34 11]\n",
      " [ 1  0  3 18 43]]\n",
      "##### KNeighborsClassifier - LogisticRegressionCV #####\n",
      "Train ACC: 69.528%\n",
      "Test ACC: 63.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  5  1  0]\n",
      " [ 7 40 11  2  2]\n",
      " [ 2 15 34 15  0]\n",
      " [ 0  4  5 36 10]\n",
      " [ 1  0  4 17 43]]\n",
      "##### KNeighborsClassifier - MLPClassifier #####\n",
      "Train ACC: 76.109%\n",
      "Test ACC: 69.333%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  4  0  0]\n",
      " [ 5 46  8  3  0]\n",
      " [ 2 13 38 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 17 45]]\n",
      "##### KNeighborsClassifier - MultinomialNB #####\n",
      "Error (KNeighborsClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### KNeighborsClassifier - NearestCentroid #####\n",
      "Train ACC: 66.381%\n",
      "Test ACC: 55.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  7  3  0  2]\n",
      " [13 30 14  4  1]\n",
      " [ 1 21 23 18  3]\n",
      " [ 1  1 11 27 15]\n",
      " [ 1  0  3 16 45]]\n",
      "##### KNeighborsClassifier - NuSVC #####\n",
      "Train ACC: 77.969%\n",
      "Test ACC: 68.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  7  3  1  0]\n",
      " [11 38 11  2  0]\n",
      " [ 1 13 40 12  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 14 48]]\n",
      "##### KNeighborsClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 66.094%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[32  9  5  6  0]\n",
      " [ 8 34 13  5  2]\n",
      " [ 2 13 28 22  1]\n",
      " [ 0  4  4 31 16]\n",
      " [ 1  0  3 14 47]]\n",
      "##### KNeighborsClassifier - Perceptron #####\n",
      "Train ACC: 56.938%\n",
      "Test ACC: 51.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  3  4  3]\n",
      " [11 17 23  8  3]\n",
      " [ 2  5 22 27 10]\n",
      " [ 0  2  2 28 23]\n",
      " [ 1  0  1 13 50]]\n",
      "##### KNeighborsClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 72.246%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[38  9  5  0  0]\n",
      " [10 43  6  3  0]\n",
      " [ 2 16 30 18  0]\n",
      " [ 0  4  5 37  9]\n",
      " [ 1  0  3 16 45]]\n",
      "##### KNeighborsClassifier - RadiusNeighborsClassifier #####\n",
      "Error (KNeighborsClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### KNeighborsClassifier - RandomForestClassifier #####\n",
      "Train ACC: 95.136%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  9  1  0  0]\n",
      " [10 45  4  2  1]\n",
      " [ 2 18 31 13  2]\n",
      " [ 0  2  5 40  8]\n",
      " [ 1  0  3 17 44]]\n",
      "##### KNeighborsClassifier - RidgeClassifier #####\n",
      "Train ACC: 70.100%\n",
      "Test ACC: 60.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  2  1  1]\n",
      " [12 37  9  2  2]\n",
      " [ 2 17 29 18  0]\n",
      " [ 0  4  7 32 12]\n",
      " [ 1  0  4 16 44]]\n",
      "##### KNeighborsClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 69.385%\n",
      "Test ACC: 60.667%\n",
      "Confusion Matrix Test:\n",
      "[[39  8  3  0  2]\n",
      " [12 38  8  2  2]\n",
      " [ 2 18 26 20  0]\n",
      " [ 0  4  5 34 12]\n",
      " [ 1  0  4 15 45]]\n",
      "##### KNeighborsClassifier - SGDClassifier #####\n",
      "Train ACC: 66.667%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[34  9  6  2  1]\n",
      " [ 5 27 26  2  2]\n",
      " [ 1  4 40 21  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 1  0  5 14 45]]\n",
      "##### KNeighborsClassifier - SVC #####\n",
      "Train ACC: 72.818%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [ 9 41  9  2  1]\n",
      " [ 2 15 33 16  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 1  0  3 17 44]]\n",
      "##### LabelPropagation - LabelSpreading #####\n",
      "Train ACC: 93.419%\n",
      "Test ACC: 47.333%\n",
      "Confusion Matrix Test:\n",
      "[[34 14  4  0  0]\n",
      " [ 9 27 15 10  1]\n",
      " [ 4 19 17 20  6]\n",
      " [ 1  5 13 27  9]\n",
      " [ 0  5  1 22 37]]\n",
      "##### LabelPropagation - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 72.246%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[34 12  5  1  0]\n",
      " [ 8 38 12  2  2]\n",
      " [ 4 17 31 14  0]\n",
      " [ 0  3  8 36  8]\n",
      " [ 0  1  5 15 44]]\n",
      "##### LabelPropagation - LinearSVC #####\n",
      "Train ACC: 74.392%\n",
      "Test ACC: 58.000%\n",
      "Confusion Matrix Test:\n",
      "[[31 15  4  2  0]\n",
      " [ 9 37 11  3  2]\n",
      " [ 4 17 28 17  0]\n",
      " [ 2  1  9 34  9]\n",
      " [ 0  1  6 14 44]]\n",
      "##### LabelPropagation - LogisticRegression #####\n",
      "Train ACC: 73.104%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[32 13  6  1  0]\n",
      " [ 8 38 12  2  2]\n",
      " [ 2 17 32 15  0]\n",
      " [ 0  3  8 34 10]\n",
      " [ 0  1  6 15 43]]\n",
      "##### LabelPropagation - LogisticRegressionCV #####\n",
      "Train ACC: 72.532%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[32 13  6  1  0]\n",
      " [ 8 38 12  2  2]\n",
      " [ 2 18 31 15  0]\n",
      " [ 0  3  7 35 10]\n",
      " [ 0  1  6 16 42]]\n",
      "##### LabelPropagation - MLPClassifier #####\n",
      "Train ACC: 79.828%\n",
      "Test ACC: 69.000%\n",
      "Confusion Matrix Test:\n",
      "[[37 11  4  0  0]\n",
      " [ 7 42 10  3  0]\n",
      " [ 2 14 38 12  0]\n",
      " [ 0  3  4 43  5]\n",
      " [ 1  1  2 14 47]]\n",
      "##### LabelPropagation - MultinomialNB #####\n",
      "Error (LabelPropagation-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### LabelPropagation - NearestCentroid #####\n",
      "Train ACC: 79.256%\n",
      "Test ACC: 52.333%\n",
      "Confusion Matrix Test:\n",
      "[[36 10  3  3  0]\n",
      " [11 33 13  4  1]\n",
      " [ 4 25 15 16  6]\n",
      " [ 0  5  9 27 14]\n",
      " [ 0  2  4 13 46]]\n",
      "##### LabelPropagation - NuSVC #####\n",
      "Train ACC: 77.969%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[38  9  5  0  0]\n",
      " [14 35 11  1  1]\n",
      " [ 2 12 40 12  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  1 17 46]]\n",
      "##### LabelPropagation - PassiveAggressiveClassifier #####\n",
      "Train ACC: 56.938%\n",
      "Test ACC: 47.000%\n",
      "Confusion Matrix Test:\n",
      "[[32  4 12  2  2]\n",
      " [ 8 12 28 10  4]\n",
      " [ 2  9 16 29 10]\n",
      " [ 1  2  3 24 25]\n",
      " [ 0  1  1  6 57]]\n",
      "##### LabelPropagation - Perceptron #####\n",
      "Train ACC: 57.368%\n",
      "Test ACC: 44.000%\n",
      "Confusion Matrix Test:\n",
      "[[33  8  4  5  2]\n",
      " [ 9 11 27 10  5]\n",
      " [ 7  3  9 29 18]\n",
      " [ 1  0  3 27 24]\n",
      " [ 1  0  2 10 52]]\n",
      "##### LabelPropagation - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 74.249%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[34 15  3  0  0]\n",
      " [ 9 41  9  3  0]\n",
      " [ 2 17 31 16  0]\n",
      " [ 0  4  4 38  9]\n",
      " [ 0  2  2 18 43]]\n",
      "##### LabelPropagation - RadiusNeighborsClassifier #####\n",
      "Error (LabelPropagation-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### LabelPropagation - RandomForestClassifier #####\n",
      "Train ACC: 99.714%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  9  1  0  0]\n",
      " [ 9 43  7  2  1]\n",
      " [ 6 18 28 13  1]\n",
      " [ 0  3  5 42  5]\n",
      " [ 0  2  2 17 44]]\n",
      "##### LabelPropagation - RidgeClassifier #####\n",
      "Train ACC: 75.107%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[33 14  4  1  0]\n",
      " [ 9 38 11  2  2]\n",
      " [ 5 20 24 17  0]\n",
      " [ 2  1 10 34  8]\n",
      " [ 1  0  5 16 43]]\n",
      "##### LabelPropagation - RidgeClassifierCV #####\n",
      "Train ACC: 74.535%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[34 13  4  1  0]\n",
      " [11 36 11  2  2]\n",
      " [ 6 20 23 17  0]\n",
      " [ 0  3  8 35  9]\n",
      " [ 0  1  4 17 43]]\n",
      "##### LabelPropagation - SGDClassifier #####\n",
      "Train ACC: 53.076%\n",
      "Test ACC: 38.333%\n",
      "Confusion Matrix Test:\n",
      "[[19 15  3  7  8]\n",
      " [ 3 20  9 24  6]\n",
      " [ 1  8  6 30 21]\n",
      " [ 0  2  5 12 36]\n",
      " [ 0  1  2  4 58]]\n",
      "##### LabelPropagation - SVC #####\n",
      "Train ACC: 80.258%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  9  2  1  0]\n",
      " [ 9 41  9  1  2]\n",
      " [ 3 13 38 12  0]\n",
      " [ 0  3  6 37  9]\n",
      " [ 1  0  3 19 42]]\n",
      "##### LabelSpreading - LinearDiscriminantAnalysis #####\n",
      "Train ACC: 71.531%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[33 13  4  2  0]\n",
      " [ 9 37 12  2  2]\n",
      " [ 4 17 31 14  0]\n",
      " [ 1  2  8 37  7]\n",
      " [ 0  1  5 14 45]]\n",
      "##### LabelSpreading - LinearSVC #####\n",
      "Train ACC: 73.104%\n",
      "Test ACC: 58.667%\n",
      "Confusion Matrix Test:\n",
      "[[32 14  4  2  0]\n",
      " [ 9 37 12  2  2]\n",
      " [ 4 18 27 17  0]\n",
      " [ 2  1 10 35  7]\n",
      " [ 0  1  6 13 45]]\n",
      "##### LabelSpreading - LogisticRegression #####\n",
      "Train ACC: 72.389%\n",
      "Test ACC: 59.000%\n",
      "Confusion Matrix Test:\n",
      "[[30 15  6  1  0]\n",
      " [ 8 38 12  2  2]\n",
      " [ 2 18 31 15  0]\n",
      " [ 0  3  8 34 10]\n",
      " [ 0  1  6 14 44]]\n",
      "##### LabelSpreading - LogisticRegressionCV #####\n",
      "Train ACC: 72.818%\n",
      "Test ACC: 59.000%\n",
      "Confusion Matrix Test:\n",
      "[[30 14  7  1  0]\n",
      " [ 9 37 12  2  2]\n",
      " [ 2 18 31 15  0]\n",
      " [ 0  3  7 35 10]\n",
      " [ 0  1  5 15 44]]\n",
      "##### LabelSpreading - MLPClassifier #####\n",
      "Train ACC: 77.539%\n",
      "Test ACC: 69.333%\n",
      "Confusion Matrix Test:\n",
      "[[37 10  5  0  0]\n",
      " [ 7 44  8  3  0]\n",
      " [ 2 12 39 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  1  1 13 49]]\n",
      "##### LabelSpreading - MultinomialNB #####\n",
      "Error (LabelSpreading-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### LabelSpreading - NearestCentroid #####\n",
      "Train ACC: 78.684%\n",
      "Test ACC: 52.000%\n",
      "Confusion Matrix Test:\n",
      "[[35 11  3  3  0]\n",
      " [11 33 13  4  1]\n",
      " [ 4 25 15 16  6]\n",
      " [ 0  5 10 27 13]\n",
      " [ 0  2  4 13 46]]\n",
      "##### LabelSpreading - NuSVC #####\n",
      "Train ACC: 77.539%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[38  9  4  1  0]\n",
      " [11 37 12  1  1]\n",
      " [ 2 12 41 11  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  1 16 47]]\n",
      "##### LabelSpreading - PassiveAggressiveClassifier #####\n",
      "Train ACC: 68.670%\n",
      "Test ACC: 51.333%\n",
      "Confusion Matrix Test:\n",
      "[[30 14  6  2  0]\n",
      " [ 7 22 22  9  2]\n",
      " [ 4  6 16 36  4]\n",
      " [ 1  1  3 29 21]\n",
      " [ 0  2  1  5 57]]\n",
      "##### LabelSpreading - Perceptron #####\n",
      "Train ACC: 56.223%\n",
      "Test ACC: 44.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  4  4  2]\n",
      " [10 10 28  9  5]\n",
      " [ 7  3  8 30 18]\n",
      " [ 1  0  3 27 24]\n",
      " [ 1  0  2  9 53]]\n",
      "##### LabelSpreading - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 74.392%\n",
      "Test ACC: 62.667%\n",
      "Confusion Matrix Test:\n",
      "[[35 14  3  0  0]\n",
      " [ 9 41  9  3  0]\n",
      " [ 2 17 31 16  0]\n",
      " [ 1  3  4 38  9]\n",
      " [ 0  2  2 18 43]]\n",
      "##### LabelSpreading - RadiusNeighborsClassifier #####\n",
      "Error (LabelSpreading-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### LabelSpreading - RandomForestClassifier #####\n",
      "Train ACC: 98.426%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[41 11  0  0  0]\n",
      " [11 41  7  1  2]\n",
      " [ 4 19 27 15  1]\n",
      " [ 0  3  5 42  5]\n",
      " [ 1  2  2 19 41]]\n",
      "##### LabelSpreading - RidgeClassifier #####\n",
      "Train ACC: 74.249%\n",
      "Test ACC: 58.667%\n",
      "Confusion Matrix Test:\n",
      "[[33 14  4  1  0]\n",
      " [ 9 39 10  2  2]\n",
      " [ 5 19 25 17  0]\n",
      " [ 2  1  9 35  8]\n",
      " [ 1  0  4 16 44]]\n",
      "##### LabelSpreading - RidgeClassifierCV #####\n",
      "Train ACC: 73.963%\n",
      "Test ACC: 58.000%\n",
      "Confusion Matrix Test:\n",
      "[[33 14  4  1  0]\n",
      " [10 38 10  2  2]\n",
      " [ 5 20 24 17  0]\n",
      " [ 3  0  8 36  8]\n",
      " [ 1  0  4 17 43]]\n",
      "##### LabelSpreading - SGDClassifier #####\n",
      "Train ACC: 71.817%\n",
      "Test ACC: 51.333%\n",
      "Confusion Matrix Test:\n",
      "[[34 10  6  2  0]\n",
      " [ 7 21 22 10  2]\n",
      " [ 5  7 23 28  3]\n",
      " [ 1  2  9 28 15]\n",
      " [ 0  2  2 13 48]]\n",
      "##### LabelSpreading - SVC #####\n",
      "Train ACC: 79.399%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  9  3  1  0]\n",
      " [ 6 43 10  1  2]\n",
      " [ 3 14 36 13  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 1  0  3 19 42]]\n",
      "##### LinearDiscriminantAnalysis - LinearSVC #####\n",
      "Train ACC: 64.807%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  6  9  2  0]\n",
      " [12 30 16  2  2]\n",
      " [ 2 14 35 15  0]\n",
      " [ 1  2 10 35  7]\n",
      " [ 0  2  5 14 44]]\n",
      "##### LinearDiscriminantAnalysis - LogisticRegression #####\n",
      "Train ACC: 65.665%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  8  7  2  0]\n",
      " [13 31 14  2  2]\n",
      " [ 2 14 35 15  0]\n",
      " [ 1  2  6 37  9]\n",
      " [ 0  2  4 17 42]]\n",
      "##### LinearDiscriminantAnalysis - LogisticRegressionCV #####\n",
      "Train ACC: 65.379%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [13 31 14  2  2]\n",
      " [ 2 15 34 15  0]\n",
      " [ 1  2  6 37  9]\n",
      " [ 0  2  4 17 42]]\n",
      "##### LinearDiscriminantAnalysis - MLPClassifier #####\n",
      "Train ACC: 74.964%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[39  6  6  1  0]\n",
      " [11 38 10  3  0]\n",
      " [ 2 14 36 14  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 1  0  2 16 46]]\n",
      "##### LinearDiscriminantAnalysis - MultinomialNB #####\n",
      "Error (LinearDiscriminantAnalysis-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### LinearDiscriminantAnalysis - NearestCentroid #####\n",
      "Train ACC: 63.662%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [13 28 18  1  2]\n",
      " [ 3 16 35 12  0]\n",
      " [ 2  2  5 37  9]\n",
      " [ 1  1  4 13 46]]\n",
      "##### LinearDiscriminantAnalysis - NuSVC #####\n",
      "Train ACC: 76.395%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  2  1  0]\n",
      " [12 38 10  1  1]\n",
      " [ 2 17 35 12  0]\n",
      " [ 0  3  6 37  9]\n",
      " [ 1  0  3 15 46]]\n",
      "##### LinearDiscriminantAnalysis - PassiveAggressiveClassifier #####\n",
      "Train ACC: 58.226%\n",
      "Test ACC: 52.667%\n",
      "Confusion Matrix Test:\n",
      "[[32  6 10  4  0]\n",
      " [ 8 27 16  9  2]\n",
      " [ 2  8 16 39  1]\n",
      " [ 1  2  1 38 13]\n",
      " [ 1  1  2 16 45]]\n",
      "##### LinearDiscriminantAnalysis - Perceptron #####\n",
      "Train ACC: 61.230%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[34  7  8  2  1]\n",
      " [15 22 20  3  2]\n",
      " [ 4  6 31 24  1]\n",
      " [ 2  1  3 37 12]\n",
      " [ 0  2  1 15 47]]\n",
      "##### LinearDiscriminantAnalysis - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 69.957%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  8  7  1  0]\n",
      " [10 36 14  2  0]\n",
      " [ 2 16 34 14  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 0  1  3 19 42]]\n",
      "##### LinearDiscriminantAnalysis - RadiusNeighborsClassifier #####\n",
      "Error (LinearDiscriminantAnalysis-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### LinearDiscriminantAnalysis - RandomForestClassifier #####\n",
      "Train ACC: 86.266%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  6  6  1  0]\n",
      " [11 36 12  1  2]\n",
      " [ 1 16 35 14  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 0  1  2 17 45]]\n",
      "##### LinearDiscriminantAnalysis - RidgeClassifier #####\n",
      "Train ACC: 64.807%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  2  0]\n",
      " [13 31 14  2  2]\n",
      " [ 2 15 33 16  0]\n",
      " [ 1  2  8 37  7]\n",
      " [ 0  2  5 14 44]]\n",
      "##### LinearDiscriminantAnalysis - RidgeClassifierCV #####\n",
      "Train ACC: 65.093%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [12 32 14  2  2]\n",
      " [ 2 16 32 16  0]\n",
      " [ 1  2  7 37  8]\n",
      " [ 0  2  5 14 44]]\n",
      "##### LinearDiscriminantAnalysis - SGDClassifier #####\n",
      "Train ACC: 60.372%\n",
      "Test ACC: 54.667%\n",
      "Confusion Matrix Test:\n",
      "[[32  6 11  3  0]\n",
      " [10 19 24  7  2]\n",
      " [ 1  6 31 28  0]\n",
      " [ 1  2  4 43  5]\n",
      " [ 0  1  3 22 39]]\n",
      "##### LinearDiscriminantAnalysis - SVC #####\n",
      "Train ACC: 70.100%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[43  5  3  1  0]\n",
      " [10 40  9  1  2]\n",
      " [ 2 14 34 16  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 1  0  3 16 45]]\n",
      "##### LinearSVC - LogisticRegression #####\n",
      "Train ACC: 65.665%\n",
      "Test ACC: 60.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  2  0]\n",
      " [10 35 13  2  2]\n",
      " [ 2 15 34 15  0]\n",
      " [ 1  2  7 36  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### LinearSVC - LogisticRegressionCV #####\n",
      "Train ACC: 65.236%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  2  0]\n",
      " [11 34 13  2  2]\n",
      " [ 2 15 34 15  0]\n",
      " [ 1  2  7 36  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### LinearSVC - MLPClassifier #####\n",
      "Train ACC: 75.107%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  6  7  0  0]\n",
      " [ 9 40 11  2  0]\n",
      " [ 2 15 35 14  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 1  0  3 19 42]]\n",
      "##### LinearSVC - MultinomialNB #####\n",
      "Error (LinearSVC-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### LinearSVC - NearestCentroid #####\n",
      "Train ACC: 64.521%\n",
      "Test ACC: 56.667%\n",
      "Confusion Matrix Test:\n",
      "[[34  8  8  2  0]\n",
      " [14 27 17  2  2]\n",
      " [ 3 16 32 14  1]\n",
      " [ 2  2  7 34 10]\n",
      " [ 1  1  4 16 43]]\n",
      "##### LinearSVC - NuSVC #####\n",
      "Train ACC: 75.536%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  2  1  0]\n",
      " [11 39 10  2  0]\n",
      " [ 2 15 37 12  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 1  0  3 15 46]]\n",
      "##### LinearSVC - PassiveAggressiveClassifier #####\n",
      "Train ACC: 62.661%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  3 12  2  0]\n",
      " [12 24 21  3  2]\n",
      " [ 2 11 34 18  1]\n",
      " [ 1  2  7 35 10]\n",
      " [ 0  1  5 14 45]]\n",
      "##### LinearSVC - Perceptron #####\n",
      "Train ACC: 58.369%\n",
      "Test ACC: 52.667%\n",
      "Confusion Matrix Test:\n",
      "[[38  4  8  2  0]\n",
      " [32  9 16  3  2]\n",
      " [ 5  9 30 21  1]\n",
      " [ 2  1  4 35 13]\n",
      " [ 0  2  2 15 46]]\n",
      "##### LinearSVC - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 69.242%\n",
      "Test ACC: 62.000%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  8  1  0]\n",
      " [ 8 37 13  2  2]\n",
      " [ 2 17 32 15  0]\n",
      " [ 0  3  7 37  8]\n",
      " [ 0  1  5 16 43]]\n",
      "##### LinearSVC - RadiusNeighborsClassifier #####\n",
      "Error (LinearSVC-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### LinearSVC - RandomForestClassifier #####\n",
      "Train ACC: 83.977%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[38  7  6  0  1]\n",
      " [ 9 39 11  1  2]\n",
      " [ 2 16 33 15  0]\n",
      " [ 1  2  6 38  8]\n",
      " [ 0  1  3 18 43]]\n",
      "##### LinearSVC - RidgeClassifier #####\n",
      "Train ACC: 64.664%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  5  9  1  1]\n",
      " [13 29 16  2  2]\n",
      " [ 2 15 32 16  1]\n",
      " [ 2  1 10 32 10]\n",
      " [ 0  2  5 14 44]]\n",
      "##### LinearSVC - RidgeClassifierCV #####\n",
      "Train ACC: 64.664%\n",
      "Test ACC: 57.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  5  9  1  1]\n",
      " [13 29 16  2  2]\n",
      " [ 2 15 32 16  1]\n",
      " [ 2  1 10 32 10]\n",
      " [ 0  2  5 14 44]]\n",
      "##### LinearSVC - SGDClassifier #####\n",
      "Train ACC: 60.229%\n",
      "Test ACC: 52.667%\n",
      "Confusion Matrix Test:\n",
      "[[39  3 10  0  0]\n",
      " [27 14 18  1  2]\n",
      " [ 3 13 42  8  0]\n",
      " [ 3  0 15 30  7]\n",
      " [ 1  1  7 23 33]]\n",
      "##### LinearSVC - SVC #####\n",
      "Train ACC: 70.815%\n",
      "Test ACC: 65.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [ 8 42  9  1  2]\n",
      " [ 2 16 33 15  0]\n",
      " [ 0  2  7 39  7]\n",
      " [ 1  0  3 20 41]]\n",
      "##### LogisticRegression - LogisticRegressionCV #####\n",
      "Train ACC: 66.381%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  9  1  0]\n",
      " [12 32 14  2  2]\n",
      " [ 1 17 34 14  0]\n",
      " [ 1  3  5 37  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### LogisticRegression - MLPClassifier #####\n",
      "Train ACC: 76.967%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  4  6  1  0]\n",
      " [ 9 40 10  3  0]\n",
      " [ 1 17 35 13  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 1  0  3 15 46]]\n",
      "##### LogisticRegression - MultinomialNB #####\n",
      "Error (LogisticRegression-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### LogisticRegression - NearestCentroid #####\n",
      "Train ACC: 66.094%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[34  8  8  2  0]\n",
      " [12 32 14  2  2]\n",
      " [ 2 16 35 13  0]\n",
      " [ 2  2  5 37  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### LogisticRegression - NuSVC #####\n",
      "Train ACC: 75.680%\n",
      "Test ACC: 64.667%\n",
      "Confusion Matrix Test:\n",
      "[[39  9  3  1  0]\n",
      " [13 36 11  0  2]\n",
      " [ 1 17 37 11  0]\n",
      " [ 0  3  6 37  9]\n",
      " [ 1  0  3 16 45]]\n",
      "##### LogisticRegression - PassiveAggressiveClassifier #####\n",
      "Train ACC: 59.943%\n",
      "Test ACC: 58.000%\n",
      "Confusion Matrix Test:\n",
      "[[27 13 10  2  0]\n",
      " [ 5 37 13  5  2]\n",
      " [ 1 13 25 27  0]\n",
      " [ 0  3  3 39 10]\n",
      " [ 0  1  2 16 46]]\n",
      "##### LogisticRegression - Perceptron #####\n",
      "Train ACC: 62.232%\n",
      "Test ACC: 57.333%\n",
      "Confusion Matrix Test:\n",
      "[[33  8  9  1  1]\n",
      " [12 25 19  4  2]\n",
      " [ 3  8 31 23  1]\n",
      " [ 2  1  2 36 14]\n",
      " [ 0  1  3 14 47]]\n",
      "##### LogisticRegression - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 69.814%\n",
      "Test ACC: 61.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  8  7  1  0]\n",
      " [10 36 13  2  1]\n",
      " [ 2 17 32 15  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 0  1  3 18 43]]\n",
      "##### LogisticRegression - RadiusNeighborsClassifier #####\n",
      "Error (LogisticRegression-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### LogisticRegression - RandomForestClassifier #####\n",
      "Train ACC: 86.981%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [ 9 38 12  1  2]\n",
      " [ 2 15 38 11  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 0  1  2 18 44]]\n",
      "##### LogisticRegression - RidgeClassifier #####\n",
      "Train ACC: 65.808%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [12 33 13  2  2]\n",
      " [ 2 14 34 16  0]\n",
      " [ 1  2  7 36  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### LogisticRegression - RidgeClassifierCV #####\n",
      "Train ACC: 64.807%\n",
      "Test ACC: 61.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  8  2  0]\n",
      " [ 9 36 13  2  2]\n",
      " [ 2 14 34 16  0]\n",
      " [ 1  3  6 36  9]\n",
      " [ 0  2  4 17 42]]\n",
      "##### LogisticRegression - SGDClassifier #####\n",
      "Train ACC: 64.378%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[34  9  8  1  0]\n",
      " [12 36 10  2  2]\n",
      " [ 2 18 35 11  0]\n",
      " [ 1  3 10 36  5]\n",
      " [ 0  2  4 21 38]]\n",
      "##### LogisticRegression - SVC #####\n",
      "Train ACC: 70.672%\n",
      "Test ACC: 64.667%\n",
      "Confusion Matrix Test:\n",
      "[[43  5  3  1  0]\n",
      " [11 39  9  1  2]\n",
      " [ 3 13 34 16  0]\n",
      " [ 0  3  7 35 10]\n",
      " [ 1  0  3 18 43]]\n",
      "##### LogisticRegressionCV - MLPClassifier #####\n",
      "Train ACC: 75.536%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [ 7 41 11  3  0]\n",
      " [ 1 16 36 13  0]\n",
      " [ 0  3  7 36  9]\n",
      " [ 0  1  3 17 44]]\n",
      "##### LogisticRegressionCV - MultinomialNB #####\n",
      "Error (LogisticRegressionCV-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### LogisticRegressionCV - NearestCentroid #####\n",
      "Train ACC: 65.951%\n",
      "Test ACC: 59.333%\n",
      "Confusion Matrix Test:\n",
      "[[34  8  8  2  0]\n",
      " [13 31 14  2  2]\n",
      " [ 1 17 35 13  0]\n",
      " [ 2  2  5 37  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### LogisticRegressionCV - NuSVC #####\n",
      "Train ACC: 75.250%\n",
      "Test ACC: 64.667%\n",
      "Confusion Matrix Test:\n",
      "[[39  9  3  1  0]\n",
      " [13 36 11  1  1]\n",
      " [ 1 17 37 11  0]\n",
      " [ 0  3  6 37  9]\n",
      " [ 1  0  3 16 45]]\n",
      "##### LogisticRegressionCV - PassiveAggressiveClassifier #####\n",
      "Train ACC: 61.660%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[31  8 12  1  0]\n",
      " [10 24 24  2  2]\n",
      " [ 2  6 45 13  0]\n",
      " [ 1  2  7 34 11]\n",
      " [ 0  1  5 13 46]]\n",
      "##### LogisticRegressionCV - Perceptron #####\n",
      "Train ACC: 62.518%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[34  7  9  1  1]\n",
      " [15 23 20  2  2]\n",
      " [ 3  9 31 22  1]\n",
      " [ 2  1  2 36 14]\n",
      " [ 0  2  2 14 47]]\n",
      "##### LogisticRegressionCV - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 69.957%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  8  7  1  0]\n",
      " [10 36 13  2  1]\n",
      " [ 2 16 33 15  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 0  1  4 17 43]]\n",
      "##### LogisticRegressionCV - RadiusNeighborsClassifier #####\n",
      "Error (LogisticRegressionCV-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### LogisticRegressionCV - RandomForestClassifier #####\n",
      "Train ACC: 82.833%\n",
      "Test ACC: 64.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  7  8  1  0]\n",
      " [ 7 40 12  1  2]\n",
      " [ 2 16 35 13  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 0  1  3 17 44]]\n",
      "##### LogisticRegressionCV - RidgeClassifier #####\n",
      "Train ACC: 65.808%\n",
      "Test ACC: 60.000%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  9  1  0]\n",
      " [12 33 13  2  2]\n",
      " [ 2 14 35 15  0]\n",
      " [ 1  2  7 36  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### LogisticRegressionCV - RidgeClassifierCV #####\n",
      "Train ACC: 64.950%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[35  7  9  1  0]\n",
      " [12 33 13  2  2]\n",
      " [ 2 14 34 16  0]\n",
      " [ 1  2  7 36  9]\n",
      " [ 0  2  4 18 41]]\n",
      "##### LogisticRegressionCV - SGDClassifier #####\n",
      "Train ACC: 59.084%\n",
      "Test ACC: 55.333%\n",
      "Confusion Matrix Test:\n",
      "[[31  7 10  2  2]\n",
      " [ 8 25 22  3  4]\n",
      " [ 1  8 33 15  9]\n",
      " [ 0  3  6 30 16]\n",
      " [ 0  1  6 11 47]]\n",
      "##### LogisticRegressionCV - SVC #####\n",
      "Train ACC: 71.388%\n",
      "Test ACC: 63.667%\n",
      "Confusion Matrix Test:\n",
      "[[43  5  3  1  0]\n",
      " [13 36 10  1  2]\n",
      " [ 3 13 34 16  0]\n",
      " [ 0  3  7 35 10]\n",
      " [ 1  0  3 18 43]]\n",
      "##### MLPClassifier - MultinomialNB #####\n",
      "Error (MLPClassifier-MultinomialNB): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MLPClassifier - NearestCentroid #####\n",
      "Train ACC: 79.113%\n",
      "Test ACC: 68.667%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [ 7 42 10  3  0]\n",
      " [ 2 16 37 11  0]\n",
      " [ 0  3  5 40  7]\n",
      " [ 1  1  2 15 46]]\n",
      "##### MLPClassifier - NuSVC #####\n",
      "Train ACC: 78.112%\n",
      "Test ACC: 68.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  9  3  1  0]\n",
      " [11 39 10  2  0]\n",
      " [ 2 11 41 12  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 0  1  3 13 48]]\n",
      "##### MLPClassifier - PassiveAggressiveClassifier #####\n",
      "Train ACC: 74.392%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  5  5  1  0]\n",
      " [ 6 42 11  3  0]\n",
      " [ 1 17 28 20  0]\n",
      " [ 0  3  5 40  7]\n",
      " [ 1  1  1 15 47]]\n",
      "##### MLPClassifier - Perceptron #####\n",
      "Train ACC: 75.966%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  3  6  1  0]\n",
      " [15 32 12  3  0]\n",
      " [ 2 11 36 17  0]\n",
      " [ 0  3  3 39 10]\n",
      " [ 0  2  1 13 49]]\n",
      "##### MLPClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 76.252%\n",
      "Test ACC: 68.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  6  7  0  0]\n",
      " [ 8 43 10  1  0]\n",
      " [ 1 14 39 12  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 0  2  1 16 46]]\n",
      "##### MLPClassifier - RadiusNeighborsClassifier #####\n",
      "Error (MLPClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### MLPClassifier - RandomForestClassifier #####\n",
      "Train ACC: 87.268%\n",
      "Test ACC: 71.667%\n",
      "Confusion Matrix Test:\n",
      "[[42  5  5  0  0]\n",
      " [ 5 45 10  2  0]\n",
      " [ 1 16 39 10  0]\n",
      " [ 0  3  6 41  5]\n",
      " [ 0  1  2 14 48]]\n",
      "##### MLPClassifier - RidgeClassifier #####\n",
      "Train ACC: 75.680%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  6  7  0  0]\n",
      " [ 7 41 12  2  0]\n",
      " [ 2 16 33 15  0]\n",
      " [ 0  3  7 36  9]\n",
      " [ 0  2  1 16 46]]\n",
      "##### MLPClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 76.252%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  5  5  0  0]\n",
      " [ 7 41 12  2  0]\n",
      " [ 1 16 34 15  0]\n",
      " [ 0  3  8 36  8]\n",
      " [ 1  1  1 16 46]]\n",
      "##### MLPClassifier - SGDClassifier #####\n",
      "Train ACC: 76.824%\n",
      "Test ACC: 69.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  7  5  1  0]\n",
      " [ 8 43  8  3  0]\n",
      " [ 2 12 40 12  0]\n",
      " [ 1  2  6 41  5]\n",
      " [ 1  1  1 18 44]]\n",
      "##### MLPClassifier - SVC #####\n",
      "Train ACC: 74.821%\n",
      "Test ACC: 68.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  7  2  1  0]\n",
      " [ 8 43  8  2  1]\n",
      " [ 2 15 36 13  0]\n",
      " [ 0  3  5 38  9]\n",
      " [ 1  0  3 16 45]]\n",
      "##### MultinomialNB - NearestCentroid #####\n",
      "Error (MultinomialNB-NearestCentroid): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - NuSVC #####\n",
      "Error (MultinomialNB-NuSVC): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - PassiveAggressiveClassifier #####\n",
      "Error (MultinomialNB-PassiveAggressiveClassifier): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - Perceptron #####\n",
      "Error (MultinomialNB-Perceptron): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - QuadraticDiscriminantAnalysis #####\n",
      "Error (MultinomialNB-QuadraticDiscriminantAnalysis): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - RadiusNeighborsClassifier #####\n",
      "Error (MultinomialNB-RadiusNeighborsClassifier): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - RandomForestClassifier #####\n",
      "Error (MultinomialNB-RandomForestClassifier): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - RidgeClassifier #####\n",
      "Error (MultinomialNB-RidgeClassifier): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - RidgeClassifierCV #####\n",
      "Error (MultinomialNB-RidgeClassifierCV): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - SGDClassifier #####\n",
      "Error (MultinomialNB-SGDClassifier): Negative values in data passed to MultinomialNB (input X)\n",
      "##### MultinomialNB - SVC #####\n",
      "Error (MultinomialNB-SVC): Negative values in data passed to MultinomialNB (input X)\n",
      "##### NearestCentroid - NuSVC #####\n",
      "Train ACC: 76.252%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[40  8  3  1  0]\n",
      " [16 33 11  1  1]\n",
      " [ 2 13 39 12  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 16 46]]\n",
      "##### NearestCentroid - PassiveAggressiveClassifier #####\n",
      "Train ACC: 53.076%\n",
      "Test ACC: 46.000%\n",
      "Confusion Matrix Test:\n",
      "[[30 12  9  1  0]\n",
      " [12 35 12  3  0]\n",
      " [ 3 35 23  5  0]\n",
      " [ 1  8 19 22  5]\n",
      " [ 1  1  9 26 28]]\n",
      "##### NearestCentroid - Perceptron #####\n",
      "Train ACC: 46.781%\n",
      "Test ACC: 45.333%\n",
      "Confusion Matrix Test:\n",
      "[[28  6 14  3  1]\n",
      " [ 7 16 27  8  4]\n",
      " [ 5  4 15 29 13]\n",
      " [ 2  0  3 24 26]\n",
      " [ 1  1  1  9 53]]\n",
      "##### NearestCentroid - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 70.243%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  8  7  1  0]\n",
      " [ 9 36 14  3  0]\n",
      " [ 2 18 31 15  0]\n",
      " [ 0  4  5 39  7]\n",
      " [ 0  1  3 16 45]]\n",
      "##### NearestCentroid - RadiusNeighborsClassifier #####\n",
      "Error (NearestCentroid-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### NearestCentroid - RandomForestClassifier #####\n",
      "Train ACC: 94.850%\n",
      "Test ACC: 64.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  6  3  0  1]\n",
      " [11 36 11  2  2]\n",
      " [ 3 19 30 12  2]\n",
      " [ 0  2 10 39  4]\n",
      " [ 0  1  5 14 45]]\n",
      "##### NearestCentroid - RidgeClassifier #####\n",
      "Train ACC: 63.948%\n",
      "Test ACC: 56.333%\n",
      "Confusion Matrix Test:\n",
      "[[36  5  9  2  0]\n",
      " [16 26 16  2  2]\n",
      " [ 3 21 26 15  1]\n",
      " [ 2  2  6 35 10]\n",
      " [ 1  1  4 13 46]]\n",
      "##### NearestCentroid - RidgeClassifierCV #####\n",
      "Train ACC: 64.378%\n",
      "Test ACC: 57.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  6  8  1  1]\n",
      " [15 27 16  2  2]\n",
      " [ 3 21 26 15  1]\n",
      " [ 2  2  6 35 10]\n",
      " [ 1  1  4 12 47]]\n",
      "##### NearestCentroid - SGDClassifier #####\n",
      "Train ACC: 47.210%\n",
      "Test ACC: 43.000%\n",
      "Confusion Matrix Test:\n",
      "[[17 18  6 11  0]\n",
      " [ 1 24 14 20  3]\n",
      " [ 3  7 10 42  4]\n",
      " [ 1  1  4 26 23]\n",
      " [ 1  1  1 10 52]]\n",
      "##### NearestCentroid - SVC #####\n",
      "Train ACC: 71.817%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[44  4  3  1  0]\n",
      " [11 38 10  1  2]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  3 21 40]]\n",
      "##### NuSVC - PassiveAggressiveClassifier #####\n",
      "Train ACC: 68.670%\n",
      "Test ACC: 58.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  8  3  2  0]\n",
      " [17 26 12  7  0]\n",
      " [ 2  8 25 31  0]\n",
      " [ 0  3  4 41  7]\n",
      " [ 1  0  0 20 44]]\n",
      "##### NuSVC - Perceptron #####\n",
      "Train ACC: 72.818%\n",
      "Test ACC: 68.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  9  2  1  0]\n",
      " [12 37 11  1  1]\n",
      " [ 2 11 41 12  0]\n",
      " [ 0  3  6 32 14]\n",
      " [ 1  0  1  9 54]]\n",
      "##### NuSVC - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 76.967%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[38 11  2  1  0]\n",
      " [10 40 10  2  0]\n",
      " [ 2 12 38 14  0]\n",
      " [ 0  3  7 38  7]\n",
      " [ 1  0  2 14 48]]\n",
      "##### NuSVC - RadiusNeighborsClassifier #####\n",
      "Error (NuSVC-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### NuSVC - RandomForestClassifier #####\n",
      "Train ACC: 86.266%\n",
      "Test ACC: 68.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  9  3  1  0]\n",
      " [11 38 11  1  1]\n",
      " [ 2 12 40 12  0]\n",
      " [ 0  3  6 38  8]\n",
      " [ 1  0  1 14 49]]\n",
      "##### NuSVC - RidgeClassifier #####\n",
      "Train ACC: 75.680%\n",
      "Test ACC: 66.333%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  2  1  0]\n",
      " [11 39 10  2  0]\n",
      " [ 2 15 37 12  0]\n",
      " [ 0  3  7 38  7]\n",
      " [ 1  0  3 15 46]]\n",
      "##### NuSVC - RidgeClassifierCV #####\n",
      "Train ACC: 75.966%\n",
      "Test ACC: 65.667%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  2  1  0]\n",
      " [12 38 10  2  0]\n",
      " [ 2 16 36 12  0]\n",
      " [ 0  3  7 38  7]\n",
      " [ 1  0  3 15 46]]\n",
      "##### NuSVC - SGDClassifier #####\n",
      "Train ACC: 77.682%\n",
      "Test ACC: 66.667%\n",
      "Confusion Matrix Test:\n",
      "[[39 10  2  1  0]\n",
      " [11 37 12  1  1]\n",
      " [ 2 12 40 12  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  2 17 45]]\n",
      "##### NuSVC - SVC #####\n",
      "Train ACC: 75.393%\n",
      "Test ACC: 67.667%\n",
      "Confusion Matrix Test:\n",
      "[[43  6  2  1  0]\n",
      " [11 39 10  1  1]\n",
      " [ 2 14 38 12  0]\n",
      " [ 0  3  7 36  9]\n",
      " [ 1  0  2 15 47]]\n",
      "##### PassiveAggressiveClassifier - Perceptron #####\n",
      "Train ACC: 39.485%\n",
      "Test ACC: 38.667%\n",
      "Confusion Matrix Test:\n",
      "[[20  4 20  4  4]\n",
      " [ 3  4 36  5 14]\n",
      " [ 4  2 19 14 27]\n",
      " [ 1  1  2 22 29]\n",
      " [ 0  0  3 11 51]]\n",
      "##### PassiveAggressiveClassifier - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 66.810%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[34 13  5  0  0]\n",
      " [ 7 42 12  1  0]\n",
      " [ 1 21 36  8  0]\n",
      " [ 0  3 10 33  9]\n",
      " [ 0  2  6 13 44]]\n",
      "##### PassiveAggressiveClassifier - RadiusNeighborsClassifier #####\n",
      "Error (PassiveAggressiveClassifier-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### PassiveAggressiveClassifier - RandomForestClassifier #####\n",
      "Train ACC: 86.409%\n",
      "Test ACC: 61.667%\n",
      "Confusion Matrix Test:\n",
      "[[37 11  3  0  1]\n",
      " [ 6 47  6  1  2]\n",
      " [ 2 31 24  9  0]\n",
      " [ 1  7  3 41  3]\n",
      " [ 0  2  3 24 36]]\n",
      "##### PassiveAggressiveClassifier - RidgeClassifier #####\n",
      "Train ACC: 59.371%\n",
      "Test ACC: 54.333%\n",
      "Confusion Matrix Test:\n",
      "[[41  6  4  1  0]\n",
      " [26 26  6  2  2]\n",
      " [ 3 31 18 14  0]\n",
      " [ 2  3 10 30 10]\n",
      " [ 0  5  4  8 48]]\n",
      "##### PassiveAggressiveClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 61.230%\n",
      "Test ACC: 58.000%\n",
      "Confusion Matrix Test:\n",
      "[[36  4 11  1  0]\n",
      " [17 22 19  2  2]\n",
      " [ 5  9 39 12  1]\n",
      " [ 2  1 11 31 10]\n",
      " [ 1  1  4 13 46]]\n",
      "##### PassiveAggressiveClassifier - SGDClassifier #####\n",
      "Train ACC: 50.930%\n",
      "Test ACC: 44.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  4  4  1]\n",
      " [16  4 31 11  0]\n",
      " [ 2  3 29 31  1]\n",
      " [ 1  1  6 37 10]\n",
      " [ 0  1  7 30 27]]\n",
      "##### PassiveAggressiveClassifier - SVC #####\n",
      "Train ACC: 70.529%\n",
      "Test ACC: 63.000%\n",
      "Confusion Matrix Test:\n",
      "[[42  7  2  1  0]\n",
      " [10 39 10  2  1]\n",
      " [ 2 19 29 16  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  3 21 40]]\n",
      "##### Perceptron - QuadraticDiscriminantAnalysis #####\n",
      "Train ACC: 65.808%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  5  8  1  1]\n",
      " [ 8 35 13  6  0]\n",
      " [ 2  7 31 26  0]\n",
      " [ 0  3  2 37 13]\n",
      " [ 1  0  2 15 47]]\n",
      "##### Perceptron - RadiusNeighborsClassifier #####\n",
      "Error (Perceptron-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### Perceptron - RandomForestClassifier #####\n",
      "Train ACC: 86.123%\n",
      "Test ACC: 52.000%\n",
      "Confusion Matrix Test:\n",
      "[[38  4  2  7  1]\n",
      " [11 15 26  6  4]\n",
      " [ 3  5 17 36  5]\n",
      " [ 0  2  2 40 11]\n",
      " [ 1  0  1 17 46]]\n",
      "##### Perceptron - RidgeClassifier #####\n",
      "Train ACC: 54.649%\n",
      "Test ACC: 47.667%\n",
      "Confusion Matrix Test:\n",
      "[[36  5  7  3  1]\n",
      " [23 10 17  9  3]\n",
      " [ 4  5 16 36  5]\n",
      " [ 2  1  2 29 21]\n",
      " [ 1  1  1 10 52]]\n",
      "##### Perceptron - RidgeClassifierCV #####\n",
      "Train ACC: 52.933%\n",
      "Test ACC: 47.333%\n",
      "Confusion Matrix Test:\n",
      "[[35  6  7  3  1]\n",
      " [20 13 12 14  3]\n",
      " [ 4  5 13 37  7]\n",
      " [ 2  1  2 28 22]\n",
      " [ 1  1  1  9 53]]\n",
      "##### Perceptron - SGDClassifier #####\n",
      "Train ACC: 45.494%\n",
      "Test ACC: 42.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  3  8  0  2]\n",
      " [27  6 22  4  3]\n",
      " [10  5 22  1 28]\n",
      " [ 2  1  8  8 36]\n",
      " [ 1  1  4  7 52]]\n",
      "##### Perceptron - SVC #####\n",
      "Train ACC: 68.813%\n",
      "Test ACC: 67.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [ 5 45  9  1  2]\n",
      " [ 2 16 34 14  0]\n",
      " [ 0  3  5 31 16]\n",
      " [ 1  0  3 11 50]]\n",
      "##### QuadraticDiscriminantAnalysis - RadiusNeighborsClassifier #####\n",
      "Error (QuadraticDiscriminantAnalysis-RadiusNeighborsClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### QuadraticDiscriminantAnalysis - RandomForestClassifier #####\n",
      "Train ACC: 87.411%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[38 10  3  1  0]\n",
      " [ 8 43  9  1  1]\n",
      " [ 2 15 35 14  0]\n",
      " [ 0  3  5 39  8]\n",
      " [ 0  1  2 15 47]]\n",
      "##### QuadraticDiscriminantAnalysis - RidgeClassifier #####\n",
      "Train ACC: 69.242%\n",
      "Test ACC: 61.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  8  1  0]\n",
      " [ 9 38 12  2  1]\n",
      " [ 2 18 30 16  0]\n",
      " [ 0  3  7 38  7]\n",
      " [ 0  1  3 19 42]]\n",
      "##### QuadraticDiscriminantAnalysis - RidgeClassifierCV #####\n",
      "Train ACC: 69.814%\n",
      "Test ACC: 62.333%\n",
      "Confusion Matrix Test:\n",
      "[[37  6  8  1  0]\n",
      " [ 8 39 12  2  1]\n",
      " [ 2 17 31 16  0]\n",
      " [ 0  3  7 38  7]\n",
      " [ 0  1  3 19 42]]\n",
      "##### QuadraticDiscriminantAnalysis - SGDClassifier #####\n",
      "Train ACC: 66.524%\n",
      "Test ACC: 60.333%\n",
      "Confusion Matrix Test:\n",
      "[[39  8  3  2  0]\n",
      " [11 35 10  6  0]\n",
      " [ 2 14 24 26  0]\n",
      " [ 0  3  2 44  6]\n",
      " [ 0  1  3 22 39]]\n",
      "##### QuadraticDiscriminantAnalysis - SVC #####\n",
      "Train ACC: 73.104%\n",
      "Test ACC: 67.333%\n",
      "Confusion Matrix Test:\n",
      "[[42  7  2  1  0]\n",
      " [10 39 10  2  1]\n",
      " [ 2 14 36 14  0]\n",
      " [ 0  3  5 40  7]\n",
      " [ 1  0  3 16 45]]\n",
      "##### RadiusNeighborsClassifier - RandomForestClassifier #####\n",
      "Error (RadiusNeighborsClassifier-RandomForestClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### RadiusNeighborsClassifier - RidgeClassifier #####\n",
      "Error (RadiusNeighborsClassifier-RidgeClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### RadiusNeighborsClassifier - RidgeClassifierCV #####\n",
      "Error (RadiusNeighborsClassifier-RidgeClassifierCV): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### RadiusNeighborsClassifier - SGDClassifier #####\n",
      "Error (RadiusNeighborsClassifier-SGDClassifier): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### RadiusNeighborsClassifier - SVC #####\n",
      "Error (RadiusNeighborsClassifier-SVC): No neighbors found for test samples array([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "        31,  32,  34,  36,  37,  38,  39,  41,  42,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  68,  69,  72,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  87,  88,  90,  91,  92,  94,  95,  98,  99, 100,\n",
      "       101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "##### RandomForestClassifier - RidgeClassifier #####\n",
      "Train ACC: 88.555%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[39  7  5  0  1]\n",
      " [10 38 11  1  2]\n",
      " [ 3 15 34 14  0]\n",
      " [ 1  2  6 42  4]\n",
      " [ 0  1  3 19 42]]\n",
      "##### RandomForestClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 88.126%\n",
      "Test ACC: 65.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  6  5  0  1]\n",
      " [13 35 11  1  2]\n",
      " [ 1 17 35 13  0]\n",
      " [ 0  3  3 43  6]\n",
      " [ 0  1  5 17 42]]\n",
      "##### RandomForestClassifier - SGDClassifier #####\n",
      "Train ACC: 78.255%\n",
      "Test ACC: 46.333%\n",
      "Confusion Matrix Test:\n",
      "[[30  0  9 11  2]\n",
      " [ 3  8 30 16  5]\n",
      " [ 1  5 12 44  4]\n",
      " [ 0  2  1 37 15]\n",
      " [ 0  1  0 12 52]]\n",
      "##### RandomForestClassifier - SVC #####\n",
      "Train ACC: 83.834%\n",
      "Test ACC: 68.000%\n",
      "Confusion Matrix Test:\n",
      "[[43  5  3  1  0]\n",
      " [ 9 40 10  1  2]\n",
      " [ 2 14 37 13  0]\n",
      " [ 0  3  6 39  7]\n",
      " [ 1  0  3 16 45]]\n",
      "##### RidgeClassifier - RidgeClassifierCV #####\n",
      "Train ACC: 64.235%\n",
      "Test ACC: 59.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  5  8  1  1]\n",
      " [14 30 14  2  2]\n",
      " [ 2 16 31 16  1]\n",
      " [ 2  1  8 35  9]\n",
      " [ 0  2  5 12 46]]\n",
      "##### RidgeClassifier - SGDClassifier #####\n",
      "Train ACC: 59.657%\n",
      "Test ACC: 52.667%\n",
      "Confusion Matrix Test:\n",
      "[[37  9  6  0  0]\n",
      " [19 29 10  4  0]\n",
      " [ 4 22 29 11  0]\n",
      " [ 2  3 15 29  6]\n",
      " [ 1  2  5 23 34]]\n",
      "##### RidgeClassifier - SVC #####\n",
      "Train ACC: 70.529%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [ 8 42  9  2  1]\n",
      " [ 2 16 33 15  0]\n",
      " [ 0  2  7 39  7]\n",
      " [ 1  0  3 18 43]]\n",
      "##### RidgeClassifierCV - SGDClassifier #####\n",
      "Train ACC: 53.505%\n",
      "Test ACC: 51.000%\n",
      "Confusion Matrix Test:\n",
      "[[34  0 15  2  1]\n",
      " [15  3 36  5  3]\n",
      " [ 2  4 31 27  2]\n",
      " [ 2  0  3 34 16]\n",
      " [ 0  1  2 11 51]]\n",
      "##### RidgeClassifierCV - SVC #####\n",
      "Train ACC: 70.386%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[41  8  2  1  0]\n",
      " [ 8 42  9  2  1]\n",
      " [ 2 16 33 15  0]\n",
      " [ 0  2  8 39  6]\n",
      " [ 1  0  3 18 43]]\n",
      "##### SGDClassifier - SVC #####\n",
      "Train ACC: 72.389%\n",
      "Test ACC: 66.000%\n",
      "Confusion Matrix Test:\n",
      "[[40  9  2  1  0]\n",
      " [ 5 44 10  2  1]\n",
      " [ 2 14 36 14  0]\n",
      " [ 0  3  7 38  7]\n",
      " [ 1  0  3 21 40]]\n",
      "########## Best Estimator ##########\n",
      "['GradientBoostingClassifier-MLPClassifier', 72.0]\n",
      "Total time: 654.5964770317078\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimators_stacked_trained, best_stacked_estimator_name = run_sklearn_estimators_with_stacking(\n",
    "    all_estimators,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    model_type\n",
    ")\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b0d684-33bf-419b-b59d-4c171e29b1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;GradientBoostingClassifier&#x27;,\n",
       "                                GradientBoostingClassifier()),\n",
       "                               (&#x27;MLPClassifier&#x27;, MLPClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(estimators=[(&#x27;GradientBoostingClassifier&#x27;,\n",
       "                                GradientBoostingClassifier()),\n",
       "                               (&#x27;MLPClassifier&#x27;, MLPClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>GradientBoostingClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>MLPClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('GradientBoostingClassifier',\n",
       "                                GradientBoostingClassifier()),\n",
       "                               ('MLPClassifier', MLPClassifier())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_stacked_trained[best_stacked_estimator_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a42d4-3bad-4a1c-a8c9-dee86bc52bb5",
   "metadata": {},
   "source": [
    "### Save Estimator stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32120e1f-2db5-41c8-b53f-2dc4588c3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(estimators_trained[best_estimator_name], open('results/estimator_sklearn_stacked.sav', 'wb'))\n",
    "\n",
    "# Scaler\n",
    "pickle.dump(scaler, open('results/scaler.pkl','wb'))\n",
    "\n",
    "# Save columns names and informations\n",
    "data_to_save = {\n",
    "    'col_names_order': col_names_order,\n",
    "    'num_col_names': num_col_names,\n",
    "    'cat_col_names': cat_col_names,\n",
    "    'date_col_names': date_col_names,\n",
    "    'target_cols': target_cols,\n",
    "    'category_mappings': category_mappings,\n",
    "    'window_size': window_size\n",
    "}\n",
    "with open('results/columns_metadata_sklearn_stacked.json', 'w') as json_file:\n",
    "    json.dump(data_to_save, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538ba71-15e3-42db-a526-cb376135a073",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c843071-fc93-45c4-bca3-a1fd36a7fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43724cc0-8d03-4e8e-a4d4-4a0eefb8a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "loaded_estimator = pickle.load(open('results/estimator_sklearn_stacked.sav', 'rb'))\n",
    "# Scaler\n",
    "loaded_scaler = pickle.load(open('results/scaler.pkl','rb'))\n",
    "# columns_metadata\n",
    "columns_metadata = json.load(open('results/columns_metadata_sklearn_stacked.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1ef45e9-aa23-4ce3-819f-d6e4081582c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inference_data(new_input, columns_metadata, scaler=None):\n",
    "    \"\"\"\n",
    "    Preprocess the input data for inference based on metadata and scaler for numeric normalization.\n",
    "\n",
    "    Args:\n",
    "        new_input (list of list): Data to preprocess (each inner list is a row).\n",
    "        columns_metadata (dict): Metadata defining column names, types, mappings, and order.\n",
    "        scaler (StandardScaler): Trained scaler for numerical columns.\n",
    "    \n",
    "    Returns:\n",
    "        list: Preprocessed data ready for inference.\n",
    "    \"\"\"\n",
    "    # Exclude target columns from col_names_order for inference\n",
    "    target_cols = columns_metadata['target_cols']\n",
    "    col_names_order = [col for col in columns_metadata['col_names_order'] if col not in target_cols]\n",
    "    # Transform the new_input into a DataFrame with the correct column order\n",
    "    df_input = pd.DataFrame(new_input, columns=col_names_order)\n",
    "\n",
    "    # Convert categorical columns based on category_mappings\n",
    "    category_mappings = columns_metadata['category_mappings']\n",
    "    for col in columns_metadata['cat_col_names']:\n",
    "        if col in df_input.columns and col in category_mappings:\n",
    "            # Replace string categories with mapped integer IDs\n",
    "            df_input[col] = df_input[col].map(category_mappings[col])\n",
    "            if df_input[col].isnull().any():\n",
    "                raise ValueError(f'Invalid value found in column \"{col}\" that is not in the category mappings.')\n",
    "\n",
    "    # Normalize numeric columns using the trained scaler\n",
    "    num_col_names = columns_metadata['num_col_names']\n",
    "    if num_col_names and scaler:\n",
    "        df_input[num_col_names] = scaler.transform(df_input[num_col_names])\n",
    "\n",
    "    # Ensure date columns are in the correct datetime format\n",
    "    for col in columns_metadata['date_col_names']:\n",
    "        if col in df_input.columns:\n",
    "            df_input[col] = pd.to_datetime(df_input[col], errors='coerce')\n",
    "            if df_input[col].isnull().any():\n",
    "                raise ValueError(f'Invalid date value found in column \"{col}\".')\n",
    "\n",
    "    # Drop target columns if they exist in the input (not used in inference)\n",
    "    target_cols = columns_metadata['target_cols']\n",
    "    df_input = df_input.drop(columns=target_cols, errors='ignore')\n",
    "\n",
    "    # Convert DataFrame to list of rows for model inference\n",
    "    processed_data = df_input.values.tolist()\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "297367d2-2bb1-41be-a3bc-f05b8811222e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5559833789472926,\n",
       "  0.0,\n",
       "  0.3854693071666423,\n",
       "  -0.004474939005985804,\n",
       "  0.2437961469288683,\n",
       "  0.8188550306915209,\n",
       "  1.1,\n",
       "  0.028423686532250032]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = [\n",
    "    [66.770774, 'A', 129.519443, 157.649826, 6.255495, 0.828523, 1.10, 0.656228]  # target type_4\n",
    "]\n",
    "new_input_preprocessed = preprocess_inference_data(new_input, columns_metadata, loaded_scaler)\n",
    "new_input_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "67ea4253-eb24-4576-9654-954ee536bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = columns_metadata['target_cols'][0]\n",
    "clss_to_cat = {}\n",
    "if target in columns_metadata['category_mappings']:\n",
    "    for key, value in columns_metadata['category_mappings'][target].items():\n",
    "        clss_to_cat[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e1adcc30-d10d-42f6-b7a6-4332800409c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_4\n",
      "Total time: 0.0004429817199707031\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "result = loaded_estimator.predict(new_input_preprocessed)\n",
    "if clss_to_cat:\n",
    "    result = clss_to_cat[result[0]]\n",
    "print(result)\n",
    "print(f'Total time: {time.time() - tic}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
